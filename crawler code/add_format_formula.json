{
  "{\\displaystyle H[m]=\\sum _{i=1}^{N}\\sum _{j=1}^{N}\\Lambda (x_{i}-m_{j},m_{i}-m_{j},x_{i}-x_{j},i-j)} ( 1 )": {
    "before": "All the algorithms mentioned above have certain advantages and disadvantages in particular circumstances, yet, a surprisingly large number of these step detection algorithms are special cases of a more general algorithm.  This algorithm involves the minimization of a global functional: ",
    "after": "Here, x i for i = 1, ...., N is the discrete-time input signal of length N , and m i is the signal output from the algorithm. The goal is to minimize H [ m ] with respect to the output signal m . The form of the function {\\displaystyle \\scriptstyle \\Lambda } determines the particular algorithm. For example, choosing:",
    "url": "https://en.wikipedia.org/wiki/Step detection"
  },
  "{\\displaystyle \\Lambda ={\\frac {1}{2}}\\left|x_{i}-m_{j}\\right|^{2}I(i-j=0)+\\gamma \\left|m_{i}-m_{j}\\right|I(i-j=1)}": {
    "before": "Here, x i for i = 1, ...., N is the discrete-time input signal of length N , and m i is the signal output from the algorithm. The goal is to minimize H [ m ] with respect to the output signal m . The form of the function {\\displaystyle \\scriptstyle \\Lambda } determines the particular algorithm. For example, choosing:",
    "after": "where I ( S ) = 0 if the condition S is false, and one otherwise, obtains the total variation denoising algorithm with regularization parameter {\\displaystyle \\gamma } . Similarly:",
    "url": "https://en.wikipedia.org/wiki/Step detection"
  },
  "{\\displaystyle \\Lambda =\\min \\left\\{{\\frac {1}{2}}\\left|m_{i}-m_{j}\\right|^{2},W\\right\\}}": {
    "before": "where I ( S ) = 0 if the condition S is false, and one otherwise, obtains the total variation denoising algorithm with regularization parameter {\\displaystyle \\gamma } . Similarly:",
    "after": "leads to the mean shift algorithm, when using an adaptive step size Euler integrator initialized with the input signal x .  Here W > 0 is a parameter that determines the support of the mean shift kernel. Another example is:",
    "url": "https://en.wikipedia.org/wiki/Step detection"
  },
  "{\\displaystyle \\Lambda ={\\frac {1-\\exp(-\\beta |m_{i}-m_{j}|^{2}/2)}{\\beta }}\\cdot I(|i-j|\\leq W)}": {
    "before": "leads to the mean shift algorithm, when using an adaptive step size Euler integrator initialized with the input signal x .  Here W > 0 is a parameter that determines the support of the mean shift kernel. Another example is:",
    "after": "leading to the bilateral filter , where {\\displaystyle \\scriptstyle \\beta >0} is the tonal kernel parameter, and W is the spatial kernel support. Yet another special case is:",
    "url": "https://en.wikipedia.org/wiki/Step detection"
  },
  "{\\displaystyle \\Lambda ={\\frac {1}{2}}\\left|x_{i}-m_{j}\\right|^{2}I(i-j=0)+\\gamma \\left|m_{i}-m_{j}\\right|^{0}I(i-j=1)}": {
    "before": "leading to the bilateral filter , where {\\displaystyle \\scriptstyle \\beta >0} is the tonal kernel parameter, and W is the spatial kernel support. Yet another special case is:",
    "after": "specifying a group of algorithms that attempt to greedily fit 0-degree splines to the signal.   Here, {\\displaystyle \\scriptstyle \\left|x\\right|^{0}} is defined as zero if x = 0, and one otherwise.",
    "url": "https://en.wikipedia.org/wiki/Step detection"
  },
  "{\\displaystyle u^{*}=\\arg \\min _{u\\in \\mathbb {R} ^{N}}\\gamma \\|\\nabla u\\|_{0}+\\|u-x\\|_{p}^{p}}": {
    "before": "A classical variational method for step detection is the Potts model. It is given by the non-convex optimization problem",
    "after": "The term {\\displaystyle \\|\\nabla u\\|_{0}=\\#\\{i:u_{i}\\neq u_{i+1}\\}} penalizes the number of jumps and the term {\\displaystyle \\|u-x\\|_{p}^{p}=\\sum _{i=1}^{N}|u_{i}-x_{i}|^{p}} measures fidelity to data x . The parameter γ > 0 controls the tradeoff between regularity and data fidelity . Since the minimizer {\\displaystyle u^{*}} is piecewise constant the steps are given by the non-zero locations of the gradient {\\displaystyle \\nabla u^{*}} . For {\\displaystyle p=2} and {\\displaystyle p=1} there are fast algorithms which give an exact solution of the Potts problem in {\\displaystyle O(N^{2})} .    ",
    "url": "https://en.wikipedia.org/wiki/Step detection"
  },
  "{\\displaystyle SUE_{t}={\\frac {Q_{t}-E(Q_{t})}{\\sigma (Q_{t}-E(Q_{t}))}}}": {
    "before": "In accounting research , a measure that uses historical earnings is standardized unexpected earnings (SUE). SUE is the standardized difference between reported earnings and expected earnings, where expected earnings is modelled based on the assumption that earnings follows a seasonal random walk with a trend . In other words, in the case of quarterly earnings the SUE for quarter t is",
    "after": "where σ(X) is the standard deviation of X, and the expected earnings, E ( Q t ), is calculated using prior reported earnings:",
    "url": "https://en.wikipedia.org/wiki/Earnings surprise"
  },
  "{\\displaystyle E(Q_{t})=\\delta +Q_{t-4}}": {
    "before": "where σ(X) is the standard deviation of X, and the expected earnings, E ( Q t ), is calculated using prior reported earnings:",
    "after": "where Q t -4 is the reported earnings for quarter t -4 and δ is the average trend. ",
    "url": "https://en.wikipedia.org/wiki/Earnings surprise"
  },
  "{\\displaystyle SUE={\\frac {EPS-Forecast}{\\sigma (EPS-Forecast)}}}": {
    "before": "An alternative measure of SUE that uses analysts' forecasts is",
    "after": "where EPS is a firm's earnings per share , and Forecast is analysts' consensus forecast of its earnings per share. ",
    "url": "https://en.wikipedia.org/wiki/Earnings surprise"
  },
  "{\\displaystyle Y=a+bX}": {
    "before": "In the simplest case, where cost is linear in output, the equation for the total semi-variable cost is as follows: ",
    "after": "where {\\displaystyle Y} is the total cost, {\\displaystyle a} is the fixed cost, {\\displaystyle b} is the variable cost per unit, and {\\displaystyle X} is the number of units (i.e. the output produced).",
    "url": "https://en.wikipedia.org/wiki/Semi-variable cost"
  },
  "{\\displaystyle Y=a+bX=5,000+300*20=11,000}": {
    "before": "A factory costs £5000 per week to produce goods at a minimum level and due to high demand it has to produce for an extra 20 hours in the week. Including the wages, utility bills, raw materials etc. the extra cost per hour (the variable cost) is £300. In this example, the weekly fixed cost ( {\\displaystyle a} ) is £5000, the variable cost ( {\\displaystyle b} ) is £300 per hour, and the output ( {\\displaystyle X} ) is 20 hours. To find the total cost {\\displaystyle Y} , we calculate:",
    "after": "The total cost would be £11,000 to run the factory for this particular week.",
    "url": "https://en.wikipedia.org/wiki/Semi-variable cost"
  },
  "{\\displaystyle b=(Y_{1}-Y_{2})/(X_{1}-X_{2})}": {
    "before": "If the variable part of the cost is not linear, calculating an estimate can be more difficult. The high-low method is a relatively common method used by managers and accountants alike to estimate the variable costs as if they were linear. By identifying the time period where production is at its highest and its lowest, and inputting the figures into the high–low equation, we can separate out the variable and fixed costs. To find the variable cost {\\displaystyle b} per unit:  ",
    "after": "where {\\displaystyle Y_{1}} is the total variable cost at the high end of activity, {\\displaystyle Y_{2}} is the cost at the low end of activity, {\\displaystyle X_{1}} is the number of units at the high end, and {\\displaystyle X_{2}} is the number of units at the low end.",
    "url": "https://en.wikipedia.org/wiki/Semi-variable cost"
  },
  "DAC amortization rate = [present value of DAE + accumulated value of DAC]/[present value of estimated gross profits (EGPs) + accumulated value of actual gross profits (AGPs)]": {
    "before": "Also referred to as KDAC, the K-factor is basically the percentage of gross profits required to provide for deferred policy acquisition costs. KDAC is",
    "after": "The K-factor can change from year to year due to:",
    "url": "https://en.wikipedia.org/wiki/Deferred acquisition costs"
  },
  "TCE = total equity – intangible assets – goodwill – preferred stock[citation needed]": {
    "before": "Formula[edit]",
    "after": "TCE ratio = TCE / (total assets)[citation needed]",
    "url": "https://en.wikipedia.org/wiki/Tangible common equity"
  },
  "TCE ratio = TCE / (total assets)[citation needed]": {
    "before": "TCE = total equity – intangible assets – goodwill – preferred stock[citation needed]",
    "after": "Leverage ratio = (total assets – intangible assets – goodwill) / TCE[citation needed]",
    "url": "https://en.wikipedia.org/wiki/Tangible common equity"
  },
  "Leverage ratio = (total assets – intangible assets – goodwill) / TCE[citation needed]": {
    "before": "TCE ratio = TCE / (total assets)[citation needed]",
    "after": "Example[edit]",
    "url": "https://en.wikipedia.org/wiki/Tangible common equity"
  },
  "AR = IR × CR × DR [ clarification needed ]": {
    "before": "Inherent risk (IR) , the risk involved in the nature of business or transaction. Example, transactions involving exchange of cash may have higher IR than transactions involving settlement by cheques. The term inherent risk may have other definitions in other contexts.;  Control risk (CR), the risk that a misstatement may not be prevented or detected and corrected due to weakness in the entity's internal control mechanism. Example, control risk assessment may be higher in an entity where separation of duties is not well defined; and Detection risk (DR) , the probability that the auditing procedures may fail to detect existence of a material error or fraud. Detection risk may be due to sampling error or non-sampling error . Audit risk can be calculated as:",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Audit risk"
  },
  "{\\displaystyle FCFE=FCFF+Net\\ Borrowing-Interest*(1-t)}": {
    "before": "Basic formulae [ edit ]Assuming there is no preferred stock outstanding:",
    "after": "where:FCFF is the free cash flow to firm ; Net Borrowing is the difference between debt principals paid and raised; Interest*(1–t) is the firm's after-tax interest expense . ",
    "url": "https://en.wikipedia.org/wiki/Free cash flow to equity"
  },
  "{\\displaystyle FCFE=NI+D\\&A-Capex-\\Delta WC+Net\\ Borrowing}": {
    "before": "FCFF is the free cash flow to firm ; Net Borrowing is the difference between debt principals paid and raised; Interest*(1–t) is the firm's after-tax interest expense . or",
    "after": "or {\\displaystyle FCFE=NI-[(1-b)(Capex-D\\&A)+(1-b)(\\Delta WC)]}",
    "url": "https://en.wikipedia.org/wiki/Free cash flow to equity"
  },
  "{\\displaystyle FCFE=NI-[(1-b)(Capex-D\\&A)+(1-b)(\\Delta WC)]}": {
    "before": "{\\displaystyle FCFE=NI+D\\&A-Capex-\\Delta WC+Net\\ Borrowing} or",
    "after": "where:NI is the firm's net income ; D&A is the depreciation and amortisation; b is the debt ratio; Capex is the capital expenditure ; ΔWC is the change in working capital ; Net Borrowing is the difference between debt principals paid and raised; In this case, it is important not to include interest expense, as this is already figured into net income. ",
    "url": "https://en.wikipedia.org/wiki/Free cash flow to equity"
  },
  "{\\textstyle HHI^{*}={\\cfrac {\\left(HHI-{\\dfrac {1}{N}}\\right)}{1-{\\dfrac {1}{N}}}}}": {
    "before": "There is also a normalized Herfindahl index. Whereas the Herfindahl index ranges from 1/N to one, the normalized Herfindahl index ranges from 0 to 1. It is computed as:",
    "after": "for N > 1 and",
    "url": "https://en.wikipedia.org/wiki/Herfindahl–Hirschman index"
  },
  "{\\textstyle H={\\dfrac {1}{N}}={\\dfrac {1}{2}}=0.5}": {
    "before": "where again, N is the number of firms in the market, and H is the usual Herfindahl Index, as above. Using the normalized Herfindahl index, information about the total number of players (N) is lost, as shown in the following example: Assume a market with two players and equally distributed market share;",
    "after": "and",
    "url": "https://en.wikipedia.org/wiki/Herfindahl–Hirschman index"
  },
  "{\\textstyle H=N\\left({\\dfrac {1}{N}}\\right)^{2}={\\dfrac {1}{N}}}": {
    "before": "When all the firms in an industry have equal market shares,",
    "after": ". The Herfindahl is correlated with the number of firms in an industry because its lower bound when there are N firms is 1/N. In the more general case of unequal market share, 1/H is called \"equivalent (or effective) number of firms in the industry\", Neqi or Neff. An industry with 3 firms cannot have a lower Herfindahl than an industry with 20 firms when firms have equal market shares. But as market shares of the 20-firm industry diverge from equality the Herfindahl can exceed that of the equal-market-share 3-firm industry (e.g., if one firm has 81% of the market and the remaining 19 have 1% each, then",
    "url": "https://en.wikipedia.org/wiki/Herfindahl–Hirschman index"
  },
  "{\\textstyle H=\\sum \\|w\\|^{2}}": {
    "before": " held in a portfolio, where",
    "after": "is computed as the sum of the squares of the proportion of market value invested in each security. A low H-index implies a very diversified portfolio: as an example, a portfolio with",
    "url": "https://en.wikipedia.org/wiki/Herfindahl–Hirschman index"
  },
  "{\\textstyle s_{i}=x_{i}/\\sum _{j=1}^{N}x_{j}}": {
    "before": "and market share",
    "after": ", then the index can be expressed as",
    "url": "https://en.wikipedia.org/wiki/Herfindahl–Hirschman index"
  },
  "{\\textstyle H={\\frac {1}{N}}+(N-1)\\sigma ^{2}}": {
    "before": ", then the index can be expressed as",
    "after": ", where",
    "url": "https://en.wikipedia.org/wiki/Herfindahl–Hirschman index"
  },
  "{\\textstyle \\sigma ^{2}={\\frac {1}{N-1}}\\sum _{i=1}^{N}\\left(s_{i}-\\mu \\right)^{2}}": {
    "before": "is the statistical variance of the firm shares, defined as",
    "after": "where",
    "url": "https://en.wikipedia.org/wiki/Herfindahl–Hirschman index"
  },
  "{\\textstyle \\mu ={\\frac {1}{N}}}": {
    "before": "where",
    "after": "is the mean of participations. If all firms have equal (identical) shares (that is, if the market structure is completely symmetric, in which case",
    "url": "https://en.wikipedia.org/wiki/Herfindahl–Hirschman index"
  },
  "{\\displaystyle {\\text{Assets}}={\\text{Liabilities}}+{\\text{Equity}}}   {\\displaystyle A=L+E} {\\displaystyle {\\text{Assets}}={\\text{Stockholder Equity}}+{\\text{Liabilities}}}   {\\displaystyle a=oe+l}": {
    "before": "The fundamental accounting equation , also called the balance sheet equation , represents the relationship between the assets , liabilities , and owner's equity of a person or business. It is the foundation for the double-entry bookkeeping system . For each transaction, the total debits equal the total credits. It can be expressed as furthermore:",
    "after": "In a corporation, capital represents the stockholders' equity. Since every business transaction affects at least two of a company's accounts, the accounting equation will always be \"in balance\", meaning the left side of its balance sheet should always equal the right side. Thus, the accounting formula essentially shows that what the firm owns (its assets) has been purchased with equity and/or liabilities. That is, with funds it has borrowed and therefore owes (its liabilities) plus funds invested by the founding shareholders (its shareholders' equity or capital); note that the profits earned by the company ultimately belong to its owners.",
    "url": "https://en.wikipedia.org/wiki/Accounting equation"
  },
  "Assets − Liabilities = ( Shareholders ' or Owners' Equity ) ": {
    "before": "In a corporation, capital represents the stockholders' equity. Since every business transaction affects at least two of a company's accounts, the accounting equation will always be \"in balance\", meaning the left side of its balance sheet should always equal the right side. Thus, the accounting formula essentially shows that what the firm owns (its assets) has been purchased with equity and/or liabilities. That is, with funds it has borrowed and therefore owes (its liabilities) plus funds invested by the founding shareholders (its shareholders' equity or capital); note that the profits earned by the company ultimately belong to its owners.The formula can be rewritten:",
    "after": "Now it shows owners' equity is equal to property (assets) minus debts (liabilities). Since in a corporation owners are shareholders , owner's equity is called shareholders' equity . Every accounting transaction affects at least one element of the equation, but always balances. Simple transactions also include: ",
    "url": "https://en.wikipedia.org/wiki/Accounting equation"
  },
  "Owner's equity = Contributed Capital + Retained Earnings": {
    "before": "This equation is part of the transaction analysis model,  for which we also write",
    "after": "Retained Earnings = Net Income − Dividends",
    "url": "https://en.wikipedia.org/wiki/Accounting equation"
  },
  "Retained Earnings = Net Income − Dividends": {
    "before": "Owner's equity = Contributed Capital + Retained Earnings",
    "after": "andNet Income = Revenue − Expenses",
    "url": "https://en.wikipedia.org/wiki/Accounting equation"
  },
  "Net Income = Revenue − Expenses": {
    "before": "Retained Earnings = Net Income − Dividendsand",
    "after": "The equation resulting from making these substitutions in the accounting equation may be referred to as the expanded accounting equation, because it yields the breakdown of the equity component of the equation. ",
    "url": "https://en.wikipedia.org/wiki/Accounting equation"
  },
  "Assets = Liabilities + Contributed Capital + Revenue − Expenses − Dividends": {
    "before": "The equation resulting from making these substitutions in the accounting equation may be referred to as the expanded accounting equation, because it yields the breakdown of the equity component of the equation. ",
    "after": "Applications [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Accounting equation"
  },
  "Beginning Inventory + Purchases − (Sales + Adjustments) = Booked (Invoiced) Inventory": {
    "before": "Shrinkage figures can be calculated by:",
    "after": "Booked Inventory − Physical Counted Inventory = Shrinkage",
    "url": "https://en.wikipedia.org/wiki/Shrinkage (accounting)"
  },
  "Booked Inventory − Physical Counted Inventory = Shrinkage": {
    "before": "Beginning Inventory + Purchases − (Sales + Adjustments) = Booked (Invoiced) Inventory",
    "after": "Shrinkage/Total Sales x 100 = Shrinkage Percent",
    "url": "https://en.wikipedia.org/wiki/Shrinkage (accounting)"
  },
  "Shrinkage/Total Sales x 100 = Shrinkage Percent": {
    "before": "Booked Inventory − Physical Counted Inventory = Shrinkage",
    "after": "See also[edit]",
    "url": "https://en.wikipedia.org/wiki/Shrinkage (accounting)"
  },
  "Assets = Liabilities + Equity": {
    "before": "The balance sheet is the financial statement showing a firm's assets, liabilities and equity (capital) at a set point in time, usually the end of the fiscal year reported on the accompanying income statement. The total assets always equal the total combined liabilities and equity. This statement best demonstrates the basic accounting equation:",
    "after": "The statement can be used to help show the financial position of a company because liability accounts are external claims on the firm's assets while equity accounts are internal claims on the firm's assets.",
    "url": "https://en.wikipedia.org/wiki/Financial accounting"
  },
  "Cash at beginning of period + Changes in cash during period = Cash at end of period ": {
    "before": "Accounting identities also apply between accounting periods, such as changes in cash balances. For example:",
    "after": "Value of an asset [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Accounting identity"
  },
  "Carrying value = Historic cost + Change in value": {
    "before": "Any asset recorded in a firm's balance sheet will have a carrying value . By definition, the carrying value must equal the historic cost (or acquisition cost) of the asset, plus (or minus) any subsequent adjustments in the value of the asset, such as depreciation .",
    "after": "Economics [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Accounting identity"
  },
  "Current Account Surplus + Capital Account Surplus = Increase in Official Reserve Account": {
    "before": "One of the most commonly known is the balance of payments identity,  where:",
    "after": "A common problem with the balance of payments identity is that, due to measurement error, the balance of payments may not total correctly. For example, in the context of the identity that the sum of all countries' current accounts must be zero, The Economist magazine has noted that \"In theory, individual countries’ current-account deficits and surpluses should cancel each other out. But because of statistical errors and omissions they never do.\" ",
    "url": "https://en.wikipedia.org/wiki/Accounting identity"
  },
  "GDP = consumption + investment + government spending + ( exports − imports ) .": {
    "before": "The basic equation for gross domestic product is also an identity, and is sometimes referred to as the National Income Identity : ",
    "after": "This identity holds because investment refers to the sum of intended and unintended investment, the latter being unintended accumulations of inventories; unintended inventory accumulation necessarily equals output produced (GDP) minus intended uses of that output—consumption, intended investment in machinery, inventories, etc., government spending, and net exports.",
    "url": "https://en.wikipedia.org/wiki/Accounting identity"
  },
  "Investment = Fixed investment + Inventory investment": {
    "before": "This identity holds because investment refers to the sum of intended and unintended investment, the latter being unintended accumulations of inventories; unintended inventory accumulation necessarily equals output produced (GDP) minus intended uses of that output—consumption, intended investment in machinery, inventories, etc., government spending, and net exports.Investment [ edit ]",
    "after": "Gross investment – Depreciation = Net investment",
    "url": "https://en.wikipedia.org/wiki/Accounting identity"
  },
  "Gross investment – Depreciation = Net investment": {
    "before": "Investment = Fixed investment + Inventory investment",
    "after": "Banking [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Accounting identity"
  },
  "Bank assets = Bank liabilities + Owners' equity": {
    "before": "A key identity that is used in explaining the multiple expansion of the money supply is:",
    "after": "Here the liabilities include deposits of customers, against which reserves often must be held.",
    "url": "https://en.wikipedia.org/wiki/Accounting identity"
  },
  "For example: if the railway coach company normally produced 40 coaches per month, and the fixed costs were still $1000/month, then each coach could be said to incur an Operating Cost/overhead of $25 =($1000 / 40). Adding this to the variable costs of $300 per coach produced a full cost of $325 per coach.": {
    "before": "In modern cost account of recording historical costs was taken further, by allocating the company's fixed costs over a given period of time to the items produced during that period, and recording the result as the total cost of production. This allowed the full cost of products that were not sold in the period they were produced to be recorded in inventory using a variety of complex accounting methods, which was consistent with the principles of Generally Accepted Accounting Principles (GAAP). It also essentially enabled managers to ignore the fixed costs, and look at the results of each period in relation to the \"standard cost\" for any given product.",
    "after": "This method tended to slightly distort the resulting unit cost, but in mass-production industries that made one product line, and where the fixed costs were relatively low, the distortion was very minor.",
    "url": "https://en.wikipedia.org/wiki/Standard cost accounting"
  },
  "For example: if the railway coach company made 100 coaches one month, then the unit cost would become $310 per coach ($300 + ($1000 / 100)). If the next month the company made 50 coaches, then the unit cost = $320 per coach ($300 + ($1000 / 50)), a relatively minor difference.": {
    "before": "This method tended to slightly distort the resulting unit cost, but in mass-production industries that made one product line, and where the fixed costs were relatively low, the distortion was very minor.",
    "after": "Variance analysis [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Standard cost accounting"
  },
  "{\\displaystyle {\\dot {A}}_{i}=\\delta \\cdot A(t)^{\\phi }\\cdot L_{A}(t)^{\\lambda -1}\\cdot L_{A_{i}}(t)}": {
    "before": "For a single company i According to the following modeling applies to the emergence of new ideas or design instructions:",
    "after": "With {\\displaystyle L_{A}} :: Number of employees in the research sector",
    "url": "https://en.wikipedia.org/wiki/Jones model"
  },
  "{\\displaystyle {\\dot {A}}} refers to the derivation of the variables {\\displaystyle A} A after the time, so {\\displaystyle {\\dot {A}}={\\frac {\\partial A(t)}{\\partial t}}}": {
    "before": "{\\displaystyle L_{A}} :: Number of employees in the research sector {\\displaystyle A} : Technology level",
    "after": "where the parameters take the following values: {\\displaystyle 0<\\lambda <1;\\phi <1} , For parameter values of {\\displaystyle \\lambda =\\phi =1} results in the Romer model ( {\\displaystyle {\\dot {A}}=\\delta \\cdot A\\cdot L_{A}} ). After aggregation across all companies results:",
    "url": "https://en.wikipedia.org/wiki/Jones model"
  },
  "{\\displaystyle {\\dot {A}}=\\delta \\cdot A(t)^{\\phi }\\cdot L_{A}(t)^{\\lambda }} .": {
    "before": "where the parameters take the following values: {\\displaystyle 0<\\lambda <1;\\phi <1} , For parameter values of {\\displaystyle \\lambda =\\phi =1} results in the Romer model ( {\\displaystyle {\\dot {A}}=\\delta \\cdot A\\cdot L_{A}} ). After aggregation across all companies results:",
    "after": "Here the parameters have the following meaning:",
    "url": "https://en.wikipedia.org/wiki/Jones model"
  },
  "{\\displaystyle {\\frac {\\dot {\\hat {A(t)}}}{\\hat {A(t)}}}=0\\quad \\Leftrightarrow \\quad {\\hat {A(t)}}={\\frac {\\lambda \\cdot n}{1-\\phi }}} n for the growth rate of persons working in the research sector.": {
    "before": "In the Jones model, growth in steady state is given by:",
    "after": "Further reading [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Jones model"
  },
  "{\\displaystyle {\\text{Throughput}}={\\text{Sales revenue – Total Variable Costs}}} ": {
    "before": "These relationships between financial ratios as illustrated by Goldratt are very similar to a set of relationships defined by DuPont and General Motors financial executive Donaldson Brown about 1920. Brown did not advocate changes in management accounting methods, but instead used the ratios to evaluate traditional financial accounting data.Explanation [ edit ]",
    "after": "{\\displaystyle {\\text{Throughput accounting Ratio}}={\\text{Return per factory hour}}/{\\text{Cost per factory hour}}} ",
    "url": "https://en.wikipedia.org/wiki/Throughput accounting"
  },
  "{\\displaystyle {\\text{Throughput accounting Ratio}}={\\text{Return per factory hour}}/{\\text{Cost per factory hour}}} ": {
    "before": "{\\displaystyle {\\text{Throughput}}={\\text{Sales revenue – Total Variable Costs}}} ",
    "after": "For example: The railway coach company was offered a contract to make 15 open-topped streetcars each month, using a design that included ornate brass foundry work, but very little of the metalwork needed to produce a covered rail coach. The buyer offered to pay $280 per streetcar. The company had a firm order for 40 rail coaches each month for $350 per unit.",
    "url": "https://en.wikipedia.org/wiki/Throughput accounting"
  },
  "Net profit (NP) = throughput – operating expense = T – OE": {
    "before": "The answers to these questions determine the effect of proposed changes on system wide measurements:",
    "after": "Return on investment (ROI) = net profit / investment = NP/I",
    "url": "https://en.wikipedia.org/wiki/Throughput accounting"
  },
  "Return on investment (ROI) = net profit / investment = NP/I": {
    "before": "Net profit (NP) = throughput – operating expense = T – OE",
    "after": "TA Productivity = throughput / operating expense = T/OE",
    "url": "https://en.wikipedia.org/wiki/Throughput accounting"
  },
  "TA Productivity = throughput / operating expense = T/OE": {
    "before": "Return on investment (ROI) = net profit / investment = NP/I",
    "after": "Investment turns (IT) = throughput / investment = T/I",
    "url": "https://en.wikipedia.org/wiki/Throughput accounting"
  },
  "Investment turns (IT) = throughput / investment = T/I": {
    "before": "TA Productivity = throughput / operating expense = T/OE",
    "after": "These relationships between financial ratios as illustrated by Goldratt are very similar to a set of relationships defined by DuPont and General Motors financial executive Donaldson Brown about 1920. Brown did not advocate changes in management accounting methods, but instead used the ratios to evaluate traditional financial accounting data.",
    "url": "https://en.wikipedia.org/wiki/Throughput accounting"
  },
  "{\\displaystyle {\\mbox{annual depreciation expense}}={{\\mbox{cost of fixed asset}}-{\\mbox{residual value}} \\over {\\mbox{useful life of asset}}(years)}}": {
    "before": "Straight-line depreciation is the simplest and most often used method. The straight-line depreciation is calculated by dividing the difference between assets pagal sale cost and its expected salvage value by the number of years for its expected useful life. (The salvage value may be zero, or even negative due to costs required to retire it; however, for depreciation purposes salvage value is not generally calculated at below zero.) The company will then charge the same amount to depreciation each year over that period, until the value shown for the asset has reduced from the original cost to the salvage value.Straight-line method:",
    "after": "DE=(Cost-SL)/UL",
    "url": "https://en.wikipedia.org/wiki/Sum of Digits depreciation"
  },
  "{\\displaystyle {\\mbox{annual depreciation expense}}={{\\mbox{cost of fixed asset}}-{\\mbox{residual value}} \\over {\\mbox{estimated total production}}}\\times {\\mbox{actual production}}}": {
    "before": "Units-of-production depreciation method calculates greater deductions for depreciation in years when the asset is heavily used",
    "after": "DE= ((OV-SV)/EPC) x Units per year",
    "url": "https://en.wikipedia.org/wiki/Sum of Digits depreciation"
  },
  "book value = original cost − accumulated depreciation": {
    "before": "This table illustrates the straight-line method of depreciation. Book value at the beginning of the first year of depreciation is the original cost of the asset. At any time book value equals original cost minus accumulated depreciation.",
    "after": "Book value at the end of year becomes book value at the beginning of next year. The asset is depreciated until the book value equals scrap value.",
    "url": "https://en.wikipedia.org/wiki/Sum of Digits depreciation"
  },
  "DE= 2 x SLDP x BV": {
    "before": "where N is the estimated life of the asset (for example, in years).",
    "after": "Annuity depreciation[edit]",
    "url": "https://en.wikipedia.org/wiki/Sum of Digits depreciation"
  },
  "SYD depreciation = depreciable base x (remaining useful life/sum of the years' digits)": {
    "before": "Sum of the years' digits method of depreciation is one of the accelerated depreciation techniques which are based on the assumption that assets are generally more productive when they are new and their productivity decreases as they become old. The formula to calculate depreciation under SYD method is:",
    "after": "depreciable base = cost − salvage value",
    "url": "https://en.wikipedia.org/wiki/Sum of Digits depreciation"
  },
  "depreciable base = cost − salvage value": {
    "before": "SYD depreciation = depreciable base x (remaining useful life/sum of the years' digits)",
    "after": "Example: If an asset has original cost of $1000, a useful life of 5 years and a salvage value of $100, compute its depreciation schedule.",
    "url": "https://en.wikipedia.org/wiki/Sum of Digits depreciation"
  },
  "Asset = Liability + Owner's equity": {
    "before": "The fundamental accounting equation is the following:",
    "after": "The account on left side of this equation has a normal balance of debit.",
    "url": "https://en.wikipedia.org/wiki/Normal balance"
  },
  "{\\displaystyle \\mathbf {P} \\mathbf {B} \\times \\left({\\frac {MR-PBR}{MR}}\\right)}": {
    "before": "",
    "after": "PB is the Patent Box profit for the company, MR is the main rate of corporation tax, and PBR is the special Patent Box tax rate (10 per cent)",
    "url": "https://en.wikipedia.org/wiki/Patent box"
  },
  "Debits = Credits: algebraic manipulations on the left-hand and right-hand sides of an equal sign had to \"balance\" or they were in error. This is the algebraic equivalent of double-entries \"bookkeeping equation\" for error control.": {
    "before": "Al-Khwarizmı's book introduced al-jabr meaning \"restoration” (which European translated as \"algebra\") to its inheritance accounting, leading to three fundamental accounting - algebreic concepts:",
    "after": "Real accounts: These included assets for tracking wealth, weighed against liabilities from the claims of others against that wealth, and the difference which is the owner's net wealth, or owner's equity.This was al-Khwarizmi's \"basic accounting equation\".",
    "url": "https://en.wikipedia.org/wiki/History of accounting"
  },
  "A hybrid Cost-per-Click (CPC) auction calculated by multiplying the CPC times the click-through rate (CTR), and multiplying that by one thousand. (Represented by: (CPC x CTR) x 1000 = eCPM.) This monetization model is used by Google to rank site-targeted CPM ads (in the Google content network) against keyword-targeted CPC ads (Google AdWords PPC) in their hybrid auction.  ": {
    "before": "The Search Engine Marketing Professionals Organization (SEMPO) defines eCPM as:",
    "after": "In internet marketing, effective cost per mille is used to measure the effectiveness of a publisher's inventory being sold (by the publisher) via a CPA , CPC , or Cost per time basis. In other words, the eCPM tells the publisher what they would have received if they sold the advertising inventory on a CPM basis (instead of a CPA, CPC, or Cost per time). This information can be used to compare revenue across channels that may have widely varying traffic—by figuring the earnings per thousand impressions.",
    "url": "https://en.wikipedia.org/wiki/Cost per mille"
  },
  "{\\displaystyle M=\\beta \\cdot (\\max {(\\sum _{i=1}^{N}{Assets_{i}},\\sum _{i=1}^{N}{Revenues_{i}})})^{\\alpha }.\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Materiality (auditing)"
  },
  "{\\displaystyle \\alpha =\\,} a constant that is between zero and one, i.e. {\\displaystyle 0<\\alpha <1.\\,} {\\displaystyle i=1,2,...,N\\,} for each asset or revenue account, transaction, etc.": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Materiality (auditing)"
  },
  "Year 1: $1,000,000 in fund + $10,000 dividends + $80,800 interest = $1,090,800 Year 2: $1,090,800 in fund + $12,000 dividends + $66,168 interest = $1,168,968 etc., until all payment periods are accounted for.": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Diminution in value"
  },
  "{\\displaystyle {\\text{sum of cost input}}={\\text{sum of cost output}}}": {
    "before": "As with the other cost allocation methods, the conservation of the cost sum applies, that is:",
    "after": "The cost of the main product, usually for the product with the highest physical or economical output, receives for example the equivalence number 1. On the basis of selected indicators (average market prices, physical properties, etc.) other equivalence numbers are formed, using suitable ratios between the different co-products. Multiplying the equivalence numbers by the production or sales figures results in the allocation keys for a specific product type. From this the cost of a co-product can be calculated, both for main and by-products.",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "{\\displaystyle K_{1}^{var}=a_{1}\\cdot K_{I}^{var}={\\frac {f_{1}}{f_{1}+f_{2}}}\\cdot k_{I}\\cdot I\\quad {\\text{respectively}}\\quad K_{2}^{var}=a_{2}\\cdot K_{I}^{var}={\\frac {f_{2}}{f_{1}+f_{2}}}\\cdot k_{I}\\cdot I}": {
    "before": "The costs k 1 , k 2 are the variable costs of the two outputs which need to be determined. k I represents the known variable costs of the input. K var denotes the respective sum of the variable costs. a 1 and a 2 are the allocation factors for the respective output, i.e. they describe the proportion of the input that is assigned to a co-product.The weighting keys are f 1 and f 2 :",
    "after": "This results in specific variable costs k 1 and k 2 :",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "{\\displaystyle k_{1}={\\frac {K_{1}^{var}}{O_{1}}}={\\frac {K_{1}^{var}}{f_{1}\\cdot I}}\\quad {\\text{respectively}}\\quad k_{2}={\\frac {K_{2}^{var}}{O_{2}}}={\\frac {K_{2}^{var}}{f_{2}\\cdot I}}}": {
    "before": "This results in specific variable costs k 1 and k 2 :",
    "after": "According to the introducing relation of the cost allocation, the following applies:",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "{\\displaystyle k_{I}\\cdot I=k_{1}\\cdot O_{1}+k_{2}\\cdot O_{2}\\quad {\\text{or}}\\quad K_{I}^{var}=K_{1}^{var}+K_{2}^{var}}": {
    "before": "According to the introducing relation of the cost allocation, the following applies:",
    "after": "Further reading [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "apass = mpass / (mpass + mfreight)": {
    "before": "An airline can determine the cost of the transportation service by dividing air freight and passengers by weight. The average passenger weight of booked seats is to be compared to the weight of the loaded air cargo containers.",
    "after": "afreight = mfreight / (mpass + mfreight)",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "afreight = mfreight / (mpass + mfreight)": {
    "before": "apass = mpass / (mpass + mfreight)",
    "after": "In a refinery, one can assume the input as crude oil and as output gasoline, diesel and heavy fuel oil as well as (flare) losses. The equivalence number method can use the energy content of the products as an allocation key. E is the product of energy density and production quantity.",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "agas = Egas / (Egas + Ediesel + EHFO)": {
    "before": "In a refinery, one can assume the input as crude oil and as output gasoline, diesel and heavy fuel oil as well as (flare) losses. The equivalence number method can use the energy content of the products as an allocation key. E is the product of energy density and production quantity.",
    "after": "adiesel = Ediesel / (Egas + Ediesel + EHFO)",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "adiesel = Ediesel / (Egas + Ediesel + EHFO)": {
    "before": "agas = Egas / (Egas + Ediesel + EHFO)",
    "after": "aHFO = EHFO / (Egas + Ediesel + EHFO)",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "aHFO = EHFO / (Egas + Ediesel + EHFO)": {
    "before": "adiesel = Ediesel / (Egas + Ediesel + EHFO)",
    "after": "In the cogeneration plants, the Carnot method allocates the fuel to the products useful heat and electrical work. The weighting key is the exergy content of the output energies.",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "ael= ηel / (ηel + ηc × ηth)": {
    "before": "In the cogeneration plants, the Carnot method allocates the fuel to the products useful heat and electrical work. The weighting key is the exergy content of the output energies.",
    "after": "ath= (ηc x ηth) / (ηel + ηc × ηth)",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "ath= (ηc x ηth) / (ηel + ηc × ηth)": {
    "before": "ael= ηel / (ηel + ηc × ηth)",
    "after": "In the alternative generation method, the key is thermal and weighted electrical efficiency, where the weighting factor is the ratio of thermal to electrical reference efficiencies (γ = ηth, ref/ηel,ref).",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "ael= (γ ηel) / (γ ηel + ηth)": {
    "before": "In the alternative generation method, the key is thermal and weighted electrical efficiency, where the weighting factor is the ratio of thermal to electrical reference efficiencies (γ = ηth, ref/ηel,ref).",
    "after": "ath= ηth / (γ ηel + ηth)",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "ath= ηth / (γ ηel + ηth)": {
    "before": "ael= (γ ηel) / (γ ηel + ηth)",
    "after": "Criticism[edit]",
    "url": "https://en.wikipedia.org/wiki/Equivalence number method"
  },
  "The disposal tax effect formula: DTE = (BookValue – SalvageValue) x TR.": {
    "before": "The Central collection agency (CCA) uses a method of depreciation and the undepreciated value which is the undepreciated capital cost. As CCA uses a declining balance it makes the disposal of assets complicated. The disposal tax effect (DTE) takes into account that the salvage value can cause a gain or a loss.",
    "after": "The relevant book value in this case is determining the tax gain or loss of the asset. The tax basis then is the difference between the original cost and any accumulated depreciation.",
    "url": "https://en.wikipedia.org/wiki/Disposal tax effect"
  },
  "Tax on recapture is calculated by = (BookValue – BasisValue) x TR Capital gains tax = (BasisValue – Salvage Value) x TR/2 Disposal tax effect (DTE) = (tax on recapture + Capital gains tax)": {
    "before": "For businesses, the capital gain is from the appreciation value of the asset depending at which tax rate (TR) or tax law that will be applied at the time of the sale. The recapture of depreciation is calculated by how much the company has over-depreciated the asset in its life. The recapture allocation is taxed at ordinary rates as excess depreciation over the years essentially reduced taxable income. The basis value is the price of the fixed asset.",
    "after": "If a company sells an asset for less than the tax basis this causes a loss in capital. This means that the asset's value has decreased more than its depreciation value for tax. When capital loss occurs then a special tax rate is given. The benefit of this is that the sale of an asset is the amount by which the taxes are reduced (tax shield).",
    "url": "https://en.wikipedia.org/wiki/Disposal tax effect"
  },
  "An advertisement for The Silence = Death Project of ACT UP to bring about HIV treatment reform": {
    "before": "Throughout the past decade, there have been activist movements that have influenced the procurement lower HIV drug prices at greater accessibility. In 2000, the cost for first-line treatment was over $10,000 per patient per year, and nearly two decades later in 2018, the cost has decreased to as low as $75 per patient per year.",
    "after": "In 1987, AIDS Coalition to Unleash Power (ACT UP) was the first international organization designed to advocate for people with HIV. On September 14, 1989, members of ACT UP protested at the New York Stock Exchange over the Burroughs Wellcome's setting a price of US$10,000 per year for AZT, which was the only effective treatment for HIV discovered and was unaffordable to many HIV positive persons. Several days later in response to the protest the company lowered the price of AZT to $6,400 per patient per year, a 20% reduction.",
    "url": "https://en.wikipedia.org/wiki/Cost of HIV treatment"
  },
  "Silence=Death Project": {
    "before": "Reports from the Holocaust",
    "after": "Day Without Art",
    "url": "https://en.wikipedia.org/wiki/Cost of HIV treatment"
  },
  "Total product (= Output, Q) = Quantity of goods": {
    "before": "Calculating cost functions[edit]",
    "after": "Average Variable Cost (AVC) = Total Variable Cost / Quantity of goods (This formula is cyclic with the TVC one)",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Average Variable Cost (AVC) = Total Variable Cost / Quantity of goods (This formula is cyclic with the TVC one)": {
    "before": "Total product (= Output, Q) = Quantity of goods",
    "after": "Average Fixed Cost (AFC) = ATC – AVC",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Average Fixed Cost (AFC) = ATC – AVC": {
    "before": "Average Variable Cost (AVC) = Total Variable Cost / Quantity of goods (This formula is cyclic with the TVC one)",
    "after": "Total Cost = (AVC + AFC) X Quantity of goods",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Total Cost = (AVC + AFC) X Quantity of goods": {
    "before": "Average Fixed Cost (AFC) = ATC – AVC",
    "after": "Total Variable Cost = Variable cost per unit X Quantity of goods",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Total Variable Cost = Variable cost per unit X Quantity of goods": {
    "before": "Total Cost = (AVC + AFC) X Quantity of goods",
    "after": "Total Fixed Cost = TC – TVC",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Total Fixed Cost = TC – TVC": {
    "before": "Total Variable Cost = Variable cost per unit X Quantity of goods",
    "after": "Marginal Cost = Change in Total Costs / Change in Quantity of goods",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Marginal Cost = Change in Total Costs / Change in Quantity of goods": {
    "before": "Total Fixed Cost = TC – TVC",
    "after": "Marginal Product = Change in Quantity of goods / Change in Variable Factor",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Marginal Product = Change in Quantity of goods / Change in Variable Factor": {
    "before": "Marginal Cost = Change in Total Costs / Change in Quantity of goods",
    "after": "Marginal Revenue = Change in Total Revenue / Change in Quantity of goods",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Marginal Revenue = Change in Total Revenue / Change in Quantity of goods": {
    "before": "Marginal Product = Change in Quantity of goods / Change in Variable Factor",
    "after": "Average Product = Quantity of goods / Variable Factor",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Average Product = Quantity of goods / Variable Factor": {
    "before": "Marginal Revenue = Change in Total Revenue / Change in Quantity of goods",
    "after": "Total Revenue = Price X Quantity of goods",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Total Revenue = Price X Quantity of goods": {
    "before": "Average Product = Quantity of goods / Variable Factor",
    "after": "Average Revenue = TR / Quantity of goods",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Average Revenue = TR / Quantity of goods": {
    "before": "Total Revenue = Price X Quantity of goods",
    "after": "Total Product = AP X Variable Factor",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Total Product = AP X Variable Factor": {
    "before": "Average Revenue = TR / Quantity of goods",
    "after": "Profit = TR – TC or (P-ATC)*Q",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Profit = TR – TC or (P-ATC)*Q": {
    "before": "Total Product = AP X Variable Factor",
    "after": "Loss = TC – TR (if positive)",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Loss = TC – TR (if positive)": {
    "before": "Profit = TR – TC or (P-ATC)*Q",
    "after": "Break Even Point: value of Quantity of goods where Average Revenue = Average Total Cost",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Break Even Point: value of Quantity of goods where Average Revenue = Average Total Cost": {
    "before": "Loss = TC – TR (if positive)",
    "after": "Profit Maximizing Condition: Marginal Revenue = Marginal Cost",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Profit Maximizing Condition: Marginal Revenue = Marginal Cost": {
    "before": "Break Even Point: value of Quantity of goods where Average Revenue = Average Total Cost",
    "after": "Marginal Revenue =The rate of change in Total Revenue with Quantity",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "Marginal Revenue =The rate of change in Total Revenue with Quantity": {
    "before": "Profit Maximizing Condition: Marginal Revenue = Marginal Cost",
    "after": "See also[edit]",
    "url": "https://en.wikipedia.org/wiki/Total cost"
  },
  "\"value of decision situation with perfect information while paying VoC\" = \"value of current decision situation\".": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Value of information"
  },
  "VoC = \"value of decision situation with perfect information\" - \"value of current decision situation\".": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Value of information"
  },
  "E = gk + (1-g)k',": {
    "before": "In a typical consultant situation, the consultant would be paid up to cost c for their information, based on the expected cost E without the consultant and the revised cost F with the consultant's information. In a perfect information scenario, E can be defined as the sum product of the probability of a good outcome g times its cost k, plus the probability of a bad outcome (1-g) times its cost k'>k:",
    "after": "which is revised to reflect expected cost F of perfect information including consulting cost c. The perfect information case assumes the bad outcome does not occur due to the perfect information consultant.",
    "url": "https://en.wikipedia.org/wiki/Value of information"
  },
  "F = g(k+c)": {
    "before": "E = gk + (1-g)(k'+m+E)",
    "after": "If the consultant is imperfect with frequency f, then the consultant cost is solved with the probability of error included:",
    "url": "https://en.wikipedia.org/wiki/Value of information"
  },
  "E = gk + (1-g)(k'+m+E)": {
    "before": "In the case of a recursive decision tree, we often have an additional cost m that results from correcting the error, and the process restarts such that the expected cost will appear on both the left and right sides of our equations. This is typical of hiring-rehiring decisions or value chain decisions for which assembly line components must be replaced if erroneously ordered or installed:",
    "after": "F = g(k+c)",
    "url": "https://en.wikipedia.org/wiki/Value of information"
  },
  "F = g(k+c)(1-f) + g(k+c+F)f + (1-g)(1-f)(k+c+F) + (1-g)f(k'+c+m+F)": {
    "before": "If the consultant is imperfect with frequency f, then the consultant cost is solved with the probability of error included:",
    "after": "VoI is also used to do an inspection and maintenance planning of the structures. analyze to what extent the value associated with the information collected during the service life of engineered structures, for example, inspections, in the context of integrity management, is affected by not only measurement random errors but also biases (systematic errors), taking the dependency between the collections into account",
    "url": "https://en.wikipedia.org/wiki/Value of information"
  },
  "{\\displaystyle LQ={\\frac {e_{i}/e}{E_{i}/E}}}": {
    "before": "The formula for computing location quotients can be written as:",
    "after": "Where: {\\displaystyle e_{i}=} Local employment in industry i",
    "url": "https://en.wikipedia.org/wiki/Economic base analysis"
  },
  "{\\displaystyle AFC={\\frac {FC}{Q}}.}": {
    "before": "In economics , average fixed cost ( AFC ) is the fixed costs of production (FC) divided by the quantity (Q) of output produced. Fixed costs are those costs that must be incurred in fixed quantity regardless of the level of output produced.",
    "after": "Average fixed cost is the fixed cost per unit of output. As the total number of units of the good produced increases, the average fixed cost decreases because the same amount of fixed costs is being spread over a larger number of units of output.",
    "url": "https://en.wikipedia.org/wiki/Average fixed cost"
  },
  "{\\displaystyle ATC=AVC+AFC}": {
    "before": "Average variable cost plus average fixed cost equals average total cost :",
    "after": "Explanation [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Average fixed cost"
  },
  "{\\displaystyle FMV\\,=\\,{VBAB*TAB_{factor}}}": {
    "before": "The present value of the future tax savings is a mathematical function of the fair market value. This creates circularity, because the fair market value includes the present value of the tax savings.  This circularity can be handled using a two-step procedure consisting in estimating the value of the intangible asset in the absence of the tax amortization benefit first and then grossing up the previous value by a tax amortization benefit factor. ",
    "after": "whereFMV is the fair market value of the intangible asset VBAB is the value of the intangible asset before amortization benefits TAB factor is the result of the formula defined below",
    "url": "https://en.wikipedia.org/wiki/Tax amortization benefit"
  },
  "{\\displaystyle TAB_{factor}\\,=\\,{1 \\over [1-{t \\over n}*({1 \\over k}-{1 \\over (k*(1+k)^{n})})]}}": {
    "before": "The tax amortization benefit factor (or TAB factor) is the result of a mathematical function of a corporate tax rate, a discount rate and a tax amortization period:",
    "after": "whereTAB factor is the value assuming end-year discounting t is the corporate tax rate applicable to the future amortization of the asset n is the tax amortization period of the asset in years k is the discount rate",
    "url": "https://en.wikipedia.org/wiki/Tax amortization benefit"
  },
  "Net sales = gross sales – (customer discounts, returns, and allowances) Gross profit = net sales – cost of goods sold Operating profit = gross profit – total operating expenses Net profit = operating profit – taxes – interest Net profit = net sales – cost of goods sold – operating expense – taxes – interest": {
    "before": "When the US government reports wholesale sales, this includes excise taxes on certain products.  Other terms [ edit ]",
    "after": "References [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Sales (accounting)"
  },
  "{\\displaystyle {\\text{Net sales}}={\\text{Gross sales}}-{\\text{(Customer discounts, returns, allowances)}}}": {
    "before": "Gross sales and net sales [ edit ]",
    "after": "General Journal - Merchandise return example Date Description of entry Debit Credit 8-7 Sales returns and allowances 20.00 Accounts receivable 20.00 Full credit for customer return of merchandise purchased on account. 8-7 Inventory 15.00 Cost of goods sold 15.00 Restore returned merchandise to inventory.",
    "url": "https://en.wikipedia.org/wiki/Sales (accounting)"
  },
  "{\\displaystyle Inc_{k}=[{\\frac {\\sum _{i=1}^{m}Costs_{i}}{\\sum _{i=1}^{N}E(Costs_{i})}}\\cdot \\sum _{i=1}^{N}Revenues_{i})]-\\sum _{i=1}^{m-1}Inc_{i}.\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Percentage-of-completion method"
  },
  "{\\displaystyle N=\\,} the expected length of the contract {\\displaystyle k=\\,} the current period {\\displaystyle E=\\,} the total estimated cost of contract": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Percentage-of-completion method"
  },
  "Revenue = 70% of 12,000 – previously recognized = 8,400 – 6,000 = 2,400.": {
    "before": "Percentage completion = 10,500/15,000 = 70%",
    "after": "However, because we are going to have a total loss of 3,000 on the contract..... we must recognize the total loss in the period it is estimated. As a result, our Cost of goods will be 5,900 (total loss recognized because of 500 profit recognized in previous periods [3,500] + Sales [2,400]); we reached this inductively by figuring the Sales and the Loss before the Cost of goods.",
    "url": "https://en.wikipedia.org/wiki/Percentage-of-completion method"
  },
  "Total Profit/Loss from the contract = 600-100-3,500= 3,000 Net Loss": {
    "before": "0",
    "after": "Balance sheet presentation[edit]",
    "url": "https://en.wikipedia.org/wiki/Percentage-of-completion method"
  },
  "costs of sales − Stock Variation = Purchase of goods. (2)": {
    "before": "Cash paid to operating suppliers",
    "after": "+ all other expenses",
    "url": "https://en.wikipedia.org/wiki/Operating cash flow"
  },
  "Cost of Sales = Stock Out for sales. It is Cash Neutral. Cost of Sales − Stock Variation = Stock out − (Stock out − Stock In) = Stock In = Purchase of goods: Cash Out": {
    "before": "operating: Variations of Assets Suppliers and Clients accounts will be disclosed in the Financial Cash Flow",
    "after": "Operating Cash Flow vs. Net Income, EBIT, and EBITDA[edit]",
    "url": "https://en.wikipedia.org/wiki/Operating cash flow"
  },
  "2 kg of unobtainium at $ 60 per kg ( = $ 120 per unit).": {
    "before": "Let us assume that standard direct material cost of widget is as follows:",
    "after": "Let us assume further that during the given period, 100 widgets were manufactured, using 212 kg of unobtainium which cost $ 13,144.",
    "url": "https://en.wikipedia.org/wiki/Direct material total variance"
  },
  "{\\displaystyle {\\mbox{Assets}}={\\mbox{Liabilities}}+{\\mbox{(Shareholders' or Owners' equity)}}} .  ": {
    "before": "Because each bookkeeping entry debits one account and credits another account in an equal amount, the double-entry bookkeeping system helps ensure that the general ledger is always in balance, thus maintaining the accounting equation :",
    "after": "The accounting equation is the mathematical structure of the balance sheet . Although a general ledger appears to be fairly simple, in large or complex organizations or organizations with various subsidiaries, the general ledger can grow to be quite large and take several hours or days to audit or balance.  [ citation needed ]",
    "url": "https://en.wikipedia.org/wiki/General ledger"
  },
  "Cash Inflow - Cash Outflow + Opening Balance = Closing Balance": {
    "before": "The statement of cash flows considers the inputs and outputs in concrete cash within a stated period. The general template of a cash flow statement is as follows:",
    "after": "Example 1: in the beginning of September, Ellen started out with $5 in her bank account. During that same month, Ellen borrowed $20 from Tom. At the end of the month, Ellen bought a pair of shoes for $7. Ellen's cash flow statement for the month of September looks like this:",
    "url": "https://en.wikipedia.org/wiki/Financial accounting"
  },
  "Closing balance: $50 – 2*$25 + $0 = $50–50=$0 - Indeed, the cash flow for the month of June for WikiTables amounts to $0 and not $50.": {
    "before": "Opening balance: $0",
    "after": "Important: the cash flow statement only considers the exchange of actual cash, and ignores what the person in question owes or is owed.",
    "url": "https://en.wikipedia.org/wiki/Financial accounting"
  },
  "– depreciation/ amortization= earnings before interest and taxes (EBIT)": {
    "before": "– selling, general, administrative expenses (SGA)",
    "after": "– interest and tax expenses",
    "url": "https://en.wikipedia.org/wiki/Financial accounting"
  },
  "– interest and tax expenses= profit/loss": {
    "before": "= earnings before interest and taxes (EBIT)",
    "after": "Statement of financial position (balance sheet)[edit]",
    "url": "https://en.wikipedia.org/wiki/Financial accounting"
  },
  "- Dividends= Retained earnings at the end of period.": {
    "before": "+ Net Income for the period",
    "after": "Basic concepts[edit]",
    "url": "https://en.wikipedia.org/wiki/Financial accounting"
  },
  "The accounting equation (Assets = Liabilities + Owners' Equity) and financial statements are the main topics of financial accounting.": {
    "before": "Graphic definition[edit]",
    "after": "The trial balance, which is usually prepared using the double-entry accounting system, forms the basis for preparing the financial statements. All the figures in the trial balance are rearranged to prepare a profit & loss statement and balance sheet. Accounting standards determine the format for these accounts (SSAP, FRS, IFRS). Financial statements display the income and expenditure for the company and a summary of the assets, liabilities, and shareholders' or owners' equity of the company on the date to which the accounts were prepared.",
    "url": "https://en.wikipedia.org/wiki/Financial accounting"
  },
  "Y = C + G": {
    "before": "Once the accounting framework is fulfilled then the structure of the model, based on stylized facts, is defined. The set of equations in the model defines relationship between different variables, not determined by the accounting framework. The model structure basically helps in understanding how the flows are connected from a behavioral perspective or in simple words how the behavior of a sector affects the flow of funds in the system, e.g., the factors that affect the consumption (C) of the household is not clear from the flow of funds but can be explained by the model. The model structure with a set of equations for a simple closed economy is given by:",
    "after": "T = θY",
    "url": "https://en.wikipedia.org/wiki/Stock-flow consistent model"
  },
  "T = θY": {
    "before": "Y = C + G",
    "after": "YD = Y – T",
    "url": "https://en.wikipedia.org/wiki/Stock-flow consistent model"
  },
  "YD = Y – T": {
    "before": "T = θY",
    "after": "C = α1 Y + α2 Ht-1",
    "url": "https://en.wikipedia.org/wiki/Stock-flow consistent model"
  },
  "C = α1 Y + α2 Ht-1": {
    "before": "YD = Y – T",
    "after": "ΔHs = G – T",
    "url": "https://en.wikipedia.org/wiki/Stock-flow consistent model"
  },
  "ΔHs = G – T": {
    "before": "C = α1 Y + α2 Ht-1",
    "after": "ΔHh = YD – C",
    "url": "https://en.wikipedia.org/wiki/Stock-flow consistent model"
  },
  "ΔHh = YD – C": {
    "before": "ΔHs = G – T",
    "after": "H = ΔH + Ht-1",
    "url": "https://en.wikipedia.org/wiki/Stock-flow consistent model"
  },
  "H = ΔH + Ht-1": {
    "before": "ΔHh = YD – C",
    "after": "Y (Income), C (Consumption), G (Government Expenditures), T (Taxes), YD (Disposable Income), ΔH (Changes in stock of money) and θ is the tax rate on the income of household sector.",
    "url": "https://en.wikipedia.org/wiki/Stock-flow consistent model"
  },
  "{\\displaystyle {\\begin{aligned}&{\\text{Target Income Sales (in Units)}}&&={\\frac {{\\text{Fixed Costs}}+{\\text{Target Income}}}{\\text{Unit Contribution}}}\\\\&{\\text{Target Income Sales (in Sales proceeds)}}&&={\\frac {{\\text{Fixed Costs}}+{\\text{Target Income}}}{\\text{Contribution Margin Ratio}}}\\end{aligned}}}": {
    "before": "In cost accounting , target income sales are the sales necessary to achieve a given target income (or targeted income ). It can be measured either in units or in currency (sales proceeds), and can be computed using contribution margin similarly to break-even point :",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Target income sales"
  },
  "{\\displaystyle MC(Q)={\\frac {\\ dC}{\\ dQ}}.}": {
    "before": "If the cost function {\\displaystyle C} is continuous and differentiable , the marginal cost {\\displaystyle MC} is the first derivative of the cost function with respect to the output quantity {\\displaystyle Q} : ",
    "after": "If the cost function is not differentiable, the marginal cost can be expressed as follows:",
    "url": "https://en.wikipedia.org/wiki/Marginal cost"
  },
  "{\\displaystyle MC={\\frac {\\Delta C}{\\Delta Q}},}": {
    "before": "If the cost function is not differentiable, the marginal cost can be expressed as follows:",
    "after": "where {\\displaystyle \\Delta } denotes an incremental change of one unit.",
    "url": "https://en.wikipedia.org/wiki/Marginal cost"
  },
  "{\\displaystyle ATC={\\frac {C_{0}+\\Delta C}{Q}}.}": {
    "before": "Fixed costs represent the costs that do not change as the production quantity changes. Fixed costs are costs incurred by things like rent, building space, machines, etc. Variable costs change as the production quantity changes, and are often associated with labor or materials. The derivative of fixed cost is zero, and this term drops out of the marginal cost equation: that is, marginal cost does not depend on fixed costs. This can be compared with average total cost (ATC), which is the total cost (including fixed costs, denoted C 0 ) divided by the number of units produced:",
    "after": "For discrete calculation without calculus , marginal cost equals the change in total (or variable) cost that comes with each additional unit produced. Since fixed cost does not change in the short run, it has no effect on marginal cost.",
    "url": "https://en.wikipedia.org/wiki/Marginal cost"
  },
  "{\\displaystyle MC={\\frac {\\Delta VC}{\\Delta Q}}} {\\displaystyle \\Delta VC={w\\Delta L}}": {
    "before": "Marginal costs can also be expressed as the cost per unit of labor divided by the marginal product of labor.  Denoting variable cost as VC, the constant wage rate as w, and labor usage as L, we have",
    "after": "{\\displaystyle MC={\\frac {w\\Delta L}{\\Delta Q}}={\\frac {w}{MPL}}.}",
    "url": "https://en.wikipedia.org/wiki/Marginal cost"
  },
  "{\\displaystyle MC={\\frac {w\\Delta L}{\\Delta Q}}={\\frac {w}{MPL}}.}": {
    "before": "{\\displaystyle MC={\\frac {\\Delta VC}{\\Delta Q}}} {\\displaystyle \\Delta VC={w\\Delta L}}",
    "after": "Here MPL is the ratio of increase in the quantity produced per unit increase in labour: i.e. ΔQ/ΔL, the marginal product of labor . The last equality holds because {\\displaystyle {\\frac {\\Delta L}{\\Delta Q}}} is the change in quantity of labor that brings about a one-unit change in output.  Since the wage rate is assumed constant, marginal cost and marginal product of labor have an inverse relationship—if the marginal product of labor is decreasing (or, increasing), then marginal cost is increasing (decreasing), and AVC = VC/Q=wL/Q = w/(Q/L) = w/AP L",
    "url": "https://en.wikipedia.org/wiki/Marginal cost"
  },
  "{\\displaystyle Y=C+I+G+(X-M)} ( 1 )": {
    "before": "GDP ( Gross Domestic Product ) is the value of all goods and services sold within a country during one year. GDP measures flows rather than stocks (example: the public deficit is a flow, the government debt is a stock). Flows are derived from the National Accounting relationship between aggregate spending and income. Ergo:",
    "after": "where {\\displaystyle Y} is GDP (expenditure), {\\displaystyle C} is consumption spending, {\\displaystyle I} is private investment spending, {\\displaystyle G} is government spending, {\\displaystyle X} is exports and {\\displaystyle M} is imports (so {\\displaystyle X-M} = net exports).",
    "url": "https://en.wikipedia.org/wiki/Sectoral balances"
  },
  "{\\displaystyle Y=C+S+T} ( 2 )": {
    "before": "Another perspective on the national income accounting is to note that households can use total income ( {\\displaystyle Y} ) for the following uses:",
    "after": "where {\\displaystyle S} is total saving and {\\displaystyle T} is total taxation (the other variables are as previously defined).",
    "url": "https://en.wikipedia.org/wiki/Sectoral balances"
  },
  "{\\displaystyle C+S+T=Y=C+I+G+(X-M)} ( 3 )": {
    "before": "You then bring the two perspectives together (because they are both just “views” of {\\displaystyle Y} ) to write:",
    "after": "You can then drop the {\\displaystyle C} (common on both sides) and you get:",
    "url": "https://en.wikipedia.org/wiki/Sectoral balances"
  },
  "{\\displaystyle S+T=I+G+(X-M)} ( 4 )": {
    "before": "You can then drop the {\\displaystyle C} (common on both sides) and you get:",
    "after": "Then you can convert this into the following sectoral balances accounting relations, which allow us to understand the influence of fiscal policy over private sector indebtedness. Hence, equation ( 4 ) can be rearranged to get the accounting identity for the three sectoral balances – private domestic, government budget and external:",
    "url": "https://en.wikipedia.org/wiki/Sectoral balances"
  },
  "{\\displaystyle (S-I)=(G-T)+(X-M)} ( 5 )": {
    "before": "Then you can convert this into the following sectoral balances accounting relations, which allow us to understand the influence of fiscal policy over private sector indebtedness. Hence, equation ( 4 ) can be rearranged to get the accounting identity for the three sectoral balances – private domestic, government budget and external:",
    "after": "or {\\displaystyle (S-I)+(M-X)+(T-G)=0} ( 6 )",
    "url": "https://en.wikipedia.org/wiki/Sectoral balances"
  },
  "{\\displaystyle (S-I)+(T-G)=(X-M)} ( 7 )": {
    "before": "{\\displaystyle (S-I)+(M-X)+(T-G)=0} ( 6 ) or",
    "after": "which implies that deficits at home (private and government) result in current account or trade deficits, and thus borrowing from abroad.",
    "url": "https://en.wikipedia.org/wiki/Sectoral balances"
  },
  "(G – T) = (S – I) – NX": {
    "before": "Therefore, budget deficits, by definition, are equivalent to adding net financial assets to the private sector; whereas budget surpluses remove financial assets from the private sector. This is represented by the identity:",
    "after": "which is",
    "url": "https://en.wikipedia.org/wiki/Sectoral balances"
  },
  "(Government sector balance) = (Private sector balance) – External sector balance": {
    "before": "which is",
    "after": "where G is government spending, T is taxes, S is savings, I is investment and NX is net exports.",
    "url": "https://en.wikipedia.org/wiki/Sectoral balances"
  },
  "{\\displaystyle \\ln w=f(s,x)=\\ln w_{0}+\\rho s+\\beta _{1}x+\\beta _{2}x^{2}}": {
    "before": "The Mincer earnings function is a single-equation model that explains wage income as a function of schooling and experience. It is named after Jacob Mincer .   Thomas Lemieux argues it is \"one of the most widely used models in empirical economics\". The equation has been examined on many datasets. Typically the logarithm of earnings is modelled as the sum of years of education and a quadratic function of \"years of potential experience\".  ",
    "after": "Where the variables have the following meanings; {\\displaystyle w} is earnings (the intercept {\\displaystyle w_{0}} is the earnings of someone with no education and no experience); {\\displaystyle s} is years of schooling; {\\displaystyle x} is years of potential labour market experience.  The parameters {\\displaystyle \\rho } , and {\\displaystyle \\beta _{1}} , {\\displaystyle \\beta _{2}} can be interpreted as the returns to schooling and experience, respectively.",
    "url": "https://en.wikipedia.org/wiki/Mincer earnings function"
  },
  "{\\displaystyle C=P-V} ": {
    "before": "The Unit Contribution Margin (C) is Unit Revenue (Price, P) minus Unit Variable Cost (V):",
    "after": "The Contribution Margin Ratio is the percentage of Contribution over Total Revenue, which can be calculated from the unit contribution over unit price or total contribution over Total Revenue:",
    "url": "https://en.wikipedia.org/wiki/Contribution margin"
  },
  "{\\displaystyle {\\frac {C}{P}}={\\frac {P-V}{P}}={\\frac {\\text{Unit Contribution Margin}}{\\text{Price}}}={\\frac {\\text{Total Contribution Margin}}{\\text{Total Revenue}}}}": {
    "before": "The Contribution Margin Ratio is the percentage of Contribution over Total Revenue, which can be calculated from the unit contribution over unit price or total contribution over Total Revenue:",
    "after": "For example, if the price is $10 and the unit variable cost is $2, then the unit contribution margin is $8, and the contribution margin ratio is $8/$10 = 80%.",
    "url": "https://en.wikipedia.org/wiki/Contribution margin"
  },
  "{\\displaystyle {\\begin{aligned}{\\text{PL}}&={\\text{TR}}-{\\text{TC}}\\\\&=\\left(P\\right)\\times X-\\left({\\text{TFC}}+{\\text{TVC}}\\right)\\\\&=C\\times X-{\\text{TFC}}\\end{aligned}}}": {
    "before": "Cost-Volume-Profit Analysis (CVP): assuming the linear CVP model, the computation of Profit and Loss ( Net Income ) reduces as follows:",
    "after": "where TC = TFC + TVC is Total Cost = Total Fixed Cost + Total Variable Cost and X is Number of Units. Thus Profit is the Contribution Margin times Number of Units, minus the Total Fixed Costs.",
    "url": "https://en.wikipedia.org/wiki/Contribution margin"
  },
  "{\\displaystyle {\\text{TC}}={\\text{TFC}}+V\\times X}": {
    "before": "One can decompose total costs as fixed costs plus variable costs:",
    "after": "Following a matching principle of matching a portion of sales against variable costs, one can decompose sales as contribution plus variable costs, where contribution is \"what's left after deducting variable costs\". One can think of contribution as \"the marginal contribution of a unit to the profit\", or \"contribution towards offsetting fixed costs\".",
    "url": "https://en.wikipedia.org/wiki/Cost–volume–profit analysis"
  },
  "{\\displaystyle {\\begin{aligned}{\\text{TR}}&=P\\times X\\\\&={\\bigl (}\\left(P-V\\right)+V{\\bigr )}\\times X\\\\&=\\left(C+V\\right)\\times X\\\\&=C\\times X+V\\times X\\end{aligned}}}": {
    "before": "Following a matching principle of matching a portion of sales against variable costs, one can decompose sales as contribution plus variable costs, where contribution is \"what's left after deducting variable costs\". One can think of contribution as \"the marginal contribution of a unit to the profit\", or \"contribution towards offsetting fixed costs\".In symbols:",
    "after": "whereC = Unit Contribution (Margin)",
    "url": "https://en.wikipedia.org/wiki/Cost–volume–profit analysis"
  },
  "{\\displaystyle {\\begin{aligned}{\\text{PL}}&={\\text{TR}}-{\\text{TC}}\\\\&=\\left(C+V\\right)\\times X-\\left({\\text{TFC}}+V\\times X\\right)\\\\&=C\\times X-{\\text{TFC}}\\\\&={\\text{TCM}}-{\\text{TFC}}\\end{aligned}}}": {
    "before": "Thus the Total Variable Costs {\\displaystyle {\\text{TVC}}=V\\times X} offset, and the Net Income (Profit and Loss) is Total Contribution Margin minus Total Fixed Costs:",
    "after": "Combined Profit Volume Ratio can be calculated by using following formula",
    "url": "https://en.wikipedia.org/wiki/Contribution margin"
  },
  "Combined Profit Volume Ratio = Combined Contribution/Combined Sale * 100": {
    "before": "Combined Profit Volume Ratio can be calculated by using following formula",
    "after": "Examples [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Contribution margin"
  },
  "TCFP [Total Cost of Faulty Part] =Direct Cost (manufacturing cost)": {
    "before": "The damages of poor quality augment as the inception point is further down the supply chain:",
    "after": "➔ failure at supplier's site (bad)",
    "url": "https://en.wikipedia.org/wiki/Cost of poor quality"
  },
  "{\\displaystyle {\\text{AVC}}={\\frac {\\text{VC}}{\\text{Q}}}}": {
    "before": "In economics , average variable cost ( AVC ) is a firm's variable costs (labour, electricity, etc.) divided by the quantity of output produced. Variable costs are those costs which vary with the output level:",
    "after": "where {\\displaystyle {\\text{VC}}} = variable cost, {\\displaystyle {\\text{AVC}}} = average variable cost, and {\\displaystyle {\\text{Q}}} = quantity of output produced.",
    "url": "https://en.wikipedia.org/wiki/Average variable cost"
  },
  "{\\displaystyle {\\text{AVC}}+{\\text{AFC}}={\\text{ATC}}.}": {
    "before": "Average variable cost plus average fixed cost equals average total cost :",
    "after": "A firm would choose to shut down if the price of its output is below average variable cost at the profit-maximizing level of output (or, more generally if it sells at multiple prices, its average revenue is less than AVC). Producing anything would not generate revenue significant enough to offset the associated variable costs; producing some output would add losses (additional costs in excess of revenues) to the costs inevitably being incurred (the fixed costs ). By not producing, the firm loses only the fixed costs.",
    "url": "https://en.wikipedia.org/wiki/Average variable cost"
  },
  "T = Updated Base Year": {
    "before": "0 = Original Base Year",
    "after": "Pt = Price Index in Year t",
    "url": "https://en.wikipedia.org/wiki/Value of life"
  },
  "Pt = Price Index in Year t": {
    "before": "T = Updated Base Year",
    "after": "It = Real Incomes in Year t",
    "url": "https://en.wikipedia.org/wiki/Value of life"
  },
  "It = Real Incomes in Year t": {
    "before": "Pt = Price Index in Year t",
    "after": "Ɛ = Income Elasticity of VSL.",
    "url": "https://en.wikipedia.org/wiki/Value of life"
  },
  "Ɛ = Income Elasticity of VSL.": {
    "before": "It = Real Incomes in Year t",
    "after": "Comparisons to other methods[edit]",
    "url": "https://en.wikipedia.org/wiki/Value of life"
  },
  "{\\displaystyle Q=a+bP{\\text{ where }}b<0} .": {
    "before": "Demand curves are often graphed as straight lines, where a and b are parameters:",
    "after": "The constant a embodies the effects of all factors other than price that affect demand. If income were to change, for example, the effect of the change would be represented by a change in the value of \"a\" and be reflected graphically as a shift of the demand curve. The constant b is the slope of the demand curve and shows how the price of the good affects the quantity demanded. ",
    "url": "https://en.wikipedia.org/wiki/Demand curve"
  },
  "{\\displaystyle P={\\frac {Q-a}{b}}} . ": {
    "before": "The graph of the demand curve uses the inverse demand function in which price is expressed as a function of quantity. The standard form of the demand equation can be converted to the inverse equation by solving for P:",
    "after": "Assumptions underlying the derivation of the demand curve [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Demand curve"
  },
  "{\\displaystyle Q=aP^{c}}": {
    "before": "The elasticity of demand usually will vary depending on the price. If the demand curve is linear, demand is inelastic at high prices and elastic at low prices, with unitary elasticity somewhere in between. There does exist a family of demand curves with constant elasticity for all prices. They have the demand equation",
    "after": ", where c",
    "url": "https://en.wikipedia.org/wiki/Demand curve"
  },
  "{\\displaystyle {\\begin{alignedat}{2}{\\text{Net Cash Flows from Financing Activities}}=&\\left[{\\text{Dividends received from }}3^{\\rm {rd}}{\\text{ parties}}\\right]\\\\&-\\left[{\\text{Dividends paid to }}3^{\\rm {rd}}{\\text{ parties}}\\right]\\\\&-[{\\text{Dividends paid to NCI but not}}\\\\&{\\text{intracompany dividend payments}}]\\end{alignedat}}}": {
    "before": "A traditional equation for this might look something like,",
    "after": "Example: cash flow of XYZ :   ",
    "url": "https://en.wikipedia.org/wiki/Cash flow statement"
  },
  "{\\displaystyle {\\text{Net Cash Flows from Operating Activities}}={\\text{ Net Income}}+{\\text{Rule Items}}}": {
    "before": "The intricacies of this procedure might be seen as,",
    "after": "For example, consider a company that has a net income of $100 this year, and its A/R increased by $25 since the beginning of the year. If the balances of all other current assets, long term assets and current liabilities did not change over the year, the cash flows could be determined by the rules above as $100 – $25 = Cash Flows from Operating Activities = $75. The logic is that, if the company made $100 that year (net income), and they are using the accrual accounting system (not cash based) then any income they generated that year which has not yet been paid for in cash should be subtracted from the net income figure in order to find cash flows from operating activities. And the increase in A/R meant that $25 of sales occurred on credit and have not yet been paid for in cash .",
    "url": "https://en.wikipedia.org/wiki/Cash flow statement"
  },
  "{\\displaystyle \\Delta y=\\Delta T*{\\frac {-b_{C}}{1-b_{C}(1-b_{T})+b_{M}}}} [ citation needed ]": {
    "before": "y is original output (GDP) {\\displaystyle b_{C}} is marginal propensity to consume (MPC) {\\displaystyle b_{T}} is original income tax rate {\\displaystyle b_{M}} is marginal propensity to import (MPI) {\\displaystyle \\Delta y} is change in income (equivalent to GDP) {\\displaystyle \\Delta G} is change in government spending {\\displaystyle \\Delta T} is change in aggregate taxesIncome tax multiplier [ edit ]",
    "after": "Note: only {\\displaystyle \\Delta b_{T}} is here because if this is a change in income tax rate then {\\displaystyle \\Delta a_{T}} is implied to be 0.",
    "url": "https://en.wikipedia.org/wiki/Fiscal multiplier"
  },
  "{\\displaystyle \\Delta y=\\Delta G*{\\frac {1}{1-b_{C}(1-b_{T}t)+b_{M}}}}": {
    "before": "Note: only {\\displaystyle \\Delta b_{T}} is here because if this is a change in income tax rate then {\\displaystyle \\Delta a_{T}} is implied to be 0.Government spending multiplier [ edit ]",
    "after": "Balanced-budget fiscal multiplier [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Fiscal multiplier"
  },
  "{\\displaystyle \\Delta y=\\Delta G*1=\\Delta T*1}": {
    "before": "{\\displaystyle \\Delta y=\\Delta G*{\\frac {1}{1-b_{C}(1-b_{T}t)+b_{M}}}} Balanced-budget fiscal multiplier [ edit ]",
    "after": "Estimated values [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Fiscal multiplier"
  },
  "{\\displaystyle Y=C\\left({Y}-{T(Y)}\\right)+I\\left({r}\\right)+G+NX(Y),}": {
    "before": "The IS curve also represents the equilibria where total private investment equals total saving, with saving equal to consumer saving plus government saving (the budget surplus) plus foreign saving (the trade surplus). The level of real GDP (Y) is determined along this line for each interest rate . Every level of the real interest rate will generate a certain level of investment and spending: lower interest rates encourage higher investment and more spending. The multiplier effect of an increase in fixed investment resulting from a lower interest rate raises real GDP. This explains the downward slope of the IS curve. In summary, the IS curve shows the causation from interest rates to planned fixed investment to rising national income and output.The IS curve is defined by the equation",
    "after": "where Y represents income, {\\displaystyle C(Y-T(Y))} represents consumer spending increasing as a function of disposable income (income, Y , minus taxes, T ( Y ), which themselves depend positively on income), {\\displaystyle I(r)} represents business investment decreasing as a function of the real interest rate, G represents government spending, and NX ( Y ) represents net exports (exports minus imports) decreasing as a function of income (decreasing because imports are an increasing function of income).",
    "url": "https://en.wikipedia.org/wiki/IS–LM model"
  },
  "For Example: if the railway coach company normally produced 40 coaches per month, and the fixed costs were still $1000/month, then each coach could be said to incur an Operating Cost/overhead of $25 =($1000 / 40). Adding this to the variable costs of $300 per coach produced a full cost of $325 per coach.": {
    "before": "Standard Costing is a technique of Cost Accounting to compare the actual costs with standard costs (that are pre-defined) with the help of Variance Analysis. It is used to understand the variations of product costs in manufacturing.  Standard costing allocates fixed costs incurred in an accounting period to the goods produced during that period. This allowed the full cost of products that were not sold in the period they were produced to be recorded as 'inventory' in the Balance sheet to be carried forward to the next accounting period, using a variety of complex accounting methods, which was consistent with the principles of GAAP (Generally Accepted Accounting Principles). It also essentially enabled managers to ignore the fixed costs, and look at the results of each period in relation to the \"standard cost\" for any given product.",
    "after": "This method tended to slightly distort the resulting unit cost, but in mass-production industries that made one product line, and where the fixed costs were relatively low, the distortion was very minor.",
    "url": "https://en.wikipedia.org/wiki/Cost accounting"
  },
  "For Example: if the railway coach company made 100 coaches one month, then the unit cost would become $310 per coach ($300 + ($1000 / 100)). If the next month the company made 50 coaches, then the unit cost = $320 per coach ($300 + ($1000 / 50)), a relatively minor difference.": {
    "before": "This method tended to slightly distort the resulting unit cost, but in mass-production industries that made one product line, and where the fixed costs were relatively low, the distortion was very minor.",
    "after": "An important part of standard cost accounting is a variance analysis , which breaks down the variation between actual cost and standard costs into various components (volume variation, material cost variation, labor cost variation, etc.) so managers can understand why costs were different from what was planned and take appropriate action to correct the situation.",
    "url": "https://en.wikipedia.org/wiki/Cost accounting"
  },
  "{\\displaystyle {\\text{throughput cost accounting ratio}}={\\frac {\\text{return}}{\\text{factory hours}}}} {\\displaystyle {\\text{throughput}}={\\text{sales}}-{\\text{material costs}}}": {
    "before": "\"Throughput\", in this context, refers to the amount of money obtained from sales minus the cost of materials that have gone into making them.Mathematical formulae [ edit ]",
    "after": "Activity-based costing [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Cost accounting"
  },
  "{\\displaystyle {\\text{Contribution Margin Ratio}}=({\\text{Sales - Variable Costs}})/{\\text{Sales}}}": {
    "before": "The contribution margin can also be expressed as a percentage. The contribution margin ratio, which is sometimes called the profit-volume ratio, indicates the percentage of each sales dollar available to cover fixed costs and to provide operating revenue. For the company Fusion, Inc. the contribution margin ratio is 40%, which is computed as follows:",
    "after": "The contribution margin ratio measures the effect on operating income of an increase or a decrease in sales volume. For example, assume that the management of Fusion, Inc. is studying the effect of adding $80,000 in sales orders. Multiplying the contribution margin ratio (40%) by the change in sales volume ($80,000) indicates that operating income will increase $32,000 if additional orders are obtained. To validate this analysis the table below shows the income statement of the company including additional orders:",
    "url": "https://en.wikipedia.org/wiki/Cost accounting"
  },
  "{\\displaystyle P=({\\frac {E*G}{K^{2}}})+({\\frac {D}{K}})}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Sum of perpetuities method"
  },
  "{\\displaystyle P=({\\frac {E*G}{K^{2}}})+({\\frac {D}{K}})} {\\displaystyle P=({\\frac {E*G}{0.10^{2}}})+0} {\\displaystyle P=E*G*100}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Sum of perpetuities method"
  },
  "I: {\\displaystyle E=X+D} II: {\\displaystyle G=({\\frac {X}{E}})*R} ": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Sum of perpetuities method"
  },
  "{\\displaystyle P={\\frac {E}{K}}={\\frac {D}{K}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Sum of perpetuities method"
  },
  "{\\displaystyle P={\\frac {E}{K}}={\\frac {(X+D)}{K}}={\\frac {X}{K}}+{\\frac {D}{K}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Sum of perpetuities method"
  },
  "{\\displaystyle P={\\frac {PVx}{K}}+{\\frac {D}{K}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Sum of perpetuities method"
  },
  "{\\displaystyle PVx={\\frac {X*R}{K}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Sum of perpetuities method"
  },
  "{\\displaystyle P={\\frac {\\frac {X*R}{K}}{K}}+{\\frac {D}{K}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Sum of perpetuities method"
  },
  "{\\displaystyle P={\\frac {E*G}{K^{2}}}+{\\frac {D}{K}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Sum of perpetuities method"
  },
  "FV = PV(1+i) n": {
    "before": "Assume you have a spaceship that can approach lightspeed and thus you can make, say 1,000 years, seem like 10 years. If you can gain the time value of money 100 times faster, that effectively makes the interest rate 100x higher for you. Thus time preference is meaningless. This is a problem for economic theory. Krugman's solution is to force the interest rate to correspond to the cost of making the trip.Here is the standard compound interest formula:",
    "after": "Fuel costs for the above trip are $X. Let us say you have $1,000 to invest and wonder whether it is worth taking a near-lightspeed voyage to increase your return 10 subjective years from now.",
    "url": "https://en.wikipedia.org/wiki/The Theory of Interstellar Trade"
  },
  "A = $1000(1 + i) 10": {
    "before": "Fuel costs for the above trip are $X. Let us say you have $1,000 to invest and wonder whether it is worth taking a near-lightspeed voyage to increase your return 10 subjective years from now.Stay on earth:",
    "after": "Take trip:B = ($1000(1 + i) 1000 ) – $X",
    "url": "https://en.wikipedia.org/wiki/The Theory of Interstellar Trade"
  },
  "B = ($1000(1 + i) 1000 ) – $X": {
    "before": "A = $1000(1 + i) 10Take trip:",
    "after": "Krugman says that it is necessarily true that A=B, for time preference theory to stay consistent; thus it will be driven by X. In the future, given a free market, spaceship fuel costs will be the primary determinant of interest rates. The less the fuel cost, the less the interest rate, and vice versa.",
    "url": "https://en.wikipedia.org/wiki/The Theory of Interstellar Trade"
  },
  "{\\displaystyle Y=AF(K,L)\\,} ,": {
    "before": "Hicks-neutral technical change is change in the production function of a business or industry which satisfies certain economic neutrality conditions. The concept of Hicks neutrality was first put forth in 1932 by John Hicks in his book The Theory of Wages .  A change is considered to be Hicks neutral if the change does not affect the balance of labor and capital in the products' production function . More formally, given the Solow model production function",
    "after": "a Hicks-neutral change is one which only changes {\\displaystyle A} . ",
    "url": "https://en.wikipedia.org/wiki/Hicks-neutral technical change"
  },
  "Average cost (AC) are total costs divided by output. AC = TFC/q + TVC/q": {
    "before": "Total fixed cost (TFC)",
    "after": "Average fixed cost (AFC) is equal to total fixed cost divided by output i.e. AFC = TFC/q. The average fixed cost function continuously declines as production increases.",
    "url": "https://en.wikipedia.org/wiki/Economic cost"
  },
  "Average variable cost (A.V.C) = variable costs divided by output. AVC =TVC/q. The average variable cost curve is typically U-shaped. It lies below the average cost curve and generally has the same shape - the vertical distance between the average cost curve and average variable cost curve equals average fixed costs. The curve normally starts to the right of the y axis because with zero production": {
    "before": "Average fixed cost (AFC) is equal to total fixed cost divided by output i.e. AFC = TFC/q. The average fixed cost function continuously declines as production increases.",
    "after": "Marginal cost (MC): Marginal cost is obtained from the additional cost that results from increasing output by one unit. It is the additional cost per additional unit of output.",
    "url": "https://en.wikipedia.org/wiki/Economic cost"
  },
  "{\\displaystyle FCF_{t}=OCB_{t}-I_{t}\\,}": {
    "before": "operating cash flow (OCF) less expenditures necessary to maintain assets ( capital expenditures or \"capex\") but this does not include increase in working capital. less interest charges.In symbols:",
    "after": "whereOCB t is the firm's net operating profit after taxes (Also known as NOPAT) during period t I t is the firm's investment during period t including variation of working capital",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "{\\displaystyle I_{t}=K_{t}-K_{t-1}\\,}": {
    "before": "Investment is simply the net increase (decrease) in the firm's capital, from the end of one period to the end of the next period:",
    "after": "where K t represents the firm's invested capital at the end of period t . Increases in non-cash current assets may, or may not be deducted, depending on whether they are considered to be maintaining the status quo, or to be investments for growth.",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "Element Source Net Profit Current Income Statement + Interest expense Current Income Statement - Net Capital Expenditure (CAPEX) Current Income Statement - Net changes in Working Capital Prior & Current Balance Sheets: Current Assets and Liability accounts - Tax shield on Interest Expense Current Income Statement = Free Cash Flow": {
    "before": "",
    "after": "Net Capital Expenditure (CAPEX) = Capex - Depreciation & Amortization Tax Shield = Net Interest Expense X Marginal Tax Rate",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "Prior & Current Balance Sheets: Property, Plant and Equipment accounts= Free Cash Flow": {
    "before": "- Capital expenditure (CAPEX)",
    "after": "Note that the first three lines above are calculated on the standard Statement of Cash Flows.",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "Balance Sheets, Cash Flow Statements= Free Cash Flow": {
    "before": "- Changes in Working Capital X (1-d)",
    "after": "where d - is the debt/equity ratio. e.g.: For a 3:4 mix it will be 3/7.",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "Prior & Current Balance Sheets= Cash Flows from Operations": {
    "before": "- Changes in Working Capital",
    "after": "same as Statement of Cash Flows: section 1, from Operations",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "Statement of Cash Flows: section 2, from Investment= Levered Free Cash Flow": {
    "before": "- Investment in Operating Capital",
    "after": "Difference with net income[edit]",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "Net Free Cash Flow = Operation Cash flow – Capital Expenses to keep current level of operation – dividends – Current Portion of long term debt – Depreciation": {
    "before": "The net free cash flow definition should also allow for cash available to pay off the company's short term debt. It should also take into account any dividends that the company means to pay.",
    "after": "Here Capex Definition should not include additional investment on new equipment. However maintenance cost can be added.",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "FCFF = After tax operating income + Noncash charges (such as D&A) - CAPEX - Working capital expenditures = Free cash flow to firm (FCFF)": {
    "before": "Investment bankers compute free cash flow using the following formulae:",
    "after": "FCFE = Net income + Noncash charges (such as D&A) - CAPEX - Change in non-cash working capital + Net borrowing = Free cash flow to equity (FCFE)",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "FCFE = Net income + Noncash charges (such as D&A) - CAPEX - Change in non-cash working capital + Net borrowing = Free cash flow to equity (FCFE)": {
    "before": "FCFF = After tax operating income + Noncash charges (such as D&A) - CAPEX - Working capital expenditures = Free cash flow to firm (FCFF)",
    "after": "Or simply:",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "FCFE = FCFF + Net borrowing - Interest*(1-t)": {
    "before": "Or simply:",
    "after": "Uses[edit]",
    "url": "https://en.wikipedia.org/wiki/Free cash flow"
  },
  "{\\displaystyle c={\\frac {d\\ln \\left(\\displaystyle {\\frac {df}{dx_{1}}}/\\displaystyle {\\frac {df}{dx_{2}}}\\right)}{d\\ln(x_{2}/x_{1})}}={\\frac {\\displaystyle {\\frac {d({\\frac {df}{dx_{1}}}/{\\frac {df}{dx_{2}}})}{{\\frac {df}{dx_{1}}}/{\\frac {df}{dx_{2}}}}}}{\\displaystyle {\\frac {d(x_{2}/x_{1})}{x_{2}/x_{1}}}}}.}": {
    "before": "Given the production function {\\displaystyle f(x_{1},x_{2})} then the elasticity of complementarity is defined as",
    "after": "The inverse of elasticity of complementarity is elasticity of substitution .",
    "url": "https://en.wikipedia.org/wiki/Elasticity of complementarity"
  },
  "{\\displaystyle E[w_{0}\\mid \\mathrm {Immigrate} ]=a_{0}+\\rho s_{0}\\left({\\frac {\\phi ({v})}{1-\\phi ({v})}}\\right)} (1)": {
    "before": "George Borjas was the first to formalize the model of Roy in a mathematical sense and apply it to self-selection in immigration . Specifically, assume source country 0 and destination country 1, with log earnings in a country i given by w i = a i + e i , where e i ∼N(0, {\\displaystyle s_{i}^{2}} ) . Additionally, assume there is a cost C associated with migrating from country 0 to country 1 and workers know all parameters and their own realization of e 0 and e 1 . Borjas then uses the implications of the Roy model to infer something about what wages for immigrants in country 1 would have been had they stayed in country 0 and what wages for non-immigrants in country 0 would have been had they migrated. The third, and final, element needed for this is the correlation between the wages in the two countries, ρ . A worker will choose to immigrate if {\\displaystyle a_{1}-a_{0}-C+e_{1}-e_{0}>0} which will happen with probability 1-Φ(v) where v is {\\displaystyle {\\frac {-(a_{1}-a_{0}-{C})}{s_{v}}}} , s v is the standard deviation of e 1 – e 0 , and Φ is the standard normal cdf.  This leads to the famous central result that the expected wage for immigrants depends on the selection mechanism, as shown in equation (1), where ϕ is the standard normal pdf and, like before, Φ is the standard normal cdf.",
    "after": "While Borjas was the first to mathematically formalize the Roy model, it has guided thinking in other fields of research as well. A famous example by James Heckman and Bo Honoré who study labor market participation using the Roy model, where the choice equation leads to the Heckman correction procedure.  More generally, Heckman and Vytlacil propose the Roy model as an alternative to the LATE framework proposed by Joshua Angrist and Guido Imbens .  ",
    "url": "https://en.wikipedia.org/wiki/Roy model"
  },
  "assets = liabilities + equity": {
    "before": "Double-entry bookkeeping is governed by the accounting equation . If revenue equals expenses, the following (basic) equation must be true:",
    "after": "For the accounts to remain in balance, a change in one account must be matched with a change in another account. These changes are made by debits and credits to the accounts. Note that the usage of these terms in accounting is not identical to their everyday usage. Whether one uses a debit or credit to increase or decrease an account depends on the normal balance of the account. Assets, Expenses, and Drawings accounts (on the left side of the equation) have a normal balance of debit . Liability, Revenue, and Capital accounts (on the right side of the equation) have a normal balance of credit . On a general ledger , debits are recorded on the left side and credits on the right side for each account. Since the accounts must always balance, for each transaction there will be a debit made to one or several accounts and a credit made to one or several accounts. The sum of all debits made in each day's transactions must equal the sum of all credits in those transactions. After a series of transactions, therefore, the sum of all the accounts with a debit balance will equal the sum of all the accounts with a credit balance.",
    "url": "https://en.wikipedia.org/wiki/Double-entry bookkeeping"
  },
  "current equity = sum of equity changes across time (increases on the left side are debits, and increases on the right side are credits, and vice versa for decreases)": {
    "before": "The account types are related as follows:",
    "after": "current equity = Assets – Liabilities",
    "url": "https://en.wikipedia.org/wiki/Double-entry bookkeeping"
  },
  "current equity = Assets – Liabilities": {
    "before": "current equity = sum of equity changes across time (increases on the left side are debits, and increases on the right side are credits, and vice versa for decreases)",
    "after": "sum of equity changes across time = owner's investment (Capital above) + Revenues – Expenses",
    "url": "https://en.wikipedia.org/wiki/Double-entry bookkeeping"
  },
  "sum of equity changes across time = owner's investment (Capital above) + Revenues – Expenses": {
    "before": "current equity = Assets – Liabilities",
    "after": "See also[edit]",
    "url": "https://en.wikipedia.org/wiki/Double-entry bookkeeping"
  },
  "Sales - Cost of Sales = Gross Profit": {
    "before": "Primary formula[edit]",
    "after": "Cost of sales[edit]",
    "url": "https://en.wikipedia.org/wiki/Trading statement"
  },
  "Sales = Sales for the year - Returns in (Goods that were returned to the entity during the course of the year)": {
    "before": "Sales calculation:",
    "after": "Sales = £14500 - £1400",
    "url": "https://en.wikipedia.org/wiki/Trading statement"
  },
  "Therefore, Cost of sales = Goods available for sale - Closing inventory": {
    "before": "(£2000)",
    "after": "Cost of sales = £13520 - £2000",
    "url": "https://en.wikipedia.org/wiki/Trading statement"
  },
  "Gross profit = Sales - Cost of sales": {
    "before": "Gross profit calculation:",
    "after": "Gross profit = £13100 - £11520",
    "url": "https://en.wikipedia.org/wiki/Trading statement"
  },
  "{\\displaystyle u(x_{1},x_{2})=\\min(x_{1},x_{2})}": {
    "before": "2. Consider an economy with two commodity types, 1 and 2. Consider a preference relation represented by the following Leontief utility function :",
    "after": "This preference relation is convex. Proof : suppose x and y are two equivalent bundles, i.e. {\\displaystyle \\min(x_{1},x_{2})=\\min(y_{1},y_{2})} . If the minimum-quantity commodity in both bundles is the same (e.g. commodity 1), then this implies {\\displaystyle x_{1}=y_{1}\\leq x_{2},y_{2}} . Then, any weighted average also has the same amount of commodity 1, so any weighted average is equivalent to {\\displaystyle x} and {\\displaystyle y} . If the minimum commodity in each bundle is different (e.g. {\\displaystyle x_{1}\\leq x_{2}} but {\\displaystyle y_{1}\\geq y_{2}} ), then this implies {\\displaystyle x_{1}=y_{2}\\leq x_{2},y_{1}} . Then {\\displaystyle \\theta x_{1}+(1-\\theta )y_{1}\\geq x_{1}} and {\\displaystyle \\theta x_{2}+(1-\\theta )y_{2}\\geq y_{2}} , so {\\displaystyle \\theta x+(1-\\theta )y\\succeq x,y} . This preference relation is convex, but not strictly-convex.",
    "url": "https://en.wikipedia.org/wiki/Convex preferences"
  },
  "{\\displaystyle u(x_{1},x_{2})=\\max(x_{1},x_{2})}": {
    "before": "3. A preference relation represented by linear utility functions is convex, but not strictly convex. Whenever {\\displaystyle x\\sim y} , every convex combination of {\\displaystyle x,y} is equivalent to any of them.4. Consider a preference relation represented by:",
    "after": "This preference relation is not convex. Proof : let {\\displaystyle x=(3,5)} and {\\displaystyle y=(5,3)} . Then {\\displaystyle x\\sim y} since both have utility 5. However, the convex combination {\\displaystyle 0.5x+0.5y=(4,4)} is worse than both of them since its utility is 4.",
    "url": "https://en.wikipedia.org/wiki/Convex preferences"
  },
  "Use x and y to denote two consumption bundles. A preference relation {\\displaystyle \\succeq } is called convex if for any": {
    "before": "",
    "after": "{\\displaystyle x,y\\in X} where {\\displaystyle y\\succeq x}",
    "url": "https://en.wikipedia.org/wiki/Convex preferences"
  },
  "{\\displaystyle Y_{1}=F_{1}(K,L)\\,}": {
    "before": "If good 1 is an investment good governed by the equation",
    "after": "and good 2 be a consumption good governed by the equation",
    "url": "https://en.wikipedia.org/wiki/Harrod–Johnson diagram"
  },
  "{\\displaystyle Y_{s}=F_{s}(K,L)\\,} ,": {
    "before": "and good 2 be a consumption good governed by the equation",
    "after": "then rental and wage rates can be calculated by optimizing a representative firm's profit function, giving",
    "url": "https://en.wikipedia.org/wiki/Harrod–Johnson diagram"
  },
  "{\\displaystyle p_{1}D_{K}[F_{1}(K,L)]=r=p_{2}D_{K}[F_{2}(K,L)]\\,}": {
    "before": "then rental and wage rates can be calculated by optimizing a representative firm's profit function, giving",
    "after": "for the rental rate of capital, r , and",
    "url": "https://en.wikipedia.org/wiki/Harrod–Johnson diagram"
  },
  "{\\displaystyle p_{1}D_{L}[F_{1}(K,L)]=w=p_{2}D_{L}[F_{2}(K,L)]\\,}": {
    "before": "{\\displaystyle p_{1}D_{K}[F_{1}(K,L)]=r=p_{2}D_{K}[F_{2}(K,L)]\\,} for the rental rate of capital, r , and",
    "after": "for the wage rate of labor, w , so the input price ratio, {\\displaystyle \\omega } , is",
    "url": "https://en.wikipedia.org/wiki/Harrod–Johnson diagram"
  },
  "{\\displaystyle \\omega =w/r={\\frac {p_{i}D_{L}[F_{i}(K,L)],p_{i}D_{K}[F_{i}(K,L)]}{\\,}}} for {\\displaystyle i=\\{1,2\\}.}": {
    "before": "for the wage rate of labor, w , so the input price ratio, {\\displaystyle \\omega } , is",
    "after": "Normalizing this equation by letting {\\displaystyle k_{i}=K_{i}/L_{i}} , and solving for {\\displaystyle k_{i},} provides the formulas to be graphed in the first quadrant.",
    "url": "https://en.wikipedia.org/wiki/Harrod–Johnson diagram"
  },
  "{\\displaystyle p_{1}D_{K}[F_{1}(K,L)]=p_{2}D_{K}[F_{2}(K,L)]} (or {\\displaystyle p_{1}D_{L}[F_{1}(K,L)]=p_{2}D_{L}[F_{2}(K,L)]\\,} , which is presumably equivalent),": {
    "before": "Normalizing this equation by letting {\\displaystyle k_{i}=K_{i}/L_{i}} , and solving for {\\displaystyle k_{i},} provides the formulas to be graphed in the first quadrant.On the other hand, normalizing the equation",
    "after": "and solving for the price ratio, {\\displaystyle p_{1}/P_{2},} provides the formula which is to be graphed in the fourth quadrant. Graphing these three functions together shows the relationship.",
    "url": "https://en.wikipedia.org/wiki/Harrod–Johnson diagram"
  },
  "{\\textstyle PMV=N\\times P}": {
    "before": "More specifically, the post-money valuation of a financial investment deal is given by the formula",
    "after": ", where PMV is the post-money valuation, N is the number of shares the company has after the investment, and P is the price per share at which the investment was made. This formula is similar to the market capitalization formula used to express the value of public companies.",
    "url": "https://en.wikipedia.org/wiki/Post-money valuation"
  },
  "There is a widely recognised production function in economics: Q= f(NR, L, K, t, E):": {
    "before": "Production function[edit]",
    "after": "The point of diminishing returns can be realised, by use of the second derivative in the above production function.",
    "url": "https://en.wikipedia.org/wiki/Diminishing returns"
  },
  "Which can be simplified to: Q= f(L,K).": {
    "before": "The point of diminishing returns can be realised, by use of the second derivative in the above production function.",
    "after": "This signifies that output (Q) is dependent on a function of all variable (L) and fixed (K) inputs in the production process. This is the basis to understand. What is important to understand after this is the math behind Marginal Product. MP= ΔTP/ ΔL. ",
    "url": "https://en.wikipedia.org/wiki/Diminishing returns"
  },
  "{\\displaystyle Y=Y^{d}({\\tfrac {M}{P}},G,T,Z_{1})}": {
    "before": "The equation for the AD curve in general terms is:",
    "after": "where Y is real GDP , M is the nominal money supply , P is the price level , G is real government spending , T is real taxes levied, and Z 1 other variables that affect the location of the IS curve (any component of spending) or the LM curve (influences on money demand). The real money supply has a positive effect on aggregate demand, as does real government spending; taxation has a negative effect on it.",
    "url": "https://en.wikipedia.org/wiki/AD–AS model"
  },
  "{\\displaystyle Y=Y^{s}(W/P,\\ \\ P/P^{e},\\ \\ Z_{2})}": {
    "before": "The equation for the aggregate supply curve in general terms for the case of excess supply in the labor market, called the short-run aggregate supply curve, is",
    "after": "where W is the nominal wage rate (exogenous due to stickiness in the short run), P e is the anticipated (expected) price level, and Z 2 is a vector of exogenous variables that can affect the position of the labor demand curve (the capital stock or the current state of technological knowledge). The real wage has a negative effect on firms' employment of labor and hence on aggregate supply. The price level relative to its expected level has a positive effect on aggregate supply because of firms' mistakes in production plans due to mis-predictions of prices.",
    "url": "https://en.wikipedia.org/wiki/AD–AS model"
  },
  "{\\displaystyle Y=Y^{s}(Z_{2})}": {
    "before": "The long-run aggregate supply curve refers not to a time frame in which the capital stock is free to be set optimally (as would be the terminology in the micro-economic theory of the firm ), but rather to a time frame in which wages are free to adjust in order to equilibrate the labor market and in which price anticipations are accurate. In this case the nominal wage rate is endogenous and so does not appear as an independent variable in the aggregate supply equation. The long-run aggregate supply equation is simply",
    "after": "and is vertical at the full-employment level of output. In this long-run case, Z 2 also includes factors affecting the position of the labor supply curve (such as population), since in labor market equilibrium the location of labor supply affects the labor market outcome.",
    "url": "https://en.wikipedia.org/wiki/AD–AS model"
  },
  "{\\displaystyle STC=P_{K}\\cdot K+P_{L}\\cdot L} ,": {
    "before": "The average total cost curve is constructed to capture the relation between cost per unit of output and the level of output , ceteris paribus . A perfectly competitive and productively efficient firm organizes its factors of production in such a way that the usage of the factors of production is as low as possible consistent with the given level of output to be produced. In the short run , when at least one factor of production is fixed, this occurs at the output level where it has enjoyed all possible average cost gains from increasing production. This is at the minimum point in the above diagram.Short-run total cost is given by",
    "after": "where P K is the unit price of using physical capital per unit time, P L is the unit price of labor per unit time (the wage rate), K is the quantity of physical capital used, and L is the quantity of labor used. From this we obtain short-run average cost, denoted either SATC or SRAC, as STC / Q:",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "{\\displaystyle SRATC\\ or\\ SRAC={\\frac {P_{K}\\cdot K}{Q}}+{\\frac {P_{L}\\cdot L}{Q}}={\\frac {P_{K}\\cdot P_{K}}{A}}+{\\frac {P_{L}\\cdot P_{L}}{A}}} ,": {
    "before": "where P K is the unit price of using physical capital per unit time, P L is the unit price of labor per unit time (the wage rate), K is the quantity of physical capital used, and L is the quantity of labor used. From this we obtain short-run average cost, denoted either SATC or SRAC, as STC / Q:",
    "after": "where {\\textstyle AP_{K}={\\frac {Q}{K}}} is the average product of capital and {\\textstyle AP_{L}={\\frac {Q}{L}}} is the average product of labor.  : 191",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "SR = short run (costs spent on non-reusable materials e.g raw materials)": {
    "before": "There are standard acronyms for each cost concept, expressed in terms of the following descriptors:",
    "after": "LR = long-run (cost spent on renewable materials e.g equipment)",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "LR = long-run (cost spent on renewable materials e.g equipment)": {
    "before": "SR = short run (costs spent on non-reusable materials e.g raw materials)",
    "after": "A = average (per unit of output)",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "A = average (per unit of output)": {
    "before": "LR = long-run (cost spent on renewable materials e.g equipment)",
    "after": "M = marginal (for an additional unit of output)",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "M = marginal (for an additional unit of output)": {
    "before": "A = average (per unit of output)",
    "after": "F = fixed (unadjustable)",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "F = fixed (unadjustable)": {
    "before": "M = marginal (for an additional unit of output)",
    "after": "V = variable (adjustable)",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "V = variable (adjustable)": {
    "before": "F = fixed (unadjustable)",
    "after": "T = total (fixed plus variable)",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "T = total (fixed plus variable)": {
    "before": "V = variable (adjustable)",
    "after": "C = cost",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "C = cost": {
    "before": "T = total (fixed plus variable)",
    "after": "These can be combined in various ways to express different cost concepts (with SR and LR often omitted when the context is clear): one from the first group (SR or LR); none or one from the second group (A, M, or none (meaning “level”); none or one from the third group (F, V, or T); and the fourth item (C).",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "Total Cost = Fixed Costs (FC) + Variable Costs (VC) = Average Total Cost (ATC) x Quantity (Q)": {
    "before": "Relationship between different curves[edit]",
    "after": "Marginal Cost (MC) = dC/dQ; MC equals the slope of the total cost function and of the variable cost function",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "Marginal Cost (MC) = dC/dQ; MC equals the slope of the total cost function and of the variable cost function": {
    "before": "Total Cost = Fixed Costs (FC) + Variable Costs (VC) = Average Total Cost (ATC) x Quantity (Q)",
    "after": "Average Total Cost (ATC) = Total Cost/Q",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "Average Total Cost (ATC) = Total Cost/Q": {
    "before": "Marginal Cost (MC) = dC/dQ; MC equals the slope of the total cost function and of the variable cost function",
    "after": "Average Fixed Cost (AFC) = FC/Q",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "Average Fixed Cost (AFC) = FC/Q": {
    "before": "Average Total Cost (ATC) = Total Cost/Q",
    "after": "Average Variable Cost (AVC) = VC/Q.",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "Average Variable Cost (AVC) = VC/Q.": {
    "before": "Average Fixed Cost (AFC) = FC/Q",
    "after": "ATC = AFC + AVC",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "ATC = AFC + AVC": {
    "before": "Average Variable Cost (AVC) = VC/Q.",
    "after": "At a level of Q at which the MC curve is above the average total cost or average variable cost curve, the latter curve is rising.: 212",
    "url": "https://en.wikipedia.org/wiki/Cost curve"
  },
  "{\\displaystyle MPS={\\frac {\\text{Change in Savings}}{\\text{Change in Income}}}}": {
    "before": "MPS can be calculated as the change in savings divided by the change in income.",
    "after": "Or mathematically, the marginal propensity to save (MPS) function is expressed as the derivative of the savings (S) function with respect to disposable income (Y).",
    "url": "https://en.wikipedia.org/wiki/Marginal propensity to save"
  },
  "{\\displaystyle MPS={\\frac {dS}{dY}}} where, dS=Change in Savings and dY=Change in income.": {
    "before": "Or mathematically, the marginal propensity to save (MPS) function is expressed as the derivative of the savings (S) function with respect to disposable income (Y).",
    "after": "  Value [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Marginal propensity to save"
  },
  "{\\displaystyle Multiplier={\\frac {1}{1-[MPC(1-T)-MPI]}}}": {
    "before": "This section incorporates automatic stabilization into a broadly Keynesian multiplier model.",
    "after": "MPC = Marginal propensity to consume (fraction of incremental income spent on domestic consumption) T = Marginal (induced) tax rate (fraction of incremental income that is paid in taxes) MPI = Marginal Propensity to Import (fraction of incremental income spent on imports)",
    "url": "https://en.wikipedia.org/wiki/Automatic stabilizer"
  },
  "State Council = Central People's Government (constitutionally since 1954)": {
    "before": "Cryptography(☭ Leading Group)",
    "after": "☭ denotes name reserved by Communist Party agencies.",
    "url": "https://en.wikipedia.org/wiki/National Audit Office (China)"
  },
  "Assets = Equity + Liabilities,  A = E + L.": {
    "before": "Each transaction that takes place within the business will consist of at least one debit to a specific account and at least one credit to another specific account. A debit to one account can be balanced by more than one credit to other accounts, and vice versa. For all transactions, the total debits must be equal to the total credits and therefore balance .The general accounting equation is as follows:",
    "after": "The equation thus becomes A – L – E = 0 (zero). When the total debits equals the total credits for each account, then the equation balances.",
    "url": "https://en.wikipedia.org/wiki/Debits and credits"
  },
  "Assets + Expenses = Equity/Capital + Liabilities + Income, A + Ex = E + L + I.": {
    "before": "The equation thus becomes A – L – E = 0 (zero). When the total debits equals the total credits for each account, then the equation balances.The extended accounting equation is as follows:",
    "after": "In this form, increases to the amount of accounts on the left-hand side of the equation are recorded as debits, and decreases as credits. Conversely for accounts on the right-hand side, increases to the amount of accounts are recorded as credits to the account, and decreases as debits.",
    "url": "https://en.wikipedia.org/wiki/Debits and credits"
  },
  "Assets = Liabilities + Equity/Capital + (Income − Expenses), A = L + E + (I − Ex),": {
    "before": "This can also be rewritten in the equivalent form:",
    "after": "where the relationship of the Income and Expenses accounts to Equity and profit is a bit clearer.  Here Income and Expenses are regarded as temporary or nominal accounts which pertain only to the current accounting period whereas Asset, Liability, and Equity accounts are permanent or real accounts pertaining to the lifetime of the business.  The temporary accounts are closed to the Equity account at the end of the accounting period to record profit/loss for the period. Both sides of these equations must be equal (balance).",
    "url": "https://en.wikipedia.org/wiki/Debits and credits"
  },
  "A = E + L, 500 = 0 + 500 (the accounting equation is therefore balanced).": {
    "before": "The journal entry \"ABC Computers\" is indented to indicate that this is the credit transaction. It is accepted accounting practice to indent credit transactions recorded within a journal.In the accounting equation form:",
    "after": "Further examples [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Debits and credits"
  },
  "{\\displaystyle \\ \\epsilon =\\left[{\\frac {\\partial (slope)}{\\partial (L/K)}}{\\frac {L/K}{slope}}\\right]^{-1}}": {
    "before": "The elasticity of substitution between factors of production is a measure of how easily one factor can be substituted for another. With two factors of production, say, K and L , it is a measure of the curvature of a production isoquant . The mathematical definition is:",
    "after": "where \"slope\" denotes the slope of the isoquant, given by",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle \\ slope=-{\\frac {\\partial F(K,L)/\\partial K}{\\partial F(K,L)/\\partial L}}.}": {
    "before": "where \"slope\" denotes the slope of the isoquant, given by",
    "after": "Returns to scale [ edit ]",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle Y=A[\\alpha K^{\\gamma }+(1-\\alpha )L^{\\gamma }]^{\\frac {1}{\\gamma }}} , with {\\displaystyle \\gamma \\in [-\\infty ,1]}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "Linear production (or perfect substitutes) {\\displaystyle \\ Y=A[\\alpha K+(1-\\alpha )L]} when {\\displaystyle \\ \\gamma =1} Cobb–Douglas production function (or imperfect complements) {\\displaystyle \\ Y=AK^{\\alpha }L^{1-\\alpha }} when {\\displaystyle \\gamma \\to 0} Leontief production function (or perfect complements) {\\displaystyle \\ Y={\\text{Min}}[K,L]} when {\\displaystyle \\gamma \\to -\\infty }": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle \\ Y=A[\\alpha K+(1-\\alpha )L]} when {\\displaystyle \\ \\gamma =1}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle \\ Y=AK^{\\alpha }L^{1-\\alpha }} when {\\displaystyle \\gamma \\to 0}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle \\ Y={\\text{Min}}[K,L]} when {\\displaystyle \\gamma \\to -\\infty }": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle \\ln(Y)=\\ln(A)+a_{L}\\ln(L)+a_{K}\\ln(K)+b_{LL}\\ln ^{2}(L)+b_{LK}\\ln(L)\\ln(K)+b_{KK}\\ln ^{2}(K)}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle Y=A\\prod _{i=1}^{n}(x_{i}-z_{i})^{\\alpha _{i}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle Y=AK^{av}[L+baK]^{(1-a)v}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle Y=Ae^{a_{1}K+a_{2}L}K^{1-b}L^{b}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle Y=AK^{\\alpha }L^{1-\\alpha }-mL}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle y=m-A\\prod _{i=1}^{n}a_{i}^{x_{i}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle Y=\\min\\{Y^{*},\\beta _{1}+\\beta _{2}L,\\beta _{2}+\\beta _{4}K\\}} where {\\displaystyle Y^{*}} is the maximal yield (considers capacity limits).": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/List of production functions"
  },
  "{\\displaystyle Q(P)=3P-6} , and": {
    "before": "1) linear supply function, e.g., the slanted line",
    "after": "2) the constant- elasticity  supply function (also called isoelastic or log-log or loglinear supply function), e.g., the smooth curve",
    "url": "https://en.wikipedia.org/wiki/Supply and demand"
  },
  "{\\displaystyle Q(P)=5P^{0.5}}": {
    "before": "2) the constant- elasticity  supply function (also called isoelastic or log-log or loglinear supply function), e.g., the smooth curve",
    "after": "which can be rewritten as",
    "url": "https://en.wikipedia.org/wiki/Supply and demand"
  },
  "{\\displaystyle \\log Q(P)=\\log 5+0.5\\log P}": {
    "before": "{\\displaystyle Q(P)=5P^{0.5}} which can be rewritten as",
    "after": "By its very nature, the concept of a supply curve assumes that firms are perfect competitors , having no influence over the market price. This is because each point on the supply curve answers the question, \"If this firm is faced with this potential price, how much output will it sell?\" If a firm has market power—in violation of the perfect competitor model—its decision on how much output to bring to market influences the market price. Thus the firm is not \"faced with\" any given price, and a more complicated model, e.g., a monopoly or oligopoly or differentiated-product model, should be used.",
    "url": "https://en.wikipedia.org/wiki/Supply and demand"
  },
  "{\\displaystyle Q(P)=32-2P}": {
    "before": "Mathematically, a demand curve is represented by a demand function, giving the quantity demanded as a function of its price and as many other variables as desired to better explain quantity demanded. The two most common specifications are linear demand, e.g., the slanted line",
    "after": "and the constant- elasticity demand function (also called isoelastic or log-log or loglinear demand function), e.g., the smooth curve",
    "url": "https://en.wikipedia.org/wiki/Supply and demand"
  },
  "{\\displaystyle Q(P)=3P^{-2}}": {
    "before": "and the constant- elasticity demand function (also called isoelastic or log-log or loglinear demand function), e.g., the smooth curve",
    "after": "which can be rewritten as",
    "url": "https://en.wikipedia.org/wiki/Supply and demand"
  },
  "{\\displaystyle \\log Q(P)=\\log 3-2\\log P}": {
    "before": "{\\displaystyle Q(P)=3P^{-2}} which can be rewritten as",
    "after": "Note that really a demand curve should be drawn with price on the horizontal x -axis, since it is the independent variable. Instead, price is put on the vertical, f(x) y -axis as a matter of unfortunate historical convention.",
    "url": "https://en.wikipedia.org/wiki/Supply and demand"
  },
  "I = P × A × T": {
    "before": "Earth's energy budget",
    "after": "Kaya identity",
    "url": "https://en.wikipedia.org/wiki/Demand"
  },
  "{\\displaystyle {\\dot {c}}(t)={\\frac {1}{\\sigma }}\\cdot (r-\\rho )\\cdot c(t)}": {
    "before": "In macroeconomics , the Keynes–Ramsey rule is a necessary condition for the optimality of intertemporal consumption choice.  Usually it is expressed as a differential equation relating the rate of change of consumption with interest rates , time preference , and (intertemporal) elasticity of substitution . If derived from a basic Ramsey–Cass–Koopmans model , the Keynes–Ramsey rule may look like",
    "after": "where {\\displaystyle c(t)} is consumption and {\\displaystyle {\\dot {c}}(t)} its change over time (in Newton notation ), {\\displaystyle \\rho \\in (0,1)} is the discount rate , {\\displaystyle r\\in (0,1)} is the real interest rate , and {\\displaystyle \\sigma >0} is the (intertemporal) elasticity of substitution . ",
    "url": "https://en.wikipedia.org/wiki/Keynes–Ramsey rule"
  },
  "{\\displaystyle p\\cdot \\pi =p\\cdot Y^{S}-w\\cdot L^{D}}": {
    "before": "In nominal terms the profit function is:",
    "after": "In real terms this becomes:",
    "url": "https://en.wikipedia.org/wiki/Classical general equilibrium model"
  },
  "{\\displaystyle \\pi =Y^{S}-{\\frac {w}{p}}\\cdot L^{D}=Y^{S}-\\omega \\cdot L^{D}}": {
    "before": "In real terms this becomes:",
    "after": "Firms' optimal (profit maximizing) condition [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Classical general equilibrium model"
  },
  "{\\displaystyle {\\frac {dY^{S}(L^{D})}{dL^{D}}}=\\omega }": {
    "before": "In an attempt to achieve an optimal situation, firms can maximize profits with this Maximized profit function :",
    "after": "When functions are given, Labor Demand (L D ) can be derived from this equation.",
    "url": "https://en.wikipedia.org/wiki/Classical general equilibrium model"
  },
  "{\\displaystyle Y^{D}=\\pi +\\omega \\cdot L^{S}}": {
    "before": "Consumption constraint = profit income + wage income",
    "after": "Households' utility function [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Classical general equilibrium model"
  },
  "profit = revenue - cost": {
    "before": "Generally a firm's profit is calculated as:",
    "after": "In nominal terms the profit function is:",
    "url": "https://en.wikipedia.org/wiki/Classical general equilibrium model"
  },
  "total utility = utility from consumption - disutility from work": {
    "before": "Households' utility function[edit]",
    "after": "{\\displaystyle U=Y^{D}-D(L^{S})}",
    "url": "https://en.wikipedia.org/wiki/Classical general equilibrium model"
  },
  "Y = C + I + G": {
    "before": "Aggregate demand[edit]",
    "after": "whereby Y is output, C is consumption, I is investment and G is government spending",
    "url": "https://en.wikipedia.org/wiki/Classical general equilibrium model"
  },
  "MV=PY(Fisher's Equation of Exchange)": {
    "before": "Monetary market[edit]",
    "after": "References[edit]",
    "url": "https://en.wikipedia.org/wiki/Classical general equilibrium model"
  },
  "That is, [IS = C + I + G +Nx(Q)]. In this case, net exports is dependent on Q (as Q goes up, foreign countries' goods are relatively more expensive, and home countries' goods are cheaper, therefore there are higher net exports).": {
    "before": "The first assumption is essentially saying that the IS curve (demand for goods) position is in some way dependent on the real effective exchange rate Q.",
    "after": "Assumption 2:",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " r = r* +Δse (uncovered interest rate parity - approximation)": {
    "before": "Formal Notation",
    "after": " Δse = θ(ŝ – s) (Expectations of market participants)",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " Δse = θ(ŝ – s) (Expectations of market participants)": {
    "before": " r = r* +Δse (uncovered interest rate parity - approximation)",
    "after": " m - p = ky-lr (Demand/Supply on money)",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " m - p = ky-lr (Demand/Supply on money)": {
    "before": " Δse = θ(ŝ – s) (Expectations of market participants)",
    "after": " yd = h(s-p) = h(q) (demand for the home country output)",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " yd = h(s-p) = h(q) (demand for the home country output)": {
    "before": " m - p = ky-lr (Demand/Supply on money)",
    "after": " þ = π(yd- ŷ)(proportional change in prices with respect to time) dP/dTime",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " þ = π(yd- ŷ)(proportional change in prices with respect to time) dP/dTime": {
    "before": " yd = h(s-p) = h(q) (demand for the home country output)",
    "after": "From the above can be derived the following (using algebraic substitution)",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " p - p_hat = - lθ(ŝ - s)": {
    "before": "From the above can be derived the following (using algebraic substitution)",
    "after": " þ = π[h(s-p) - ŷ]",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " þ = π[h(s-p) - ŷ]": {
    "before": " p - p_hat = - lθ(ŝ - s)",
    "after": "In equilibrium",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  "yd = ŷ (demand for output equals the long run demand for output)": {
    "before": "In equilibrium",
    "after": "from this substitution shows that",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " ŷ/h = ŝ - p_hat": {
    "before": "from this substitution shows that",
    "after": "That is, in the long run, the only variable that affects the real exchange rate is growth in capacity output.",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  "Δse = 0 (that is, in the long run the expected change of inflection is equal to zero)": {
    "before": "Also,",
    "after": "Substituting into  yields r = r*.",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  "Substituting into  yields r = r*.": {
    "before": "Δse = 0 (that is, in the long run the expected change of inflection is equal to zero)",
    "after": "Substituting that into  shows:",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " p_hat = m -kŷ + l r*": {
    "before": "Substituting that into  shows:",
    "after": "taking  &  together:",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " ŝ = ŷ(h−1 - k) + m +lr*": {
    "before": "taking  &  together:",
    "after": "comparing  & , it is clear that the only difference between them is the intercept (that is the slope of both is the same). This reveals that given a rise in money stock pushes up the long run values of both in equally proportional measures, the real exchange rate (q) must remain at the same value as it was before the market shock. Therefore, the properties of the model at the beginning are preserved in long run equilibrium, the original equilibrium was stable.",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  "In equilibrium  implies 0 = π[h(ŝ-p_hat) - ŷ]": {
    "before": "The standard approach is to rewrite the basic equations  &  in terms of the deviation from the long run equilibrium).",
    "after": "Subtracting this from  yields",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " þ = π[h(q-q_hat)": {
    "before": "Subtracting this from  yields",
    "after": "The rate of exchange is positive whenever the real exchange rate is above its equilibrium level, also it is moving towards the equilibrium level] - This yields the direction and movement of the exchange rate.",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  " p - p_hat = -lθ(s-ŝ)": {
    "before": "→←←",
    "after": "This shows the line upon which the exchange rate must be moving (the line with slope -lθ).",
    "url": "https://en.wikipedia.org/wiki/Overshooting model"
  },
  "{\\displaystyle x={e^{-t} \\over (1+e^{-t})^{2}}={1 \\over 2+2\\cosh t}={1 \\over 4}\\operatorname {sech} ^{2}{t \\over 2}.}": {
    "before": "The prototypical Hubbert curve is a probability density function of a logistic distribution curve. It is not a gaussian function (which is used to plot normal distributions ), but the two have a similar appearance. The density of a Hubbert curve approaches zero more slowly than a gaussian function:",
    "after": "The graph of a Hubbert curve consists of three key elements:",
    "url": "https://en.wikipedia.org/wiki/Hubbert curve"
  },
  "2 kg of unobtainium at € 60 per kg ( = € 120 per unit).": {
    "before": "Let us assume that standard direct material cost of widget is as follows:",
    "after": "Let us assume further that during given period, 100 widgets were manufactured, using 212 kg of unobtainium which cost € 13,144.",
    "url": "https://en.wikipedia.org/wiki/Direct material usage variance"
  },
  "1 t = (1/0.907) short tons = 1.102 short tons.": {
    "before": "kilogram (kg), the standard SI unit of mass. tonne (t), a non- SI but an accepted metric unit, defined as 1,000 kilograms . \" short ton \" is used in the US; 1 short ton = 2,000 pounds = 0.907 tonnes.",
    "after": "Payload-distance [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Units of measurement in transportation"
  },
  "the international statute mile (mi) is used in the US; 1 mi = 1.609344 km": {
    "before": "kilometre (km) or kilometer is a metric unit used, outside the US, to measure the length of a journey;",
    "after": "nautical mile is rarely used to derive units of transportation quantity.",
    "url": "https://en.wikipedia.org/wiki/Units of measurement in transportation"
  },
  "passenger-mile (or pmi ?) sometimes in the US; 1 pmi = 1.609344 pkm": {
    "before": "passenger-kilometre or pkm internationally;",
    "after": "Passengers per hour per direction[edit]",
    "url": "https://en.wikipedia.org/wiki/Units of measurement in transportation"
  },
  "ton-mile in the US: 1 ton-mile * ( 0.907185 t / short ton) * ( 1.609344 km / mile ) = 1.460 tkm": {
    "before": "tonne-kilometre or kilometre-tonne (t⋅km or km⋅t, also tkm or kmt), the transportation of one tonne over one kilometre; 1 tkm = 1,000 kgkm.",
    "after": "Usage[edit]",
    "url": "https://en.wikipedia.org/wiki/Units of measurement in transportation"
  },
  "{\\displaystyle Ec={\\frac {\\Delta C/C}{\\Delta q/q}}.}": {
    "before": "Economies of scale refers to the cost advantage arise from increasing amount of production. Mathematically, it is a situation in which the firm can double its output for less than doubling the cost, which brings cost advantages. Usually, economies of scale can be represented in connection with a cost-production elasticity, E c . ",
    "after": "cost-production elasticity",
    "url": "https://en.wikipedia.org/wiki/Minimum efficient scale"
  },
  "{\\displaystyle Ec={\\frac {\\Delta C/C}{\\Delta q/q}}={\\frac {\\Delta C/\\Delta q}{C/q}}=MarginalCost(MC)/AverageCost(AC)}": {
    "before": "The cost-production elasticity equation can be rewritten to express the relationship between marginal cost and average cost.",
    "after": "The minimum efficient scale can be computed by equating average cost (AC) with marginal cost (MC).i.e. {\\displaystyle Ec=MC/AC=1.} . The rationale behind this is that if a firm were to produce a small number of units, its average cost per unit would be high because the bulk of the costs would come from fixed costs . But if the firm produces more units, the average cost incurred per unit will be lower as the fixed costs are spread over a larger number of units; the marginal cost is below the average cost, pulling the latter down. The efficient scale of production is then reached when the average cost is at its minimum and therefore the same as the marginal cost.",
    "url": "https://en.wikipedia.org/wiki/Minimum efficient scale"
  },
  "{\\displaystyle k=1/[MPS+MRT+MPM]=1/MPW\\,\\!}": {
    "before": "The size of the multiplier should take account of all leakages from the circular flow of income and expenditure occurring in all sectors. The complex multiplier can be measured by the following formula:",
    "after": "where MPS= Marginal propensity to save, MRT= Marginal rate of taxation, MPM= marginal propensity to import. MPW = Marginal propensity to withdraw",
    "url": "https://en.wikipedia.org/wiki/Complex multiplier"
  },
  "{\\displaystyle l={\\frac {q}{a}}} ,": {
    "before": "A number of derived quantities are helpful to define the model. The amount of employed labour is given by",
    "after": "the employment ratio is given by",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle v={\\frac {l}{n}}} ,": {
    "before": "{\\displaystyle l={\\frac {q}{a}}} ,the employment ratio is given by",
    "after": "the workers' share in the output is given by",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle u={\\frac {wl}{q}}={\\frac {w}{a}}} ,": {
    "before": "{\\displaystyle v={\\frac {l}{n}}} ,the workers' share in the output is given by",
    "after": "and the share of the capitalists in the output ( {\\displaystyle s} for surplus) is given by",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle s=1-u} .": {
    "before": "and the share of the capitalists in the output ( {\\displaystyle s} for surplus) is given by",
    "after": "The model is then defined by a set of differential equations. Firstly, the change in labour productivity is defined by",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle {\\frac {\\dot {a}}{a}}=\\alpha } ,": {
    "before": "The model is then defined by a set of differential equations. Firstly, the change in labour productivity is defined by",
    "after": "that is, steady growth, with {\\displaystyle a_{t}=a_{0}e^{\\alpha t}} . (Note that {\\displaystyle {\\dot {x}}} is the derivative over time {\\displaystyle {dx}/{dt}} .) The labour force changes according to",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle {\\frac {\\dot {n}}{n}}=\\beta } ,": {
    "before": "that is, steady growth, with {\\displaystyle a_{t}=a_{0}e^{\\alpha t}} . (Note that {\\displaystyle {\\dot {x}}} is the derivative over time {\\displaystyle {dx}/{dt}} .) The labour force changes according to",
    "after": "again, steady growth, with {\\displaystyle n_{t}=n_{0}e^{\\beta t}} . Real wages change according to",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle {\\frac {\\dot {w}}{w}}=-\\gamma +\\rho v} ,": {
    "before": "again, steady growth, with {\\displaystyle n_{t}=n_{0}e^{\\beta t}} . Real wages change according to",
    "after": "that is, the real wage change curve is modelled as linear. Note that to correctly model the assumptions, {\\displaystyle \\gamma } and {\\displaystyle \\rho } must be picked to ensure that real wages increase when {\\displaystyle v} is near 1. In other words, if the labor market is ' tight ' (employment is already high) there is upward pressure on wages and vice versa in a 'lax' labor market.",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle {\\dot {k}}=qs} ,": {
    "before": "that is, the real wage change curve is modelled as linear. Note that to correctly model the assumptions, {\\displaystyle \\gamma } and {\\displaystyle \\rho } must be picked to ensure that real wages increase when {\\displaystyle v} is near 1. In other words, if the labor market is ' tight ' (employment is already high) there is upward pressure on wages and vice versa in a 'lax' labor market.Capital changes according to",
    "after": "as the surplus is assumed to be completely invested by the capitalist. Lastly, output changes according to",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle {\\frac {\\dot {q}}{q}}={\\frac {s}{\\sigma }}} ,": {
    "before": "as the surplus is assumed to be completely invested by the capitalist. Lastly, output changes according to",
    "after": "that is, in proportion to the surplus invested.",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle {\\frac {\\dot {q}}{q}}={\\frac {\\dot {k}}{k}}={\\frac {1-u}{\\sigma }}}": {
    "before": "that is, in proportion to the surplus invested.Note that",
    "after": "by the assumption that k and q grow at the same rate by assumption of full utilization of capital and constant returns to scale.",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle {\\dot {v}}=v(-{\\frac {1}{\\sigma }}u+{\\frac {1}{\\sigma }}-\\alpha -\\beta )} {\\displaystyle {\\dot {u}}=u(\\rho v-\\gamma -\\alpha )} .": {
    "before": "The defining equations can be solved for {\\displaystyle {\\dot {u}}} and {\\displaystyle {\\dot {v}}} , which gives the two differential equations",
    "after": "These are the key equations of the model and in fact are the Lotka–Volterra equations , which are used in biology to model predator-prey interaction. These equations have two fixed points. The first is when",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle u=0} and {\\displaystyle v=0}": {
    "before": "These are the key equations of the model and in fact are the Lotka–Volterra equations , which are used in biology to model predator-prey interaction. These equations have two fixed points. The first is when",
    "after": "and the second is when",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "{\\displaystyle u=1-(\\alpha +\\beta )\\sigma } {\\displaystyle v={\\frac {\\gamma +\\alpha }{\\rho }}} ,": {
    "before": "{\\displaystyle u=0} and {\\displaystyle v=0} and the second is when",
    "after": "which determines the center of a family of cyclic trajectories.",
    "url": "https://en.wikipedia.org/wiki/Goodwin model (economics)"
  },
  "output= initial inventory + input - final inventory": {
    "before": "The main difference between the periodic inventory and the perpetual inventory is that the perpetual inventory does not keep the inventory-balance by using the inventory accounts, instead the entire input is booked immediately on the expense accounts. The principle is the following:",
    "after": "At the end of the accounting period the inventory is assessed through stock-taking:",
    "url": "https://en.wikipedia.org/wiki/Backflush accounting"
  },
  "inventory asset account = expense account": {
    "before": "At the end of the accounting period the inventory is assessed through stock-taking:",
    "after": "At the beginning of the accounting period the stock is canceled using the opposite booking:",
    "url": "https://en.wikipedia.org/wiki/Backflush accounting"
  },
  "expense account = inventory asset account": {
    "before": "At the beginning of the accounting period the stock is canceled using the opposite booking:",
    "after": "During the accounting period any input is booked directly to the expense account. For example, if we buy materials the bookings are:",
    "url": "https://en.wikipedia.org/wiki/Backflush accounting"
  },
  "material account = supplier account": {
    "before": "During the accounting period any input is booked directly to the expense account. For example, if we buy materials the bookings are:",
    "after": "material expense account = material account",
    "url": "https://en.wikipedia.org/wiki/Backflush accounting"
  },
  "material expense account = material account": {
    "before": "material account = supplier account",
    "after": "At the end of the accounting period, at the stock-taking the booking will be",
    "url": "https://en.wikipedia.org/wiki/Backflush accounting"
  },
  "material account = material expenses account": {
    "before": "In the context of perpetual inventory, backflushing is automatic accounting of material consumed for production, at the time of confirmation of the production, e.g. when a 4-wheeler automobile is rolled out from assembly line, 4 wheels and tires are deemed to be consumed and issued to production order automatically by way of back flushing by the system. Typically the assembly line has its own limited stock of materials as work in process. This stock is replenished by transferring materials from a warehouse (store) into the assembly lines own designated location, e.g. a supermarket. At goods receipt the consumed materials are posted automatically from the location designated to the issuing production line. In other words, back flushing refers only to materials which are already withdrawn from the inventory of the warehouse (store) and were delivered to the shop floor. Parts are issued from stores to Work-In-Process inventory, but not based on a job order or for a specific production order. They are issued in quantities estimated to cover requirements of individual work centers and production lines. The issuing may be used to cover a period of time or to fill a fixed—size container. But unlike the traditional approach, also known as \"preproduction issuing\" where the costs are assigned to the product order at the withdrawal of materials from the stores and after completion of production any excess material is given back to the stores, backflushing delays that until the goods receipt of the finished product or assembly is issued. The remaining quantity of unused material left on the shops is still held in the system as floor stock and so material will not be ordered incorrectly through the Manufacturing resource planning (MRP). By eliminating work-in-process accounts, backflush costing simplifies the accounting process. However, this simplification and other deviations from traditional costing systems mean that backflush costing may not always conform to generally accepted accounting principles (GAAP). Another drawback of this system is the lack of a sequential audit trail. The main advantage of postproduction issuing, not necessarily of backflushing, is that there is no need to update the store balances of inventory at the withdrawal of the materials from stores and recording the excess material through reverse posting (storno). This is especially useful in series or mass production where it is no need to give back excess material to the stores because it is used for the next production order. Even if excess material is given back to stores it does not involve any update to the inventory balance in the financial accounting (stock accounts). It involves only a stock transfer in the inventory management or warehouse management. Only the materials reported as consumed through the method of backflushing or by the MES imply an update to the inventory balance:",
    "after": "Back flush is used for materials which are required for the product and have a fixed relationship with it. Depending on how backflushing is implemented in the accounting software being used and depending on organizational rules, the back flushing may create error records which need to be analyzed by someone in charge for the cost accounting. One possible reason for the creation of these error records can be that there is no sufficient book inventory available in the designated back flushing location (shop floor). By simply deleting the error record, without working it out, could mean that the costs are not assigned correctly to products and/or even that the expenses in the financial accounting (inventory accounts) are not being recorded. The error record as such, is not a specific consequence of using back flushing. It may exist also when a MES system is being used when no back flushing is needed. The reason for this is that any error in transmitting and/or interpreting the data being sent by the MES system to the ERP system is consigned and needs to be worked out. When using back flushing, any scrap, material usage variance (using more or less than specified in the BOM) or substitution must be reported separately in order to maintain acceptable inventory accuracy. These are typically implemented as unplanned transactions. The downside of unplanned transactions is that they are prone to error. Unplanned inventory transactions must be eliminated and replaced creatively with planned transactions because even a very low percentage of misreported transactions will take inventory accuracy quickly to an unacceptable level. That is why the usage of backflushing is recommended only if 2 conditions are met: low I/O Variation and low Production Lead Times. Without low part I/O variation through low scrap, non-standard usage, and substitution, system inventory levels become unreliable. The exception transactions just cannot come through quickly or accurately enough to tame the beast. Loss of trust in the system occurs. Without short manufacturing lead times, components get moved into production but don't get relieved right away from the ERP inventory. This leads to confusion. Evident discrepancies between physical and system inventory counts cause frustration and lack of trust in the system. Without accurate and timely inventory levels, internal production plans and external purchase orders cannot be scheduled effectively, leading to inventory shortages and excess inventory. Inventory shortages cause disruptions to the manufacturing schedule, forcing additional setups, forced substitutions, overtime, premium freight charges, missed shipments and lost capacity. Excess inventory increases obsolescence, and consumes precious cash flow and shelf space. Both excess inventory and shortages can indirectly lead to poor quality. A plant cannot cycle-count its way to accurate inventories. Cycle counting is not timely enough to be of benefit. And cycle counts are more likely to introduce errors than to correct them.",
    "url": "https://en.wikipedia.org/wiki/Backflush accounting"
  },
  "{\\displaystyle \\sum _{t=0}^{\\infty }{\\frac {1}{\\|p_{t}\\|}}<\\infty ,}": {
    "before": "If {\\displaystyle p_{t}} represents the vector of Arrow–Debreu commodity prices prevailing in period {\\displaystyle t} and if",
    "after": "then a competitive equilibrium allocation is inefficient . ",
    "url": "https://en.wikipedia.org/wiki/Cass criterion"
  },
  ", where, s = Cost of obtaining price at quote with": {
    "before": "{\\displaystyle p_{1}^{*}=p_{2}^{*}=...=p_{n}^{*}=p^{m}}",
    "after": "{\\displaystyle 0<s<CS(p^{m})}",
    "url": "https://en.wikipedia.org/wiki/Search cost"
  },
  ", CS = Consumer surplus and p = Price.": {
    "before": "{\\displaystyle 0<s<CS(p^{m})}",
    "after": "The model implies that search frictions can result in the perfectly competitive market price shifting to the monopoly price. However, Diamond's original model is rudimentary and ignores some empirical observations:",
    "url": "https://en.wikipedia.org/wiki/Search cost"
  },
  "{\\displaystyle {\\frac {dK(t)}{dt}}=I^{g}(t)-D(t)=I^{n}(t)}": {
    "before": "For example, if the capital stock {\\displaystyle \\,K(t)\\,} is increased gradually over time by a flow of gross investment {\\displaystyle \\,I^{g}(t)\\,} and decreased gradually over time by a flow of depreciation {\\displaystyle \\,D(t)\\,} , then the instantaneous rate of change in the capital stock is given by",
    "after": "where the notation {\\displaystyle \\,I^{n}(t)\\,} refers to the flow of net investment , which is the difference between gross investment and depreciation.",
    "url": "https://en.wikipedia.org/wiki/Stock and flow"
  },
  "{\\displaystyle \\ {\\text{Stock A}}=\\int _{0}^{t}-{\\text{Flow }}\\,dt}": {
    "before": "Equations that change the two stocks via the flow are:",
    "after": "{\\displaystyle \\ {\\text{Stock B}}=\\int _{0}^{t}{\\text{Flow }}\\,dt}",
    "url": "https://en.wikipedia.org/wiki/Stock and flow"
  },
  "{\\displaystyle \\ {\\text{Stock B}}=\\int _{0}^{t}{\\text{Flow }}\\,dt}": {
    "before": "{\\displaystyle \\ {\\text{Stock A}}=\\int _{0}^{t}-{\\text{Flow }}\\,dt}",
    "after": "List of all the equations, in their order of execution in each time, from time = 1 to 36:",
    "url": "https://en.wikipedia.org/wiki/Stock and flow"
  },
  "{\\displaystyle 1)\\ {\\text{Flow}}=\\sin(5t)}": {
    "before": "List of all the equations, in their order of execution in each time, from time = 1 to 36:",
    "after": "{\\displaystyle 2.1)\\ {\\text{Stock A}}\\ -={\\text{Flow}}\\ }",
    "url": "https://en.wikipedia.org/wiki/Stock and flow"
  },
  "{\\displaystyle 2.1)\\ {\\text{Stock A}}\\ -={\\text{Flow}}\\ }": {
    "before": "List of all the equations, in their order of execution in each time, from time = 1 to 36: {\\displaystyle 1)\\ {\\text{Flow}}=\\sin(5t)}",
    "after": "{\\displaystyle 2.2)\\ {\\text{Stock B}}\\ +={\\text{Flow}}\\ }",
    "url": "https://en.wikipedia.org/wiki/Stock and flow"
  },
  "{\\displaystyle 2.2)\\ {\\text{Stock B}}\\ +={\\text{Flow}}\\ }": {
    "before": "{\\displaystyle 2.1)\\ {\\text{Stock A}}\\ -={\\text{Flow}}\\ }",
    "after": "History [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Stock and flow"
  },
  "This means that if A and B are identical in all respects the consumer will recognize this fact and be indifferent in comparing A and B A = B ⇒ A I B ": {
    "before": "Assume that there are two consumption bundles A and B each containing two commodities x and y . A consumer can unambiguously determine that one and only one of the following is the case: A is preferred to B , formally written as A p B  B is preferred to A , formally written as B p A  A is indifferent to B , formally written as A I B  This axiom precludes the possibility that the consumer cannot decide,  It assumes that a consumer is able to make this comparison with respect to every conceivable bundle of goods. Preferences are reflexive",
    "after": "Preferences are transitive [nb 1]",
    "url": "https://en.wikipedia.org/wiki/Indifference curve"
  },
  "{\\displaystyle dU\\left(x_{0},y_{0}\\right)=U_{1}\\left(x_{0},y_{0}\\right)dx+U_{2}\\left(x_{0},y_{0}\\right)dy}": {
    "before": "Consider a particular bundle {\\displaystyle \\left(x_{0},y_{0}\\right)} and take the total derivative of {\\displaystyle U\\left(x,y\\right)} about this point:",
    "after": "or, without loss of generality,",
    "url": "https://en.wikipedia.org/wiki/Indifference curve"
  },
  "{\\displaystyle {\\frac {dU\\left(x_{0},y_{0}\\right)}{dx}}=U_{1}(x_{0},y_{0}).1+U_{2}(x_{0},y_{0}){\\frac {dy}{dx}}} (Eq. 1)": {
    "before": "{\\displaystyle dU\\left(x_{0},y_{0}\\right)=U_{1}\\left(x_{0},y_{0}\\right)dx+U_{2}\\left(x_{0},y_{0}\\right)dy} or, without loss of generality,",
    "after": "where {\\displaystyle U_{1}\\left(x,y\\right)} is the partial derivative of {\\displaystyle U\\left(x,y\\right)} with respect to its first argument, evaluated at {\\displaystyle \\left(x,y\\right)} . (Likewise for {\\displaystyle U_{2}\\left(x,y\\right).} )",
    "url": "https://en.wikipedia.org/wiki/Indifference curve"
  },
  "{\\displaystyle {\\frac {dU\\left(x_{0},y_{0}\\right)}{dx}}=0} , or, substituting 0 into (Eq. 1) above to solve for dy/dx : {\\displaystyle {\\frac {dU\\left(x_{0},y_{0}\\right)}{dx}}=0\\Leftrightarrow {\\frac {dy}{dx}}=-{\\frac {U_{1}(x_{0},y_{0})}{U_{2}(x_{0},y_{0})}}} .": {
    "before": "The indifference curve through {\\displaystyle \\left(x_{0},y_{0}\\right)} must deliver at each bundle on the curve the same utility level as bundle {\\displaystyle \\left(x_{0},y_{0}\\right)} . That is, when preferences are represented by a utility function, the indifference curves are the level curves of the utility function. Therefore, if one is to change the quantity of {\\displaystyle x\\,} by {\\displaystyle dx\\,} , without moving off the indifference curve, one must also change the quantity of {\\displaystyle y\\,} by an amount {\\displaystyle dy\\,} such that, in the end, there is no change in U :",
    "after": "Thus, the ratio of marginal utilities gives the absolute value of the slope of the indifference curve at point {\\displaystyle \\left(x_{0},y_{0}\\right)} . This ratio is called the marginal rate of substitution between {\\displaystyle x\\,} and {\\displaystyle y\\,} .",
    "url": "https://en.wikipedia.org/wiki/Indifference curve"
  },
  "{\\displaystyle {\\frac {dx}{dy}}=-{\\frac {\\beta }{\\alpha }}.}": {
    "before": "If the utility function is of the form {\\displaystyle U\\left(x,y\\right)=\\alpha x+\\beta y} then the marginal utility of {\\displaystyle x\\,} is {\\displaystyle U_{1}\\left(x,y\\right)=\\alpha } and the marginal utility of {\\displaystyle y\\,} is {\\displaystyle U_{2}\\left(x,y\\right)=\\beta } . The slope of the indifference curve is, therefore,",
    "after": "Observe that the slope does not depend on {\\displaystyle x\\,} or {\\displaystyle y\\,} : the indifference curves are straight lines.",
    "url": "https://en.wikipedia.org/wiki/Indifference curve"
  },
  "{\\displaystyle {\\frac {dx}{dy}}=-{\\frac {1-\\alpha }{\\alpha }}\\left({\\frac {x}{y}}\\right).}": {
    "before": "2. They are very flexible and can be adjusted to fit real-world data very easily. If the utility function is of the form {\\displaystyle U\\left(x,y\\right)=x^{\\alpha }y^{1-\\alpha }} the marginal utility of {\\displaystyle x\\,} is {\\displaystyle U_{1}\\left(x,y\\right)=\\alpha \\left(x/y\\right)^{\\alpha -1}} and the marginal utility of {\\displaystyle y\\,} is {\\displaystyle U_{2}\\left(x,y\\right)=(1-\\alpha )\\left(x/y\\right)^{\\alpha }} .Where {\\displaystyle \\alpha <1} . The slope of the indifference curve, and therefore the negative of the marginal rate of substitution , is then",
    "after": "CES utility [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Indifference curve"
  },
  "{\\displaystyle U(x,y)=\\left(\\alpha x^{\\rho }+(1-\\alpha )y^{\\rho }\\right)^{1/\\rho }}": {
    "before": "A general CES ( Constant Elasticity of Substitution ) form is",
    "after": "where {\\displaystyle \\alpha \\in (0,1)} and {\\displaystyle \\rho \\leq 1} . (The Cobb–Douglas is a special case of the CES utility, with {\\displaystyle \\rho \\rightarrow 0\\,} .) The marginal utilities are given by",
    "url": "https://en.wikipedia.org/wiki/Indifference curve"
  },
  "{\\displaystyle U_{1}(x,y)=\\alpha \\left(\\alpha x^{\\rho }+(1-\\alpha )y^{\\rho }\\right)^{\\left(1/\\rho \\right)-1}x^{\\rho -1}}": {
    "before": "where {\\displaystyle \\alpha \\in (0,1)} and {\\displaystyle \\rho \\leq 1} . (The Cobb–Douglas is a special case of the CES utility, with {\\displaystyle \\rho \\rightarrow 0\\,} .) The marginal utilities are given by",
    "after": "and {\\displaystyle U_{2}(x,y)=(1-\\alpha )\\left(\\alpha x^{\\rho }+(1-\\alpha )y^{\\rho }\\right)^{\\left(1/\\rho \\right)-1}y^{\\rho -1}.}",
    "url": "https://en.wikipedia.org/wiki/Indifference curve"
  },
  "{\\displaystyle U_{2}(x,y)=(1-\\alpha )\\left(\\alpha x^{\\rho }+(1-\\alpha )y^{\\rho }\\right)^{\\left(1/\\rho \\right)-1}y^{\\rho -1}.}": {
    "before": "{\\displaystyle U_{1}(x,y)=\\alpha \\left(\\alpha x^{\\rho }+(1-\\alpha )y^{\\rho }\\right)^{\\left(1/\\rho \\right)-1}x^{\\rho -1}} and",
    "after": "Therefore, along an indifference curve,",
    "url": "https://en.wikipedia.org/wiki/Indifference curve"
  },
  "{\\displaystyle {\\frac {dx}{dy}}=-{\\frac {1-\\alpha }{\\alpha }}\\left({\\frac {x}{y}}\\right)^{1-\\rho }.}": {
    "before": "{\\displaystyle U_{2}(x,y)=(1-\\alpha )\\left(\\alpha x^{\\rho }+(1-\\alpha )y^{\\rho }\\right)^{\\left(1/\\rho \\right)-1}y^{\\rho -1}.} Therefore, along an indifference curve,",
    "after": "These examples might be useful for modelling individual or aggregate demand.",
    "url": "https://en.wikipedia.org/wiki/Indifference curve"
  },
  "{\\displaystyle {\\begin{aligned}&c={\\frac {dY}{dK}}={\\frac {Y(t+1)-Y(t)}{K(t)+sY(t)-\\delta \\ K(t)-K(t)}}\\\\[8pt]&c={\\frac {Y(t+1)-Y(t)}{sY(t)-\\delta \\ {\\frac {dK}{dY}}Y(t)}}\\\\[8pt]&c(sY(t)-\\delta \\ {\\frac {dK}{dY}}Y(t))=Y(t+1)-Y(t)\\\\[8pt]&cY(t)\\left(s-\\delta \\ {\\frac {dK}{dY}}\\right)=Y(t+1)-Y(t)\\\\[8pt]&cs-c\\delta \\ {\\frac {dK}{dY}}={\\frac {Y(t+1)-Y(t)}{Y(t)}}\\\\[8pt]&s{\\frac {dY}{dK}}-\\delta \\ {\\frac {dY}{dK}}{\\frac {dK}{dY}}={\\frac {Y(t+1)-Y(t)}{Y(t)}}\\\\[8pt]&sc-\\delta \\ ={\\frac {\\Delta Y}{Y}}\\end{aligned}}}": {
    "before": "Derivations [ edit ]Derivation of output growth rate:",
    "after": "A derivation with calculus is as follows, using dot notation (for example, {\\displaystyle \\ {\\dot {Y}}} ) for the derivative of a variable with respect to time.",
    "url": "https://en.wikipedia.org/wiki/Harrod–Domar model"
  },
  "{\\displaystyle \\ Y=cK\\Rightarrow log(Y)=log(c)+log(K)}": {
    "before": "First, assumptions (1)–(3) imply that output and capital are linearly related (for readers with an economics background, this proportionality implies a capital- elasticity of output equal to unity). These assumptions thus generate equal growth rates between the two variables. That is,",
    "after": "Since the marginal product of capital, c , is a constant, we have",
    "url": "https://en.wikipedia.org/wiki/Harrod–Domar model"
  },
  "{\\displaystyle \\ {\\frac {d\\log(Y)}{dt}}={\\frac {d\\log(K)}{dt}}\\Rightarrow {\\frac {\\dot {Y}}{Y}}={\\frac {\\dot {K}}{K}}}": {
    "before": "Since the marginal product of capital, c , is a constant, we have",
    "after": "Next, with assumptions (4) and (5), we can find capital's growth rate as,",
    "url": "https://en.wikipedia.org/wiki/Harrod–Domar model"
  },
  "{\\displaystyle \\ {\\frac {\\dot {K}}{K}}={\\frac {I}{K}}-\\delta \\ =s{\\frac {Y}{K}}-\\delta \\ } {\\displaystyle \\ \\Rightarrow {\\frac {\\dot {Y}}{Y}}=sc-\\delta \\ }": {
    "before": "Next, with assumptions (4) and (5), we can find capital's growth rate as,",
    "after": "In summation, the savings rate times the marginal product of capital minus the depreciation rate equals the output growth rate. Increasing the savings rate, increasing the marginal product of capital, or decreasing the depreciation rate will increase the growth rate of output; these are the means to achieve growth in the Harrod–Domar model.",
    "url": "https://en.wikipedia.org/wiki/Harrod–Domar model"
  },
  "{\\displaystyle \\ Y=f(K)}": {
    "before": "{\\displaystyle \\ Y=f(K)} 1: Output is a function of capital stock only (labor is irrelevant).",
    "after": "1: Output is a function of capital stock only (labor is irrelevant).",
    "url": "https://en.wikipedia.org/wiki/Harrod–Domar model"
  },
  "{\\displaystyle \\ {\\frac {dY}{dK}}=c\\Rightarrow {\\frac {dY}{dK}}={\\frac {Y}{K}}}": {
    "before": "{\\displaystyle \\ {\\frac {dY}{dK}}=c\\Rightarrow {\\frac {dY}{dK}}={\\frac {Y}{K}}} 2: The marginal product of capital is constant; the production function exhibits constant returns to scale. This implies capital's marginal and average products are equal.",
    "after": "2: The marginal product of capital is constant; the production function exhibits constant returns to scale. This implies capital's marginal and average products are equal.",
    "url": "https://en.wikipedia.org/wiki/Harrod–Domar model"
  },
  "{\\displaystyle \\ sY=S=I}": {
    "before": "{\\displaystyle \\ sY=S=I} 4: The product of the savings rate and output equals saving, which equals investment",
    "after": "4: The product of the savings rate and output equals saving, which equals investment",
    "url": "https://en.wikipedia.org/wiki/Harrod–Domar model"
  },
  "{\\displaystyle \\ \\Delta \\ K=I-\\delta \\ K}": {
    "before": "{\\displaystyle \\ \\Delta \\ K=I-\\delta \\ K} 5: The change in the capital stock equals investment less the depreciation of the capital stock",
    "after": "5: The change in the capital stock equals investment less the depreciation of the capital stock",
    "url": "https://en.wikipedia.org/wiki/Harrod–Domar model"
  },
  "Overhead Rate = (Total budgeted overhead / Basis)": {
    "before": "To find the overhead rate, first determine the right basis that will describe the best the behavior of the cost. Then, divide the total budgeted overhead by the basis to calculate the overhead rate:",
    "after": "What is the right basis to use to calculate the overhead rate[edit]",
    "url": "https://en.wikipedia.org/wiki/Pre-determined overhead rate"
  },
  "The share of the order of the overhead = Overhead Rate * Resources consumed": {
    "before": "In order to find the overhead rate we will use the same basis that we have chosen by multiplying this basis by the calculated rate. For example, if we choose the labor hours to be the basis then we will multiply the rate by the direct labor hours in each task during the manufacturing process.",
    "after": "Sources[edit]",
    "url": "https://en.wikipedia.org/wiki/Pre-determined overhead rate"
  },
  "Total costs = fixed costs + (unit variable cost × number of units) Total revenue = sales price × number of unit": {
    "before": "The assumptions of the CVP model yield the following linear equations for total costs and total revenue (sales):",
    "after": "These are linear because of the assumptions of constant costs and prices, and there is no distinction between units produced and units sold, as these are assumed to be equal. Note that when such a chart is drawn, the linear CVP model is assumed, often implicitly.",
    "url": "https://en.wikipedia.org/wiki/Cost–volume–profit analysis"
  },
  "{\\displaystyle {\\text{TC}}={\\text{TFC}}+V\\times X} {\\displaystyle {\\text{TR}}=P\\times X}": {
    "before": "These are linear because of the assumptions of constant costs and prices, and there is no distinction between units produced and units sold, as these are assumed to be equal. Note that when such a chart is drawn, the linear CVP model is assumed, often implicitly.In symbols:",
    "after": "whereTC = Total costs TFC = Total fixed costs V = Unit variable cost ( variable cost per unit ) X = Number of units TR = S = Total revenue = Sales P = (Unit) sales price",
    "url": "https://en.wikipedia.org/wiki/Cost–volume–profit analysis"
  },
  "{\\displaystyle {\\begin{aligned}{\\text{PL}}&={\\text{TR}}-{\\text{TC}}\\\\&=\\left(C+V\\right)\\times X-\\left({\\text{TFC}}+V\\times X\\right)\\\\&=C\\times X-{\\text{TFC}}\\end{aligned}}}": {
    "before": "Subtracting variable costs from both costs and sales yields the simplified diagram and equation for profit and loss.In symbols:",
    "after": "Diagram relating all quantities in CVP.",
    "url": "https://en.wikipedia.org/wiki/Cost–volume–profit analysis"
  },
  "MP L = MRS Leisure, Coconuts": {
    "before": "Recall that the marginal rate of substitution is the rate at which a consumer is ready to give up one good in exchange for another good while maintaining the same level of utility.  Additionally, an input's marginal product is the extra output that can be produced by using one more unit of the input, assuming that the quantities of no other inputs to production change.  Then,",
    "after": "whereMP L = marginal product of labour, and",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "MP L = marginal product of labour, and": {
    "before": "MP L = MRS Leisure, Coconutswhere",
    "after": "MRS Leisure, Coconuts = marginal rate of substitution between leisure and coconuts",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "MRS Leisure, Coconuts = marginal rate of substitution between leisure and coconuts": {
    "before": "whereMP L = marginal product of labour, and",
    "after": "Crusoe's multifaceted role [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "{\\displaystyle \\Pi =C-wL\\,}": {
    "before": "Assume that when the firm produces C amount of total coconuts, {\\displaystyle \\Pi } represents its profit level. Also assume that when the wage rate at which the firm employs labour is w , L is the amount of labour that will be employed. Then,",
    "after": "{\\displaystyle C=\\Pi +wL\\,}",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "{\\displaystyle C=\\Pi +wL\\,}": {
    "before": "Assume that when the firm produces C amount of total coconuts, {\\displaystyle \\Pi } represents its profit level. Also assume that when the wage rate at which the firm employs labour is w , L is the amount of labour that will be employed. Then, {\\displaystyle \\Pi =C-wL\\,}",
    "after": "The above function describes iso-profit lines (the locus of combinations between labour and coconuts that produce a constant profit of Π). Profits can be maximised when the marginal product of labour equals the wage rate (marginal cost of production).  Symbolically,",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "MP L = w": {
    "before": "Graphically this occurs when the diagrams under consumer and producer are superimposed.  Notice that,MRS Leisure, Coconuts = w",
    "after": "=> MRS Leisure, Coconuts = MP L",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "MRS Leisure, Coconuts = w": {
    "before": "Graphically this occurs when the diagrams under consumer and producer are superimposed.  Notice that,",
    "after": "MP L = w=> MRS Leisure, Coconuts = MP L",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "{\\displaystyle F=4L_{f}\\,}": {
    "before": "Suppose that Crusoe can produce 4 pounds of fish or 8 pounds of coconuts per hour. If he devotes L f hours to fish gathering and L c hours to gathering coconuts, he will produce 4L f pounds of fish and 8L c pounds of coconuts. Suppose that he decides to work for 12 hours a day. Then the production possibilities set will consist of all combinations of fish, F , and coconuts, C , such that",
    "after": "{\\displaystyle C=8L_{c}\\,}",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "{\\displaystyle C=8L_{c}\\,}": {
    "before": "Suppose that Crusoe can produce 4 pounds of fish or 8 pounds of coconuts per hour. If he devotes L f hours to fish gathering and L c hours to gathering coconuts, he will produce 4L f pounds of fish and 8L c pounds of coconuts. Suppose that he decides to work for 12 hours a day. Then the production possibilities set will consist of all combinations of fish, F , and coconuts, C , such that {\\displaystyle F=4L_{f}\\,}",
    "after": "{\\displaystyle L_{f}+L_{c}=12\\,}",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "MRT Coconuts, Fish {\\displaystyle ={\\Delta C \\over \\Delta F}\\,}  {\\displaystyle =-8/4=-2\\,}": {
    "before": "This equation represents Crusoe's PPF. The slope of this PPF measures the Marginal rate of transformation (MRT), i.e., how much of the first good must be given up in order to increase the production of the second good by one unit. If Crusoe works one hour less on hunting fish, he will have 4 less fish. If he devotes this extra hour to collecting coconuts, he will have 8 extra coconuts. The MRT is thus,",
    "after": "Comparative advantage [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "{\\displaystyle {\\begin{aligned}&F=8L_{f}\\\\[6pt]&C=4L_{c}\\\\[6pt]&L_{f}+L_{c}=12\\\\[6pt]\\Longrightarrow &{\\frac {F}{8}}+{\\frac {C}{4}}=12\\end{aligned}}}": {
    "before": "Friday can produce 8 pounds of fish or 4 pounds of coconuts per hour. If he too decides to work for 12 hours, his production possibilities set will be determined by the following relations:",
    "after": "Thus, MRT Coconuts, Fish {\\textstyle =\\Delta C/\\Delta F\\,}  {\\displaystyle =-4/8=-1/2\\,}",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "MRT Coconuts, Fish = MRS Coconuts, Fish ": {
    "before": "From the figure 8, it is clear that an economy operating at a position where the MRS of either Crusoe or Friday is not equal to the MRT between coconuts and fish cannot be Pareto efficient . This is because the rate at which, say Friday is willing to trade coconuts for fish is different from the rate at which coconuts can be transformed into fish. Thus, there is a way to make Friday better off by rearranging the production pattern.  Thus for Pareto efficiency,",
    "after": "( for both Crusoe and Friday )",
    "url": "https://en.wikipedia.org/wiki/Robinson Crusoe economy"
  },
  "Savings + Taxes + Imports = Investment + Government Spending + Exports": {
    "before": "In terms of the five sector circular flow of income model the state of equilibrium occurs when the total leakages are equal to the total injections that occur in the economy. This can be shown as:",
    "after": "OR",
    "url": "https://en.wikipedia.org/wiki/Circular flow of income"
  },
  "S + T + M = I + G + X.": {
    "before": "OR",
    "after": "This can be further illustrated through a fictitious economy where:",
    "url": "https://en.wikipedia.org/wiki/Circular flow of income"
  },
  "S + T + M = I + G + X": {
    "before": "This can be further illustrated through a fictitious economy where:",
    "after": "$100 + $150 + $50 = $50 + $100 + $150",
    "url": "https://en.wikipedia.org/wiki/Circular flow of income"
  },
  "{\\displaystyle Q_{C}=L/a_{LC}-(a_{LW}/a_{LC})Q_{W}} .": {
    "before": "from which it follows that Home's cloth consumption at the production possibilities frontier is",
    "after": "With free trade, Home produces cloth exclusively, an amount of which it exports in exchange for wine at the prevailing rate. Thus Home's overall consumption is now subject to the constraint",
    "url": "https://en.wikipedia.org/wiki/Comparative advantage"
  },
  "{\\displaystyle Q_{C}=L/a_{LC}-(P_{W}/P_{C})Q_{W}\\geq L/a_{LC}-(a_{LW}/a_{LC})Q_{W}} .": {
    "before": "while its cloth consumption at the consumption possibilities frontier is given by",
    "after": "A symmetric argument holds for Foreign. Therefore, by trading and specializing in a good for which it has a comparative advantage, each country can expand its consumption possibilities. Consumers can choose from bundles of wine and cloth that they could not have produced themselves in closed economies.",
    "url": "https://en.wikipedia.org/wiki/Comparative advantage"
  },
  "Industry 3: 4Y + 3Z = 1700 ⇒ X = 100, Y = 200, Z = 300.": {
    "before": "Industry 2: 6X + Z = 900",
    "after": "Given that a factor is used in the production of a range of first-order goods, its value is determined by the good that is worth the least among all the goods in the range. This value is determined at the margin, the marginal utility of the last unit of the least valuable good produced by the factor. In connection with his opportunity cost, the value so derived represents an opportunity cost across all industries, and the values of the factors of production and goods are determined in the whole system. Thus, supply and demand do not develop into the determinants of value; the determinant of value is the marginal utility.",
    "url": "https://en.wikipedia.org/wiki/Theory of imputation"
  },
  "{\\displaystyle rK+wL=C\\,}": {
    "before": "In economics , an isocost line shows all combinations of inputs which cost the same total amount.   Although similar to the budget constraint in consumer theory , the use of the isocost line pertains to cost-minimization in production, as opposed to utility-maximization. For the two production inputs labour and capital, with fixed unit costs of the inputs, the equation of the isocost line is",
    "after": "where w represents the wage rate of labour, r represents the rental rate of capital, K is the amount of capital used, L is the amount of labour used, and C is the total cost of acquiring those quantities of the two inputs.",
    "url": "https://en.wikipedia.org/wiki/Isocost"
  },
  "It is on the y-isoquant (i.e. F(K, L) = y where F is the production function), and": {
    "before": "If the isoquants are smooth and convex to the origin and the cost-minimizing input bundle involves a positive amount of each input, then this bundle satisfies the following two conditions:",
    "after": "the MRTS at (K, L) equals w/r.",
    "url": "https://en.wikipedia.org/wiki/Isocost"
  },
  "C=rK+wL": {
    "before": "if w represents the wage rate of labour, r represents the rental rate of capital, K is the amount of capital used, L is the amount of labour used, and C is the total cost of the two inputs, than the isocost line can be",
    "after": "In the figure, the point C / w on the horizontal axis represents that all the given costs are used in labor, and the point C / r on the vertical axis represents that all the given costs are used in capital . The line connecting these two points is the isocost line.",
    "url": "https://en.wikipedia.org/wiki/Isocost"
  },
  "With no government subsidy (s=0) the resulting equilibrium will be the standard Cournot outcome, as shown in the graph by the intersection of the best response functions. A subsidy however has the effect of shifting the domestic firm's best response function to the right. Because its output is subsidized, the domestic firm increases production. This in turn means that the foreign firm's best response is to cut output, although not proportionally (hence, the market price falls). In the new equilibrium domestic firm produces more and foreign firm produces less.": {
    "before": ". These are illustrated in the figure below, with the domestic firm's output on the x axis and foreign firm's output on the y axis.[note 2]",
    "after": "In the model, domestic social welfare can be defined as the home firm's profit net of the subsidy (the model can be extended so that social welfare includes the firm's monopoly profit as well as the wages paid to the firm's workers; the results are qualitatively the same). It can be shown that the profit function evaluated at equilibrium quantity levels is concave in s and eventually negatively sloped. As a result, there is an \"optimal subsidy\" which maximizes the domestic firm's profits and hence domestic social welfare. As it turns out, if the government sets the subsidy exactly at the optimal level, the resulting equilibrium is the same as that of the \"leader and follower\" Stackelberg model. In that case one of the firms (in this case the domestic firm) has the ability to choose its output first. This creates the ability to credibly commit to a particular action, resulting in \"first mover advantage\". In the Brender–Spencer model, the government's subsidy creates this credible commitment even when the private firm does not have that ability.",
    "url": "https://en.wikipedia.org/wiki/Brander–Spencer model"
  },
  "{\\displaystyle {\\text{Phase 1}}:AL({\\text{from figure}})=MP=0{\\text{ and }}AB({\\text{from figure}})=AP\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fei–Ranis model of economic growth"
  },
  "{\\displaystyle MP={\\text{Real wages}}=AB={\\text{Constant institutional wages (CIW)}}\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fei–Ranis model of economic growth"
  },
  "{\\displaystyle R={\\frac {ts}{Ot}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fei–Ranis model of economic growth"
  },
  "{\\displaystyle S={\\frac {tE}{Ot}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fei–Ranis model of economic growth"
  },
  "{\\displaystyle T={\\frac {ts}{te}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fei–Ranis model of economic growth"
  },
  "{\\displaystyle T={\\frac {ts/Ot}{te/Ot}}={\\frac {R}{S}},{\\text{ or }}T={\\frac {R}{S}}\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fei–Ranis model of economic growth"
  },
  "{\\displaystyle K_{t}=K_{o}+S_{o}+\\Pi _{o}\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fei–Ranis model of economic growth"
  },
  "The question of whether MPL = 0 is that of an empirical one. The underdeveloped countries mostly exhibit seasonality in food production, which suggests that especially during favorable climatic conditions, say that of harvesting or sowing, MPL would definitely be greater than zero.": {
    "before": "While mentioning the important role of high agricultural productivity and the creation of surplus for economic development, they have failed to mention the need for capital as well. Although it is important to create surplus, it is equally important to maintain it through technical progress, which is possible through capital accumulation, but the Fei-Ranis model considers only labor and output as factors of production.",
    "after": "Fei and Ranis assume a close model and hence there is no presence of foreign trade in the economy, which is very unrealistic as food or raw materials can not be imported. If we take the example of Japan again, the country imported cheap farm products from other countries and this made better the country's terms of trade. Later they relaxed the assumption and said that the presence of a foreign sector was allowed as long as it was a \"facilitator\" and not the main driving force.",
    "url": "https://en.wikipedia.org/wiki/Fei–Ranis model of economic growth"
  },
  "{\\displaystyle y=f\\left(x_{1},x_{2},\\ldots ,x_{n}\\right)}": {
    "before": "Quantified conception [ edit ]Assume a functional relationship",
    "after": "Discrete change [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Marginal value"
  },
  "{\\displaystyle \\Delta x_{i}=x_{i,1}-x_{i,0}}": {
    "before": "If the value of {\\displaystyle x_{i}} is discretely changed from {\\displaystyle x_{i,0}} to {\\displaystyle x_{i,1}} while other independent variables remain unchanged, then the marginal value of the change in {\\displaystyle x_{i}} is",
    "after": "and the “marginal value” of {\\displaystyle y} may refer to",
    "url": "https://en.wikipedia.org/wiki/Marginal value"
  },
  "{\\displaystyle \\Delta y=f\\left(x_{1},x_{2},\\ldots ,x_{i,1},\\ldots ,x_{n}\\right)-f\\left(x_{1},x_{2},\\ldots ,x_{i,0},\\ldots ,x_{n}\\right)}": {
    "before": "and the “marginal value” of {\\displaystyle y} may refer to",
    "after": "or to {\\displaystyle {\\frac {\\Delta y}{\\Delta x}}={\\frac {f\\left(x_{1},x_{2},\\ldots ,x_{i,1},\\ldots ,x_{n}\\right)-f\\left(x_{1},x_{2},\\ldots ,x_{i,0},\\ldots ,x_{n}\\right)}{x_{i,1}-x_{i,0}}}}",
    "url": "https://en.wikipedia.org/wiki/Marginal value"
  },
  "{\\displaystyle {\\frac {\\Delta y}{\\Delta x}}={\\frac {f\\left(x_{1},x_{2},\\ldots ,x_{i,1},\\ldots ,x_{n}\\right)-f\\left(x_{1},x_{2},\\ldots ,x_{i,0},\\ldots ,x_{n}\\right)}{x_{i,1}-x_{i,0}}}}": {
    "before": "{\\displaystyle \\Delta y=f\\left(x_{1},x_{2},\\ldots ,x_{i,1},\\ldots ,x_{n}\\right)-f\\left(x_{1},x_{2},\\ldots ,x_{i,0},\\ldots ,x_{n}\\right)} or to",
    "after": "Example [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Marginal value"
  },
  "{\\displaystyle {\\frac {\\partial y}{\\partial x_{i}}}={\\frac {\\partial f\\left(x_{1},x_{2},\\ldots ,x_{n}\\right)}{\\partial x_{i}}}}": {
    "before": "If infinitesimal values are considered, then a marginal value of {\\displaystyle x_{i}} would be {\\displaystyle dx_{i}} , and the “marginal value” of {\\displaystyle y} would typically refer to",
    "after": "(For a linear functional relationship {\\displaystyle y=a+b\\cdot x} , the marginal value of {\\displaystyle y} will simply be the co-efficient of {\\displaystyle x} (in this case, {\\displaystyle b} ) and this will not change as {\\displaystyle x} changes. However, in the case where the functional relationship is non-linear, say {\\displaystyle y=a\\cdot b^{x}} , the marginal value of {\\displaystyle y} will be different for different values of {\\displaystyle x} .)",
    "url": "https://en.wikipedia.org/wiki/Marginal value"
  },
  "{\\displaystyle C=C\\left(Y\\right)}": {
    "before": "Assume that, in some economy, aggregate consumption is well-approximated by",
    "after": "where {\\displaystyle Y} is aggregate income .",
    "url": "https://en.wikipedia.org/wiki/Marginal value"
  },
  "{\\displaystyle MPC={\\frac {dC}{dY}}}": {
    "before": "{\\displaystyle Y} is aggregate income .Then the marginal propensity to consume is",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Marginal value"
  },
  "{\\displaystyle Qdx=f(P_{x},I,P_{y},T)}": {
    "before": "The above equation, when plotted with quantity demanded ( {\\displaystyle Q_{x}} ) on the {\\displaystyle x} -axis and price ( {\\displaystyle P_{x}} ) on the {\\displaystyle y} -axis, gives the demand curve , which is also known as the demand schedule. The demand curve is downward sloping illustrating the inverse relationship between quantity demanded and price. Therefore, a downward sloping demand curve embeds the law of demand.In a more specific manner: ",
    "after": "Which is a functional relationship where the quantity demanded by the consumer {\\displaystyle Qdx} depends on the price of the good {\\displaystyle P_{x}} , the monetary income of the consumer {\\displaystyle I} , the prices of other goods {\\displaystyle P_{y}} , and the taste of the consumer {\\displaystyle T} .",
    "url": "https://en.wikipedia.org/wiki/Law of demand"
  },
  "{\\displaystyle E_{\\langle p\\rangle }={\\frac {\\Delta Q/Q}{\\Delta P/P}}}": {
    "before": "The variation in demand with regards to a change in price is known as the price elasticity of demand . The formula to solve for the coefficient of price elasticity of demand is the percentage change in quantity demanded divided by the percentage change in Price.",
    "after": "An elastic demand is one in which the elasticity is greater than one, and thus a change in price has substantial effect on the demand of that good. A good is inelastic if the change in price does not directly cause a fluctuation in demand, and therefore an inelastic demand is one in which elasticity is less than one. A good is unitary elastic if the elasticity is equal to one. ",
    "url": "https://en.wikipedia.org/wiki/Law of demand"
  },
  "{\\displaystyle {\\text{Cross-price Elasticity Of Demand}}={\\frac {\\%{\\text{ change in quantity demanded of good A}}}{\\%{\\text{ change in price of good B}}}}}": {
    "before": "The cross elasticity of demand is an economic concept that measures the relative change in demand of a good when another good varies in price. The formula to solve for the coefficient of cross elasticity of demand is calculated by dividing the percentage change in quantity demanded of good A by the percentage change in price of good B.",
    "after": "The Cross elasticity of demand, also commonly referred to as the Cross-price elasticity of demand, allows companies to establish competitive prices against substitute goods and complementary goods . The metric figure produced by the equation thus determines the strength of both the relationship and competition between the two goods. ",
    "url": "https://en.wikipedia.org/wiki/Law of demand"
  },
  "{\\displaystyle \\epsilon _{d}={\\frac {\\%\\ {\\mbox{change in quantity demanded}}}{\\%\\ {\\mbox{change in income}}}}}": {
    "before": "Income elasticity of demand is an economic measurement tool developed to measure the sensitivity of a goods quantity demanded when there is a change in the real income of a consumer. To calculate the income elasticity of demand, the percentage change in quantity demanded is divided by the percentage change in the consumers income.",
    "after": "The Income elasticity of demand allows businesses to analyse and further predict the impact of business cycles on total sales.  The Income elastitcty of demand thus allows goods to be broadly categorised as Normal goods and Inferior goods . A positive measurement suggests that the good is a normal good, and a negative measurement suggests an inferior good. The Income elasticity of demand effectively represents a consumers idea as to whether a good is a luxury or a necessity.",
    "url": "https://en.wikipedia.org/wiki/Law of demand"
  },
  "{\\displaystyle AED={\\frac {\\%\\ {\\mbox{change in quantity demanded}}}{\\%\\ {\\mbox{change in spending on advertising}}}}={\\frac {\\Delta Q_{d}/Q_{d}}{\\Delta A/A}}}": {
    "before": "Advertising elasticity of demand measures the effectiveness of an advertising campaign as to generate new sales. To calculate the Advertising elasticity of demand, the percentage change in quantity demanded is divided by the percentage change in advertising expenditures. ",
    "after": "A business utilises the advertising elasticity of demand to measure the effectiveness of advertising on generating new sales. A positive elasticity indicates success for the advertisement as demand for the goods has increased. However, this measurement is also subject to the availability of substitutes, consumer behaviours and price points of the good being advertised. ",
    "url": "https://en.wikipedia.org/wiki/Law of demand"
  },
  "{\\displaystyle {\\frac {\\partial x_{i}}{\\partial p_{i}}}={\\frac {\\partial h_{i}}{\\partial p_{i}}}-{\\frac {\\partial x_{i}}{\\partial m}}x_{i}}": {
    "before": "Giffen goods violate the law of demand due to the income effect dominating the substitution effect . This can be illustrated with the Slutsky equation for a change in a good's own price:",
    "after": "The first term on the right-hand side is the substitution effect, which is always negative. The second term on the right side is the income effect, which can be positive or negative. For inferior goods, this is negative, so subtracting this means adding its positive absolute value. The non-derivative component of the income effect is a measure of a consumer's existing demand for the good, meaning that if a consumer spends a large amount of his income on an inferior good, then a price increase could cause the income effect to dominate the substitution effect. This leads to a positive partial derivative of the good's demand with regards to its price, which violates the law of demand.",
    "url": "https://en.wikipedia.org/wiki/Law of demand"
  },
  "{\\displaystyle {\\frac {dS}{dp}}={\\frac {{\\frac {1}{N}}\\sum {\\frac {\\partial x^{y}}{\\partial p}}}{1-{\\frac {1}{N}}\\sum {\\frac {\\partial x^{j}}{dS}}}}}": {
    "before": "However, despite appearing to break the law of demand, the upward-sloping demand curve for a Veblen good does not actually violate the law. This is because the social value of the good is itself dependent on the price; in other words, the good itself changes as the price changes.  This is illustrated when looking at the derivative of societal demand for a social good (goods whose value depends on others' consumption of it) with respect to price:",
    "after": "or {\\displaystyle \\left({\\frac {dS}{dp}}\\right)\\left(1-{\\frac {1}{N}}\\sum {\\frac {\\partial x^{j}}{dS}}\\right)={\\frac {1}{N}}\\sum {\\frac {\\partial x^{y}}{\\partial p}}}",
    "url": "https://en.wikipedia.org/wiki/Law of demand"
  },
  "{\\displaystyle \\left({\\frac {dS}{dp}}\\right)\\left(1-{\\frac {1}{N}}\\sum {\\frac {\\partial x^{j}}{dS}}\\right)={\\frac {1}{N}}\\sum {\\frac {\\partial x^{y}}{\\partial p}}}": {
    "before": "{\\displaystyle {\\frac {dS}{dp}}={\\frac {{\\frac {1}{N}}\\sum {\\frac {\\partial x^{y}}{\\partial p}}}{1-{\\frac {1}{N}}\\sum {\\frac {\\partial x^{j}}{dS}}}}} or",
    "after": "In other words, the rise in price increases the societal demand for the good, and because an individual demands less of this good the more others have, the entire left-hand side is positive, meaning the right-hand side is positive. The RHS means that in general, people will demand more of the social good the higher price goes (though not necessarily every individual will do so). Because of the price itself leading to a change in the social good's value, as opposed to a pure price effect leading to an increase in demand, this does not constitute a law of demand violation.",
    "url": "https://en.wikipedia.org/wiki/Law of demand"
  },
  "{\\textstyle p_{j}'-p_{j}=0\\;\\forall j\\neq i}": {
    "before": "This formula states that, for all possible prices p' and p, and corresponding demands x' and x, prices and demand must move in opposite directions, i.e. as price increases, demand must decrease and vice versa. Note that demands are demand bundles, not individual demands. Demand for a single good can still increase even though its price also increased, if there is another good whose price increased and which is sufficiently substituted away from. If good i is a Giffen good whose price increases while other goods' prices are held fixed (so that",
    "after": "), the law of demand is clearly violated, as we have both",
    "url": "https://en.wikipedia.org/wiki/Law of demand"
  },
  "{\\textstyle (p'-p)(x'-x)=(p_{i}'-p_{i})(x_{i}'-x_{i})>0}": {
    "before": "(as we consider a Giffen good), so that",
    "after": ".",
    "url": "https://en.wikipedia.org/wiki/Law of demand"
  },
  "Arable industry: {\\displaystyle A={{K}^{1/3}}{{L}^{2/3}}} Fishing industry: {\\displaystyle F={{K}^{1/2}}{{L}^{1/2}}}": {
    "before": "The CRS production functions must differ to make trade worthwhile in this model. For instance if the functions are Cobb–Douglas technologies the parameters applied to the inputs must vary. An example would be:",
    "after": "where A is the output in arable production, F is the output in fish production, and K , L are capital and labor in both cases.",
    "url": "https://en.wikipedia.org/wiki/Heckscher–Ohlin model"
  },
  "{\\displaystyle \\mathbf {F_{C}} =\\mathbf {V_{C}} -s_{C}\\mathbf {V} }": {
    "before": "Various attempts in the 1960s and 1970s have been made to \"solve\" the Leontief paradox and save the Heckscher–Ohlin model from failing. From the 1980s a new series of statistical tests had been tried. The new tests depended on Vanek's formula.  It takes a simple form",
    "after": "where {\\displaystyle \\mathbf {F_{C}} } is the net trade of factor service vector for country {\\displaystyle c} , {\\displaystyle \\mathbf {V_{C}} } the factor endowment vector for country {\\displaystyle c} , and {\\displaystyle s_{C}} the country {\\displaystyle c} 's share of the world consumption and {\\displaystyle \\mathbf {V} } the world total endowment vector of factors. For many countries and many factors, it is possible to estimate the left hand sides and right hand sides independently. To put it another way, the left hand side tells the direction of factor service trade. Thus it is possible to ask how this system of equations holds. The results obtained by Bowen, Leamer and Sveiskaus (1987) were disastrous.  They examined the cases of 12 factors and 27 countries for the year 1967. They found that the two sides of the equations had the same sign only for 61% of 324 cases. For the year 1983, the result was more disastrous. Both sides had the same sign only for 148 cases out of 297 cases (or the rate of correct predictions was 49.8%). The results of Bowen, Leamer, and Sveiskaus (1987) mean that the Heckscher–Ohlin–Vanek (HOV) theory has no predictive power concerning the direction of trade.",
    "url": "https://en.wikipedia.org/wiki/Heckscher–Ohlin model"
  },
  "algebraic sum of inflows = sinks − sources": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Economic model"
  },
  "{\\displaystyle \\pi (x,t)=xp(x)-C(x)-tx\\quad }": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Economic model"
  },
  "{\\displaystyle {\\frac {\\partial \\pi (x,t)}{\\partial x}}={\\frac {\\partial (xp(x)-C(x))}{\\partial x}}-t=0}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Economic model"
  },
  "{\\displaystyle {\\frac {\\partial ^{2}(xp(x)-C(x))}{\\partial ^{2}x}}={\\partial ^{2}\\pi (x,t) \\over \\partial x^{2}},}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Economic model"
  },
  "{\\displaystyle NNP=GNP-Depreciation}": {
    "before": "In national accounting , net national product (NNP) and net domestic product (NDP) are given by the two following formulas:",
    "after": "{\\displaystyle NDP=GDP-Depreciation}",
    "url": "https://en.wikipedia.org/wiki/Net national product"
  },
  "{\\displaystyle NDP=GDP-Depreciation}": {
    "before": "In national accounting , net national product (NNP) and net domestic product (NDP) are given by the two following formulas: {\\displaystyle NNP=GNP-Depreciation}",
    "after": "Use in economics [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Net national product"
  },
  "{\\displaystyle U_{i}(a_{i},b_{j},c_{i})=\\pi _{i}(a_{i},b_{j})+{\\tilde {f}}_{j}(b_{j},c_{i})*[1+f_{i}(a_{i},b_{j})].}": {
    "before": "Rabin formalized fairness using a two-person, modified game theory matrix with two decisions (a two by two matrix), where i is the person whose utility is being measured. Furthermore, within the game theory matrix payoffs for each person are allocated. The following formula was created by Rabin to model utility to include fairness:",
    "after": "Where: a i represents player i's strategy, b j represents player i's belief about what player j's strategy will be, and c i represents what player i's beliefs about player j's beliefs about player i's strategy. Although this seems complicated, a is simply player i's strategy, b is player j's strategy given how he/she believes player i will act, and c is player i's decision given what strategy player j is believed to partake in. In the game below, a, b, and c, will all take the form of either Grab or Share and then the payoffs would be determined and placed into Rabin's Fairness Model. {\\displaystyle \\pi _{i}(a_{i},b_{j})} represents the payoffs player i receives Player i's kindness to player j is given by: {\\displaystyle f_{i}(a_{i},b_{j})=[\\pi _{j}(b_{j},a_{i})-\\pi _{j}^{e}(b_{j})]/[\\pi _{j}^{h}(b_{j})-\\pi _{j}^{\\text{min}}(b_{j})]} {\\displaystyle \\pi _{j}^{e}(b_{j})=[\\pi _{j}^{h}(b_{j})+\\pi _{j}^{l}(b_{j})]/2,} , where {\\displaystyle \\pi _{j}^{h}(b_{j})} is player j's highest payoff and {\\displaystyle \\pi _{j}^{l}(b_{j})} is player j's lowest payoff among points that are Pareto efficient {\\displaystyle \\pi _{j}^{\\text{min}}(b_{j})} is the worst possible payoff in the matrix for player j Player i's belief about how kind player j is being to him is given by: {\\displaystyle {\\tilde {f}}_{j}(b_{j},c_{i})=[\\pi _{i}(c_{i},b_{j})-\\pi _{i}^{e}(c_{i})]/[\\pi _{i}^{h}(c_{i})-\\pi _{i}^{\\text{min}}(c_{i})]} {\\displaystyle \\pi _{i}^{\\text{min}}(c_{i})} is player i's worst possible payoff {\\displaystyle \\pi _{i}^{e}(c_{i})=[\\pi _{i}^{h}(c_{i})+\\pi _{i}^{l}(c_{i})]/2} , where {\\displaystyle \\pi _{i}^{h}(c_{i})} is player i's highest payoff and {\\displaystyle \\pi _{i^{l}}(c_{i})} is player i's lowest payoff among points that are Pareto efficient The two functions above can now specify player's preferences. Player i chooses a i to maximize the expected utility of {\\displaystyle U_{i}(a_{i},b_{j},c_{i})}",
    "url": "https://en.wikipedia.org/wiki/Rabin fairness"
  },
  "{\\displaystyle ICER={\\frac {(C_{1}-C_{0})}{(E_{1}-E_{0})}}} ,": {
    "before": "The incremental cost-effectiveness ratio ( ICER ) is a statistic used in cost-effectiveness analysis to summarise the cost-effectiveness of a health care intervention. It is defined by the difference in cost between two possible interventions, divided by the difference in their effect. It represents the average incremental cost associated with 1 additional unit of the measure of effect. The ICER can be estimated as:",
    "after": "where {\\textstyle C_{1}} and {\\displaystyle E_{1}} are the cost and effect in the intervention group and where {\\textstyle C_{0}} and {\\textstyle E_{0}} are the cost and effect in the control care group.  Costs are usually described in monetary units, while effects can be measured in terms of health status or another outcome of interest. A common application of the ICER is in cost-utility analysis , in which case the ICER is synonymous with the cost per quality-adjusted life year (QALY) gained.",
    "url": "https://en.wikipedia.org/wiki/Incremental cost-effectiveness ratio"
  },
  "Y = level of output": {
    "before": ", where:",
    "after": "K = private fixed capital",
    "url": "https://en.wikipedia.org/wiki/Infrastructure-based development"
  },
  "K = private fixed capital": {
    "before": "Y = level of output",
    "after": "G = level of government productive services",
    "url": "https://en.wikipedia.org/wiki/Infrastructure-based development"
  },
  "G = level of government productive services": {
    "before": "K = private fixed capital",
    "after": "N = population or labor force",
    "url": "https://en.wikipedia.org/wiki/Infrastructure-based development"
  },
  "N = population or labor force": {
    "before": "G = level of government productive services",
    "after": "Z = index of technological progress",
    "url": "https://en.wikipedia.org/wiki/Infrastructure-based development"
  },
  "Z = index of technological progress": {
    "before": "N = population or labor force",
    "after": "α and β are constants determined by available technology.",
    "url": "https://en.wikipedia.org/wiki/Infrastructure-based development"
  },
  "{\\displaystyle gW=gW^{T}-f(U)}": {
    "before": "The traditional Phillips curve story starts with a wage Phillips Curve, of the sort described by Phillips himself. This describes the rate of growth of money wages ( gW ). Here and below, the operator g is the equivalent of \"the percentage rate of growth of\" the variable that follows.",
    "after": "The \"money wage rate\" ( W ) is shorthand for total money wage costs per production employee, including benefits and payroll taxes. The focus is on only production workers' money wages, because (as discussed below) these costs are crucial to pricing decisions by the firms.",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "{\\displaystyle gW=gW^{T}-f(U)+\\lambda gP^{\\text{ex}}.}": {
    "before": "During the 1970s, this story had to be modified, because (as the late Abba Lerner had suggested in the 1940s) workers try to keep up with inflation. Since the 1970s, the equation has been changed to introduce the role of inflationary expectations (or the expected inflation rate, gP ex ). This produces the expectations-augmented wage Phillips curve:",
    "after": "The introduction of inflationary expectations into the equation implies that actual inflation can feed back into inflationary expectations and thus cause further inflation. The late economist James Tobin dubbed the last term \"inflationary inertia,\" because in the current period, inflation exists which represents an inflationary impulse left over from the past.",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "{\\displaystyle gW=gW^{T}-f(U-U^{*})+\\lambda gP^{\\text{ex}}.} ( 1 )": {
    "before": "In addition, the function f () was modified to introduce the idea of the non-accelerating inflation rate of unemployment (NAIRU) or what's sometimes called the \"natural\" rate of unemployment or the inflation-threshold unemployment rate:",
    "after": "Here, U* is the NAIRU. As discussed below, if U < U *, inflation tends to accelerate. Similarly, if U > U *, inflation tends to slow. It is assumed that f (0) = 0, so that when U = U *, the f term drops out of the equation.",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "{\\displaystyle gW^{T}=gZ^{T}.} ( 2 )": {
    "before": "An alternative is to assume that the trend rate of growth of money wages equals the trend rate of growth of average labor productivity ( Z ). That is:",
    "after": "Under assumption ( 2 ), when U equals U* and λ equals unity, expected real wages would increase with labor productivity. This would be consistent with an economy in which actual real wages increase with labor productivity. Deviations of real-wage trends from those of labor productivity might be explained by reference to other variables in the model.",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "gZ = gZ T and Z = Z T .": {
    "before": "The standardization involves later ignoring deviations from the trend in labor productivity. For example, assume that the growth of labor productivity is the same as that in the trend and that current productivity equals its trend value:",
    "after": "The markup reflects both the firm's degree of market power and the extent to which overhead costs have to be paid. Put another way, all else equal, M rises with the firm's power to set prices or with a rise of overhead costs relative to total costs.",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "P = M × ( unit labor cost ) + (unit materials cost)": {
    "before": "The markup reflects both the firm's degree of market power and the extent to which overhead costs have to be paid. Put another way, all else equal, M rises with the firm's power to set prices or with a rise of overhead costs relative to total costs.So pricing follows this equation:",
    "after": "= M × ( total production employment cost )/( quantity of output ) + UMC .",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "P = M × ( production employment cost per worker )/( output per production employee ) + UMC .": {
    "before": "UMC is unit raw materials cost (total raw materials costs divided by total output). So the equation can be restated as:",
    "after": "This equation can again be stated as:",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "P = M ×( average money wage )/( production labor productivity ) + UMC": {
    "before": "P = M × ( production employment cost per worker )/( output per production employee ) + UMC .This equation can again be stated as:",
    "after": "= M ×( W / Z ) + UMC .",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "gP = gW − gZ T .": {
    "before": "Now, assume that both the average price/cost mark-up ( M ) and UMC are constant. On the other hand, labor productivity grows, as before. Thus, an equation determining the price inflation rate ( gP ) is:",
    "after": "Price [ edit ]Then, combined with the wage Phillips curve [equation 1] and the assumption made above about the trend behavior of money wages [equation 2], this price-inflation equation gives us a simple expectations-augmented price Phillips curve:",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "gP = − f ( U − U* ) + λ · gP ex .": {
    "before": "Then, combined with the wage Phillips curve [equation 1] and the assumption made above about the trend behavior of money wages [equation 2], this price-inflation equation gives us a simple expectations-augmented price Phillips curve:",
    "after": "Some assume that we can simply add in gUMC , the rate of growth of UMC , in order to represent the role of supply shocks (of the sort that plagued the U.S. during the 1970s). This produces a standard short-term Phillips curve:",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "gP = − f ( U − U* ) + λ · gP ex + gUMC .": {
    "before": "Some assume that we can simply add in gUMC , the rate of growth of UMC , in order to represent the role of supply shocks (of the sort that plagued the U.S. during the 1970s). This produces a standard short-term Phillips curve:",
    "after": "Economist Robert J. Gordon has called this the \"Triangle Model\" because it explains short-run inflationary behavior by three factors: demand inflation (due to low unemployment), supply-shock inflation ( gUMC ), and inflationary expectations or inertial inflation.",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "gP = [1/(1 − λ )]·(− f ( U − U* ) + gUMC ).": {
    "before": "Expectational equilibrium gives us the long-term Phillips curve. First, with λ less than unity:",
    "after": "This is nothing but a steeper version of the short-run Phillips curve above. Inflation rises as unemployment falls, while this connection is stronger. That is, a low unemployment rate (less than U* ) will be associated with a higher inflation rate in the long run than in the short run. This occurs because the actual higher-inflation situation seen in the short run feeds back to raise inflationary expectations, which in turn raises the inflation rate further. Similarly, at high unemployment rates (greater than U* ) lead to low inflation rates. These in turn encourage lower inflationary expectations, so that inflation itself drops again.",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "- f ( U − U* ) = gUMC .": {
    "before": "This logic goes further if λ is equal to unity, i.e., if workers are able to protect their wages completely from expected inflation, even in the short run. Now, the Triangle Model equation becomes:",
    "after": "If we further assume (as seems reasonable) that there are no long-term supply shocks, this can be simplified to become:",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "− f ( U − U* ) = 0 which implies that U = U* .": {
    "before": "If we further assume (as seems reasonable) that there are no long-term supply shocks, this can be simplified to become:",
    "after": "All of the assumptions imply that in the long run, there is only one possible unemployment rate, U* at any one time. This uniqueness explains why some call this unemployment rate \"natural.\"",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "{\\displaystyle Y=Y_{n}+a(P-P_{e})\\,}": {
    "before": "The Phillips curve equation can be derived from the (short-run) Lucas aggregate supply function . The Lucas approach is very different from that of the traditional view. Instead of starting with empirical data, he started with a classical economic model following very simple economic principles.Start with the aggregate supply function:",
    "after": "where Y is log value of the actual output , {\\displaystyle Y_{n}} is log value of the \"natural\" level of output, {\\displaystyle a} is a positive constant, {\\displaystyle P} is log value of the actual price level , and {\\displaystyle P_{e}} is log value of the expected price level . Lucas assumes that {\\displaystyle Y_{n}} has a unique value.",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "{\\displaystyle P=P_{e}+{\\frac {Y-Y_{n}}{a}}}": {
    "before": "This differs from other views of the Phillips curve, in which the failure to attain the \"natural\" level of output can be due to the imperfection or incompleteness of markets, the stickiness of prices, and the like. In the non-Lucas view, incorrect expectations can contribute to aggregate demand failure, but they are not the only cause. To the \"new Classical\" followers of Lucas, markets are presumed to be perfect and always attain equilibrium (given inflationary expectations).We re-arrange the equation into:",
    "after": "Next we add unexpected exogenous shocks to the world supply {\\displaystyle v} :",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "{\\displaystyle P=P_{e}+{\\frac {Y-Y_{n}}{a}}+v}": {
    "before": "Next we add unexpected exogenous shocks to the world supply {\\displaystyle v} :",
    "after": "Subtracting last year's price levels {\\displaystyle P_{-1}} will give us inflation rates, because",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "{\\displaystyle {\\frac {Y-Y_{n}}{a}}=-b(U-U_{n})}": {
    "before": "There is also a negative relationship between output and unemployment (as expressed by Okun's law ). Therefore, using",
    "after": "where {\\displaystyle b} is a positive constant, {\\displaystyle U} is unemployment, and {\\displaystyle U_{n}} is the natural rate of unemployment or NAIRU , we arrive at the final form of the short-run Phillips curve:",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "{\\displaystyle \\pi =\\pi _{e}-b(U-U_{n})+v.}": {
    "before": "where {\\displaystyle b} is a positive constant, {\\displaystyle U} is unemployment, and {\\displaystyle U_{n}} is the natural rate of unemployment or NAIRU , we arrive at the final form of the short-run Phillips curve:",
    "after": "This equation, plotting inflation rate {\\displaystyle \\pi } against unemployment {\\displaystyle U} gives the downward-sloping curve in the diagram that characterizes the Phillips curve.",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "{\\displaystyle \\pi _{t}=\\beta E_{t}[\\pi _{t+1}]+\\kappa y_{t}}": {
    "before": "The New Keynesian Phillips curve was originally derived by Roberts in 1995,  and since been used in most state-of-the-art New Keynesian DSGE models like the one of Clarida, Galí, and Gertler (2000).  ",
    "after": "where {\\displaystyle \\kappa ={\\frac {\\alpha [1-(1-\\alpha )\\beta ]\\phi }{1-\\alpha }}.}",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "{\\displaystyle \\kappa ={\\frac {\\alpha [1-(1-\\alpha )\\beta ]\\phi }{1-\\alpha }}.}": {
    "before": "{\\displaystyle \\pi _{t}=\\beta E_{t}[\\pi _{t+1}]+\\kappa y_{t}} where",
    "after": "The current expectations of next period's inflation are incorporated as {\\displaystyle \\beta E_{t}[\\pi _{t+1}]} .",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "P = M × (unit labor cost) + (unit materials cost)= M × (total production employment cost)/(quantity of output) + UMC.": {
    "before": "So pricing follows this equation:",
    "after": "UMC is unit raw materials cost (total raw materials costs divided by total output). So the equation can be restated as:",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "P = M×(average money wage)/(production labor productivity) + UMC= M×(W/Z) + UMC.": {
    "before": "This equation can again be stated as:",
    "after": "Now, assume that both the average price/cost mark-up (M) and UMC are constant. On the other hand, labor productivity grows, as before. Thus, an equation determining the price inflation rate (gP) is:",
    "url": "https://en.wikipedia.org/wiki/Phillips curve"
  },
  "Currency: 1 Nepali rupee (NPR) = 100 paisa": {
    "before": "Economic aid - recipient: $2 billion (FY 2019/20)",
    "after": "Fiscal year: 16 July - 15 July",
    "url": "https://en.wikipedia.org/wiki/Economy of Nepal"
  },
  "{\\displaystyle Y(t)=K(t)^{\\alpha }(A(t)L(t))^{1-\\alpha }\\,}": {
    "before": "The textbook Solow–Swan model is set in continuous-time world with no government or international trade. A single good (output) is produced using two factors of production , labor ( {\\displaystyle L} ) and capital ( {\\displaystyle K} ) in an aggregate production function that satisfies the Inada conditions , which imply that the elasticity of substitution must be asymptotically equal to one.  ",
    "after": "where {\\displaystyle t} denotes time, {\\displaystyle 0<\\alpha <1} is the elasticity of output with respect to capital, and {\\displaystyle Y(t)} represents total production. {\\displaystyle A} refers to labor-augmenting technology or “ knowledge ”, thus {\\displaystyle AL} represents effective labor. All factors of production are fully employed, and initial values {\\displaystyle A(0)} , {\\displaystyle K(0)} , and {\\displaystyle L(0)} are given. The number of workers, i.e. labor, as well as the level of technology grow exogenously at rates {\\displaystyle n} and {\\displaystyle g} , respectively:",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle L(t)=L(0)e^{nt}} {\\displaystyle A(t)=A(0)e^{gt}}": {
    "before": "where {\\displaystyle t} denotes time, {\\displaystyle 0<\\alpha <1} is the elasticity of output with respect to capital, and {\\displaystyle Y(t)} represents total production. {\\displaystyle A} refers to labor-augmenting technology or “ knowledge ”, thus {\\displaystyle AL} represents effective labor. All factors of production are fully employed, and initial values {\\displaystyle A(0)} , {\\displaystyle K(0)} , and {\\displaystyle L(0)} are given. The number of workers, i.e. labor, as well as the level of technology grow exogenously at rates {\\displaystyle n} and {\\displaystyle g} , respectively:",
    "after": "The number of effective units of labor, {\\displaystyle A(t)L(t)} , therefore grows at rate {\\displaystyle (n+g)} . Meanwhile, the stock of capital depreciates over time at a constant rate {\\displaystyle \\delta } . However, only a fraction of the output ( {\\displaystyle cY(t)} with {\\displaystyle 0<c<1} ) is consumed , leaving a saved share {\\displaystyle s=1-c} for investment . This dynamic is expressed through the following differential equation :",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle {\\dot {K}}(t)=s\\cdot Y(t)-\\delta \\cdot K(t)\\,}": {
    "before": "The number of effective units of labor, {\\displaystyle A(t)L(t)} , therefore grows at rate {\\displaystyle (n+g)} . Meanwhile, the stock of capital depreciates over time at a constant rate {\\displaystyle \\delta } . However, only a fraction of the output ( {\\displaystyle cY(t)} with {\\displaystyle 0<c<1} ) is consumed , leaving a saved share {\\displaystyle s=1-c} for investment . This dynamic is expressed through the following differential equation :",
    "after": "where {\\displaystyle {\\dot {K}}} is shorthand for {\\displaystyle {\\frac {dK(t)}{dt}}} , the derivative with respect to time. Derivative with respect to time means that it is the change in capital stock—output that is neither consumed nor used to replace worn-out old capital goods is net investment.",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle y(t)={\\frac {Y(t)}{A(t)L(t)}}=k(t)^{\\alpha }}": {
    "before": "Since the production function {\\displaystyle Y(K,AL)} has constant returns to scale , it can be written as output per effective unit of labour {\\displaystyle y} , which is a measure for wealth creation: [note 2]",
    "after": "The main interest of the model is the dynamics of capital intensity {\\displaystyle k} , the capital stock per unit of effective labour. Its behaviour over time is given by the key equation of the Solow–Swan model: [note 3]",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle {\\dot {k}}(t)=sk(t)^{\\alpha }-(n+g+\\delta )k(t)}": {
    "before": "The main interest of the model is the dynamics of capital intensity {\\displaystyle k} , the capital stock per unit of effective labour. Its behaviour over time is given by the key equation of the Solow–Swan model: [note 3]",
    "after": "The first term, {\\displaystyle sk(t)^{\\alpha }=sy(t)} , is the actual investment per unit of effective labour: the fraction {\\displaystyle s} of the output per unit of effective labour {\\displaystyle y(t)} that is saved and invested. The second term, {\\displaystyle (n+g+\\delta )k(t)} , is the “break-even investment”: the amount of investment that must be invested to prevent {\\displaystyle k} from falling.  : 16 The equation implies that {\\displaystyle k(t)} converges to a steady-state value of {\\displaystyle k^{*}} , defined by {\\displaystyle sk(t)^{\\alpha }=(n+g+\\delta )k(t)} , at which there is neither an increase nor a decrease of capital intensity:",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle k^{*}=\\left({\\frac {s}{n+g+\\delta }}\\right)^{1/(1-\\alpha )}\\,}": {
    "before": "The first term, {\\displaystyle sk(t)^{\\alpha }=sy(t)} , is the actual investment per unit of effective labour: the fraction {\\displaystyle s} of the output per unit of effective labour {\\displaystyle y(t)} that is saved and invested. The second term, {\\displaystyle (n+g+\\delta )k(t)} , is the “break-even investment”: the amount of investment that must be invested to prevent {\\displaystyle k} from falling.  : 16 The equation implies that {\\displaystyle k(t)} converges to a steady-state value of {\\displaystyle k^{*}} , defined by {\\displaystyle sk(t)^{\\alpha }=(n+g+\\delta )k(t)} , at which there is neither an increase nor a decrease of capital intensity:",
    "after": "at which the stock of capital {\\displaystyle K} and effective labour {\\displaystyle AL} are growing at rate {\\displaystyle (n+g)} . Likewise, it is possible to calculate the steady-state of created wealth {\\displaystyle y^{*}} that corresponds with {\\displaystyle k^{*}} :",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle y^{*}=\\left({\\frac {s}{n+g+\\delta }}\\right)^{\\alpha /(1-\\alpha )}\\,}": {
    "before": "at which the stock of capital {\\displaystyle K} and effective labour {\\displaystyle AL} are growing at rate {\\displaystyle (n+g)} . Likewise, it is possible to calculate the steady-state of created wealth {\\displaystyle y^{*}} that corresponds with {\\displaystyle k^{*}} :",
    "after": "By assumption of constant returns, output {\\displaystyle Y} is also growing at that rate. In essence, the Solow–Swan model predicts that an economy will converge to a balanced-growth equilibrium , regardless of its starting point. In this situation, the growth of output per worker is determined solely by the rate of technological progress .  : 18",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle {\\frac {K(t)}{Y(t)}}={\\frac {s}{n+g+\\delta }}}": {
    "before": "Since, by definition, {\\displaystyle {\\frac {K(t)}{Y(t)}}=k(t)^{1-\\alpha }} , at the equilibrium {\\displaystyle k^{*}} we have",
    "after": "Therefore, at the equilibrium, the capital/output ratio depends only on the saving, growth, and depreciation rates. This is the Solow–Swan model's version of the golden rule saving rate .",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle MPK={\\frac {\\partial Y}{\\partial K}}={\\frac {\\alpha A^{1-\\alpha }}{(K/L)^{1-\\alpha }}}}": {
    "before": "Since {\\displaystyle {\\alpha }<1} , at any time {\\displaystyle t} the marginal product of capital {\\displaystyle K(t)} in the Solow–Swan model is inversely related to the capital/labor ratio.",
    "after": "If productivity {\\displaystyle A} is the same across countries, then countries with less capital per worker {\\displaystyle K/L} have a higher marginal product, which would provide a higher return on capital investment. As a consequence, the model predicts that in a world of open market economies and global financial capital, investment will flow from rich countries to poor countries, until capital/worker {\\displaystyle K/L} and income/worker {\\displaystyle Y/L} equalize across countries.",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle \\alpha ={\\frac {K{\\frac {\\partial Y}{\\partial K}}}{Y}}={\\frac {rK}{Y}}\\,}": {
    "before": "Because the marginal product of capital {\\displaystyle {\\frac {\\partial Y}{\\partial K}}} equals the rate of return {\\displaystyle r}",
    "after": "so that {\\displaystyle \\alpha } is the fraction of income appropriated by capital. Thus, the Solow–Swan model assumes from the beginning that the labor-capital split of income is constant.",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle Y(t)=K(t)^{\\alpha }H(t)^{\\beta }(A(t)L(t))^{1-\\alpha -\\beta },}": {
    "before": "Similar to the textbook Solow–Swan model, the production function is of Cobb–Douglas type:",
    "after": "where {\\displaystyle H(t)} is the stock of human capital, which depreciates at the same rate {\\displaystyle \\delta } as physical capital. For simplicity, they assume the same function of accumulation for both types of capital. Like in Solow–Swan, a fraction of the outcome, {\\displaystyle sY(t)} , is saved each period, but in this case split up and invested partly in physical and partly in human capital, such that {\\displaystyle s=s_{K}+s_{H}} . Therefore, there are two fundamental dynamic equations in this model:",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle {\\dot {k}}=s_{K}k^{\\alpha }h^{\\beta }-(n+g+\\delta )k} {\\displaystyle {\\dot {h}}=s_{H}k^{\\alpha }h^{\\beta }-(n+g+\\delta )h}": {
    "before": "where {\\displaystyle H(t)} is the stock of human capital, which depreciates at the same rate {\\displaystyle \\delta } as physical capital. For simplicity, they assume the same function of accumulation for both types of capital. Like in Solow–Swan, a fraction of the outcome, {\\displaystyle sY(t)} , is saved each period, but in this case split up and invested partly in physical and partly in human capital, such that {\\displaystyle s=s_{K}+s_{H}} . Therefore, there are two fundamental dynamic equations in this model:",
    "after": "The balanced (or steady-state) equilibrium growth path is determined by {\\displaystyle {\\dot {k}}={\\dot {h}}=0} , which means {\\displaystyle s_{K}k^{\\alpha }h^{\\beta }-(n+g+\\delta )k=0} and {\\displaystyle s_{H}k^{\\alpha }h^{\\beta }-(n+g+\\delta )h=0} . Solving for the steady-state level of {\\displaystyle k} and {\\displaystyle h} yields:",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle k^{*}=\\left({\\frac {s_{K}^{1-\\beta }s_{H}^{\\beta }}{n+g+\\delta }}\\right)^{\\frac {1}{1-\\alpha -\\beta }}} {\\displaystyle h^{*}=\\left({\\frac {s_{K}^{\\alpha }s_{H}^{1-\\alpha }}{n+g+\\delta }}\\right)^{\\frac {1}{1-\\alpha -\\beta }}}": {
    "before": "The balanced (or steady-state) equilibrium growth path is determined by {\\displaystyle {\\dot {k}}={\\dot {h}}=0} , which means {\\displaystyle s_{K}k^{\\alpha }h^{\\beta }-(n+g+\\delta )k=0} and {\\displaystyle s_{H}k^{\\alpha }h^{\\beta }-(n+g+\\delta )h=0} . Solving for the steady-state level of {\\displaystyle k} and {\\displaystyle h} yields:",
    "after": "In the steady state, {\\displaystyle y^{*}=(k^{*})^{\\alpha }(h^{*})^{\\beta }} .",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle MPK={\\frac {\\partial Y}{\\partial K}}={\\frac {\\alpha A^{1-\\alpha }(H/L)^{\\beta }}{(K/L)^{1-\\alpha }}}}": {
    "before": "Theodore Breton provided an insight that reconciled the large effect of human capital from schooling in the Mankiw, Romer and Weil model with the smaller effect of schooling on workers' salaries. He demonstrated that the mathematical properties of the model include significant external effects between the factors of production, because human capital and physical capital are multiplicative factors of production.  The external effect of human capital on the productivity of physical capital is evident in the marginal product of physical capital:",
    "after": "He showed that the large estimates of the effect of human capital in cross-country estimates of the model are consistent with the smaller effect typically found on workers' salaries when the external effects of human capital on physical capital and labor are taken into account. This insight significantly strengthens the case for the Mankiw, Romer, and Weil version of the Solow–Swan model. Most analyses criticizing this model fail to account for the pecuniary external effects of both types of capital inherent in the model. ",
    "url": "https://en.wikipedia.org/wiki/Solow–Swan model"
  },
  "{\\displaystyle y_{i}=f(x_{i};\\beta )\\cdot TE_{i}\\cdot \\exp \\left\\{{v_{i}}\\right\\}}": {
    "before": "The stochastic production frontier will become:",
    "after": "We assume that TE i is also a stochastic variable, with a specific distribution function, common to all producers.",
    "url": "https://en.wikipedia.org/wiki/Stochastic frontier analysis"
  },
  "{\\displaystyle y_{i}=f(x_{i};\\beta )\\cdot \\exp \\left\\{{-u_{i}}\\right\\}\\cdot \\exp \\left\\{{v_{i}}\\right\\}}": {
    "before": "We can also write it as an exponential {\\displaystyle TE_{i}=\\exp \\left\\{{-u_{i}}\\right\\}} , where u i ≥ 0 , since we required TE i ≤ 1 . Thus, we obtain the following equation:",
    "after": "Now, if we also assume that f(x i , β) takes the log-linear Cobb–Douglas form, the model can be written as:",
    "url": "https://en.wikipedia.org/wiki/Stochastic frontier analysis"
  },
  "{\\displaystyle \\ln y_{i}=\\beta _{0}+\\sum \\limits _{n}{\\beta _{n}\\ln x_{ni}+v_{i}-u_{i}}}": {
    "before": "Now, if we also assume that f(x i , β) takes the log-linear Cobb–Douglas form, the model can be written as:",
    "after": "where v i is the “noise” component, which we will almost always consider as a two-sided normally distributed variable, and u i is the non-negative technical inefficiency component. Together they constitute a compound error term , with a specific distribution to be determined, hence the name of “composed error model” as is often referred.",
    "url": "https://en.wikipedia.org/wiki/Stochastic frontier analysis"
  },
  "TEi = 1 shows that the i-th firm obtains the maximum feasible output, while TEi < 1 provides a measure of the shortfall of the observed output from maximum feasible output.": {
    "before": "TEi denotes the technical efficiency defined as the ratio of observed output to maximum feasible output.",
    "after": "A stochastic component that describes random shocks affecting the production process is added. These shocks are not directly attributable to the producer or the underlying technology. These shocks may come from weather changes, economic adversities or plain luck. We denote these effects with",
    "url": "https://en.wikipedia.org/wiki/Stochastic frontier analysis"
  },
  "{\\displaystyle {\\frac {p_{A}A}{p.q}}={\\frac {p-c}{p}}.e_{A}}": {
    "before": "A simple textbook presentation of the mathematical statement of the approach is as follows:",
    "after": "Where {\\displaystyle \\ p_{A}} is the price per unit of advertising {\\displaystyle \\ A} is the amount of advertising {\\displaystyle \\ p} is the price of the good {\\displaystyle \\ q} is the output of the good {\\displaystyle \\ c} is the average or marginal, depending on the assumptions, cost of production {\\displaystyle \\ e_{A}} is the advertising elasticity of demand. ",
    "url": "https://en.wikipedia.org/wiki/Dorfman–Steiner theorem"
  },
  "{\\displaystyle \\tau ={\\frac {1-{\\bar {g}}}{1-{\\bar {g}}+{\\bar {\\zeta }}^{u}+{\\bar {\\zeta }}^{c}(\\alpha -1)}}}": {
    "before": "The sum of these effects should be zero at the optimum. Stipulating this condition results in the following formula for the optimal top tax rate, if incomes are Pareto distributed :",
    "after": "where: {\\displaystyle \\tau } is the tax rate {\\displaystyle {\\bar {g}}} is the ratio of social marginal utility for the top bracket taxpayers to the marginal value of public funds for the government, which depends on the social welfare function. The case {\\displaystyle {\\bar {g}}=0} corresponds to one where the government does not care about the welfare of top bracket taxpayers, and wants to raise as much revenue as possible from them, so setting {\\displaystyle {\\bar {g}}=0} gives a formula for the revenue-maximising top tax rate. {\\displaystyle {\\bar {\\zeta }}^{u}} and {\\displaystyle {\\bar {\\zeta }}^{c}} are respectively the uncompensated and compensated elasticity of labour supply ; higher elasticities imply that labour supply will fall more in response to an increase in taxes. {\\displaystyle \\alpha } is the shape parameter in the Pareto distribution of income.",
    "url": "https://en.wikipedia.org/wiki/Optimal labor income taxation"
  },
  "{\\displaystyle \\Delta U=U(S_{2})-U(S_{1})\\,}": {
    "before": "Under the special case in which usefulness can be quantified, the change in utility of moving from state {\\displaystyle S_{1}} to state {\\displaystyle S_{2}} is",
    "after": "Moreover, if {\\displaystyle S_{1}} and {\\displaystyle S_{2}} are distinguishable by values of just one variable {\\displaystyle g\\,} which is itself quantified, then it becomes possible to speak of the ratio of the marginal utility of the change in {\\displaystyle g\\,} to the size of that change:",
    "url": "https://en.wikipedia.org/wiki/Marginal utility"
  },
  "{\\displaystyle MRS_{AB}={\\frac {1}{MRS_{BA}}}}": {
    "before": "When the goods and services are continuously divisible in the limiting case",
    "after": "and the marginal rate of substitution is the slope of the indifference curve (multiplied by {\\displaystyle -1} ).",
    "url": "https://en.wikipedia.org/wiki/Marginalism"
  },
  "{\\displaystyle MRS_{SG}={\\frac {2{\\text{ sheep}}}{\\text{goat}}}}": {
    "before": "If, for example, Lisa will not trade a goat for anything less than two sheep, then her",
    "after": "If she will not trade a sheep for anything less than two goats, then her",
    "url": "https://en.wikipedia.org/wiki/Marginalism"
  },
  "{\\displaystyle MRS_{GS}={\\frac {2{\\text{ goat}}}{\\text{sheep}}}\\neq {\\frac {1{\\text{ goat}}}{2{\\text{ sheep}}}}={\\frac {1}{\\left({\\frac {2{\\text{ sheep}}}{\\text{goat}}}\\right)}}={\\frac {1}{MRS_{SG}}}}": {
    "before": "If she will not trade a sheep for anything less than two goats, then her",
    "after": "However, if she would trade one gram of banana for one ounce of ice cream and vice versa , then",
    "url": "https://en.wikipedia.org/wiki/Marginalism"
  },
  "{\\displaystyle MRS_{IB}={\\frac {1{\\text{ oz ice cream}}}{1{\\text{ g banana}}}}={\\frac {1}{\\left({\\frac {1{\\text{ g banana}}}{1{\\text{ oz ice cream}}}}\\right)}}={\\frac {1}{MRS_{BI}}}}": {
    "before": "However, if she would trade one gram of banana for one ounce of ice cream and vice versa , then",
    "after": "When indifference curves (which are essentially graphs of instantaneous rates of substitution) and the convexity of those curves are not taken as given, the \"law\" of diminishing marginal utility is invoked to explain diminishing marginal rates of substitution – a willingness to accept fewer units of good or service {\\displaystyle A} in substitution for {\\displaystyle B} as one's holdings of {\\displaystyle A} grow relative to those of {\\displaystyle B} . If an individual has a stock or flow of a good or service whose marginal utility is less than would be that of some other good or service for which he or she could trade, then it is in his or her interest to effect that trade. As one thing is traded-away and another is acquired, the respective marginal gains or losses from further trades are now changed. On the assumption that the marginal utility of one is diminishing, and the other is not increasing, all else being equal, an individual will demand an increasing ratio of that which is acquired to that which is sacrificed. One important way in which all else might not be equal is when the use of the one good or service complements that of the other. In such cases, exchange ratios might be constant.  If any trader can better his or her own marginal position by offering an exchange more favorable to other traders with desired goods or services, then he or she will do so.",
    "url": "https://en.wikipedia.org/wiki/Marginalism"
  },
  "{\\displaystyle Y=AK^{a}L^{1-a}\\,}": {
    "before": "The AK model production function is a special case of a Cobb–Douglas production function :",
    "after": "This equation shows a Cobb–Douglas function where Y represents the total production in an economy. A represents total factor productivity , K is capital, L is labor, and the parameter {\\displaystyle a} measures the output elasticity of capital. For the special case in which {\\displaystyle a=1} , the production function becomes linear in capital thereby giving constant returns to scale : ",
    "url": "https://en.wikipedia.org/wiki/Endogenous growth theory"
  },
  "{\\displaystyle Y=AK\\,}": {
    "before": "In an alternative form {\\displaystyle Y=AK} , {\\displaystyle K} embodies both physical capital and human capital.",
    "after": "In the above equation A is the level of technology which is positive constant and K represents volume of capital. Hence, output per capita is:",
    "url": "https://en.wikipedia.org/wiki/AK model"
  },
  "{\\displaystyle {\\frac {Y}{L}}=A\\cdot {\\frac {K}{L}}} i.e. {\\displaystyle y=Ak}": {
    "before": "In the above equation A is the level of technology which is positive constant and K represents volume of capital. Hence, output per capita is:",
    "after": "The model implicitly assumes that the average product of capital is equal to marginal product of capital which is equivalent to:",
    "url": "https://en.wikipedia.org/wiki/AK model"
  },
  "{\\displaystyle Y={\\begin{cases}\\xi K,&\\xi >0\\\\Y_{0}{\\frac {L}{L_{0}}}\\left({\\frac {L_{0}}{L}}{\\frac {P}{P_{0}}}\\right)^{\\alpha },&0<\\alpha <1\\end{cases}}}": {
    "before": "To avoid the contradictions, Russian economist Vladimir Pokrovskii proposed to write the production function in the united form",
    "after": "where {\\displaystyle P} is a capital service; {\\displaystyle Y_{0}} , {\\displaystyle L_{0}} and {\\displaystyle P_{0}} correspond to output, labour and substitutive work in the base year. This form of the theory explains growth as a consequence of the dynamics of the production factors, without any arbitrary parameters, which makes it possible to reproduce historical rates of economic growth with considerable precision.   ",
    "url": "https://en.wikipedia.org/wiki/Endogenous growth theory"
  },
  "{\\displaystyle k(t)=s\\cdot f(k)-nk}": {
    "before": "The model again assumes that labor force is growing at a constant rate ‘n’ and there is no depreciation of capital. (δ = 0 ) In this case, the basic differential equation of neo-classical growth model would be:",
    "after": "Hence, {\\displaystyle {\\frac {k(t)}{k}}=s\\cdot {\\frac {f(k)}{k}}-n}",
    "url": "https://en.wikipedia.org/wiki/AK model"
  },
  "{\\displaystyle n}= population growth rate": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/AK model"
  },
  "{\\displaystyle \\delta \\ }= depreciation": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/AK model"
  },
  "{\\displaystyle k}= capital per worker": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/AK model"
  },
  "{\\displaystyle y}= output/income per worker": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/AK model"
  },
  "{\\displaystyle L}= labor force": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/AK model"
  },
  "{\\displaystyle s}= saving rate": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/AK model"
  },
  "{\\displaystyle P_{ni}\\equiv \\Pr({\\text{Person }}n{\\text{ chooses alternative }}i)=G(x_{ni},\\;x_{nj,j\\neq i},\\;s_{n},\\;\\beta ),}": {
    "before": "A discrete choice model specifies the probability that a person chooses a particular alternative, with the probability expressed as a function of observed variables that relate to the alternatives and the person. In its general form, the probability that person n chooses alternative i is expressed as:",
    "after": "where {\\displaystyle x_{ni}} is a vector of attributes of alternative i faced by person n ,",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle y_{ni}={\\begin{cases}1&U_{ni}>U_{nj}\\quad \\forall j\\neq i\\\\0&{\\text{otherwise}}\\end{cases}}}": {
    "before": "U ni is the utility (or net benefit or well-being) that person n obtains from choosing alternative i . The behavior of the person is utility-maximizing: person n chooses the alternative that provides the highest utility. The choice of the person is designated by dummy variables, y ni , for each alternative:",
    "after": "Consider now the researcher who is examining the choice. The person's choice depends on many factors, some of which the researcher observes and some of which the researcher does not. The utility that the person obtains from choosing an alternative is decomposed into a part that depends on variables that the researcher observes and a part that depends on variables that the researcher does not observe. In a linear form, this decomposition is expressed as",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle U_{ni}=\\beta z_{ni}+\\varepsilon _{ni}}": {
    "before": "Consider now the researcher who is examining the choice. The person's choice depends on many factors, some of which the researcher observes and some of which the researcher does not. The utility that the person obtains from choosing an alternative is decomposed into a part that depends on variables that the researcher observes and a part that depends on variables that the researcher does not observe. In a linear form, this decomposition is expressed as",
    "after": "where {\\displaystyle z_{ni}} is a vector of observed variables relating to alternative i for person n that depends on attributes of the alternative, x ni , interacted perhaps with attributes of the person, s n , such that it can be expressed as {\\displaystyle z_{ni}=z(x_{ni},s_{n})} for some numerical function z , {\\displaystyle \\beta } is a corresponding vector of coefficients of the observed variables, and {\\displaystyle \\varepsilon _{ni}} captures the impact of all unobserved factors that affect the person's choice.",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle {\\begin{aligned}P_{ni}&=\\Pr(y_{ni}=1)\\\\&=\\Pr \\left(\\bigcap _{j\\neq i}U_{ni}>U_{nj},\\right)\\\\&=\\Pr \\left(\\bigcap _{j\\neq i}\\beta z_{ni}+\\varepsilon _{ni}>\\beta z_{nj}+\\varepsilon _{nj},\\right)\\\\&=\\Pr \\left(\\bigcap _{j\\neq i}\\varepsilon _{nj}-\\varepsilon _{ni}<\\beta z_{ni}-\\beta z_{nj},\\right)\\end{aligned}}}": {
    "before": "{\\displaystyle z_{ni}} is a vector of observed variables relating to alternative i for person n that depends on attributes of the alternative, x ni , interacted perhaps with attributes of the person, s n , such that it can be expressed as {\\displaystyle z_{ni}=z(x_{ni},s_{n})} for some numerical function z , {\\displaystyle \\beta } is a corresponding vector of coefficients of the observed variables, and {\\displaystyle \\varepsilon _{ni}} captures the impact of all unobserved factors that affect the person's choice.The choice probability is then",
    "after": "Given β , the choice probability is the probability that the random terms, ε nj − ε ni (which are random from the researcher's perspective, since the researcher does not observe them) are below the respective quantities {\\displaystyle \\forall j\\neq i:\\beta z_{ni}-\\beta z_{nj}.} Different choice models (i.e. different specifications of G) arise from different distributions of ε ni for all i and different treatments of β .",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle P_{ni}=\\Pr(y_{ni}=1)=\\Pr \\left(\\bigcap _{j\\neq i}U_{ni}>U_{nj}\\right)=\\Pr \\left(\\bigcap _{j\\neq i}U_{ni}-U_{nj}>0\\right)}": {
    "before": "The probability that a person chooses a particular alternative is determined by comparing the utility of choosing that alternative to the utility of choosing other alternatives:",
    "after": "As the last term indicates, the choice probability depends only on the difference in utilities between alternatives, not on the absolute level of utilities. Equivalently, adding a constant to the utilities of all the alternatives does not change the choice probabilities.",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle {\\begin{cases}U_{n}=\\beta s_{n}+\\varepsilon _{n}\\\\y_{n}={\\begin{cases}1&U_{n}>0\\\\0&U_{n}\\leqslant 0\\end{cases}}\\\\\\varepsilon \\sim {\\text{Logistic}}\\end{cases}}\\quad \\Rightarrow \\quad P_{n1}={\\frac {1}{1+\\exp(-\\beta s_{n})}}}": {
    "before": "U n is the utility (or net benefit) that person n obtains from taking an action (as opposed to not taking the action). The utility the person obtains from taking the action depends on the characteristics of the person, some of which are observed by the researcher and some are not. The person takes the action, y n = 1 , if U n > 0. The unobserved term, ε n , is assumed to have a logistic distribution . The specification is written succinctly as:",
    "after": "B. Probit with attributes of the person but no attributes of the alternatives [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle {\\begin{cases}U_{n}=\\beta s_{n}+\\varepsilon _{n}\\\\y_{n}={\\begin{cases}1&U_{n}>0\\\\0&U_{n}\\leqslant 0\\end{cases}}\\\\\\varepsilon \\sim {\\text{Standard normal}}\\end{cases}}\\quad \\Rightarrow \\quad P_{n1}=\\Phi (\\beta s_{n}),}": {
    "before": "The description of the model is the same as model A , except the unobserved terms are distributed standard normal instead of logistic .",
    "after": "where {\\displaystyle \\Phi } is cumulative distribution function of standard normal .",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle {\\begin{cases}U_{n1}=\\beta z_{n1}+\\varepsilon _{n1}\\\\U_{n2}=\\beta z_{n2}+\\varepsilon _{n2}\\\\\\varepsilon _{n1},\\varepsilon _{n2}\\sim {\\text{iid extreme value}}\\end{cases}}\\quad \\Rightarrow \\quad P_{n1}={\\frac {\\exp(\\beta z_{n1})}{\\exp(\\beta z_{n1})+\\exp(\\beta z_{n2})}}}": {
    "before": "U ni is the utility person n obtains from choosing alternative i . The utility of each alternative depends on the attributes of the alternatives interacted perhaps with the attributes of the person. The unobserved terms are assumed to have an extreme value distribution. [nb 1]",
    "after": "We can relate this specification to model A above, which is also binary logit. In particular, P n 1 can also be expressed as",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle P_{n1}={\\frac {1}{1+\\exp(-\\beta (z_{n1}-z_{n2}))}}}": {
    "before": "We can relate this specification to model A above, which is also binary logit. In particular, P n 1 can also be expressed as",
    "after": "Note that if two error terms are iid extreme value , [nb 1] their difference is distributed logistic , which is the basis for the equivalence of the two specifications.",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle P_{n1}=\\Phi (\\beta (z_{n1}-z_{n2})),}": {
    "before": "The description of the model is the same as model C , except the difference of the two unobserved terms are distributed standard normal instead of logistic .Then the probability of taking the action is",
    "after": "where Φ is the cumulative distribution function of standard normal .",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle P_{ni}={\\exp(\\beta _{i}s_{n}) \\over \\sum _{j=1}^{J}\\exp(\\beta _{j}s_{n})},}": {
    "before": "U ni = β i s n + ε ni , Since only differences in utility matter, it is necessary to normalize {\\displaystyle \\beta _{i}=0} for one alternative. Assuming {\\displaystyle \\beta _{1}=0} , ε ni are iid extreme value [nb 1]The choice probability takes the form",
    "after": "where J is the total number of alternatives.",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle {\\begin{cases}U_{ni}=\\beta z_{ni}+\\varepsilon _{ni}\\\\\\varepsilon _{ni}\\sim {\\text{iid extreme value}}\\end{cases}}\\quad \\Rightarrow \\quad P_{ni}={\\exp(\\beta z_{ni}) \\over \\sum _{j=1}^{J}\\exp(\\beta z_{nj})},}": {
    "before": "The utility for each alternative depends on attributes of that alternative, interacted perhaps with attributes of the person:",
    "after": "where J is the total number of alternatives.",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle z_{nj}=\\left\\{w_{nj}^{1},\\cdots ,w_{nj}^{J}\\right\\}\\quad {\\text{and}}\\quad \\beta =\\left\\{\\beta _{1},\\cdots ,\\beta _{J}\\right\\},}": {
    "before": "Note that model E can be expressed in the same form as model F by appropriate respecification of variables. Define {\\displaystyle w_{nj}^{k}=s_{n}\\delta _{jk}} where {\\displaystyle \\delta _{jk}} is the Kronecker delta and s n are from model E . Then, model F is obtained by using",
    "after": "where J is the total number of alternatives.",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle {\\begin{cases}U_{ni}=\\beta z_{ni}+\\varepsilon _{ni}\\\\\\varepsilon _{n}\\equiv (\\varepsilon _{n1},\\cdots ,\\varepsilon _{nJ})\\sim N(0,\\Omega )\\end{cases}}\\quad \\Rightarrow \\quad P_{ni}=\\Pr \\left(\\bigcap _{j\\neq i}\\beta z_{ni}+\\varepsilon _{ni}>\\beta z_{nj}+\\varepsilon _{nj}\\right)=\\int I\\left(\\bigcap _{j\\neq i}\\beta z_{ni}+\\varepsilon _{ni}>\\beta z_{nj}+\\varepsilon _{nj}\\right)\\phi (\\varepsilon _{n}|\\Omega )\\;d\\varepsilon _{n},}": {
    "before": "The model is the same as model G except that the unobserved terms are distributed jointly normal , which allows any pattern of correlation and heteroscedasticity :",
    "after": "where {\\displaystyle \\phi (\\varepsilon _{n}|\\Omega )} is the joint normal density with mean zero and covariance {\\displaystyle \\Omega } .",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle P_{ni}=\\int _{\\beta }L_{ni}(\\beta )f(\\beta |\\theta )\\,d\\beta ,}": {
    "before": "U ni = βz ni + ε ni , {\\displaystyle \\beta \\sim f(\\beta |\\theta )} for any distribution {\\displaystyle {\\it {f}}} , where {\\displaystyle \\theta } is the set of distribution parameters (e.g. mean and variance) to be estimated, ε ni ~ iid extreme value , [nb 1]The choice probability is",
    "after": "where {\\displaystyle L_{ni}(\\beta )={\\exp(\\beta z_{ni}) \\over {\\sum _{j=1}^{J}\\exp(\\beta z_{nj})}}}",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle L_{ni}(\\beta )={\\exp(\\beta z_{ni}) \\over {\\sum _{j=1}^{J}\\exp(\\beta z_{nj})}}}": {
    "before": "{\\displaystyle P_{ni}=\\int _{\\beta }L_{ni}(\\beta )f(\\beta |\\theta )\\,d\\beta ,} where",
    "after": "is logit probability evaluated at {\\displaystyle \\beta ,} with {\\displaystyle J} the total number of alternatives.",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle \\Pr({\\text{ranking }}1,2,\\ldots ,J)={\\exp(\\beta z_{1}) \\over \\sum _{j=1}^{J}\\exp(\\beta z_{nj})}{\\exp(\\beta z_{2}) \\over \\sum _{j=2}^{J}\\exp(\\beta z_{nj})}\\ldots {\\exp(\\beta z_{J-1}) \\over \\sum _{j=J-1}^{J}\\exp(\\beta z_{nj})}}": {
    "before": "Without loss of generality, the alternatives can be relabeled to represent the person's ranking, such that alternative 1 is the first choice, 2 the second choice, etc. The choice probability of ranking J alternatives as 1, 2, ..., J is then",
    "after": "As with standard logit, the exploded logit model assumes no correlation in unobserved factors over alternatives. The exploded logit can be generalized, in the same way as the standard logit is generalized, to accommodate correlations among alternatives and random taste variation. The \"mixed exploded logit\" model is obtained by probability of the ranking, given above, for L ni in the mixed logit model ( model I ).",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle {\\begin{aligned}\\Pr({\\text{choosing }}1)&=\\Pr(U_{n}<a)=\\Pr(\\varepsilon <a-\\beta z_{n})={1 \\over 1+\\exp(-(a-\\beta z_{n}))}\\\\\\Pr({\\text{choosing }}2)&=\\Pr(a<U_{n}<b)=\\Pr(a-\\beta z_{n}<\\varepsilon <b-\\beta z_{n})={1 \\over 1+\\exp(-(b-\\beta z_{n}))}-{1 \\over 1+\\exp(-(a-\\beta z_{n}))}\\\\&\\cdots \\\\\\Pr({\\text{choosing }}5)&=\\Pr(U_{n}>d)=\\Pr(\\varepsilon >d-\\beta z_{n})=1-{1 \\over 1+\\exp(-(d-\\beta z_{n}))}\\end{aligned}}}": {
    "before": "Defining {\\displaystyle U_{n}=\\beta z_{n}+\\varepsilon ,\\;\\varepsilon \\sim } Logistic , then the probability of each possible response is:",
    "after": "The parameters of the model are the coefficients β and the cut-off points a − d , one of which must be normalized for identification. When there are only two possible responses, the ordered logit is the same a binary logit ( model A ), with one cut-off point normalized to zero.",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "{\\displaystyle {\\begin{aligned}\\Pr({\\text{choosing }}1)&=\\Phi (a-\\beta z_{n})\\\\\\Pr({\\text{choosing }}2)&=\\Phi (b-\\beta z_{n})-\\Phi (a-\\beta z_{n})\\\\&\\cdots \\end{aligned}}}": {
    "before": "The choice probabilities are ( {\\displaystyle \\Phi } is the cumulative distribution function of the standard normal distribution):",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Discrete choice"
  },
  "K = k × Y": {
    "before": "The accelerator effect is shown in the simple accelerator model . This model assumes that the stock of capital goods ( K ) is proportional to the level of production ( Y ):",
    "after": "This implies that if k (the capital-output ratio) is constant, an increase in Y requires an increase in K . That is, net investment, I n equals:",
    "url": "https://en.wikipedia.org/wiki/Accelerator effect"
  },
  "I n = k ×Δ Y": {
    "before": "This implies that if k (the capital-output ratio) is constant, an increase in Y requires an increase in K . That is, net investment, I n equals:",
    "after": "Suppose that k = 2 (usually, k is assumed to be in (0,1)). This equation implies that if Y rises by 10, then net investment will equal 10×2 = 20, as suggested by the accelerator effect. If Y then rises by only 5, the equation implies that the level of investment will be 5×2 = 10. This means that the simple accelerator model implies that fixed investment will fall if the growth of production slows . An actual fall in production is not needed to cause investment to fall. However, such a fall in output will result if slowing growth of production causes investment to fall, since that reduces aggregate demand . Thus, the simple accelerator model implies an endogenous explanation of the business-cycle downturn, the transition to a recession.",
    "url": "https://en.wikipedia.org/wiki/Accelerator effect"
  },
  "{\\displaystyle I_{n}=x(K^{d}-K_{-1})}": {
    "before": "Modern economists have described the accelerator effect in terms of the more sophisticated flexible accelerator model of investment. Businesses are described as engaging in net investment in fixed capital goods in order to close the gap between the desired stock of capital goods ( K d ) and the existing stock of capital goods left over from the past ( K −1 ):",
    "after": "where x is a coefficient representing the speed of adjustment (1 ≥ x ≥ 0).",
    "url": "https://en.wikipedia.org/wiki/Accelerator effect"
  },
  "{\\displaystyle I_{t}=\\mu v\\sum _{i=1}^{\\infty }\\left(1-\\mu \\right)^{i}\\left(Y_{t-i}-Y_{t-i-1}\\right)}": {
    "before": "where x is a coefficient representing the speed of adjustment (1 ≥ x ≥ 0).",
    "after": "The desired stock of capital goods is determined by such variables as the expected profit rate , the expected level of output, the interest rate (the cost of finance), and technology. Because the expected level of output plays a role, this model exhibits behavior described by the accelerator effect but less extreme than that of the simple accelerator. Because the existing capital stock grows over time due to past net investment, a slowing of the growth of output (GDP) can cause the gap between the desired K and the existing K to narrow, close, or even become negative, causing current net investment to fall.",
    "url": "https://en.wikipedia.org/wiki/Accelerator effect"
  },
  "1 kina (K) = 100 toea": {
    "before": "Currency:",
    "after": "Exchange rates:",
    "url": "https://en.wikipedia.org/wiki/Economy of Papua New Guinea"
  },
  "{\\displaystyle Y=C+I+G+(X-M),}": {
    "before": "Standard macroeconomic theory points to how a budget deficit can be a contributing factor to a current account deficit. This link can be seen from considering the national accounting model of the economy:",
    "after": "where Y represents national income or GDP, C is consumption, I is investment, G is government spending and X–M stands for net exports. This represents GDP because all the production in an economy (the left hand side of the equation) is used as consumption ( C ), investment ( I ), government spending ( G ), and goods that are exported in excess of imports ( NX ). Another equation defining GDP using alternative terms (which in theory results in the same value [ citation needed ] ) is",
    "url": "https://en.wikipedia.org/wiki/Twin deficits hypothesis"
  },
  "{\\displaystyle Y=C+S+T,}": {
    "before": "where Y represents national income or GDP, C is consumption, I is investment, G is government spending and X–M stands for net exports. This represents GDP because all the production in an economy (the left hand side of the equation) is used as consumption ( C ), investment ( I ), government spending ( G ), and goods that are exported in excess of imports ( NX ). Another equation defining GDP using alternative terms (which in theory results in the same value [ citation needed ] ) is",
    "after": "where Y is again GDP, C is consumption, S is private saving, and T is taxes. This is because national income is also equal to output, and all individual income either goes to pay for consumption ( C ), to pay taxes ( T ), or is saved ( S ).",
    "url": "https://en.wikipedia.org/wiki/Twin deficits hypothesis"
  },
  "{\\displaystyle (S-I)+(T-G)=(NX)}": {
    "before": "{\\displaystyle S=G-T+NX+I} , which simplifies to the sectoral balances identity",
    "after": "If (T-G) is negative, we have a budget deficit .",
    "url": "https://en.wikipedia.org/wiki/Twin deficits hypothesis"
  },
  "{\\displaystyle CA=(S-I)+(T-G)}": {
    "before": "In the case of the United States, the twin deficit graph as a percentage of GDP shows that the budget and current account deficits did move broadly in sync from 1981 until the early 1990s, but since then, they have moved apart. Data thus confirm that as a government budget deficit widens, the current account falls, but the relationship is complicated by what happens to investment and private saving.",
    "after": "Current Account = (Private Saving – Investment) + (Taxes levied – Government Expenditure)",
    "url": "https://en.wikipedia.org/wiki/Twin deficits hypothesis"
  },
  "Saving + Trade Deficit = Investment + Budget Deficit.": {
    "before": "Next we must consider the market for loan able funds. The equilibrium here is Saving + Net Capital Inflow = Investment + Budget Deficit. However, taking the Forex market into consideration we know that the Trade Deficit is equal to Net Capital Inflow. We can thus substitute for:",
    "after": "Rearranging algebraically we find that:",
    "url": "https://en.wikipedia.org/wiki/Twin deficits hypothesis"
  },
  "Budget Deficit = Saving + Trade Deficit – Investment.": {
    "before": "Rearranging algebraically we find that:",
    "after": "What we can gather from this is the understanding of why an increased budget deficit goes up and down in tandem with the Trade Deficit. This is where we derive the appellation the Twin Deficits: if the US budget deficit goes up then either household savings must go up, the trade deficit must go up, or private investment will decrease.",
    "url": "https://en.wikipedia.org/wiki/Twin deficits hypothesis"
  },
  "{\\displaystyle N_{t}^{t}=(1+n)^{t}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Overlapping generations model"
  },
  "{\\displaystyle u(c_{t}^{t},c_{t}^{t+1})=U(c_{t}^{t})+\\beta U(c_{t}^{t+1}),} where {\\displaystyle \\beta } is the rate of time preference.": {
    "before": "In the \"pure exchange economy\" version of the model, there is only one physical good and it cannot endure for more than one period. Each individual receives a fixed endowment of this good at birth. This endowment is denoted as y . In the \"production economy\" version of the model (see Diamond OLG model below), the physical good can be either consumed or invested to build physical capital. Output is produced from labor and physical capital. Each household is endowed with one unit of time which is inelastically supply on the labor market. Preferences over consumption streams are given by",
    "after": "OLG model with production [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Overlapping generations model"
  },
  "{\\displaystyle u(c_{t}^{t},c_{t}^{t+1})=U(c_{t}^{t})+\\beta U(c_{t}^{t+1}),}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Overlapping generations model"
  },
  "The size of the young generation in period t is given by Nt = N0 Et.": {
    "before": "Two generations are alive at any point in time, the young (age 1) and old (age 2).",
    "after": "Households work only in the first period of their life and earn Y1,t income. They earn no income in the second period of their life (Y2,t+1 = 0)",
    "url": "https://en.wikipedia.org/wiki/Overlapping generations model"
  },
  "{\\displaystyle (1+i_{lt})^{n}=(1+i_{st}^{{\\text{year }}1})(1+i_{st}^{{\\text{year }}2})\\cdots (1+i_{st}^{{\\text{year }}n}),}": {
    "before": "Using this, futures rates , along with the assumption that arbitrage opportunities will be minimal in future markets, and that futures rates are unbiased estimates of forthcoming spot rates, provide enough information to construct a complete expected yield curve. For example, if investors have an expectation of what 1-year interest rates will be next year, the current 2-year interest rate can be calculated as the compounding of this year's 1-year interest rate by next year's expected 1-year interest rate. More generally, returns (1+ yield) on a long-term instrument are assumed to equal the geometric mean of the expected returns on a series of short-term instruments:",
    "after": "where i st and i lt are the expected short-term and actual long-term interest rates (but {\\displaystyle i_{st}^{{\\text{year}}1}} is the actual observed short-term rate for the first year).",
    "url": "https://en.wikipedia.org/wiki/Yield curve"
  },
  "{\\displaystyle (1+i_{lt})^{n}=rp_{n}+((1+i_{st}^{\\mathrm {year} 1})(1+i_{st}^{\\mathrm {year} 2})\\cdots (1+i_{st}^{\\mathrm {year} n})),}": {
    "before": "The liquidity premium theory is an offshoot of the pure expectations theory. The liquidity premium theory asserts that long-term interest rates not only reflect investors' assumptions about future interest rates but also include a premium for holding long-term bonds (investors prefer short-term bonds to long-term bonds), called the term premium or the liquidity premium. This premium compensates investors for the added risk of having their money tied up for a longer period, including the greater price uncertainty. Because of the term premium, long-term bond yields tend to be higher than short-term yields and the yield curve slopes upward. Long-term yields are also higher not just because of the liquidity premium, but also because of the risk premium added by the risk of default from holding a security over the long term. The market expectations hypothesis is combined with the liquidity premium theory:",
    "after": "where {\\displaystyle rp_{n}} is the risk premium associated with an {\\displaystyle {n}} year bond.",
    "url": "https://en.wikipedia.org/wiki/Yield curve"
  },
  "{\\displaystyle Y(t)=P(t)^{-1/t}-1.}": {
    "before": "The usual representation of the yield curve is in terms of a function P, defined on all future times t , such that P( t ) represents the value today of receiving one unit of currency t years in the future. If P is defined for all future t then we can easily recover the yield (i.e. the annualized interest rate) for borrowing money for that period of time via the formula",
    "after": "The significant difficulty in defining a yield curve therefore is to determine the function P( t ). P is called the discount factor function or the zero coupon bond.",
    "url": "https://en.wikipedia.org/wiki/Yield curve"
  },
  "{\\displaystyle AP=F+\\varepsilon \\,}": {
    "before": "In either case the available market data provides a matrix A of cash flows, each row representing a particular financial instrument and each column representing a point in time. The ( i , j )-th element of the matrix represents the amount that instrument i will pay out on day j . Let the vector F represent today's prices of the instrument (so that the i -th instrument has value F ( i )), then by definition of our discount factor function P we should have that F = AP (this is a matrix multiplication). Actually, noise in the financial markets means it is not possible to find a P that solves this equation exactly, and our goal becomes to find a vector P such that",
    "after": "where {\\displaystyle \\varepsilon } is as small a vector as possible (where the size of a vector might be measured by taking its norm , for example).",
    "url": "https://en.wikipedia.org/wiki/Yield curve"
  },
  "{\\displaystyle Q(t)={Q_{\\rm {max}} \\over {1+ae^{-bt}}}}": {
    "before": "Given past oil discovery and production data, a Hubbert curve that attempts to approximate past discovery data may be constructed and used to provide estimates for future production. In particular, the date of peak oil production or the total amount of oil ultimately produced can be estimated that way. Cavallo  defines the Hubbert curve used to predict the U.S. peak as the derivative of:",
    "after": "where {\\displaystyle Q} max is the total resource available (ultimate recovery of crude oil), {\\displaystyle Q(t)} the cumulative production, and {\\displaystyle a} and {\\displaystyle b} are constants. The year of maximum annual production (peak) is:",
    "url": "https://en.wikipedia.org/wiki/Hubbert peak theory"
  },
  "{\\displaystyle t_{\\rm {max}}={1 \\over b}\\ln \\left({a}\\right).}": {
    "before": "where {\\displaystyle Q} max is the total resource available (ultimate recovery of crude oil), {\\displaystyle Q(t)} the cumulative production, and {\\displaystyle a} and {\\displaystyle b} are constants. The year of maximum annual production (peak) is:",
    "after": "so now the cumulative production {\\displaystyle Q(t)} reaches the half of the total available resource:",
    "url": "https://en.wikipedia.org/wiki/Hubbert peak theory"
  },
  "{\\displaystyle Q(t)=Q_{\\text{max}}/2}": {
    "before": "so now the cumulative production {\\displaystyle Q(t)} reaches the half of the total available resource:",
    "after": "The Hubbert equation assumes that oil production is symmetrical about the peak. Others have used similar but non-symmetrical equations which may provide better a fit to empirical production data. ",
    "url": "https://en.wikipedia.org/wiki/Hubbert peak theory"
  },
  "{\\displaystyle P_{i}=wl_{i}+k_{A}a_{i},(i=B,D)}": {
    "before": "Things become more complicated if production uses some scarce capital good as well. Suppose that hunting requires also some arrows {\\displaystyle (A)} , with input coefficients equal to {\\displaystyle a_{i}} , meaning that to catch, for instance, one beaver you need to use {\\displaystyle a_{B}} arrows, besides {\\displaystyle l_{B}} hours of labour. Now the unit total cost (or absolute competitive price) of beavers and deer becomes",
    "after": "where {\\displaystyle k_{A}} denotes the capital cost incurred in using each arrow.",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle P_{i}=wl_{i}+(h+r)P_{A}a_{i}}": {
    "before": "Summing up, and assuming a uniform replacement rate {\\displaystyle h} , the absolute competitive prices of beavers and deer may be written as",
    "after": "Yet we still have to determine the arrows' competitive price {\\displaystyle P_{A}} . Assuming arrows are produced by labor only, with {\\displaystyle l_{A}} man-hours per arrow, we have:",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle P_{A}=wl_{A}}": {
    "before": "Yet we still have to determine the arrows' competitive price {\\displaystyle P_{A}} . Assuming arrows are produced by labor only, with {\\displaystyle l_{A}} man-hours per arrow, we have:",
    "after": "Assuming further, for simplicity, that {\\displaystyle h=1} (i.e., all arrows are lost after just one shot, so that they are circulating capital ), the absolute competitive prices of beavers and deer become:",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle P_{i}=wl_{i}+(1+r)wl_{A}a_{i}}": {
    "before": "Assuming further, for simplicity, that {\\displaystyle h=1} (i.e., all arrows are lost after just one shot, so that they are circulating capital ), the absolute competitive prices of beavers and deer become:",
    "after": "Here, {\\displaystyle l_{i}} is the quantity of labor directly embodied in beaver and deer unit production, while {\\displaystyle l_{A}a_{i}} is the labor indirectly thus embodied, through previous arrow production. The sum of the two,",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle E_{i}=l_{i}+l_{A}a_{i}} ,": {
    "before": "Here, {\\displaystyle l_{i}} is the quantity of labor directly embodied in beaver and deer unit production, while {\\displaystyle l_{A}a_{i}} is the labor indirectly thus embodied, through previous arrow production. The sum of the two,",
    "after": "gives the total quantity of labor embodied.",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle p_{i}=c_{i}+v_{i}+s_{i}=l_{A}a_{i}+l_{W}l_{i}+s_{i}}": {
    "before": "The total value of each produced good is the sum of the above three elements: constant capital, variable capital, and surplus value. In our previous example:",
    "after": "Where {\\displaystyle p_{i}} stands for the (unit) Marxian value of beavers and deer.",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle p_{i}=l_{A}a_{i}+l_{i}=E_{i}}": {
    "before": "However, from Marx's definition of value as total labour embodied, it must also be true that:",
    "after": "Solving for {\\displaystyle s_{i}} the above two relationships one has:",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle {s_{i} \\over v_{i}}={(1-l_{W}) \\over l_{W}}=\\sigma }": {
    "before": "Solving for {\\displaystyle s_{i}} the above two relationships one has:",
    "after": "for all {\\displaystyle i} .",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle p_{i}=c_{i}+v_{i}(1+\\sigma )=l_{A}a_{i}+l_{W}l_{i}(1+\\sigma )}": {
    "before": "This necessarily uniform ratio {\\displaystyle {s_{i} \\over v_{i}}=\\sigma } is called by Marx the rate of exploitation , and it allows to re-write Marx's value equations as:",
    "after": "Classical tableaux [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle P_{A}=l_{A}} beavers.": {
    "before": "The simultaneous linear equations method of computing competitive (relative) prices in an equilibrium economy is today very well known. In the greatly simplified model of tables 1 and 2, where the wage rate is assumed as given and equal to the price of beavers, the most convenient way is to express such prices is in units of beavers, which means normalising {\\displaystyle w=P_{B}=1} . This yields the (relative) price of arrows as",
    "after": "Substituting this into the relative-price condition for beavers,",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle 1=l_{B}+(1+r)l_{A}a_{B}} ,": {
    "before": "Substituting this into the relative-price condition for beavers,",
    "after": "gives the solution for the rate of return as",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle r={(1-l_{B}) \\over (l_{A}a_{B})}-1}": {
    "before": "{\\displaystyle 1=l_{B}+(1+r)l_{A}a_{B}} ,gives the solution for the rate of return as",
    "after": "Finally, the price condition for deer can hence be written as",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle P_{D}=l_{D}+(1+r)l_{A}a_{D}=l_{D}+{a_{D}(1-l_{B}) \\over a_{B}}} .": {
    "before": "Finally, the price condition for deer can hence be written as",
    "after": "This latter result, which gives the correct competitive price of deer in units of beavers for the simple model used here, is generally inconsistent with Marx's price formulae of table 2.",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle P_{i}=\\sum _{n=0}^{\\infty }l_{in}w{(1+r)^{n}}} ,": {
    "before": "Although he never actually mentioned the transformation problem, Sraffa’s (1960) chapter 6 on the \"reduction\" of prices to \"dated\" amounts of current and past embodied labour gave implicitly the first general proof, showing that the competitive price {\\displaystyle P_{i}} of the {\\displaystyle i^{th}} produced good can be expressed as",
    "after": "where {\\displaystyle n} is the time lag, {\\displaystyle l_{in}} is the lagged-labour input coefficient, {\\displaystyle w} is the wage, and {\\displaystyle r} is the \"profit\" (or net return) rate. Since total embodied labour is defined as",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle E_{i}=\\sum _{n=0}^{\\infty }l_{in}} ,": {
    "before": "where {\\displaystyle n} is the time lag, {\\displaystyle l_{in}} is the lagged-labour input coefficient, {\\displaystyle w} is the wage, and {\\displaystyle r} is the \"profit\" (or net return) rate. Since total embodied labour is defined as",
    "after": "it follows from Sraffa’s result that there is generally no function from {\\displaystyle E_{i}} to {\\displaystyle P_{i}} , as was made explicit and elaborated upon by later writers, notably Ian Steedman in Marx after Sraffa .",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle rl_{A}(Q_{B}a_{B}+Q_{D}a_{D})=\\sigma (l_{A}a_{B}+l_{B})(Q_{B}l_{B}+Q_{D}l_{D})}": {
    "before": "Total",
    "after": "Total {\\displaystyle rl_{A}(Q_{B}a_{B}+Q_{D}a_{D})=\\sigma (l_{A}a_{B}+l_{B})(Q_{B}l_{B}+Q_{D}l_{D})}",
    "url": "https://en.wikipedia.org/wiki/Transformation problem"
  },
  "{\\displaystyle Q=r\\times [Q]}": {
    "before": "For some other quantities, invariant are ratios between attribute differences . Consider temperature, for example. In the familiar everyday instances, temperature is measured using instruments calibrated in either the Fahrenheit or Celsius scales. What are really being measured with such instruments are the magnitudes of temperature differences. For example, Anders Celsius defined the unit of the Celsius scale to be 1/100th of the difference in temperature between the freezing and boiling points of water at sea level. A midday temperature measurement of 20 degrees Celsius is simply the difference of the midday temperature and the temperature of the freezing water divided by the difference of the Celsius unit and the temperature of the freezing water.Formally expressed, a scientific measurement is:",
    "after": "where Q is the magnitude of the quantity, r is a real number and [ Q ] is a unit magnitude of the same kind.",
    "url": "https://en.wikipedia.org/wiki/Theory of conjoint measurement"
  },
  "{\\displaystyle (a,z)=(c,x),}": {
    "before": "{\\displaystyle (a,z)<(c,x),} or alternatively,",
    "after": "then double cancellation would be violated ( Michell 1988 ) and it could not be concluded that A and X are quantities.",
    "url": "https://en.wikipedia.org/wiki/Theory of conjoint measurement"
  },
  "{\\displaystyle (a_{i},x)=(a_{i+1},y).}": {
    "before": "The Archimedean condition is as follows. Let I be a set of consecutive integers, either finite or infinite, positive or negative. The levels of A form a standard sequence if and only if there exists x and y in X where x ≠ y and for all integers i and i + 1 in I :",
    "after": "What this basically means is that if x is greater than y , for example, there are levels of A which can be found which makes two relevant ordered pairs, the levels of P , equal.",
    "url": "https://en.wikipedia.org/wiki/Theory of conjoint measurement"
  },
  "{\\displaystyle \\varphi '_{A}=\\alpha \\varphi _{A}+\\beta _{A}{\\text{ and }}\\varphi '_{X}=\\alpha \\varphi _{X}+\\beta _{X}.\\,}": {
    "before": "If {\\displaystyle \\varphi '_{A}\\,} and {\\displaystyle \\varphi '_{X}\\,} are two other real valued functions satisfying the above expression, there exist {\\displaystyle \\alpha >0,\\beta _{A}\\,} and {\\displaystyle \\beta _{X}\\,} real valued constants satisfying:",
    "after": "That is, {\\displaystyle \\varphi '_{A},\\varphi _{A},\\varphi '_{X}\\,} and {\\displaystyle \\varphi _{X}\\,} are measurements of A and X unique up to affine transformation (i.e. each is an interval scale in Stevens’ (1946) parlance). The mathematical proof of this result is given in ( Krantz et al. 1971 , pp. 261–6).",
    "url": "https://en.wikipedia.org/wiki/Theory of conjoint measurement"
  },
  ". For example, if n = m = 4, then there are 16 such instances. If n = m = 5 then there are 100. The greater the number of levels in both A and X, the less probable it is that the cancellation axioms are satisfied at random (Arbuckle & Larimer 1976; McClelland 1977) and the more stringent test of quantity the application of conjoint measurement becomes.": {
    "before": "{\\displaystyle {\\tbinom {m}{3}}}",
    "after": "Solvability and Archimedean axioms[edit]",
    "url": "https://en.wikipedia.org/wiki/Theory of conjoint measurement"
  },
  "A = actor A": {
    "before": "The model is linear with two actors, A and B, on the left and right ends of the line, respectively. The line represents a good that A and B are willing to fight over. Point p represents the perceived potential division of the good that will result from a war. Actor A wants p to be as far right as possible, because it receives a greater division of the good, while actor B p to be as far left as possible. Points ca and cb represent the costs of war for A and B respectively. These costs are usually blood and treasure, the financial and manpower losses that result from a war. Points p-ca and p-cb represent the ultimate division of a good for A and B when the costs of war are calculated into the outcome. Both actors are willing to accept any deal that divides the good anywhere between points ca and cb. This is because a point in that range provides a better division than a war. A is willing to accept a point to the left of p because although the division is not in its favor, it is still better than if it were divided based on the costs of war. A is willing to accept a point to the right of p because this is a better division of the good than it predicted. The same reasoning stands for actor B, only in the opposite direction.",
    "after": "B = actor B",
    "url": "https://en.wikipedia.org/wiki/Bargaining model of war"
  },
  "B = actor B": {
    "before": "A = actor A",
    "after": "C = actor C",
    "url": "https://en.wikipedia.org/wiki/Bargaining model of war"
  },
  "C = actor C": {
    "before": "B = actor B",
    "after": "p = predicted division of a good as a result of a war",
    "url": "https://en.wikipedia.org/wiki/Bargaining model of war"
  },
  "p = predicted division of a good as a result of a war": {
    "before": "C = actor C",
    "after": "ca = the cost of fighting war for actor A",
    "url": "https://en.wikipedia.org/wiki/Bargaining model of war"
  },
  "ca = the cost of fighting war for actor A": {
    "before": "p = predicted division of a good as a result of a war",
    "after": "cb = the cost of fighting war for actor B",
    "url": "https://en.wikipedia.org/wiki/Bargaining model of war"
  },
  "cb = the cost of fighting war for actor B": {
    "before": "ca = the cost of fighting war for actor A",
    "after": "p-ca = actor A's division of the good after the costs of war are calculated",
    "url": "https://en.wikipedia.org/wiki/Bargaining model of war"
  },
  "p-ca = actor A's division of the good after the costs of war are calculated": {
    "before": "cb = the cost of fighting war for actor B",
    "after": "p-cb = actor B's division of the good after the costs of war are calculated",
    "url": "https://en.wikipedia.org/wiki/Bargaining model of war"
  },
  "p-cb = actor B's division of the good after the costs of war are calculated": {
    "before": "p-ca = actor A's division of the good after the costs of war are calculated",
    "after": "Causes of war based on the model[edit]",
    "url": "https://en.wikipedia.org/wiki/Bargaining model of war"
  },
  "www.genesys.rwth-aachen.de/index.php?id=12&L=3": {
    "before": "Website",
    "after": "GENESYS stands for Genetic Optimisation of a European Energy Supply System. The software is being developed jointly by the Institute of Power Systems and Power Economics (IAEW) and the Institute for Power Electronics and Electrical Drives (ISEA), both of RWTH Aachen University, Aachen, Germany. The project maintains a website where potential users can request access to the codebase and the dataset for the 2050 base scenario only. Detailed descriptions of the software are available. GENESYS is written in C++ and uses Boost libraries, the MySQL relational database, the Qt 4 application framework, and optionally the CPLEX solver.",
    "url": "https://en.wikipedia.org/wiki/Open energy system models"
  },
  "{\\displaystyle U(x):=\\sum _{i\\in I}u_{i}(x).}": {
    "before": "The utilitarian rule selects an element {\\displaystyle x\\in X} which maximizes the utilitarian sum",
    "after": "Tangible utility functions [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Utilitarian rule"
  },
  "{\\displaystyle V(x):=\\sum _{i\\in I}v_{i}(x),}": {
    "before": "The notion that individuals have cardinal utility functions is not that problematic. Cardinal utility has been implicitly assumed in decision theory ever since Daniel Bernoulli 's analysis of the Saint Petersburg Paradox . Rigorous mathematical theories of cardinal utility (with application to risky decision making) were developed by Frank P. Ramsey , Bruno de Finetti , von Neumann and Morgenstern , and Leonard Savage . However, in these theories, a person's utility function is only well-defined up to an `affine rescaling'. Thus, if the utility function {\\displaystyle u_{i}:X\\longrightarrow \\mathbb {R} } is valid description of her preferences, and if {\\displaystyle r_{i},s_{i}\\in \\mathbb {R} } are two constants with {\\displaystyle s_{i}>0} , then the `rescaled' utility function {\\displaystyle v_{i}(x):=s_{i}\\,u_{i}(x)+r_{i}} is an equally valid description of her preferences. If we define a new package of utility functions {\\displaystyle (v_{i})_{i\\in I}} using possibly different {\\displaystyle r_{i}\\in \\mathbb {R} } and {\\displaystyle s_{i}>0} for all {\\displaystyle i\\in I} , and we then consider the utilitarian sum",
    "after": "then in general, the maximizer of {\\displaystyle V} will not be the same as the maximizer of {\\displaystyle U} . Thus, in a sense, classic utilitarian social choice is not well-defined within the standard model of cardinal utility used in decision theory, unless a mechanism is specified to `calibrate' the utility functions of the different individuals.",
    "url": "https://en.wikipedia.org/wiki/Utilitarian rule"
  },
  "{\\displaystyle m_{i}\\ :=\\ \\min _{x\\in X}\\,u_{i}(x)\\quad {\\text{and}}\\quad M_{i}\\ :=\\ \\max _{x\\in X}\\,u_{i}(x)}": {
    "before": "Relative utilitarianism proposes a natural calibration mechanism. For every {\\displaystyle i\\in I} , suppose that the values",
    "after": "are well-defined. (For example, this will always be true if {\\displaystyle X} is finite, or if {\\displaystyle X} is a compact space and {\\displaystyle u_{i}} is a continuous function.) Then define",
    "url": "https://en.wikipedia.org/wiki/Utilitarian rule"
  },
  "{\\displaystyle w_{i}(x)\\ :=\\ {\\frac {u_{i}(x)-m_{i}}{M_{i}-m_{i}}}}": {
    "before": "are well-defined. (For example, this will always be true if {\\displaystyle X} is finite, or if {\\displaystyle X} is a compact space and {\\displaystyle u_{i}} is a continuous function.) Then define",
    "after": "for all {\\displaystyle x\\in X} . Thus, {\\displaystyle w_{i}:X\\longrightarrow \\mathbb {R} } is a `rescaled' utility function which has a minimum value of 0 and a maximum value of 1. The Relative Utilitarian social choice rule selects the element in {\\displaystyle X} which maximizes the utilitarian sum",
    "url": "https://en.wikipedia.org/wiki/Utilitarian rule"
  },
  "{\\displaystyle W(x):=\\sum _{i\\in I}w_{i}(x).}": {
    "before": "for all {\\displaystyle x\\in X} . Thus, {\\displaystyle w_{i}:X\\longrightarrow \\mathbb {R} } is a `rescaled' utility function which has a minimum value of 0 and a maximum value of 1. The Relative Utilitarian social choice rule selects the element in {\\displaystyle X} which maximizes the utilitarian sum",
    "after": "As an abstract social choice function, relative utilitarianism has been analyzed by Cao (1982),  Dhillon (1998),  Karni (1998),  Dhillon and Mertens (1999),  Segal (2000),  Sobel (2001)  and Pivato (2008).  (Cao (1982) refers to it as the `modified Thomson solution'.)",
    "url": "https://en.wikipedia.org/wiki/Utilitarian rule"
  },
  "{\\displaystyle MC={\\frac {\\Delta VC}{\\Delta Q}}} {\\displaystyle {\\Delta VC}=w{\\Delta L}} {\\displaystyle {\\Delta L}/{\\Delta Q}} (the change in quantity of labor to effect a one unit change in output) {\\displaystyle =1/MP_{L}}": {
    "before": "The marginal product of labor is directly related to costs of production . Costs are divided between fixed and variable costs . Fixed costs are costs that relate to the fixed input, capital , or rK , where r is the rental cost of capital and K is the quantity of capital. Variable costs (VC) are the costs of the variable input, labor, or wL , where w is the wage rate and L is the amount of labor employed. Thus, VC = wL . Marginal cost (MC) is the change in total cost per unit change in output or ∆C/∆Q. In the short run, production can be varied only by changing the variable input. Thus only variable costs change as output increases: ∆C = ∆VC = ∆(wL). Marginal cost is ∆(Lw)/∆Q. Now, ∆L/∆Q is the reciprocal of the marginal product of labor (∆Q/∆L). Therefore, marginal cost is simply the wage rate w divided by the marginal product of labor",
    "after": "Therefore {\\displaystyle MC=w/MP_{L}}",
    "url": "https://en.wikipedia.org/wiki/Marginal product of labor"
  },
  "MR = ∆TR/∆Q MP L = ∆Q/∆L MRP L = MR × MP L = (∆TR/∆Q) × (∆Q/∆L) = ∆TR/∆L": {
    "before": "The marginal revenue product is the change in total revenue per unit change in the variable input assume labor.  That is, MRP L = ∆TR/∆L. MRP L is the product of marginal revenue and the marginal product of labor or MRP L = MR × MP L .Derivation:",
    "after": "Example [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Marginal product of labor"
  },
  "{\\displaystyle MP_{L}=90-2L} {\\displaystyle MRP_{L}=40(90-2L)} {\\displaystyle MRP_{L}=3600-80L} {\\displaystyle MRP_{L}=MC_{L}} (Profit Max Rule) {\\displaystyle 3600-80L=30} {\\displaystyle 3570=80L} {\\displaystyle L=44.625} 44.625 is the profit maximizing number of workers. {\\displaystyle Q=90L-L^{2}} {\\displaystyle Q=90(44.625)-(44.625)^{2}} {\\displaystyle Q=4016.25-1991.39} {\\displaystyle Q=2024.86}": {
    "before": "Assume that the production function is {\\displaystyle Q=90L-L^{2}}  {\\displaystyle MC_{L}=30} Output price is $40 per unit.",
    "after": "Thus, the profit maximizing output is 2024.86 units, units might be given in thousands. Therefore quantity must not be discrete. And the profit is",
    "url": "https://en.wikipedia.org/wiki/Marginal product of labor"
  },
  "{\\displaystyle \\Pi =TR-TC} {\\displaystyle TC=MC_{L}*L} (Actually marginal cost of labor is wages paid for each worker. Therefore we get total cost if we multiply it by the quantity of labor not by the quantity of products) {\\displaystyle \\Pi =40(2024.86)-30(44.625)=80994.4-1338.75=79655.65}": {
    "before": "Thus, the profit maximizing output is 2024.86 units, units might be given in thousands. Therefore quantity must not be discrete. And the profit is",
    "after": "Some might be confused by the fact that {\\displaystyle L=44.625} as intuition would say that labor should be discrete. Remember, however, that labor is actually a time measure as well. Thus, it can be thought of as a worker not working the entire hour.",
    "url": "https://en.wikipedia.org/wiki/Marginal product of labor"
  },
  "q1 = firm 1's demand, *q1≥0": {
    "before": "Calculating the differentiated Bertrand model[edit]",
    "after": "q2 = firm 2's demand, *q1≥0",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "q2 = firm 2's demand, *q1≥0": {
    "before": "q1 = firm 1's demand, *q1≥0",
    "after": "A1 = Constant in equation for firm 1's demand",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "A1 = Constant in equation for firm 1's demand": {
    "before": "q2 = firm 2's demand, *q1≥0",
    "after": "A2 = Constant in equation for firm 2's demand",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "A2 = Constant in equation for firm 2's demand": {
    "before": "A1 = Constant in equation for firm 1's demand",
    "after": "a1 = slope coefficient for firm 1's price",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "a1 = slope coefficient for firm 1's price": {
    "before": "A2 = Constant in equation for firm 2's demand",
    "after": "a2 = slope coefficient for firm 2's price",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "a2 = slope coefficient for firm 2's price": {
    "before": "a1 = slope coefficient for firm 1's price",
    "after": "p1 = firm 1's price level pr unit",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "p1 = firm 1's price level pr unit": {
    "before": "a2 = slope coefficient for firm 2's price",
    "after": "p2 = firm 2's price level pr unit",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "p2 = firm 2's price level pr unit": {
    "before": "p1 = firm 1's price level pr unit",
    "after": "b1 = slope coefficient for how much firm 2's price affects firm 1's demand",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "b1 = slope coefficient for how much firm 2's price affects firm 1's demand": {
    "before": "p2 = firm 2's price level pr unit",
    "after": "b2 = slope coefficient for how much firm 1's price affects firm 2's demand",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "b2 = slope coefficient for how much firm 1's price affects firm 2's demand": {
    "before": "b1 = slope coefficient for how much firm 2's price affects firm 1's demand",
    "after": "q1=A1-a1*p1+b1*p2",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "q1=A1-a1*p1+b1*p2": {
    "before": "b2 = slope coefficient for how much firm 1's price affects firm 2's demand",
    "after": "q2=A2-a2*p2+b2*p1",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "q2=A2-a2*p2+b2*p1": {
    "before": "q1=A1-a1*p1+b1*p2",
    "after": "The above figure presents the best response functions of the firms, which are complements to each other.",
    "url": "https://en.wikipedia.org/wiki/Differentiated Bertrand competition"
  },
  "The revenue is in form of interest rate. Nominal interest rate - inflation = real interest rate": {
    "before": "This decision making is based on an indifference map with negative slope because if he consumes something today it means that he can't consume it in the future and vice versa.",
    "after": "Denote",
    "url": "https://en.wikipedia.org/wiki/Intertemporal choice"
  },
  "{\\displaystyle M\\cdot V=P\\cdot Q}": {
    "before": "The quantity theory of money dominated macroeconomic theory until the 1930s. Two versions were particularly influential, one developed by Irving Fisher in works that included his 1911 The Purchasing Power of Money and another by Cambridge economists over the course of the early 20th century.  Fisher's version of the quantity theory can be expressed by holding money velocity (the frequency with which a given piece of currency is used in transactions) (V) and real income (Q) constant and allowing money supply (M) and the price level (P) to vary in the equation of exchange : ",
    "after": "Most classical theories, including Fisher's, held that velocity was stable and independent of economic activity.  Cambridge economists, such as John Maynard Keynes , began to challenge this assumption. They developed the Cambridge cash-balance theory , which looked at money demand and how it impacted the economy. The Cambridge theory did not assume that money demand and supply were always at equilibrium, and it accounted for people holding more cash when the economy sagged. By factoring in the value of holding cash, the Cambridge economists took significant steps toward the concept of liquidity preference that Keynes would later develop.  Cambridge theory argued that people hold money for two reasons: to facilitate transactions and to maintain liquidity . In later work, Keynes added a third motive, speculation , to his liquidity preference theory and built on it to create his general theory. ",
    "url": "https://en.wikipedia.org/wiki/History of macroeconomic thought"
  },
  "{\\displaystyle \\ w_{A}={\\frac {L_{F}}{L_{F}+L_{I}}}w_{F}+{\\frac {L_{I}}{{L_{F}}+{L_{I}}}}w_{I}}": {
    "before": "{\\displaystyle \\ w_{A}>{\\frac {L_{F}}{L_{F}+L_{I}}}w_{F}+{\\frac {L_{I}}{{L_{F}}+{L_{I}}}}w_{I}} At equilibrium,",
    "after": "With the random matching of workers to available jobs, the ratio of available jobs to total job seekers gives the probability that any person moving from the agricultural sector to the urban sector will be able to find a job. As a result, in equilibrium, the agricultural wage rate is equal to the expected urban wage rate, which is the urban wage multiplied by the employment rate.",
    "url": "https://en.wikipedia.org/wiki/Harris–Todaro model"
  },
  "F( q i , q j ) = Bq i q j": {
    "before": "Production is broken down into {\\displaystyle n} tasks. Laborers can use a multitude of techniques of varying efficiency to carry out these tasks depending on their skill. Skill is denoted by {\\displaystyle q} , where {\\displaystyle 0\\leq q\\leq 1} . The concept of {\\displaystyle q} differs depending on interpretation. It could mean: the probability of a laborer successfully completing a task, the quality of task completion expressed as a percentage, or the quality of task completion with the condition of a margin of error that could reduce quality.  Output is determined by multiplying the {\\displaystyle q} values of each of the {\\displaystyle n} tasks together and then multiplying this result by another term (let's say {\\displaystyle B} ) denoting the individual characteristics of the firm. {\\displaystyle B} is positively correlated with the number of tasks. The production function here is simple:",
    "after": "The important implication of this production function is positive assortative matching. We can observe this through a hypothetical four-person economy with two low skill workers ( q L ) and two high skill workers ( q H ). This equation dictates the productive efficiency of skill matching:",
    "url": "https://en.wikipedia.org/wiki/O-ring theory of economic development"
  },
  "{\\displaystyle MI={\\sqrt {(Q_{1}Q_{2})/(Q_{3}Q_{4})}}}": {
    "before": "To calculate the Malmquist Index of economy A with respect to economy B, we must substitute the labour and capital inputs of economy A into the production function of B, and vice versa. The formula for MI is given below.",
    "after": "where {\\displaystyle Q_{1}=f_{a}(S_{a})} {\\displaystyle Q_{2}=f_{a}(S_{b})} {\\displaystyle Q_{3}=f_{b}(S_{a})} {\\displaystyle Q_{4}=f_{b}(S_{b})}",
    "url": "https://en.wikipedia.org/wiki/Malmquist index"
  },
  "{\\displaystyle Q_{1}=f_{a}(S_{a})} {\\displaystyle Q_{2}=f_{a}(S_{b})} {\\displaystyle Q_{3}=f_{b}(S_{a})} {\\displaystyle Q_{4}=f_{b}(S_{b})}": {
    "before": "{\\displaystyle MI={\\sqrt {(Q_{1}Q_{2})/(Q_{3}Q_{4})}}} where",
    "after": "Note that the MI of A with respect to B is the reciprocal of the MI of B with respect to A. If the MI of A with respect to B is greater than 1, the aggregate production technology of economy A is superior to that of economy B.",
    "url": "https://en.wikipedia.org/wiki/Malmquist index"
  },
  "{\\displaystyle Y=C+I+G+NX\\,}": {
    "before": "The Mundell–Fleming model is based on the following equations:The IS curve:",
    "after": "where NX is net exports .",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle {\\frac {M}{P}}=L(i,Y)}": {
    "before": "where NX is net exports .The LM curve:",
    "after": "A higher interest rate or a lower income (GDP) level leads to lower money demand.",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle BoP=CA+KA\\,}": {
    "before": "A higher interest rate or a lower income (GDP) level leads to lower money demand.The BoP (Balance of Payments) Curve:",
    "after": "where BoP is the balance of payments surplus, CA is the current account surplus, and KA is the capital account surplus.",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle C=C(Y-T(Y),i-E(\\pi ))\\,}": {
    "before": "where BoP is the balance of payments surplus, CA is the current account surplus, and KA is the capital account surplus.IS components [ edit ]",
    "after": "where E (π) is the expected rate of inflation . Higher disposable income or a lower real interest rate (nominal interest rate minus expected inflation) leads to higher consumption spending.",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle I=I(i-E(\\pi ),Y_{t-1})\\,}": {
    "before": "where E (π) is the expected rate of inflation . Higher disposable income or a lower real interest rate (nominal interest rate minus expected inflation) leads to higher consumption spending.",
    "after": "where Y t-1 is GDP in the previous period. Higher lagged income or a lower real interest rate leads to higher investment spending.",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle NX=NX(e,Y,Y^{*})}": {
    "before": "where Y t-1 is GDP in the previous period. Higher lagged income or a lower real interest rate leads to higher investment spending.",
    "after": "where NX is net exports , e is the nominal exchange rate (the price of foreign currency in terms of units of the domestic currency), Y is GDP, and Y* is the combined GDP of countries that are foreign trading partners. Higher domestic income (GDP) leads to more spending on imports and hence lower net exports; higher foreign income leads to higher spending by foreigners on the country's exports and thus higher net exports. A higher e leads to higher net exports.",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle CA=NX}": {
    "before": "where NX is net exports , e is the nominal exchange rate (the price of foreign currency in terms of units of the domestic currency), Y is GDP, and Y* is the combined GDP of countries that are foreign trading partners. Higher domestic income (GDP) leads to more spending on imports and hence lower net exports; higher foreign income leads to higher spending by foreigners on the country's exports and thus higher net exports. A higher e leads to higher net exports.Balance of payments (BoP) components [ edit ]",
    "after": "where CA is the current account and NX is net exports. That is, the current account is viewed as consisting solely of imports and exports.",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle KA=z(i-i^{*})+k}": {
    "before": "where CA is the current account and NX is net exports. That is, the current account is viewed as consisting solely of imports and exports.",
    "after": "where {\\displaystyle i^{*}} is the foreign interest rate, k is the exogenous component of financial capital flows, z is the interest-sensitive component of capital flows, and the derivative of the function z is the degree of capital mobility (the effect of differences between domestic and foreign interest rates upon capital flows KA ).",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle i=i^{\\star }+{\\frac {e'}{e}}-1}": {
    "before": "One of the assumptions of the Mundell–Fleming model is that domestic and foreign securities are perfect substitutes. Provided the world interest rate {\\displaystyle i^{\\star }} is given, the model predicts the domestic rate will become the same level of the world rate by arbitrage in money markets. However, in reality, the world interest rate is different from the domestic rate. Rüdiger Dornbusch considered how exchange rate expectations have an effect on the exchange rate.  Given the approximate formula:",
    "after": "and if the elasticity of expectations {\\displaystyle \\sigma } , is less than unity, then we have",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle {\\frac {di}{de}}=\\sigma -1<0\\quad .}": {
    "before": "and if the elasticity of expectations {\\displaystyle \\sigma } , is less than unity, then we have",
    "after": "Since domestic output is {\\displaystyle y=E(i,y)+T(e,y)} , the differentiation of income with regard to the exchange rate becomes",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle {\\frac {dy}{de}}={\\frac {\\partial E}{\\partial i}}{\\frac {di}{de}}+{\\frac {\\partial E}{\\partial y}}{\\frac {dy}{de}}+{\\frac {\\partial T}{\\partial e}}+{\\frac {\\partial T}{\\partial y}}{\\frac {dy}{de}}} {\\displaystyle {\\frac {dy}{de}}={\\frac {1}{1-E_{y}-T_{y}}}\\left(E_{i}{\\frac {di}{de}}+T_{e}\\right)\\;.}": {
    "before": "Since domestic output is {\\displaystyle y=E(i,y)+T(e,y)} , the differentiation of income with regard to the exchange rate becomes",
    "after": "The standard IS-LM theory gives us the following basic relations:",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle E_{i}<0\\;,\\quad E_{y}=1-s>0} {\\displaystyle T_{e}>0\\;,\\quad T_{y}=-m<0\\;.}": {
    "before": "The standard IS-LM theory gives us the following basic relations:",
    "after": "Investment and consumption increase as the interest rates decrease, and currency depreciation improves the trade balance.",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle {\\frac {dy}{de}}={\\frac {1}{s+m}}\\left(E_{i}{\\frac {di}{de}}+T_{e}\\right)} {\\displaystyle {\\frac {dy}{de}}={\\frac {1}{s+m}}\\left(E_{i}(\\sigma -1)+T_{e}\\right)\\;.}": {
    "before": "Investment and consumption increase as the interest rates decrease, and currency depreciation improves the trade balance.",
    "after": "Then the total differentiations of trade balance and the demand for money are derived.",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle dT={\\frac {\\partial T}{\\partial e}}de+{\\frac {\\partial T}{\\partial y}}dy=T_{e}de+T_{y}dy} {\\displaystyle dL={\\frac {\\partial L}{\\partial i}}di+{\\frac {\\partial L}{\\partial y}}dy=L_{i}di+L_{y}dy} {\\displaystyle L_{i}<0\\;,\\quad L_{y}>0}": {
    "before": "Then the total differentiations of trade balance and the demand for money are derived.",
    "after": "and then, it turns out that",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle {\\frac {dT}{dL}}={\\frac {T_{e}(s+m)+T_{y}(E_{i}(\\sigma -1)+T_{e})}{L_{i}(\\sigma -1)(s+m)+L_{y}(E_{i}(\\sigma -1)+T_{e})}}} {\\displaystyle {\\frac {dT}{dL}}={\\frac {T_{e}s+T_{y}E_{i}(\\sigma -1)}{L_{i}(\\sigma -1)(s+m)+L_{y}(E_{i}(\\sigma -1)+T_{e})}}\\;.}": {
    "before": "{\\displaystyle dT={\\frac {\\partial T}{\\partial e}}de+{\\frac {\\partial T}{\\partial y}}dy=T_{e}de+T_{y}dy} {\\displaystyle dL={\\frac {\\partial L}{\\partial i}}di+{\\frac {\\partial L}{\\partial y}}dy=L_{i}di+L_{y}dy} {\\displaystyle L_{i}<0\\;,\\quad L_{y}>0} and then, it turns out that",
    "after": "The denominator is positive, and the numerator is positive or negative. Thus, a monetary expansion, in the short run, does not necessarily improve the trade balance. This result is not compatible with what the Mundell-Fleming predicts.  This is a consequence of introducing exchange rate expectations which the MF theory ignores. Nevertheless, Dornbusch concludes that monetary policy is still effective even if it worsens a trade balance, because a monetary expansion pushes down interest rates and encourages spending. He adds that, in the short run, fiscal policy works because it raises interest rates and the velocity of money. ",
    "url": "https://en.wikipedia.org/wiki/Mundell–Fleming model"
  },
  "{\\displaystyle {\\frac {\\partial U}{\\partial g}}=\\lim _{\\Delta g\\to 0}\\left.{\\frac {\\Delta U}{\\Delta g}}\\right|_{c.p.}} .": {
    "before": "exists, and use \"marginal utility\" to refer to the partial derivative",
    "after": "Accordingly, diminishing marginal utility corresponds to the condition",
    "url": "https://en.wikipedia.org/wiki/Marginal utility"
  },
  "Zero rebound (RE = 0): The actual resource savings are equal to expected savings – the rebound effect is zero.": {
    "before": "Super conservation (RE < 0): the actual resource savings are higher than expected savings – the rebound effect is negative.",
    "after": "Partial rebound (0 < RE < 1): The actual resource savings are less than expected savings – the rebound effect is between 0% and 100%. This is sometimes known as 'take-back', and is the most common result of empirical studies on individual markets.",
    "url": "https://en.wikipedia.org/wiki/Rebound effect (conservation)"
  },
  "Full rebound (RE = 1): The actual resource savings are equal to the increase in usage – the rebound effect is at 100%.": {
    "before": "Partial rebound (0 < RE < 1): The actual resource savings are less than expected savings – the rebound effect is between 0% and 100%. This is sometimes known as 'take-back', and is the most common result of empirical studies on individual markets.",
    "after": "Backfire (RE > 1): The actual resource savings are negative because usage increased beyond potential savings – the rebound effect is higher than 100%. This situation is commonly known as the Jevons paradox.",
    "url": "https://en.wikipedia.org/wiki/Rebound effect (conservation)"
  },
  "{\\displaystyle MP={\\frac {\\Delta Y}{\\Delta X}}}": {
    "before": "The marginal product of a given input can be expressed  as:",
    "after": "where {\\displaystyle \\Delta X} is the change in the firm's use of the input (conventionally a one-unit change) and {\\displaystyle \\Delta Y} is the change in quantity of output produced (resulting from the change in the input). Note that the quantity {\\displaystyle Y} of the \"product\" is typically defined ignoring external costs and benefits .",
    "url": "https://en.wikipedia.org/wiki/Marginal product"
  },
  "{\\displaystyle Y=F(K,L)}": {
    "before": "If the output and the input are infinitely divisible, so the marginal \"units\" are infinitesimal, the marginal product is the mathematical derivative of the production function with respect to that input. Suppose a firm's output Y is given by the production function:",
    "after": "where K and L are inputs to production (say, capital and labor, respectively). Then the marginal product of capital ( MPK ) and marginal product of labor ( MPL ) are given by:",
    "url": "https://en.wikipedia.org/wiki/Marginal product"
  },
  "{\\displaystyle MPK={\\frac {\\partial F}{\\partial K}}}": {
    "before": "where K and L are inputs to production (say, capital and labor, respectively). Then the marginal product of capital ( MPK ) and marginal product of labor ( MPL ) are given by:",
    "after": "{\\displaystyle MPL={\\frac {\\partial F}{\\partial L}}}",
    "url": "https://en.wikipedia.org/wiki/Marginal product"
  },
  "{\\displaystyle MPL={\\frac {\\partial F}{\\partial L}}}": {
    "before": "{\\displaystyle MPK={\\frac {\\partial F}{\\partial K}}}",
    "after": "In the \"law\" of diminishing marginal returns , the marginal product initially increases when more of an input (say labor) is employed, keeping the other input (say capital) constant. Here, labor is the variable input and capital is the fixed input (in a hypothetical two-inputs model). As more and more of variable input (labor) is employed, marginal product starts to fall. Finally, after a certain point, the marginal product becomes negative, implying that the additional unit of labor has decreased the output, rather than increasing it. The reason behind this is the diminishing marginal productivity of labor .",
    "url": "https://en.wikipedia.org/wiki/Marginal product"
  },
  "Equal absolute sacrifice=U(Y)-U(Y-T), where y=income and t=tax amount": {
    "before": "Mathematically, the conditions are as follows:",
    "after": "Equal proportional sacrifice=(U(Y)-U(Y-T))/U(Y), where U(Y)=total utility from y",
    "url": "https://en.wikipedia.org/wiki/Theories of taxation"
  },
  "Equal proportional sacrifice=(U(Y)-U(Y-T))/U(Y), where U(Y)=total utility from y": {
    "before": "Equal absolute sacrifice=U(Y)-U(Y-T), where y=income and t=tax amount",
    "after": "Equal marginal sacrifice=(dU(Y-T))/(d(Y-T))",
    "url": "https://en.wikipedia.org/wiki/Theories of taxation"
  },
  "Equal marginal sacrifice=(dU(Y-T))/(d(Y-T))": {
    "before": "Equal proportional sacrifice=(U(Y)-U(Y-T))/U(Y), where U(Y)=total utility from y",
    "after": "References[edit]",
    "url": "https://en.wikipedia.org/wiki/Theories of taxation"
  },
  "{\\displaystyle {\\mbox{swap-regret}}=\\sum _{i=1}^{n}\\max _{j\\leq n}{\\frac {1}{T}}\\sum _{t=1}^{T}x_{i}^{t}\\cdot (p_{j}^{t}-p_{i}^{t}).}": {
    "before": "A player's swap-regret is defined to be the following:",
    "after": "Intuitively, it is how much a player could improve by switching each occurrence of decision i to the best decision j possible in hindsight . The swap regret is always nonnegative. Swap regret is useful for computing correlated equilibria .",
    "url": "https://en.wikipedia.org/wiki/Swap regret"
  },
  "{\\displaystyle {\\mbox{Mortgage Yield: ri such that P}}=\\sum _{n=1}^{N}{\\frac {C(t)}{(1+ri/1200)^{t-1}}}}": {
    "before": "When the coupon payments are made on a monthly basis, the mortgage yield can be calculated as:",
    "after": "Wheret - the time of the cash flow n - each instance of coupon payment r - the discount rate {\\displaystyle C(t)} - the net cash flow (the amount of cash) at time t.",
    "url": "https://en.wikipedia.org/wiki/Mortgage yield"
  },
  "Predetermined variables can be shown as: E(uis|xit) =0 where s > t.": {
    "before": "Predeterminedness, or sequential exogeneity, is commonly invoked in dynamic panel models.",
    "after": "The presence of predetermined variables is a motivating factor in the Arellano–Bond estimator.",
    "url": "https://en.wikipedia.org/wiki/Predetermined variables"
  },
  "{\\displaystyle {\\begin{aligned}f'_{i}(x_{i}^{0})&=\\lambda {\\mbox{ if }}x_{i}^{0}>0\\\\&\\leq \\lambda {\\mbox{ if }}x_{i}^{0}=0.\\end{aligned}}}": {
    "before": "Consider {\\displaystyle \\phi =\\sum _{i=1}^{n}f_{i}(x_{i})} . Suppose {\\displaystyle \\phi } is maximized, subject to {\\displaystyle \\sum x_{i}=X} and {\\displaystyle x_{i}\\geq 0} , at {\\displaystyle x^{0}=(x_{1}^{0},\\ldots ,x_{n}^{0})} . If the {\\displaystyle f_{i}} are differentiable , then the Gibbs lemma states that there exists a {\\displaystyle \\lambda } such that",
    "after": "Notes [ edit ] ^ J. M. Danskin (6 December 2012). The Theory of Max-Min and its Application to Weapons Allocation Problems . Springer Science & Business Media. ISBN 978-3-642-46092-0 . ... problems in which one side must make his move knowing that the other side will then learn what the move is and optimally counter. They are fundamental in particular to military weapons-selection problems involving large systems...",
    "url": "https://en.wikipedia.org/wiki/Gibbs lemma"
  },
  "{\\displaystyle \\sum _{i}p(0)*q(0)=P(0)Q(0).}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Divisia index"
  },
  "{\\displaystyle \\sum _{i}p(t)*q(t)=P(t)Q(t).}": {
    "before": "Then a price index P(t) and quantity index Q(t) are the solution to a differential equation and if P(0) and Q(0) were chosen suitably the series summarize all transactions in the sense that for all t: ",
    "after": "Discrete-time approximations [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Divisia index"
  },
  "{\\displaystyle s_{j,t}^{*}={\\frac {1}{2}}(s_{j,t}+s_{j,t-1})} (See, for example, Divisia monetary aggregates index .)": {
    "before": "Gather price and quantity for each component, using measures that have been adjusted for quality change if possible Compute cost/price/expenditure fractions for each component at time 1 and time 2. Average the time-1 and time-2 fractions for each component. Use those averages as the 'weights' for the component. Define the weights to be averages of expenditures shares or cost shares over the period of change:",
    "after": "The value of the index at time 0 is an arbitrary normalization, usually chosen to be 1 or 100 which makes it easier to make quick inferences about overall fractional or percentage changes.",
    "url": "https://en.wikipedia.org/wiki/Divisia index"
  },
  "{\\displaystyle s_{j,t}^{*}={\\frac {1}{2}}(s_{j,t}+s_{j,t-1})}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Divisia index"
  },
  "are continuous series of price data for each input from i=1 to i=n": {
    "before": "{\\displaystyle p_{i}(t)}",
    "after": "{\\displaystyle q_{i}(t)}",
    "url": "https://en.wikipedia.org/wiki/Divisia index"
  },
  "{\\displaystyle \\sum _{t=0}^{T}\\beta ^{t}u(x_{t}),}": {
    "before": "Discounted utility calculations made for events at various points in the future as well as at the present take the form",
    "after": "where {\\displaystyle u(x_{t})} is the utility of some choice {\\displaystyle x} at time {\\displaystyle t} and T is the time of the most distant future satisfaction event. Here, since utility comparisons are being made across time when the utilities are combined in a single evaluation, the utility function is necessarily cardinal in nature.",
    "url": "https://en.wikipedia.org/wiki/Discounted utility"
  },
  "Do they grant the relation: C = P & Q": {
    "before": "Q",
    "after": "C",
    "url": "https://en.wikipedia.org/wiki/Discursive dilemma"
  },
  "{\\displaystyle C_{t}=\\alpha +VM_{t}+KA_{t}} (1)": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Monetary/fiscal debate"
  },
  "{\\displaystyle {\\frac {\\sum _{i=1}^{n}({median}(L,C_{i})\\times V_{i})}{\\sum _{i=1}^{n}(V_{i})}}}": {
    "before": "The tradelane index is calculated as follows. ",
    "after": "Where: {\\displaystyle L} = tradelane value (rounded to the nearest integer) {\\displaystyle C_{1},C_{2},\\cdots ,C_{n}} = carriers {\\displaystyle V_{1},V_{2},\\cdots ,V_{n}} = carrier volumes on the tradelane {\\displaystyle {median}(L,C_{i},\\cdots ,C_{j})} = the median price for carriers {\\displaystyle C_{i},\\cdots ,C_{j}} on the tradelane {\\displaystyle L}",
    "url": "https://en.wikipedia.org/wiki/Freightos Baltic Index"
  },
  "{\\displaystyle {\\frac {\\sum _{i=1}^{12}(I_{i}\\times V_{i})}{\\sum _{i=1}^{12}(V_{i})}}}": {
    "before": "The FBX Global Container Index (FBX) is a weighted average of 12 regional tradelane indices. It is calculated as follows. ",
    "after": "Where: {\\displaystyle I_{1},I_{2},\\cdots ,I_{12}} = the 12 regional tradelanes indices {\\displaystyle V_{1},V_{2},\\cdots ,V_{12}} = respectives volumes of the 12 regional tradelanes indices",
    "url": "https://en.wikipedia.org/wiki/Freightos Baltic Index"
  },
  "{\\displaystyle f(x)={\\begin{cases}mx+y_{1}-mx_{1}&{\\text{if }}0\\leq x<x_{1}\\\\0&{\\text{if }}x\\geq x_{1}\\end{cases}}}": {
    "before": "These knees in functions are defined by piecewise functions. Below is an exemplary piecewise linear function defining that as soon as x equals or is greater than x 1 , the value of y is set to zero, respectively is not defined.",
    "after": "Polynomial, regressive, degressive and progressive functions [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Bulk dispatch lapse"
  },
  "Vmp = (Actual unit cost - Standard unit cost) * Actual Quantity Purchased or Vmp = (Actual Quantity Purchased * Actual Unit Cost) - (Actual Quantity Purchased * Standard Unit Cost) .": {
    "before": "Price variance is calculated by the following formula:",
    "after": "When the Actual Materials Price is higher than the Standard Materials Price, the variance is said to be unfavorable, since the Actual price paid on materials purchased is greater than the allowed standard. The variance is said to be favorable when the Standard materials Price is higher than the Actual Materials Price, since less money was spent in purchasing the materials than the allowed standard. ",
    "url": "https://en.wikipedia.org/wiki/Price variance"
  },
  "cost = np.sum(np.power(np.abs(A - B), p))": {
    "before": "def dlp(A, B, p=2):",
    "after": "return np.power(cost, 1 / p)",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "# [distance, DP] = TWED( A, timeSA, B, timeSB, lambda, nu )": {
    "before": "def twed(A, timeSA, B, timeSB, nu, _lambda):",
    "after": "# Compute Time Warp Edit Distance (TWED) for given time series A and B",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "# A := Time series A (e.g. [ 10 2 30 4])": {
    "before": "#",
    "after": "# timeSA := Time stamp of time series A (e.g. 1:4)",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "# timeSA := Time stamp of time series A (e.g. 1:4)": {
    "before": "# A := Time series A (e.g. [ 10 2 30 4])",
    "after": "# B := Time series B",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "# B := Time series B": {
    "before": "# timeSA := Time stamp of time series A (e.g. 1:4)",
    "after": "# timeSB := Time stamp of time series B",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "# timeSB := Time stamp of time series B": {
    "before": "# B := Time series B",
    "after": "# lambda := Penalty for deletion operation",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "# lambda := Penalty for deletion operation": {
    "before": "# timeSB := Time stamp of time series B",
    "after": "# nu := Elasticity parameter - nu >=0 needed for distance measure",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "# nu := Elasticity parameter - nu >=0 needed for distance measure": {
    "before": "# lambda := Penalty for deletion operation",
    "after": "# Reference :",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "if len(A) != len(timeSA):": {
    "before": "# Check if input arguments",
    "after": "print(\"The length of A is not equal length of timeSA\")",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "if len(B) != len(timeSB):": {
    "before": "return None, None",
    "after": "print(\"The length of B is not equal length of timeSB\")",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "A = np.array( + list(A))": {
    "before": "# Add padding",
    "after": "timeSA = np.array( + list(timeSA))",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "timeSA = np.array( + list(timeSA))": {
    "before": "A = np.array( + list(A))",
    "after": "B = np.array( + list(B))",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "B = np.array( + list(B))": {
    "before": "timeSA = np.array( + list(timeSA))",
    "after": "timeSB = np.array( + list(timeSB))",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "timeSB = np.array( + list(timeSB))": {
    "before": "B = np.array( + list(B))",
    "after": "n = len(A)",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "n = len(A)": {
    "before": "timeSB = np.array( + list(timeSB))",
    "after": "m = len(B)",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "m = len(B)": {
    "before": "n = len(A)",
    "after": "# Dynamical programming",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "DP = np.zeros((n, m))": {
    "before": "# Dynamical programming",
    "after": "# Initialize DP Matrix and set first row and column to infinity",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "DP[0, :] = np.inf": {
    "before": "# Initialize DP Matrix and set first row and column to infinity",
    "after": "DP[:, 0] = np.inf",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "DP[:, 0] = np.inf": {
    "before": "DP[0, :] = np.inf",
    "after": "DP[0, 0] = 0",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C = np.ones((3, 1)) * np.inf": {
    "before": "best_path.append((i - 1, j - 1))",
    "after": "# Keep data points in both time series",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "DP[i, j] = np.min(C)": {
    "before": "# Choose the operation with the minimal cost and update DP Matrix",
    "after": "distance = DP[n - 1, m - 1]",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "distance = DP[n - 1, m - 1]": {
    "before": "DP[i, j] = np.min(C)",
    "after": "return distance, DP",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "# [ best_path ] = BACKTRACKING ( DP )": {
    "before": "def backtracking(DP):",
    "after": "# Compute the most cost-efficient path",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "# DP := DP matrix of the TWED function": {
    "before": "# Compute the most cost-efficient path",
    "after": "x = np.shape(DP)",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "x = np.shape(DP)": {
    "before": "# DP := DP matrix of the TWED function",
    "after": "i = x - 1",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "i = x - 1": {
    "before": "x = np.shape(DP)",
    "after": "j = x - 1",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "j = x - 1": {
    "before": "i = x - 1",
    "after": "# The indices of the paths are save in opposite direction",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "# path = np.ones((i + j, 2 )) * np.inf;": {
    "before": "# The indices of the paths are save in opposite direction",
    "after": "best_path = []",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "while i != 0 or j != 0:": {
    "before": "steps = 0",
    "after": "best_path.append((i - 1, j - 1))",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C = DP[i - 1, j - 1]": {
    "before": "# Keep data points in both time series",
    "after": "# Deletion in A",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C = DP[i - 1, j]": {
    "before": "# Deletion in A",
    "after": "# Deletion in B",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C = DP[i, j - 1]": {
    "before": "# Deletion in B",
    "after": "# Find the index for the lowest cost",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "idx = np.argmin(C)": {
    "before": "# Find the index for the lowest cost",
    "after": "if idx == 0:",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "i = i - 1": {
    "before": "# Deletion in A",
    "after": "j = j",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "j = j - 1": {
    "before": "i = i",
    "after": "steps = steps + 1",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "j = j": {
    "before": "i = i - 1",
    "after": "else:",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "i = i": {
    "before": "# Deletion in B",
    "after": "j = j - 1",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "steps = steps + 1": {
    "before": "j = j - 1",
    "after": "best_path.append((i - 1, j - 1))",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "function [distance, DP] = twed(A, timeSA, B, timeSB, lambda, nu)": {
    "before": "MATLAB[edit]",
    "after": "% [distance, DP] = TWED( A, timeSA, B, timeSB, lambda, nu )",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "% [distance, DP] = TWED( A, timeSA, B, timeSB, lambda, nu )": {
    "before": "function [distance, DP] = twed(A, timeSA, B, timeSB, lambda, nu)",
    "after": "% Compute Time Warp Edit Distance (TWED) for given time series A and B",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "% A := Time series A (e.g. [ 10 2 30 4])": {
    "before": "%",
    "after": "% timeSA := Time stamp of time series A (e.g. 1:4)",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "% timeSA := Time stamp of time series A (e.g. 1:4)": {
    "before": "% A := Time series A (e.g. [ 10 2 30 4])",
    "after": "% B := Time series B",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "% B := Time series B": {
    "before": "% timeSA := Time stamp of time series A (e.g. 1:4)",
    "after": "% timeSB := Time stamp of time series B",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "% timeSB := Time stamp of time series B": {
    "before": "% B := Time series B",
    "after": "% lambda := Penalty for deletion operation",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "% lambda := Penalty for deletion operation": {
    "before": "% timeSB := Time stamp of time series B",
    "after": "% nu := Elasticity parameter - nu >=0 needed for distance measure",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "% nu := Elasticity parameter - nu >=0 needed for distance measure": {
    "before": "% lambda := Penalty for deletion operation",
    "after": "%",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "if length(A) ~= length(timeSA)": {
    "before": "% Check if input arguments",
    "after": "warning('The length of A is not equal length of timeSA')",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "if length(B) ~= length(timeSB)": {
    "before": "end",
    "after": "warning('The length of B is not equal length of timeSB')",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "A = [0 A];": {
    "before": "% Add padding",
    "after": "timeSA = [0 timeSA];",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "timeSA = [0 timeSA];": {
    "before": "A = [0 A];",
    "after": "B = [0 B];",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "B = [0 B];": {
    "before": "timeSA = [0 timeSA];",
    "after": "timeSB = [0 timeSB];",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "timeSB = [0 timeSB];": {
    "before": "B = [0 B];",
    "after": "% Dynamical programming",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "DP = zeros(length(A), length(B));": {
    "before": "% Dynamical programming",
    "after": "% Initialize DP Matrix and set first row and column to infinity",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "DP(1, :) = inf;": {
    "before": "% Initialize DP Matrix and set first row and column to infinity",
    "after": "DP(:, 1) = inf;",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "DP(:, 1) = inf;": {
    "before": "DP(1, :) = inf;",
    "after": "DP(1, 1) = 0;",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "n = length(timeSA);": {
    "before": "DP(1, 1) = 0;",
    "after": "m = length(timeSB);",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "m = length(timeSB);": {
    "before": "n = length(timeSA);",
    "after": "% Compute minimal cost",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "for i = 2:n": {
    "before": "% Compute minimal cost",
    "after": "for j = 2:m",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "for j = 2:m": {
    "before": "for i = 2:n",
    "after": "cost = Dlp(A(i), B(j));",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "cost = Dlp(A(i), B(j));": {
    "before": "for j = 2:m",
    "after": "% Calculate and save cost of various operations",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C = ones(3, 1) * inf;": {
    "before": "path(steps, :) = [i; j];",
    "after": "% Keep data points in both time series",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C(1) = DP(i - 1, j) + Dlp(A(i - 1), A(i)) + nu * (timeSA(i) - timeSA(i - 1)) + lambda;": {
    "before": "% Deletion in A",
    "after": "% Deletion in B",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C(2) = DP(i, j - 1) + Dlp(B(j - 1), B(j)) + nu * (timeSB(j) - timeSB(j - 1)) + lambda;": {
    "before": "% Deletion in B",
    "after": "% Keep data points in both time series",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C(3) = DP(i - 1, j - 1) + Dlp(A(i), B(j)) + Dlp(A(i - 1), B(j - 1)) + ...": {
    "before": "% Keep data points in both time series",
    "after": "nu * (abs(timeSA(i) - timeSB(j)) + abs(timeSA(i - 1) - timeSB(j - 1)));",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "DP(i, j) = min(C);": {
    "before": "% Choose the operation with the minimal cost and update DP Matrix",
    "after": "end",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "distance = DP(n, m);": {
    "before": "end",
    "after": "% Function to calculate euclidean distance",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "function [cost] = Dlp(A, B)": {
    "before": "% Function to calculate euclidean distance",
    "after": "cost = sqrt(sum((A - B) .^ 2, 2));",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "cost = sqrt(sum((A - B) .^ 2, 2));": {
    "before": "function [cost] = Dlp(A, B)",
    "after": "end",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "function [path] = backtracking(DP)": {
    "before": "Backtracking, to find the most cost-efficient path:",
    "after": "% [ path ] = BACKTRACKING ( DP )",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "% [ path ] = BACKTRACKING ( DP )": {
    "before": "function [path] = backtracking(DP)",
    "after": "% Compute the most cost-efficient path",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "% DP := DP matrix of the TWED function": {
    "before": "% Compute the most cost-efficient path",
    "after": "x = size(DP);",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "x = size(DP);": {
    "before": "% DP := DP matrix of the TWED function",
    "after": "i = x(1);",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "i = x(1);": {
    "before": "x = size(DP);",
    "after": "j = x(2);",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "j = x(2);": {
    "before": "i = x(1);",
    "after": "% The indices of the paths are save in opposite direction",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "path = ones(i + j, 2) * Inf;": {
    "before": "% The indices of the paths are save in opposite direction",
    "after": "steps = 1;",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "while (i ~= 1 || j ~= 1)": {
    "before": "steps = 1;",
    "after": "path(steps, :) = [i; j];",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "path(steps, :) = [i; j];": {
    "before": "while (i ~= 1 || j ~= 1)",
    "after": "C = ones(3, 1) * inf;",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C(1) = DP(i - 1, j - 1);": {
    "before": "% Keep data points in both time series",
    "after": "% Deletion in A",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C(2) = DP(i - 1, j);": {
    "before": "% Deletion in A",
    "after": "% Deletion in B",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "C(3) = DP(i, j - 1);": {
    "before": "% Deletion in B",
    "after": "% Find the index for the lowest cost",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "[~, idx] = min(C);": {
    "before": "% Find the index for the lowest cost",
    "after": "switch idx",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "i = i - 1;": {
    "before": "% Deletion in A",
    "after": "j = j;",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "j = j - 1;": {
    "before": "i = i;",
    "after": "end",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "j = j;": {
    "before": "i = i - 1;",
    "after": "case 3",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "i = i;": {
    "before": "% Deletion in B",
    "after": "j = j - 1;",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "steps = steps + 1;": {
    "before": "end",
    "after": "end",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "path(steps, :) = [i j];": {
    "before": "end",
    "after": "% Path was calculated in reversed direction.",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "path = path(1:steps, :);": {
    "before": "% Path was calculated in reversed direction.",
    "after": "path = path(end: - 1:1, :);",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "path = path(end: - 1:1, :);": {
    "before": "path = path(1:steps, :);",
    "after": "end",
    "url": "https://en.wikipedia.org/wiki/Time Warp Edit Distance"
  },
  "{\\displaystyle RCA_{cp}={\\frac {E_{cp}/\\sum _{p'\\in P}E_{cp'}}{\\sum _{c'\\in C}E_{c'p}/\\sum _{c'\\in C,p'\\in P}E_{c'p'}}}} , where:": {
    "before": "It most commonly refers to an index, called the Balassa index , introduced by Béla Balassa (1965).  In particular, the revealed comparative advantage of country {\\displaystyle c} in product/commodity/good {\\displaystyle p} is defined by:",
    "after": "E Exports c, c' Country index C Set of countries p,p' Commodity index P Set of commodities",
    "url": "https://en.wikipedia.org/wiki/Revealed comparative advantage"
  },
  "{\\displaystyle Y=AK.}": {
    "before": "This equation shows a Cobb–Douglas function where Y represents the total production in an economy. A represents total factor productivity , K is capital, L is labor, and the parameter {\\displaystyle a} measures the output elasticity of capital. For the special case in which {\\displaystyle a=1} , the production function becomes linear in capital thereby giving constant returns to scale : ",
    "after": "To avoid the contradictions, Russian economist Vladimir Pokrovskii proposed to write the production function in the united form",
    "url": "https://en.wikipedia.org/wiki/Endogenous growth theory"
  },
  "{\\displaystyle W=F_{(}{\\scriptstyle {\\text{1}}}_{)}(v)}": {
    "before": "In statistics the probability of having the \"first\" value is written as",
    "after": "With independent values and N other bidders {\\displaystyle W=F(v)^{N}}",
    "url": "https://en.wikipedia.org/wiki/Auction theory"
  },
  "{\\displaystyle u(v,b)=w(b)(v-b))}": {
    "before": "A buyer's payoff is",
    "after": "Let {\\displaystyle B} be the bid that maximizes the buyer's payoff.",
    "url": "https://en.wikipedia.org/wiki/Auction theory"
  },
  "{\\displaystyle u(v,B)>u(v,b)=W(b)(v-b)}": {
    "before": "Therefore",
    "after": "The equilibrium payoff is therefore",
    "url": "https://en.wikipedia.org/wiki/Auction theory"
  },
  "{\\displaystyle U(v)=W(B)(v-B))}": {
    "before": "The win probability is {\\displaystyle W=F(v)=v} .",
    "after": "Then {\\displaystyle (1/2)v^{2}=v(v-B(v))} .",
    "url": "https://en.wikipedia.org/wiki/Auction theory"
  },
  "{\\displaystyle U'(v)=W(B)+\\partial u/\\partial b}": {
    "before": "The final step is to take the total derivative of the equilibrium payoff",
    "after": "The second term is zero. Therefore",
    "url": "https://en.wikipedia.org/wiki/Auction theory"
  },
  "{\\displaystyle U'(v)=W}": {
    "before": "The second term is zero. Therefore",
    "after": "Then {\\displaystyle U'(v)=W} {\\displaystyle =F_{(}{\\scriptstyle {\\text{1}}}_{)}(v)}",
    "url": "https://en.wikipedia.org/wiki/Auction theory"
  },
  "{\\displaystyle B(v)=(1/2)v}": {
    "before": "Rearranging this expression,",
    "after": "With three buyers, {\\displaystyle U'(v)=W} {\\displaystyle =F_{(}{\\scriptstyle {\\text{1}}}_{)}(v)=F(v)^{2}=v^{2}} , then {\\displaystyle B(v)=(2/3)v}",
    "url": "https://en.wikipedia.org/wiki/Auction theory"
  },
  "p(r)*r = (100 - r)*r/100 =(r-50)*(r-50) + 25 .": {
    "before": "With identically and independent distributed private values, Riley and Samuelson (1981)  showed that in any auction or auction like action (such as the \"War of Attrition\") the allocation is \"participant efficient\", i.e. the item is allocated to a buyer submitting the highest bid with probability 1. They then showed that allocation equivalence implied payoff equivalence for all reserve prices. They then showed that discriminating against low value buyers by setting a minimum price or (reserve price) would increase expected revenue. Along with Myerson, they showed that the most profitable reserve price is independent of the number of bidders. There is a simple intuition. The reserve price only comes into play if there is a single bid. Thus it is equivalent to ask what reserve price would maximize the revenue from a single buyer. If values are uniformly distributed over the interval [0, 100], then the probability p(r) that this buyer's value is less than r is p(r) = (100-r)/100. Therefore the expected revenue is",
    "after": "Thus the expected revenue maximizing reserve price is 50. Myerson (1981). also examined the question of whether it might ever be more profitable to design a mechanism that awards the item to a bidder other than one with the highest value. Surprisingly, this is the case. As Maskin and Riley then showed, this is equivalent to excluding bids over certain intervals above the optimal reserve price.",
    "url": "https://en.wikipedia.org/wiki/Auction theory"
  },
  "{\\displaystyle q={\\text{Min}}\\left({\\frac {z_{1}}{a}},{\\frac {z_{2}}{b}}\\right)}": {
    "before": "For the simple case of a good that is produced with two inputs, the function is of the form",
    "after": "where q is the quantity of output produced, z 1 and z 2 are the utilised quantities of input 1 and input 2 respectively, and a and b are technologically determined constants.",
    "url": "https://en.wikipedia.org/wiki/Leontief production function"
  },
  "Number of cars = Min{1⁄4 times the number of tires, 1 times the number of steering wheels}.": {
    "before": "Suppose that the intermediate goods \"tires\" and \"steering wheels\" are used in the production of automobiles (for simplicity of the example, to the exclusion of anything else). Then in the above formula q refers to the number of automobiles produced, z 1 refers to the number of tires used, and z 2 refers to the number of steering wheels used. Assuming each car is produced with 4 tires and 1 steering wheel, the Leontief production function is",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Leontief production function"
  },
  "{\\displaystyle {\\mathit {MPC}}={\\frac {dC}{dY}}}": {
    "before": "Mathematically, the {\\displaystyle {\\mathit {MPC}}} function is expressed as the derivative of the consumption function {\\displaystyle C} with respect to disposable income {\\displaystyle Y} , i.e., the instantaneous slope of the {\\displaystyle C} - {\\displaystyle Y} curve.",
    "after": "or, approximately,",
    "url": "https://en.wikipedia.org/wiki/Marginal propensity to consume"
  },
  "{\\displaystyle {\\mathit {MPC}}={\\frac {\\Delta C}{\\Delta Y}}} , where {\\displaystyle \\Delta C} is the change in consumption, and {\\displaystyle \\Delta Y} is the change in disposable income that produced the consumption.": {
    "before": "{\\displaystyle {\\mathit {MPC}}={\\frac {dC}{dY}}} or, approximately,",
    "after": "Marginal propensity to consume can be found by dividing change in consumption by a change in income, or {\\displaystyle {\\mathit {MPC}}=\\Delta C/\\Delta Y} . The MPC can be explained with the simple example:",
    "url": "https://en.wikipedia.org/wiki/Marginal propensity to consume"
  },
  "{\\displaystyle K_{t}=2\\sum _{k=1}^{n}{\\frac {1}{n}}({\\frac {k}{n}}-\\sum _{i=1}^{k}\\gamma _{i})-G_{beforetax},}": {
    "before": "The index is calculated using the following formula:",
    "after": "where {\\displaystyle i=1,...,k} denotes individual {\\displaystyle i} , {\\displaystyle n} is the total number of individuals in society, {\\displaystyle \\gamma _{i}} is the share of total taxes paid by individual {\\displaystyle i} , and {\\displaystyle G_{beforetax}} is the before-tax Gini coefficient. Using the formula for the Gini coefficient, the equation for the Kakwani index can be reduced to:",
    "url": "https://en.wikipedia.org/wiki/Kakwani index"
  },
  "{\\displaystyle K_{t}={\\frac {2}{n}}\\sum _{k=1}^{n}(\\sum _{i=1}^{k}\\alpha _{i}-\\gamma _{i}),}": {
    "before": "where {\\displaystyle i=1,...,k} denotes individual {\\displaystyle i} , {\\displaystyle n} is the total number of individuals in society, {\\displaystyle \\gamma _{i}} is the share of total taxes paid by individual {\\displaystyle i} , and {\\displaystyle G_{beforetax}} is the before-tax Gini coefficient. Using the formula for the Gini coefficient, the equation for the Kakwani index can be reduced to:",
    "after": "where {\\displaystyle \\alpha _{i}} denotes the share of income received by individual {\\displaystyle i} .",
    "url": "https://en.wikipedia.org/wiki/Kakwani index"
  },
  "I ( a , b ) = { v | d ( a , b ) = d ( a,v ) + d ( v,b )}.": {
    "before": "In an arbitrary graph, for each two vertices a and b , the minimal number of edges between them is called their distance , denoted by d ( x , y ). The interval of vertices that lie on shortest paths between a and b is defined as",
    "after": "A median graph is defined by the property that, for every three vertices a , b , and c , these intervals intersect in a single point:",
    "url": "https://en.wikipedia.org/wiki/Median graph"
  },
  "m ( a , b , c ) = ( a ∧ b ) ∨ ( a ∧ c ) ∨ ( b ∧ c ) = ( a ∨ b ) ∧ ( a ∨ c ) ∧ ( b ∨ c ),": {
    "before": "In a distributive lattice, Birkhoff's self-dual ternary median operation ",
    "after": "satisfies certain key axioms, which it shares with the usual median of numbers in the range from 0 to 1 and with median algebras more generally:",
    "url": "https://en.wikipedia.org/wiki/Median graph"
  },
  "I ( a , b ) = { x | m ( a,x,b ) = x } = { x | a ∧ b ≤ x ≤ a ∨ b }. ": {
    "before": "The median operation may also be used to define a notion of intervals for distributive lattices:",
    "after": "The graph of a finite distributive lattice has an edge between vertices a and b whenever I ( a , b ) = { a , b }. For every two vertices a and b of this graph, the interval I ( a , b ) defined in lattice-theoretic terms above consists of the vertices on shortest paths from a to b , and thus coincides with the graph-theoretic intervals defined earlier. For every three lattice elements a , b , and c , m ( a , b , c ) is the unique intersection of the three intervals I ( a , b ), I ( a , c ) , and I ( b , c ) .  Therefore, the graph of an arbitrary finite distributive lattice is a median graph. Conversely, if a median graph G contains two vertices 0 and 1 such that every other vertex lies on a shortest path between the two (equivalently, m (0, a ,1) = a for all a ), then we may define a distributive lattice in which a ∧ b = m ( a ,0, b ) and a ∨ b = m ( a ,1, b ), and G will be the graph of this lattice. ",
    "url": "https://en.wikipedia.org/wiki/Median graph"
  },
  "W uv = { w | d ( w , u ) < d ( w , v )}": {
    "before": "A particularly important family of convex sets in a median graph, playing a role similar to that of halfspaces in Euclidean space, are the sets",
    "after": "defined for each edge uv of the graph. In words, W uv consists of the vertices closer to u than to v , or equivalently the vertices w such that some shortest path from v to w goes through u . To show that W uv is convex, let w 1 w 2 ... w k be an arbitrary shortest path that starts and ends within W uv ; then w 2 must also lie within W uv , for otherwise the two points m 1 = m ( u , w 1 , w k ) and m 2 = m ( m 1 , w 2 ... w k ) could be shown (by considering the possible distances between the vertices) to be distinct medians of u , w 1 , and w k , contradicting the definition of a median graph which requires medians to be unique. Thus, each successive vertex on a shortest path between two vertices of W uv also lies within W uv , so W uv contains all shortest paths between its nodes, one of the definitions of convexity.",
    "url": "https://en.wikipedia.org/wiki/Median graph"
  },
  "d(a,b) = d(a,m(a,b,c)) + d(m(a,b,c),b)": {
    "before": "Equivalently, for every three vertices a, b, and c one can find a vertex m(a,b,c) such that the unweighted distances in the graph satisfy the equalities",
    "after": "d(a,c) = d(a,m(a,b,c)) + d(m(a,b,c),c)",
    "url": "https://en.wikipedia.org/wiki/Median graph"
  },
  "d(a,c) = d(a,m(a,b,c)) + d(m(a,b,c),c)": {
    "before": "d(a,b) = d(a,m(a,b,c)) + d(m(a,b,c),b)",
    "after": "d(b,c) = d(b,m(a,b,c)) + d(m(a,b,c),c)",
    "url": "https://en.wikipedia.org/wiki/Median graph"
  },
  "d(b,c) = d(b,m(a,b,c)) + d(m(a,b,c),c)": {
    "before": "d(a,c) = d(a,m(a,b,c)) + d(m(a,b,c),c)",
    "after": "and m(a,b,c) is the only vertex for which this is true.",
    "url": "https://en.wikipedia.org/wiki/Median graph"
  },
  "Identity elements: m(0,a,1) = a for all a.": {
    "before": "for all a, b, c, d, and e.",
    "after": "The distributive law may be replaced by an associative law:",
    "url": "https://en.wikipedia.org/wiki/Median graph"
  },
  "Associativity: m(x,w,m(y,w,z)) = m(m(x,w,y),w,z)": {
    "before": "The distributive law may be replaced by an associative law:",
    "after": "The median operation may also be used to define a notion of intervals for distributive lattices:",
    "url": "https://en.wikipedia.org/wiki/Median graph"
  },
  "{\\displaystyle {\\begin{aligned}MR&={\\frac {\\Delta TR}{\\Delta Q}}\\\\[5pt]MP_{L}&={\\frac {\\Delta Q}{\\Delta L}}\\\\[5pt]MR\\times MP_{L}&={\\frac {\\Delta TR}{\\Delta Q}}\\times {\\frac {\\Delta Q}{\\Delta L}}={\\frac {\\Delta TR}{\\Delta L}}\\end{aligned}}}": {
    "before": "The marginal revenue product of labour {\\displaystyle MRP_{L}} is the increase in revenue per unit increase in the variable input = {\\displaystyle {\\frac {\\Delta TR}{\\Delta L}}}",
    "after": "Here: {\\displaystyle TR} is the Total Revenue (a money amount). {\\displaystyle MP} is the marginal product (units created with the marginal labor time and effort). {\\displaystyle Q} is the amount of goods (a measure of the quantity or volume sold). {\\displaystyle MR} is marginal revenue (the money revenue received from the marginal product produced). {\\displaystyle L} is Labour (amount of labor time or effort).",
    "url": "https://en.wikipedia.org/wiki/Marginal revenue product"
  },
  "{\\displaystyle {\\begin{aligned}MRP_{L}&=w\\\\[5pt]MR(MP_{L})&=w\\\\[5pt]MR&={\\frac {w}{MP_{L}}}\\\\[5pt]MR&=MC,{\\text{ which is the profit maximizing rule.}}\\end{aligned}}}": {
    "before": "The firm is modeled as choosing to add units of labor until the {\\displaystyle MRP} equals the wage rate {\\displaystyle w} — mathematically until",
    "after": "Marginal revenue product in a perfectly competitive market [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Marginal revenue product"
  },
  "{\\displaystyle {\\begin{aligned}MRP&=MPP\\times MR(D=AR=P){\\text{ as perfectly competitive labour market}}\\\\[5pt]MRP&=MPP\\times {\\text{Price}}\\end{aligned}}}": {
    "before": "Under perfect competition , marginal revenue product is equal to marginal physical product (extra unit of good produced as a result of a new employment) multiplied by price.",
    "after": "This is because the firm in perfect competition is a price taker . It does not have to lower the price in order to sell additional units of the good.",
    "url": "https://en.wikipedia.org/wiki/Marginal revenue product"
  },
  "VA d = domestic value added VA int = international value added": {
    "before": "This equals {\\displaystyle (VA} d / {\\displaystyle VA} int - {\\displaystyle 1} , where:",
    "after": "An alternative that yields an identical answer is that the effective rate of protection equals {\\displaystyle (T} f {\\displaystyle -T} i ) {\\displaystyle /VA} int , where:",
    "url": "https://en.wikipedia.org/wiki/Effective rate of protection"
  },
  "T f = the total tariff theoretically or actually paid on the final product T i = the total tariffs paid, theoretically or actually, on the importable inputs used to make that product.": {
    "before": "An alternative that yields an identical answer is that the effective rate of protection equals {\\displaystyle (T} f {\\displaystyle -T} i ) {\\displaystyle /VA} int , where:",
    "after": "The effective rate of protection is used to estimate the protection really afforded to domestic producers at each stage of production, i.e., how much extra they can charge and still be competitive with imported goods. If the total value of the tariffs on importable inputs exceeds that on the output, the effective rate of protection is negative, i.e., the industry is discriminated against in comparison with the imported product.",
    "url": "https://en.wikipedia.org/wiki/Effective rate of protection"
  },
  "{\\displaystyle ={\\frac {t}{i}}.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Marginal tax rate"
  },
  "{\\displaystyle e={\\frac {p\\times i}{p-(p\\times i)}}={\\frac {p\\times i}{p\\times (1-i)}}={\\frac {i}{1-i}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Marginal tax rate"
  },
  "15% inclusive = 18% exclusive": {
    "before": "Therefore, to convert any inclusive tax rate to an exclusive tax rate, divide the inclusive rate by 1 minus that rate.",
    "after": "20% inclusive = 25% exclusive",
    "url": "https://en.wikipedia.org/wiki/Marginal tax rate"
  },
  "20% inclusive = 25% exclusive": {
    "before": "15% inclusive = 18% exclusive",
    "after": "25% inclusive = 33% exclusive",
    "url": "https://en.wikipedia.org/wiki/Marginal tax rate"
  },
  "25% inclusive = 33% exclusive": {
    "before": "20% inclusive = 25% exclusive",
    "after": "33% inclusive = 50% exclusive",
    "url": "https://en.wikipedia.org/wiki/Marginal tax rate"
  },
  "33% inclusive = 50% exclusive": {
    "before": "25% inclusive = 33% exclusive",
    "after": "50% inclusive = 100% exclusive",
    "url": "https://en.wikipedia.org/wiki/Marginal tax rate"
  },
  "50% inclusive = 100% exclusive": {
    "before": "33% inclusive = 50% exclusive",
    "after": "See also[edit]",
    "url": "https://en.wikipedia.org/wiki/Marginal tax rate"
  },
  "E[ y it ∨ x i 1 ... x iT , c i ] = m ( x it , c i , b 0 ) = exp( c i + x it b 0 ) = a i exp( x it b 0 ) = μ ti (1)": {
    "before": "In statistics, fixed-effect Poisson models are used for static panel data when the outcome variable is count data . Hausman, Hall, and Griliches pioneered the method in the mid 1980s. Their outcome of interest was the number of patents filed by firms, where they wanted to develop methods to control for the firm fixed effects .  Linear panel data models use the linear additivity of the fixed effects to difference them out and circumvent the incidental parameter problem . Even though Poisson models are inherently nonlinear, the use of the linear index and the exponential link function lead to multiplicative separability , more specifically ",
    "after": "This formula looks very similar to the standard Poisson premultiplied by the term a i . As the conditioning set includes the observables over all periods, we are in the static panel data world and are imposing strict exogeneity .  Hausman, Hall, and Griliches then use Andersen's conditional Maximum Likelihood methodology to estimate b 0 . Using n i = Σ y it allows them to obtain the following nice distributional result of y i",
    "url": "https://en.wikipedia.org/wiki/Fixed-effect Poisson model"
  },
  "{\\displaystyle p_{t}(x_{i},b_{0})={\\frac {m(x_{it},b_{0})}{\\sum m(x_{it},b_{0})}}.\\quad } ": {
    "before": "y i ∨ n i , x i , c i ∼ Multinomial ( n i , p 1 ( x i , b 0 ), ..., p T ( x i , b 0 )) (2) where",
    "after": "At this point, the estimation of the fixed-effect Poisson model is transformed in a useful way and can be estimated by maximum-likelihood estimation techniques for multinomial log likelihoods. This is computationally not necessarily very restrictive, but the distributional assumptions up to this point are fairly stringent. Wooldridge provided evidence that these models have nice robustness properties as long as the conditional mean assumption (i.e. equation 1) holds.  Chamberlain also provided semi-parametric efficiency bounds for these estimators under slightly weaker exogeneity assumptions. However, these bounds are practically difficult to attain, as the proposed methodology needs high-dimensional nonparametric regressions for attaining these bounds.",
    "url": "https://en.wikipedia.org/wiki/Fixed-effect Poisson model"
  },
  "H = \"Hardware\"": {
    "before": "In a significant part numbering system, the part numbers are assigned intelligently, according to an encoding system, and thus they give an indication of salient characteristics of the component. For example, a screw may have the part number \"HSC0424PP\"; in this case, the letters indicate characteristics of the component:",
    "after": "S = \"Machine Screw\"",
    "url": "https://en.wikipedia.org/wiki/Part number"
  },
  "S = \"Machine Screw\"": {
    "before": "H = \"Hardware\"",
    "after": "C0424 = \"4-40, 3/4\" long\"",
    "url": "https://en.wikipedia.org/wiki/Part number"
  },
  "C0424 = \"4-40, 3/4\" long\"": {
    "before": "S = \"Machine Screw\"",
    "after": "PP = \"Panhead Phillips\"",
    "url": "https://en.wikipedia.org/wiki/Part number"
  },
  "PP = \"Panhead Phillips\"": {
    "before": "C0424 = \"4-40, 3/4\" long\"",
    "after": "In a non-significant part numbering system, part numbers are assigned in some other fashion, such as sequentially or arbitrarily. For example, a screw may have the part number \"1002\", which may not tell the user anything about its thread size, length of shank, or drive type.",
    "url": "https://en.wikipedia.org/wiki/Part number"
  },
  "UPC-A {\\displaystyle {\\begin{aligned}{\\text{(possible values per left digit)}}^{\\text{(left digits)}}&\\times {\\text{(possible values per right digit)}}^{\\text{(5 right digits)}}\\\\=10^{6}&\\times 10^{5}=100,000,000,000.\\end{aligned}}} UPC-E {\\displaystyle {\\begin{aligned}{\\text{(possible values per digit)}}^{\\text{(digits)}}&\\times {\\text{(possible parity patterns per UPC-E number)}}\\\\=10^{6}&\\times 2=2,000,000.\\end{aligned}}}": {
    "before": "The number of UPC-A and UPC-E barcodes are limited by the standards used to create them.",
    "after": "Number system digit [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Universal Product Code"
  },
  "{\\displaystyle 1a+3b=1a+3(a+d)=4a+3d} to the left hand side of the check digit equation. In the transposed order, they contribute {\\displaystyle 1b+3a=3a+1(a+d)=4a+d} . to the LHS. Subtracting the two contributions gives how much they change the LHS: {\\displaystyle (4a+3d)-(4a+d)=2d} An error will be detected as long as the modular change is nonzero; if 2d ≡ 0 modulo 10, then the change will not be detected. Consequently, only when the character difference d ≡ 5 will an error be undetected (when d ≡ 0 the degenerate \"transposition\" is not an error).": {
    "before": "is the difference between the two digits. If the digits were in their correct order, they would contribute",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Universal Product Code"
  },
  "{\\displaystyle 1a+3b=1a+3(a+d)=4a+3d}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Universal Product Code"
  },
  "{\\displaystyle 1b+3a=3a+1(a+d)=4a+d} .": {
    "before": "to the left hand side of the check digit equation. In the transposed order, they contribute",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Universal Product Code"
  },
  "{\\displaystyle (4a+3d)-(4a+d)=2d}": {
    "before": "to the LHS. Subtracting the two contributions gives how much they change the LHS:",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Universal Product Code"
  },
  "Row Sum contains the number of d -transpositions, therefore the proportion of non-detectable transposition errors is (ignoring the transpositions where d = 0 ): {\\displaystyle {\\frac {10}{18+16+14+12+10+8+6+4+2}}={\\frac {10}{90}}=11.111\\ldots \\%.} ▯": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Universal Product Code"
  },
  "{\\displaystyle {\\frac {10}{18+16+14+12+10+8+6+4+2}}={\\frac {10}{90}}=11.111\\ldots \\%.} ▯": {
    "before": "d = 0):",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Universal Product Code"
  },
  "Find the result modulo 10 (58 mod 10 = 8 = M).": {
    "before": "Add the even-numbered digits (42 + (3 + 0 + 0 + 9 + 4) = 58).",
    "after": "If M is not 0, subtract M from 10 (10 − M = 10 − 8 = 2).",
    "url": "https://en.wikipedia.org/wiki/Universal Product Code"
  },
  "{\\displaystyle e(v)={\\frac {\\int \\limits _{0}^{v}{}yf(y|v)dy}{F(v|v)}}} (2) .": {
    "before": "Equilibrium bidding in the sealed first- and second-price auctions : We consider here the simplest case in which there are two buyers and each buyer’s value {\\displaystyle {{v}_{i}}=\\phi ({{x}_{i}})} depends only on his own signal. Then the buyers’ values are private and affiliated. In the sealed second-price (or Vickrey auction ), it is a dominant strategy for each buyer to bid his value. If both buyers do so, then a buyer with value v has an expected payment of",
    "after": "In the sealed first-price auction, the increasing bid function B ( v ) is an equilibrium if bidding strategies are mutual best responses. That is, if buyer 1 has value v , their best response is to bid b = B ( v ) if they believes that their opponent is using this same bidding function. Suppose buyer 1 deviates and bids b = B ( z ) rather than B ( v ) . Let U(z) be their resulting payoff. For B ( v ) to be an equilibrium bid function, U ( z ) must take on its maximum at x = v . With a bid of b = B ( z ) buyer 1 wins if",
    "url": "https://en.wikipedia.org/wiki/Market design"
  },
  "{\\displaystyle U(z)=w(v-B(z))=F(z|v)(v-B(z))} .": {
    "before": "The win probability is then {\\displaystyle w=F(z|v)} so that buyer 1's expected payoff is",
    "after": "Taking logs and differentiating by z ,",
    "url": "https://en.wikipedia.org/wiki/Market design"
  },
  "{\\displaystyle {\\frac {{{U}^{\\prime }}(z)}{U(z)}}={\\frac {{w}'(z)}{w(z)}}-{\\frac {{B}'(z)}{v-B(z)}}={\\frac {f(z|v)}{F(z|v)}}-{\\frac {{B}'(z)}{v-B(z)}}} . (3)": {
    "before": "{\\displaystyle U(z)=w(v-B(z))=F(z|v)(v-B(z))} .Taking logs and differentiating by z ,",
    "after": "The first term on the right hand side is the proportional increase in the win probability as the buyer raises his bid from {\\displaystyle B(z)} to {\\displaystyle B(z+\\Delta z)} . The second term is the proportional drop in the payoff if the buyer wins. We have argued that, for equilibrium, U ( z ) must take on its maximum at z = v . Substituting for z in (3) and setting the derivative equal to zero yields the following necessary condition.",
    "url": "https://en.wikipedia.org/wiki/Market design"
  },
  "{\\displaystyle {B}'(v)={\\frac {f(v|v)}{F(v|v)}}(v-B(v))} . (4)": {
    "before": "The first term on the right hand side is the proportional increase in the win probability as the buyer raises his bid from {\\displaystyle B(z)} to {\\displaystyle B(z+\\Delta z)} . The second term is the proportional drop in the payoff if the buyer wins. We have argued that, for equilibrium, U ( z ) must take on its maximum at z = v . Substituting for z in (3) and setting the derivative equal to zero yields the following necessary condition.",
    "after": "Proof of the revenue ranking theorem",
    "url": "https://en.wikipedia.org/wiki/Market design"
  },
  "{\\displaystyle {\\frac {{{U}^{\\prime }}(z)}{U(z)}}={\\frac {f(z|x)}{F(z|x)}}-{\\frac {{B}'(z)}{v-B(z)}}} . (3’)": {
    "before": "Buyer 1 with value x has conditional p.d.f. {\\displaystyle f({{v}_{2}}|x)} . Suppose that he naively believes that all other buyers have the same beliefs. In the sealed high bid auction he computes the equilibrium bid function using these naive beliefs. Arguing as above, condition (3) becomes",
    "after": "Since x > v it follows by affiliation (see condition (1)) that the proportional gain to bidding higher is bigger under the naive beliefs that place higher mass on higher values. Arguing as before, a necessary condition for equilibrium is that (3’) must be zero at x = v . Therefore, the equilibrium bid function {\\displaystyle {{B}_{x}}(v)} satisfies the following differential equation.",
    "url": "https://en.wikipedia.org/wiki/Market design"
  },
  "{\\displaystyle {{B}_{x}}^{\\prime }(v)={\\frac {f(v|x)}{F(v|x)}}(v-{{B}_{x}}(v))} . (5)": {
    "before": "Since x > v it follows by affiliation (see condition (1)) that the proportional gain to bidding higher is bigger under the naive beliefs that place higher mass on higher values. Arguing as before, a necessary condition for equilibrium is that (3’) must be zero at x = v . Therefore, the equilibrium bid function {\\displaystyle {{B}_{x}}(v)} satisfies the following differential equation.",
    "after": "Appealing to the revenue equivalence theorem, if all buyers have values that are independent draws from the same distribution then the expected payment of the winner is the same in the two auctions. Therefore, {\\displaystyle {{B}_{x}}(x)=e(x)} . Thus, to complete the proof we need to establish that {\\displaystyle B(x)\\leq {{B}_{x}}(x)} . Appealing to (1), it follows from (4) and (5) that for all v < x .",
    "url": "https://en.wikipedia.org/wiki/Market design"
  },
  "{\\displaystyle {{(i)}_{}}B(y)-{{B}_{x}}(y)={{0}_{}}} and {\\displaystyle {{(ii)}_{}}B(v)-{{B}_{x}}(v)>0{{,}_{}}\\forall v\\in [y,x]} .": {
    "before": "Suppose that {\\displaystyle B(x)>{{B}_{x}}(x)} . Since the equilibrium bid of a buyer with value 0 is zero, there must be some y < x such that",
    "after": "But this is impossible since we have just shown that over such an interval, {\\displaystyle B(v)-{{B}_{x}}(v)} is decreasing. Since {\\displaystyle {{B}_{x}}(x)=e(x)} it follows that the winner bidder's expected payment is lower in the sealed high-bid auction.",
    "url": "https://en.wikipedia.org/wiki/Market design"
  },
  "MRSAXY = MRSBXY": {
    "before": "At optimality,",
    "after": "As stated above, the slope of the Utility Possibility Frontier maps the effect of a marginal change in utility.",
    "url": "https://en.wikipedia.org/wiki/Utility–possibility frontier"
  },
  "UA' = UAX (-dX) + UBY dY": {
    "before": "As stated above, the slope of the Utility Possibility Frontier maps the effect of a marginal change in utility.",
    "after": "UB' = UBX dX + UBY dY",
    "url": "https://en.wikipedia.org/wiki/Utility–possibility frontier"
  },
  "UB' = UBX dX + UBY dY": {
    "before": "UA' = UAX (-dX) + UBY dY",
    "after": "Since, MRSNXY = UNX / UNY",
    "url": "https://en.wikipedia.org/wiki/Utility–possibility frontier"
  },
  "Since, MRSNXY = UNX / UNY": {
    "before": "UB' = UBX dX + UBY dY",
    "after": "MRSAXY = UAX / UAY",
    "url": "https://en.wikipedia.org/wiki/Utility–possibility frontier"
  },
  "MRSAXY = UAX / UAY": {
    "before": "Since, MRSNXY = UNX / UNY",
    "after": "= (UA' / UAY - dY) / (-dX)",
    "url": "https://en.wikipedia.org/wiki/Utility–possibility frontier"
  },
  "MRSAXY = UAX / UAY= (UA' / UAY - dY) / (-dX)": {
    "before": "Since, MRSNXY = UNX / UNY",
    "after": "MRSBXY = UBX / UBY",
    "url": "https://en.wikipedia.org/wiki/Utility–possibility frontier"
  },
  "MRSBXY = UBX / UBY": {
    "before": "= (UA' / UAY - dY) / (-dX)",
    "after": "= (UB' / UBY - dY) / dX",
    "url": "https://en.wikipedia.org/wiki/Utility–possibility frontier"
  },
  "MRSBXY = UBX / UBY= (UB' / UBY - dY) / dX": {
    "before": "= (UA' / UAY - dY) / (-dX)",
    "after": "Since, the MRSA = MRSB along the UPF At Optimality, along the UPF Thus, as the MRSs must be equal along the UPF, which implies, after some rearrangement, that:",
    "url": "https://en.wikipedia.org/wiki/Utility–possibility frontier"
  },
  "Since, the MRSA = MRSB along the UPF At Optimality, along the UPF Thus, as the MRSs must be equal along the UPF, which implies, after some rearrangement, that:": {
    "before": "= (UB' / UBY - dY) / dX",
    "after": "UB' / UA' = - UBY/UAY",
    "url": "https://en.wikipedia.org/wiki/Utility–possibility frontier"
  },
  "UB' / UA' = - UBY/UAY": {
    "before": "Since, the MRSA = MRSB along the UPF At Optimality, along the UPF Thus, as the MRSs must be equal along the UPF, which implies, after some rearrangement, that:",
    "after": "The slope, as seen above, is equivalent to the absolute value of the marginal utilities of y.",
    "url": "https://en.wikipedia.org/wiki/Utility–possibility frontier"
  },
  "{\\displaystyle {\\begin{aligned}s_{0}&=x_{0}\\\\s_{t}&=\\alpha x_{t}+(1-\\alpha )s_{t-1},\\quad t>0\\end{aligned}}}": {
    "before": "The raw data sequence is often represented by {\\displaystyle \\{x_{t}\\}} beginning at time {\\displaystyle t=0} , and the output of the exponential smoothing algorithm is commonly written as {\\displaystyle \\{s_{t}\\}} , which may be regarded as a best estimate of what the next value of {\\displaystyle x} will be. When the sequence of observations begins at time {\\displaystyle t=0} , the simplest form of exponential smoothing is given by the formulas: ",
    "after": "where {\\displaystyle \\alpha } is the smoothing factor , and {\\displaystyle 0<\\alpha <1} .",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle s_{t}=\\alpha x_{t}+(1-\\alpha )s_{t-1}=s_{t-1}+\\alpha (x_{t}-s_{t-1}).}": {
    "before": "The simplest form of exponential smoothing is given by the formula:",
    "after": "where {\\displaystyle \\alpha } is the smoothing factor , and {\\displaystyle 0\\leq \\alpha \\leq 1} . In other words, the smoothed statistic {\\displaystyle s_{t}} is a simple weighted average of the current observation {\\displaystyle x_{t}} and the previous smoothed statistic {\\displaystyle s_{t-1}} . Simple exponential smoothing is easily applied, and it produces a smoothed statistic as soon as two observations are available. The term smoothing factor applied to {\\displaystyle \\alpha } here is something of a misnomer, as larger values of {\\displaystyle \\alpha } actually reduce the level of smoothing, and in the limiting case with {\\displaystyle \\alpha } = 1 the output series is just the current observation. Values of {\\displaystyle \\alpha } close to one have less of a smoothing effect and give greater weight to recent changes in the data, while values of {\\displaystyle \\alpha } closer to zero have a greater smoothing effect and are less responsive to recent changes.",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle \\alpha =1-e^{-\\Delta T/\\tau }} , thus {\\displaystyle \\tau =-{\\frac {\\Delta T}{\\ln(1-\\alpha )}}}": {
    "before": "The time constant of an exponential moving average is the amount of time for the smoothed response of a unit step function to reach {\\displaystyle 1-1/e\\approx 63.2\\,\\%} of the original signal. The relationship between this time constant, {\\displaystyle \\tau } , and the smoothing factor, {\\displaystyle \\alpha } , is given by the formula:",
    "after": "where {\\displaystyle \\Delta T} is the sampling time interval of the discrete time implementation. If the sampling time is fast compared to the time constant ( {\\displaystyle \\Delta T\\ll \\tau } ) then",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle {\\text{SSE}}=\\sum _{t=1}^{T}(y_{t}-{\\hat {y}}_{t\\mid t-1})^{2}=\\sum _{t=1}^{T}e_{t}^{2}} ": {
    "before": "The unknown parameters and the initial values for any exponential smoothing method can be estimated by minimizing the sum of squared errors (SSE). The errors are specified as {\\displaystyle e_{t}=y_{t}-{\\hat {y}}_{t\\mid t-1}} for {\\displaystyle t=1,\\ldots ,T} (the one-step-ahead within-sample forecast errors). Hence we find the values of the unknown parameters and the initial values that minimize",
    "after": "Unlike the regression case (where we have formulae to directly compute the regression coefficients which minimize the SSE) this involves a non-linear minimization problem and we need to use an optimization tool to perform this.",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle {\\begin{aligned}s_{t}&=\\alpha x_{t}+(1-\\alpha )s_{t-1}\\\\[3pt]&=\\alpha x_{t}+\\alpha (1-\\alpha )x_{t-1}+(1-\\alpha )^{2}s_{t-2}\\\\[3pt]&=\\alpha \\left[x_{t}+(1-\\alpha )x_{t-1}+(1-\\alpha )^{2}x_{t-2}+(1-\\alpha )^{3}x_{t-3}+\\cdots +(1-\\alpha )^{t-1}x_{1}\\right]+(1-\\alpha )^{t}x_{0}.\\end{aligned}}}": {
    "before": "By direct substitution of the defining equation for simple exponential smoothing back into itself we find that",
    "after": "In other words, as time passes the smoothed statistic {\\displaystyle s_{t}} becomes the weighted average of a greater and greater number of the past observations {\\displaystyle s_{t-1},\\ldots ,s_{t-}} , and the weights assigned to previous observations are proportional to the terms of the geometric progression",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle {\\begin{aligned}s_{0}&=x_{0}\\\\b_{0}&=x_{1}-x_{0}\\\\\\end{aligned}}}": {
    "before": "Again, the raw data sequence of observations is represented by {\\displaystyle x_{t}} , beginning at time {\\displaystyle t=0} . We use {\\displaystyle s_{t}} to represent the smoothed value for time {\\displaystyle t} , and {\\displaystyle b_{t}} is our best estimate of the trend at time {\\displaystyle t} . The output of the algorithm is now written as {\\displaystyle F_{t+m}} , an estimate of the value of {\\displaystyle x_{t+m}} at time {\\displaystyle m>0} based on the raw data up to time {\\displaystyle t} . Double exponential smoothing is given by the formulas",
    "after": "And for {\\displaystyle t>0} by",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle {\\begin{aligned}s_{t}&=\\alpha x_{t}+(1-\\alpha )(s_{t-1}+b_{t-1})\\\\b_{t}&=\\beta (s_{t}-s_{t-1})+(1-\\beta )b_{t-1}\\\\\\end{aligned}}}": {
    "before": "{\\displaystyle {\\begin{aligned}s_{0}&=x_{0}\\\\b_{0}&=x_{1}-x_{0}\\\\\\end{aligned}}} And for {\\displaystyle t>0} by",
    "after": "where {\\displaystyle \\alpha } ( {\\displaystyle 0\\leq \\alpha \\leq 1} ) is the data smoothing factor , and {\\displaystyle \\beta } ( {\\displaystyle 0\\leq \\beta \\leq 1} ) is the trend smoothing factor .",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle F_{t+m}=s_{t}+m\\cdot b_{t}}": {
    "before": "To forecast beyond {\\displaystyle x_{t}} is given by the approximation:",
    "after": "Setting the initial value {\\displaystyle b} is a matter of preference. An option other than the one listed above is {\\textstyle {\\frac {x_{n}-x_{0}}{n}}} for some {\\displaystyle n} .",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle {\\begin{aligned}s'_{0}&=x_{0}\\\\s''_{0}&=x_{0}\\\\s'_{t}&=\\alpha x_{t}+(1-\\alpha )s'_{t-1}\\\\s''_{t}&=\\alpha s'_{t}+(1-\\alpha )s''_{t-1}\\\\F_{t+m}&=a_{t}+mb_{t},\\end{aligned}}}": {
    "before": "A second method, referred to as either Brown's linear exponential smoothing (LES) or Brown's double exponential smoothing works as follows. ",
    "after": "where a t , the estimated level at time t and b t , the estimated trend at time t are:",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle {\\begin{aligned}a_{t}&=2s'_{t}-s''_{t}\\\\[5pt]b_{t}&={\\frac {\\alpha }{1-\\alpha }}(s'_{t}-s''_{t}).\\end{aligned}}}": {
    "before": "where a t , the estimated level at time t and b t , the estimated trend at time t are:",
    "after": "Triple exponential smoothing (Holt Winters) [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle {\\begin{aligned}s_{0}&=x_{0}\\\\[5pt]s_{t}&=\\alpha {\\frac {x_{t}}{c_{t-L}}}+(1-\\alpha )(s_{t-1}+b_{t-1})\\\\[5pt]b_{t}&=\\beta (s_{t}-s_{t-1})+(1-\\beta )b_{t-1}\\\\[5pt]c_{t}&=\\gamma {\\frac {x_{t}}{s_{t}}}+(1-\\gamma )c_{t-L}\\\\[5pt]F_{t+m}&=(s_{t}+mb_{t})c_{t-L+1+(m-1){\\bmod {L}}},\\end{aligned}}}": {
    "before": "The output of the algorithm is again written as {\\displaystyle F_{t+m}} , an estimate of the value of {\\displaystyle x_{t+m}} at time {\\displaystyle t+m>0} based on the raw data up to time {\\displaystyle t} . Triple exponential smoothing with multiplicative seasonality is given by the formulas ",
    "after": "where {\\displaystyle \\alpha } ( {\\displaystyle 0\\leq \\alpha \\leq 1} ) is the data smoothing factor , {\\displaystyle \\beta } ( {\\displaystyle 0\\leq \\beta \\leq 1} ) is the trend smoothing factor , and {\\displaystyle \\gamma } ( {\\displaystyle 0\\leq \\gamma \\leq 1} ) is the seasonal change smoothing factor .",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle {\\begin{aligned}b_{0}&={\\frac {1}{L}}\\left({\\frac {x_{L+1}-x_{1}}{L}}+{\\frac {x_{L+2}-x_{2}}{L}}+\\cdots +{\\frac {x_{L+L}-x_{L}}{L}}\\right)\\end{aligned}}}": {
    "before": "The general formula for the initial trend estimate {\\displaystyle b} is:",
    "after": "Setting the initial estimates for the seasonal indices {\\displaystyle c_{i}} for {\\displaystyle i=1,2,\\ldots ,L} is a bit more involved. If {\\displaystyle N} is the number of complete cycles present in your data, then:",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle c_{i}={\\frac {1}{N}}\\sum _{j=1}^{N}{\\frac {x_{L(j-1)+i}}{A_{j}}}\\quad {\\text{for }}i=1,2,\\ldots ,L}": {
    "before": "Setting the initial estimates for the seasonal indices {\\displaystyle c_{i}} for {\\displaystyle i=1,2,\\ldots ,L} is a bit more involved. If {\\displaystyle N} is the number of complete cycles present in your data, then:",
    "after": "where {\\displaystyle A_{j}={\\frac {\\sum _{i=1}^{L}x_{L(j-1)+i}}{L}}\\quad {\\text{for }}j=1,2,\\ldots ,N}",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle A_{j}={\\frac {\\sum _{i=1}^{L}x_{L(j-1)+i}}{L}}\\quad {\\text{for }}j=1,2,\\ldots ,N}": {
    "before": "{\\displaystyle c_{i}={\\frac {1}{N}}\\sum _{j=1}^{N}{\\frac {x_{L(j-1)+i}}{A_{j}}}\\quad {\\text{for }}i=1,2,\\ldots ,L} where",
    "after": "Note that {\\displaystyle A_{j}} is the average value of {\\displaystyle x} in the {\\displaystyle j^{\\text{th}}} cycle of your data.",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle {\\begin{aligned}s_{0}&=x_{0}\\\\s_{t}&=\\alpha (x_{t}-c_{t-L})+(1-\\alpha )(s_{t-1}+b_{t-1})\\\\b_{t}&=\\beta (s_{t}-s_{t-1})+(1-\\beta )b_{t-1}\\\\c_{t}&=\\gamma (x_{t}-s_{t-1}-b_{t-1})+(1-\\gamma )c_{t-L}\\\\F_{t+m}&=s_{t}+mb_{t}+c_{t-L+1+(m-1){\\bmod {L}}},\\end{aligned}}}": {
    "before": "Triple exponential smoothing with additive seasonality is given by:",
    "after": "Implementations in statistics packages [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Exponential smoothing"
  },
  "{\\displaystyle x=({\\textbf {A}}^{\\mathrm {T} }{\\textbf {A}})^{-1}{\\textbf {A}}^{\\mathrm {T} }\\phi .}": {
    "before": "where the weights vector x is chosen to minimize the sum of squared errors in approximating Φ . The solution for x is closed-form, using standard linear regression : ",
    "after": "Here the matrix A can be based on any set of functions mutually independent (not necessarily orthogonal) when evaluated at the sample times; functions used for spectral analysis are typically sines and cosines evenly distributed over the frequency range of interest. If we choose too many frequencies in a too-narrow frequency range, the functions will be insufficiently independent, the matrix ill-conditioned, and the resulting spectrum meaningless. ",
    "url": "https://en.wikipedia.org/wiki/Least-squares spectral analysis"
  },
  "{\\displaystyle x={\\textbf {A}}^{\\mathrm {T} }\\phi } — DFT case for N equally spaced samples and frequencies, within a scalar factor.": {
    "before": "When the basis functions in A are orthogonal (that is, not correlated, meaning the columns have zero pair-wise dot products ), the matrix A T A is diagonal; when the columns all have the same power (sum of squares of elements), then that matrix is an identity matrix times a constant, so the inversion is trivial. The latter is the case when the sample times are equally spaced and sinusoids chosen as sines and cosines equally spaced in pairs on the frequency interval 0 to a half cycle per sample (spaced by 1/N cycles per sample, omitting the sine phases at 0 and maximum frequency where they are identically zero). This case is known as the discrete Fourier transform , slightly rewritten in terms of measurements and coefficients. ",
    "after": "The Lomb method [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Least-squares spectral analysis"
  },
  "{\\displaystyle \\tan {2\\omega \\tau }={\\frac {\\sum _{j}\\sin 2\\omega t_{j}}{\\sum _{j}\\cos 2\\omega t_{j}}}.}": {
    "before": "Rather than just taking dot products of the data with sine and cosine waveforms directly, Scargle modified the standard periodogram formula so to find a time delay {\\displaystyle \\tau } first, such that this pair of sinusoids would be mutually orthogonal at sample times {\\displaystyle t_{j}} and also adjusted for the potentially unequal powers of these two basis functions, to obtain a better estimate of the power at a frequency.   This procedure made his modified periodogram method exactly equivalent to Lomb's method. Time delay {\\displaystyle \\tau } by definition equals to",
    "after": "Then the periodogram at frequency {\\displaystyle \\omega } is estimated as:",
    "url": "https://en.wikipedia.org/wiki/Least-squares spectral analysis"
  },
  "{\\displaystyle P_{x}(\\omega )={\\frac {1}{2}}\\left({\\frac {\\left[\\sum _{j}X_{j}\\cos \\omega (t_{j}-\\tau )\\right]^{2}}{\\sum _{j}\\cos ^{2}\\omega (t_{j}-\\tau )}}+{\\frac {\\left[\\sum _{j}X_{j}\\sin \\omega (t_{j}-\\tau )\\right]^{2}}{\\sum _{j}\\sin ^{2}\\omega (t_{j}-\\tau )}}\\right)} ,": {
    "before": "Then the periodogram at frequency {\\displaystyle \\omega } is estimated as:",
    "after": "which, as Scargle reports, has the same statistical distribution as the periodogram in the evenly sampled case. ",
    "url": "https://en.wikipedia.org/wiki/Least-squares spectral analysis"
  },
  "{\\displaystyle \\phi (t)=A\\sin \\omega t+B\\cos \\omega t.} ": {
    "before": "At any individual frequency {\\displaystyle \\omega } , this method gives the same power as does a least-squares fit to sinusoids of that frequency and of the form:",
    "after": "In practice, it is always difficult to judge if a given Lomb peak is significant or not, especially when the nature of the noise is unknown, so for example a false-alarm spectral peak in the Lomb periodogram analysis of noisy periodic signal may result from noise in turbulence data.  Fourier methods can also report false spectral peaks when analyzing patched-up or data edited otherwise. ",
    "url": "https://en.wikipedia.org/wiki/Least-squares spectral analysis"
  },
  "{\\displaystyle \\phi (t)=A\\sin \\omega t+B\\cos \\omega t+C.} ": {
    "before": "The standard Lomb–Scargle periodogram is only valid for a model with a zero mean. Commonly, this is approximated — by subtracting the mean of the data before calculating the periodogram. However, this is an inaccurate assumption when the mean of the model (the fitted sinusoids) is non-zero. The generalized Lomb–Scargle periodogram removes this assumption and explicitly solves for the mean. In this case, the function fitted is",
    "after": "The generalized Lomb–Scargle periodogram has also been referred to in the literature as a floating mean periodogram . ",
    "url": "https://en.wikipedia.org/wiki/Least-squares spectral analysis"
  },
  "{\\displaystyle v=b^{*}+{\\frac {\\Pr(b^{*}\\ {\\textrm {wins}})}{\\partial \\Pr(b^{*}\\ {\\textrm {wins}})/\\partial b}}}": {
    "before": "which can be re-arranged to yield the following equation for {\\displaystyle v}",
    "after": "Notice that the probability that a bid wins an auction can be estimated from a data set of completed auctions, where all bids are observed. This can be done using simple nonparametric estimators , such as kernel regression . If all bids are observed, it is then possible to use the above relation and the estimated probability function and its derivative to point wise estimate the underlying valuation. This will then allow the investigator to estimate the valuation distribution.",
    "url": "https://en.wikipedia.org/wiki/Methodology of econometrics"
  },
  "{\\displaystyle r=i-\\pi ^{e}}": {
    "before": "The relation between nominal and real interest rates, and inflation, is approximately given by the Fisher equation :",
    "after": "The equation states that the real interest rate ( {\\displaystyle r} ), is equal to the nominal interest rate ( {\\displaystyle i} ) minus the expected inflation rate ( {\\displaystyle \\pi ^{e}} ).",
    "url": "https://en.wikipedia.org/wiki/Fisher effect"
  },
  "{\\displaystyle 1+i=(1+r)\\times (1+\\pi ^{e})}": {
    "before": "The equation is an approximation, however, the difference with the correct value is small as long as the interest rate and the inflation rate is low. The discrepancy becomes large if either the nominal interest rate or the inflation rate is high. The accurate equation can be expressed using periodic compounding as:",
    "after": "If the real rate {\\displaystyle r} is assumed to be constant, the nominal rate {\\displaystyle i} must change point-for-point when {\\displaystyle \\pi ^{e}} rises or falls. Thus, the Fisher effect states that there will be a one-for-one adjustment of the nominal interest rate to the expected inflation rate.",
    "url": "https://en.wikipedia.org/wiki/Fisher effect"
  },
  "Voters, a finite set with at least two members, indexed as i = 1, 2, ... n.": {
    "before": "The book defines a few terms and logical symbols used thereafter and their applied empirical interpretation (pp. 11–19, 23). Key among these is the \"vote\" ('set of orderings') of the society (more generally \"collectivity\") composed of individuals (“voters” here) in the following form:",
    "after": "Commodities, the objects of choice (things that voters might want, goods and services), both private and public (municipal services, statecraft, etc.).",
    "url": "https://en.wikipedia.org/wiki/Social Choice and Individual Values"
  },
  "{\\displaystyle c+L=W} ,": {
    "before": "",
    "after": "{\\displaystyle c} is the constant capital of materials used in a period plus the depreciated portion of tools and plant used in the process. (A period is typically a day, week, year, or a single turnover: meaning the time required to complete one batch of coffee, for example.) {\\displaystyle L} is the quantity of labor time (average skill and productivity) performed in producing the finished commodities during the period {\\displaystyle W} is the value (or think \"worth\") of the product of the period ( {\\displaystyle w} comes from the German word for value: wert )",
    "url": "https://en.wikipedia.org/wiki/Labor theory of value"
  },
  "{\\displaystyle c+v+s=W}": {
    "before": "The LTV further divides the value added during the period of production, {\\displaystyle L} , into two parts. The first part is the portion of the process when the workers add value equivalent to the wages they are paid. For example, if the period in question is one week and these workers collectively are paid $1,000, then the time necessary to add $1,000 to—while preserving the value of—constant capital is considered the necessary labor portion of the period (or week): denoted {\\displaystyle NL} . The remaining period is considered the surplus labor portion of the week: or {\\displaystyle SL} . The value used to purchase labor-power, for example, the $1,000 paid in wages to these workers for the week, is called variable capital ( {\\displaystyle v} ). This is because in contrast to the constant capital expended on means of production, variable capital can add value in the labor process. The amount it adds depends on the duration, intensity, productivity and skill of the labor-power purchased: in this sense, the buyer of labor-power has purchased a commodity of variable use. Finally, the value added during the portion of the period when surplus labor is performed is called surplus value ( {\\displaystyle s} ). From the variables defined above, we find two other common expressions for the value produced during a given period:",
    "after": "and {\\displaystyle c+NL+SL=W}",
    "url": "https://en.wikipedia.org/wiki/Labor theory of value"
  },
  "{\\displaystyle c+NL+SL=W}": {
    "before": "and",
    "after": "The first form of the equation expresses the value resulting from production, focusing on the costs {\\displaystyle c+v} and the surplus value appropriated in the process of production, {\\displaystyle s} . The second form of the equation focuses on the value of production in terms of the values added by the labor performed during the process {\\displaystyle NL+SL} .",
    "url": "https://en.wikipedia.org/wiki/Labor theory of value"
  },
  "α*P(public)/P(else) = MRS(person1)": {
    "before": "We assume that there are two goods in an economy:the first one is a \"public good\", and the second is \"everything else\". The price of the public good can be assumed to be Ppublic and the price of everything else can be Pelse.",
    "after": "This is just the usual price ratio/marginal rate of substitution deal; the only change is that we multiply Ppublic by α to allow for the price adjustment to the public good. Similarly, Person 2 will choose his bundle such that:",
    "url": "https://en.wikipedia.org/wiki/Lindahl tax"
  },
  "(1-ɑ)*P(public)/P(else)= MRS(person2)": {
    "before": "This is just the usual price ratio/marginal rate of substitution deal; the only change is that we multiply Ppublic by α to allow for the price adjustment to the public good. Similarly, Person 2 will choose his bundle such that:",
    "after": "Now we have both individuals' utility maximizing. We know that in a competitive equilibrium, the marginal cost ratio or price ratio should be equal to the marginal rate of transformation, or",
    "url": "https://en.wikipedia.org/wiki/Lindahl tax"
  },
  "MC(public)/MC(else)=[P(public)/P(else)]=MRT": {
    "before": "Now we have both individuals' utility maximizing. We know that in a competitive equilibrium, the marginal cost ratio or price ratio should be equal to the marginal rate of transformation, or",
    "after": "Example[edit]",
    "url": "https://en.wikipedia.org/wiki/Lindahl tax"
  },
  "{\\displaystyle X=\\{X_{1},X_{2},\\dots \\}}": {
    "before": "In time series analysis, the lag operator (L) or back shift operator (B) operates on an element of a time series to produce the previous element. For example, given some time series",
    "after": "then {\\displaystyle LX_{t}=X_{t-1}} for all {\\displaystyle t>1}",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle LX_{t}=X_{t-1}} for all {\\displaystyle t>1}": {
    "before": "{\\displaystyle X=\\{X_{1},X_{2},\\dots \\}} then",
    "after": "or similarly in terms of the backshift operator B : {\\displaystyle BX_{t}=X_{t-1}} for all {\\displaystyle t>1} . Equivalently, this definition can be represented as",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle X_{t}=LX_{t+1}} for all {\\displaystyle t\\geq 1}": {
    "before": "or similarly in terms of the backshift operator B : {\\displaystyle BX_{t}=X_{t-1}} for all {\\displaystyle t>1} . Equivalently, this definition can be represented as",
    "after": "The lag operator (as well as backshift operator) can be raised to arbitrary integer powers so that",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle L^{-1}X_{t}=X_{t+1}}": {
    "before": "The lag operator (as well as backshift operator) can be raised to arbitrary integer powers so that",
    "after": "and {\\displaystyle L^{k}X_{t}=X_{t-k}.}",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle L^{k}X_{t}=X_{t-k}.}": {
    "before": "{\\displaystyle L^{-1}X_{t}=X_{t+1}} and",
    "after": "Lag polynomials [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle \\varepsilon _{t}=X_{t}-\\sum _{i=1}^{p}\\varphi _{i}X_{t-i}=\\left(1-\\sum _{i=1}^{p}\\varphi _{i}L^{i}\\right)X_{t}}": {
    "before": "Polynomials of the lag operator can be used, and this is a common notation for ARMA (autoregressive moving average) models. For example,",
    "after": "specifies an AR( p ) model.",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle \\varphi (L)X_{t}=\\theta (L)\\varepsilon _{t}}": {
    "before": "A polynomial of lag operators is called a lag polynomial so that, for example, the ARMA model can be concisely specified as",
    "after": "where {\\displaystyle \\varphi (L)} and {\\displaystyle \\theta (L)} respectively represent the lag polynomials",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle \\varphi (L)=1-\\sum _{i=1}^{p}\\varphi _{i}L^{i}}": {
    "before": "where {\\displaystyle \\varphi (L)} and {\\displaystyle \\theta (L)} respectively represent the lag polynomials",
    "after": "and {\\displaystyle \\theta (L)=1+\\sum _{i=1}^{q}\\theta _{i}L^{i}.\\,}",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle \\theta (L)=1+\\sum _{i=1}^{q}\\theta _{i}L^{i}.\\,}": {
    "before": "where {\\displaystyle \\theta } represents the polynomial",
    "after": "Finally, the combined ARMA( p , q ) model is given by",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle X_{t}={\\frac {\\theta (L)}{\\varphi (L)}}\\varepsilon _{t},}": {
    "before": "Polynomials of lag operators follow similar rules of multiplication and division as do numbers and polynomials of variables. For example,",
    "after": "means the same thing as",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle \\varphi (L)X_{t}=\\theta (L)\\varepsilon _{t}.}": {
    "before": "{\\displaystyle X_{t}={\\frac {\\theta (L)}{\\varphi (L)}}\\varepsilon _{t},} means the same thing as",
    "after": "As with polynomials of variables, a polynomial in the lag operator can be divided by another one using polynomial long division . In general dividing one such polynomial by another, when each has a finite order (highest exponent), results in an infinite-order polynomial.",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle \\varphi \\left(1\\right)=1-\\sum _{i=1}^{p}\\varphi _{i}}": {
    "before": "Note that {\\displaystyle \\varphi \\left(1\\right)} denotes the sum of coefficients:",
    "after": "Difference operator [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle {\\begin{aligned}\\Delta X_{t}&=X_{t}-X_{t-1}\\\\\\Delta X_{t}&=(1-L)X_{t}~.\\end{aligned}}}": {
    "before": "In time series analysis, the first difference operator : {\\displaystyle \\Delta }",
    "after": "Similarly, the second difference operator works as follows:",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle {\\begin{aligned}\\Delta (\\Delta X_{t})&=\\Delta X_{t}-\\Delta X_{t-1}\\\\\\Delta ^{2}X_{t}&=(1-L)\\Delta X_{t}\\\\\\Delta ^{2}X_{t}&=(1-L)(1-L)X_{t}\\\\\\Delta ^{2}X_{t}&=(1-L)^{2}X_{t}~.\\end{aligned}}}": {
    "before": "Similarly, the second difference operator works as follows:",
    "after": "The above approach generalises to the i -th difference operator {\\displaystyle \\Delta ^{i}X_{t}=(1-L)^{i}X_{t}\\ .}",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle E[X_{t+j}|\\Omega _{t}]=E_{t}[X_{t+j}].}": {
    "before": "It is common in stochastic processes to care about the expected value of a variable given a previous information set. Let {\\displaystyle \\Omega _{t}} be all information that is common knowledge at time t (this is often subscripted below the expectation operator); then the expected value of the realisation of X , j time-steps in the future, can be written equivalently as:",
    "after": "With these time-dependent conditional expectations, there is the need to distinguish between the backshift operator ( B ) that only adjusts the date of the forecasted variable and the Lag operator ( L ) that adjusts equally the date of the forecasted variable and the information set:",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle L^{n}E_{t}[X_{t+j}]=E_{t-n}[X_{t+j-n}],} {\\displaystyle B^{n}E_{t}[X_{t+j}]=E_{t}[X_{t+j-n}].}": {
    "before": "With these time-dependent conditional expectations, there is the need to distinguish between the backshift operator ( B ) that only adjusts the date of the forecasted variable and the Lag operator ( L ) that adjusts equally the date of the forecasted variable and the information set:",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Lag operator"
  },
  "{\\displaystyle A(L)\\,\\Delta y_{t}=\\gamma +B(L)\\,\\Delta x_{t}+\\alpha (y_{t-1}-\\beta _{0}-\\beta _{1}x_{t-1})+\\nu _{t}.}": {
    "before": "If they are both integrated to the same order (commonly I(1)), we can estimate an ECM model of the form",
    "after": "If both variables are integrated and this ECM exists, they are cointegrated by the Engle–Granger representation theorem.",
    "url": "https://en.wikipedia.org/wiki/Error correction model"
  },
  "{\\displaystyle A(L)\\,\\Delta y_{t}=\\gamma +B(L)\\,\\Delta x_{t}+\\alpha {\\hat {\\varepsilon }}_{t-1}+\\nu _{t}.}": {
    "before": "The second step is then to estimate the model using ordinary least squares : {\\displaystyle y_{t}=\\beta _{0}+\\beta _{1}x_{t}+\\varepsilon _{t}} If the regression is not spurious as determined by test criteria described above, Ordinary least squares will not only be valid, but in fact super consistent (Stock, 1987). Then the predicted residuals {\\displaystyle {\\hat {\\varepsilon _{t}}}=y_{t}-\\beta _{0}-\\beta _{1}x_{t}} from this regression are saved and used in a regression of differenced variables plus a lagged error term",
    "after": "One can then test for cointegration using a standard t-statistic on {\\displaystyle \\alpha } . While this approach is easy to apply, there are, however numerous problems:",
    "url": "https://en.wikipedia.org/wiki/Error correction model"
  },
  "X quantity of product = Y quantity of average labour hours = Z quantity of gold-money": {
    "before": "In Das Kapital Marx normally thinks of the quantity of labour that determines product-value as the ratio between the average total amount of labour-time required to produce a reproducible good, and the corresponding average amount of labour required to produce a unit of gold (see also gold standard).[note 3] Already in 1844, long before he wrote Das Kapital, Marx was very aware of credit money.[note 4][note 5] Whereas \"commodity money\" (coinage or bullion) played an important role in the earlier stages of capitalist development, the growth of integrated capital markets meant increased use of credit money. Marx felt that the initial assumption of gold-money as a standard of value was justified, in analysing the capitalist relations of production and distribution. Thus, as follows:",
    "after": "For Marx, the value of a commodity is determined by socially necessary labor time, or the amount of time \"required to produce an article under the normal conditions of production, and with the average degree of skill",
    "url": "https://en.wikipedia.org/wiki/Law of value"
  },
  "{\\displaystyle X_{t}=\\Lambda _{t}F_{t}+e_{t},}": {
    "before": "the changes of the fraction of economic data time series which increase or decrease over the selected time interval, an increase or decrease in future economic activity, provide some correlation to the business sentiment of companies. Formally",
    "after": "where {\\displaystyle F_{t}=(f_{t}^{\\top },\\dots ,f_{t-q}^{\\top })} is the vector of lagged factors of the variables in the {\\displaystyle T\\times N} matrix {\\displaystyle X_{t}} (T is the number of observations and N is the number of variables), {\\displaystyle \\Lambda _{t}} are the factor loadings, and {\\displaystyle e_{t}} is the factor error .",
    "url": "https://en.wikipedia.org/wiki/Dynamic factor"
  },
  "{\\displaystyle B_{t}=\\sum _{i=1}^{\\infty }(1+r)^{-i}PB_{t+i}} ,": {
    "before": "There is no consensus among economists about the correct criterion/definition to be used for fiscal sustainability. The most commonly used criterion is the government's inter-temporal budget constraint or inter-temporal equilibrium condition:",
    "after": "where {\\displaystyle B_{t}} is the stock of public debt, {\\displaystyle r} is the interest rate of public debt and {\\displaystyle {PB}_{t}} is the primary balance (negative of primary deficit or government revenues minus government expenditures excluding interest expenditure).",
    "url": "https://en.wikipedia.org/wiki/Fiscal sustainability"
  },
  "{\\displaystyle ITGAP={\\frac {(r-g)(b_{t}-\\sum _{i=1}^{\\infty }({\\frac {1+g}{1+r}})^{i}pb_{t+i})}{1+g}}}": {
    "before": "There are many different indicators of fiscal sustainability. The indicators measure the fiscal adjustment required to bring public finances back to sustainable track. Specifics of the indicator depend on the operational definition of fiscal sustainability and the underlying economic modelling framework employed in a study. Some of the most commonly used indicators are so-called tax gaps. For example, the infinite horizon tax gap, or S2 sustainability indicator in European Commission phraseology is defined as:",
    "after": "where {\\displaystyle b_{t}} is the debt-to-GDP ratio , {\\displaystyle r} is the interest rate of government debt, {\\displaystyle g} is the growth rate of the economy and {\\displaystyle pb_{t}} is the primary balance to GDP ratio.",
    "url": "https://en.wikipedia.org/wiki/Fiscal sustainability"
  },
  "Equation: A = P + hL": {
    "before": "Minor issues remained from these neoclassical theories, such as the question of the proper empirical definition of capital and labour in the laws of factor substitution. Other empirical issues include the so-called Solow Residual in which the heterogenous nature of labour is thoroughly explored for its qualitative elements beyond differentiation, and the concept of total factor productivity, prompting some to consider such things as technology, human capital, and stock of knowledge. Later scholars, such as Walter Benjamin, Fernand Braudel, Ben Fine, Manuel Castells and Michel Aglietta attempted to fill the gap in Marx's unfinished work. In modern times the theory has been extended to conclude that conversion of energy-driven work does not rely on labour-intensive inputs; thus use can be unsupervised work that develops a notion of human capital.",
    "after": "(A, the Concept of Substitutive Work = P, the loss of Primary Productive Energy (which is P/Ep, the coefficient of efficiency) + h, the units of energy (which is the energy consumed by workers during work done) * L, Labour time per hour)",
    "url": "https://en.wikipedia.org/wiki/Use value"
  },
  "(A, the Concept of Substitutive Work = P, the loss of Primary Productive Energy (which is P/Ep, the coefficient of efficiency) + h, the units of energy (which is the energy consumed by workers during work done) * L, Labour time per hour)": {
    "before": "Equation: A = P + hL",
    "after": "Utility[edit]",
    "url": "https://en.wikipedia.org/wiki/Use value"
  },
  "{\\displaystyle u(A)+u(B)=u(A\\cup B)-u(A\\cap B).}": {
    "before": "Additivity (also called linearity or modularity ) means that \"the whole is equal to the sum of its parts.\" That is, the utility of a set of items is the sum of the utilities of each item separately. Let {\\displaystyle S} be a finite set of items. A cardinal utility function {\\displaystyle u:2^{S}\\to \\mathbb {R} } , where {\\displaystyle 2^{S}} is the power set of {\\displaystyle S} , is additive if for any {\\displaystyle A,B\\subseteq S} ,",
    "after": "It follows that for any {\\displaystyle A\\subseteq S} ,",
    "url": "https://en.wikipedia.org/wiki/Additive utility"
  },
  "{\\displaystyle u(A)=u(\\emptyset )+\\sum _{x\\in A}{\\big (}u(\\{x\\})-u(\\emptyset ){\\big )}.}": {
    "before": "It follows that for any {\\displaystyle A\\subseteq S} ,",
    "after": "An additive utility function is characteristic of independent goods . For example, an apple and a hat are considered independent: the utility a person receives from having an apple is the same whether or not he has a hat, and vice versa. A typical utility function for this case is given at the right.",
    "url": "https://en.wikipedia.org/wiki/Additive utility"
  },
  "> monthplot(a10, ylab= \"$ million\" , xlab= \"Month\", xaxt= \"n\", main= \"Seasonal deviation plot: antidiabetic drug sales\")": {
    "before": "The following R code results in the above seasonal deviation plot of antidiabetic drug sales;",
    "after": "> axis(1, at=1:12, labels=month.abb, cex=0.8)",
    "url": "https://en.wikipedia.org/wiki/Seasonal subseries plot"
  },
  "> axis(1, at=1:12, labels=month.abb, cex=0.8)": {
    "before": "> monthplot(a10, ylab= \"$ million\" , xlab= \"Month\", xaxt= \"n\", main= \"Seasonal deviation plot: antidiabetic drug sales\")",
    "after": "References[edit]",
    "url": "https://en.wikipedia.org/wiki/Seasonal subseries plot"
  },
  "{\\displaystyle \\sum _{i=1}^{n}{\\text{MRS}}_{i}={\\text{MRT}}}": {
    "before": "For an economy with n consumers the conditions reads as follows:",
    "after": "MRS i is individual i 's marginal rate of substitution and MRT is the economy's marginal rate of transformation between the public good and an arbitrarily chosen private good.",
    "url": "https://en.wikipedia.org/wiki/Samuelson condition"
  },
  "{\\displaystyle \\sum _{i=1}^{n}{\\text{MB}}_{i}={\\text{MC}}}": {
    "before": "If the private good is a numeraire good then the Samuelson condition can be re-written as:",
    "after": "where {\\displaystyle {\\text{MB}}_{i}} is the marginal benefit to each person of consuming one more unit of the public good, and MC is the marginal cost of providing that good. In other words, the public good should be provided as long as the overall benefits to consumers from that good are at least as great as the cost of providing it. (Remember that public goods are non-rival, so can be enjoyed by many consumers simultaneously).",
    "url": "https://en.wikipedia.org/wiki/Samuelson condition"
  },
  "{\\displaystyle C(s,t)=\\operatorname {corr} (X(s),Y(t)),}": {
    "before": "For possibly distinct random variables X ( s ) and Y ( t ) at different points s and t of some space, the correlation function is",
    "after": "where {\\displaystyle \\operatorname {corr} } is described in the article on correlation . In this definition, it has been assumed that the stochastic variables are scalar-valued. If they are not, then more complicated correlation functions can be defined. For example, if X ( s ) is a random vector with n elements and Y (t) is a vector with q elements, then an n × q matrix of correlation functions is defined with {\\displaystyle i,j} element",
    "url": "https://en.wikipedia.org/wiki/Correlation function"
  },
  "{\\displaystyle C_{ij}(s,t)=\\operatorname {corr} (X_{i}(s),Y_{j}(t)).}": {
    "before": "where {\\displaystyle \\operatorname {corr} } is described in the article on correlation . In this definition, it has been assumed that the stochastic variables are scalar-valued. If they are not, then more complicated correlation functions can be defined. For example, if X ( s ) is a random vector with n elements and Y (t) is a vector with q elements, then an n × q matrix of correlation functions is defined with {\\displaystyle i,j} element",
    "after": "When n = q , sometimes the trace of this matrix is focused on. If the probability distributions have any target space symmetries, i.e. symmetries in the value space of the stochastic variable (also called internal symmetries ), then the correlation matrix will have induced symmetries. Similarly, if there are symmetries of the space (or time) domain in which the random variables exist (also called spacetime symmetries ), then the correlation function will have corresponding space or time symmetries. Examples of important spacetime symmetries are —",
    "url": "https://en.wikipedia.org/wiki/Correlation function"
  },
  "{\\displaystyle C_{i_{1}i_{2}\\cdots i_{n}}(s_{1},s_{2},\\cdots ,s_{n})=\\langle X_{i_{1}}(s_{1})X_{i_{2}}(s_{2})\\cdots X_{i_{n}}(s_{n})\\rangle .}": {
    "before": "Higher order correlation functions are often defined. A typical correlation function of order n is (the angle brackets represent the expectation value )",
    "after": "If the random vector has only one component variable, then the indices {\\displaystyle i,j} are redundant. If there are symmetries, then the correlation function can be broken up into irreducible representations of the symmetries — both internal and spacetime.",
    "url": "https://en.wikipedia.org/wiki/Correlation function"
  },
  "translational symmetry yields C(s,s') = C(s − s') where s and s' are to be interpreted as vectors giving coordinates of the points": {
    "before": "When n=q, sometimes the trace of this matrix is focused on. If the probability distributions have any target space symmetries, i.e. symmetries in the value space of the stochastic variable (also called internal symmetries), then the correlation matrix will have induced symmetries. Similarly, if there are symmetries of the space (or time) domain in which the random variables exist (also called spacetime symmetries), then the correlation function will have corresponding space or time symmetries. Examples of important spacetime symmetries are —",
    "after": "rotational symmetry in addition to the above gives C(s, s') = C(|s − s'|) where |x| denotes the norm of the vector x (for actual rotations this is the Euclidean or 2-norm).",
    "url": "https://en.wikipedia.org/wiki/Correlation function"
  },
  "{\\displaystyle U(t)=U(0)e^{-\\rho t}}": {
    "before": "It is common in economic models that involve decision-making over time to assume that decision-makers are exponential discounters . Exponential discounting posits that the decision maker assigns future utility of any good according to the formula",
    "after": "where {\\displaystyle t=0} is the present, {\\displaystyle U(0)} is the utility assigned to the good if it were consumed immediately, and {\\displaystyle \\rho } is the \"discount factor\", which is the same for all goods and constant over time. Mathematically, it is the unique continuous function that satisfies the equation",
    "url": "https://en.wikipedia.org/wiki/Dynamic inconsistency"
  },
  "{\\displaystyle U(t_{1})/U(t_{2})=U(t_{1}+c)/U(t_{2}+c);}": {
    "before": "where {\\displaystyle t=0} is the present, {\\displaystyle U(0)} is the utility assigned to the good if it were consumed immediately, and {\\displaystyle \\rho } is the \"discount factor\", which is the same for all goods and constant over time. Mathematically, it is the unique continuous function that satisfies the equation",
    "after": "that is, the ratio of utility values for a good at two different moments of time only depends on the interval between these times, but not on their choice. (If you're willing to pay 10% over list price to buy a new phone today instead of paying list price and having it delivered in a week, you'd also be willing to pay extra 10% to get it one week sooner if you were ordering it six months in advance.)",
    "url": "https://en.wikipedia.org/wiki/Dynamic inconsistency"
  },
  "{\\displaystyle U_{A}(t_{1})/U_{B}(t_{1})=U_{A}(t_{2})/U_{B}(t_{2});}": {
    "before": "If {\\displaystyle \\rho } is the same for all goods, then it is also the case that",
    "after": "that is, if good A is assigned higher utility than good B at time {\\displaystyle t_{1}} , that relationship also holds at all other times. (If you'd rather eat broccoli than cake tomorrow for lunch, you'll also pick broccoli over cake if you're hungry right now.)",
    "url": "https://en.wikipedia.org/wiki/Dynamic inconsistency"
  },
  "{\\displaystyle y_{t}=T_{t}+C_{t}+S_{t}+I_{t},}": {
    "before": "Hence a time series using an additive model can be thought of as",
    "after": "whereas a multiplicative model would be",
    "url": "https://en.wikipedia.org/wiki/Decomposition of time series"
  },
  "{\\displaystyle y_{t}=T_{t}\\times C_{t}\\times S_{t}\\times I_{t}.\\,}": {
    "before": "{\\displaystyle y_{t}=T_{t}+C_{t}+S_{t}+I_{t},} whereas a multiplicative model would be",
    "after": "An additive model would be used when the variations around the trend do not vary with the level of the time series whereas a multiplicative model would be appropriate if the trend is proportional to the level of the time series. ",
    "url": "https://en.wikipedia.org/wiki/Decomposition of time series"
  },
  "{\\displaystyle Y_{t}(u)=T+Y_{c}(u)}": {
    "before": "We can infer what Joe's potential outcome under control would have been if we make an assumption of constant effect:",
    "after": "and {\\displaystyle Y_{t}(u)-T=Y_{c}(u).}",
    "url": "https://en.wikipedia.org/wiki/Rubin causal model"
  },
  "{\\displaystyle Y_{t}(u)-T=Y_{c}(u).}": {
    "before": "{\\displaystyle Y_{t}(u)=T+Y_{c}(u)} and",
    "after": "If we wanted to infer the unobserved values we could assume a constant effect. The following tables illustrates data consistent with the assumption of a constant effect.",
    "url": "https://en.wikipedia.org/wiki/Rubin causal model"
  },
  "Joe = c, Mary = t": {
    "before": "subject",
    "after": "Joe = t, Mary = t",
    "url": "https://en.wikipedia.org/wiki/Rubin causal model"
  },
  "Joe = t, Mary = t": {
    "before": "Joe = c, Mary = t",
    "after": "Joe = c, Mary = c",
    "url": "https://en.wikipedia.org/wiki/Rubin causal model"
  },
  "Joe = c, Mary = c": {
    "before": "Joe = t, Mary = t",
    "after": "Joe = t, Mary = c",
    "url": "https://en.wikipedia.org/wiki/Rubin causal model"
  },
  "Joe = t, Mary = c": {
    "before": "Joe = c, Mary = c",
    "after": "Joe",
    "url": "https://en.wikipedia.org/wiki/Rubin causal model"
  },
  "Sessions with Search = The number of sessions that used your site's search function at least once. Percentage of sessions that used internal search = Sessions with Search / Total Sessions. Total Unique Searches = The total number of times your site search was used. This excludes multiple searches on the same keyword during the same session. Results Pageviews / Search = Pageviews of search result pages / Total Unique Searches. Search Exits = The number of searches made immediately before leaving the site. Percentage of Search Exits = Search Exits / Total Unique Searches Search Refinements = The number of times a user searched again immediately after performing a search. Percentage Search Refinements = The percentage of searches that resulted in a search refinement. Calculated as Search Refinements / Pageviews of search result pages. Time after Search = The amount of time users spend on your site after performing a search. This is calculated as Sum of all search_duration across all searches / (search_transitions + 1) Search Depth = The number of pages viewed after performing a search. This is calculated as Sum of all search_depth across all searches / (search_transitions + 1) ": {
    "before": "Taking a look at Google Insights to gauge the popularity of these services shows that compared to searches for the term Adwords (Google's popular search ad system), use of search analytics services is still very low, around 1-25% as of Oct. 2009.  This could point to a large opportunity for the users and makers of search analytics given that services have existed since 2004 with several new services being started since.Calculations [ edit ]",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Search analytics"
  },
  "{\\displaystyle V_{e}=wT+e^{-rT}[bTV_{u}+(1-bT)V_{e}]\\;,}": {
    "before": "Suppose utility is a function of wages w and effort e like {\\displaystyle u(w,e)=w-e} , and workers maximize the utility function with a discount rate r. Then let b be the probability per unit time that a worker is dismissed from his job, and now we introduce the expected lifetime utility {\\displaystyle V_{u}} of an unemployed individual. Then we find the asset value of employment during a short interval [0, T]",
    "after": "because the worker is either dismissed or kept employed during the time. The exponential function appears, because the occasion of dismiss in the interval is once and Poisson distribution is used for the discount rate. Due to the short interval, we approximate the exponential function by 1-rT",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle V_{e}=wT+(1-rT)[bTV_{u}+(1-bT)V_{e}]\\;,}": {
    "before": "because the worker is either dismissed or kept employed during the time. The exponential function appears, because the occasion of dismiss in the interval is once and Poisson distribution is used for the discount rate. Due to the short interval, we approximate the exponential function by 1-rT",
    "after": "and simple calculation yields",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle V_{e}={\\frac {wT+bTV_{u}-rbT^{2}V_{u}}{rT+bT-rbT^{2}}}\\;,} {\\displaystyle \\lim _{t\\rightarrow 0}V_{e}={\\frac {w+bV_{u}}{r+b}}\\;.}": {
    "before": "{\\displaystyle V_{e}=wT+(1-rT)[bTV_{u}+(1-bT)V_{e}]\\;,} and simple calculation yields",
    "after": "Then we find the fundamental asset equation of a worker:",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle rV_{e}=w+b(V_{u}-V_{e})\\;.}": {
    "before": "Then we find the fundamental asset equation of a worker:",
    "after": "For a nonshirker the equation is",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle rV_{e,N}=w-e+b(V_{u}-V_{e,N})\\;,}": {
    "before": "{\\displaystyle rV_{e}=w+b(V_{u}-V_{e})\\;.} For a nonshirker the equation is",
    "after": "and for a shirker",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle rV_{e,S}=w+(b+q)(V_{u}-V_{e,S})\\;,}": {
    "before": "{\\displaystyle rV_{e,N}=w-e+b(V_{u}-V_{e,N})\\;,} and for a shirker",
    "after": "where q is the probability per unit time that a worker is caught shirking and sacked.  Then we see",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle V_{e,N}={\\frac {w-e+bV_{u}}{r+b}}\\;,} {\\displaystyle V_{e,S}={\\frac {w+(b+q)V_{u}}{r+b+q}}\\;.}": {
    "before": "where q is the probability per unit time that a worker is caught shirking and sacked.  Then we see",
    "after": "The condition {\\displaystyle V_{e,S}<V_{e,N}} is called the no-shirking condition (NSC), which is expressed as",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle {\\hat {w}}=rV_{u}+{\\frac {e(r+b+q)}{q}}<w\\;,}": {
    "before": "The condition {\\displaystyle V_{e,S}<V_{e,N}} is called the no-shirking condition (NSC), which is expressed as",
    "after": "where {\\displaystyle {\\hat {w}}} is the critical wage.  The worker works hard if and only if the NSC is satisfied. Thus if workers get sufficiently high wages, then the NSC is met and they will not shirk. The condition tells us that",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle a={\\frac {bL}{N-L}}\\;,}": {
    "before": "Let {\\displaystyle a} be the probability of getting a job per unit time. In equilibrium, the flow into the unemployment pool must be equal to the flow out. Thus the probability is",
    "after": "where {\\displaystyle L} is the aggregate employment and {\\displaystyle N} is the total labour supply. In reality, an employee is offered his minimum wage {\\displaystyle {\\overline {w}}} or its equivalent by law. Thus the NSC becomes",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle {\\overline {w}}+e+{\\frac {e(a+b+r)}{q}}={\\hat {w}}<w\\;,}": {
    "before": "where {\\displaystyle L} is the aggregate employment and {\\displaystyle N} is the total labour supply. In reality, an employee is offered his minimum wage {\\displaystyle {\\overline {w}}} or its equivalent by law. Thus the NSC becomes",
    "after": "and we call it the aggregate NSC.  These two yields",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle {\\hat {w}}={\\frac {dF(L)}{dL}}\\quad .}": {
    "before": "A firm's labour demand is given by equating the cost of hiring an additional employee to the marginal product of labour. This cost consists of wages and future unemployment benefits. Now consider the case where {\\displaystyle {\\overline {w}}=0} , then we have",
    "after": "In equilibrium, {\\displaystyle F'(L)={\\hat {w}}=w^{*}} holds, where {\\displaystyle w^{*}} is the equilibrium wage. Then the equilibrium condition becomes",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle F'(L)={\\hat {w}}=e+{\\frac {e}{q}}({\\frac {b}{u}}+r)=e\\left(1+{\\frac {r+b+a}{q}}\\right)\\;\\;.}": {
    "before": "In equilibrium, {\\displaystyle F'(L)={\\hat {w}}=w^{*}} holds, where {\\displaystyle w^{*}} is the equilibrium wage. Then the equilibrium condition becomes",
    "after": "This suggests following things.",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle \\pi =g(N)-{\\frac {NL}{p}}-NM,}": {
    "before": "The level of employment is changed by rules about job security. Consider a firm which consists of an employer and homogeneous employees. Then, suppose the profit of the firm is a function of the level of employment N, the lowest wage {\\displaystyle W={\\frac {L}{p}}} and the level of monitoring M chosen by the employer.",
    "after": "where g(N) is the production function, L is the value of on-the-job leisure from shirking, and p is the probability that an employee is caught shirking and sacked.  Assume that the production function has the upper limit and its second derivative with respect to N is negative. Not to mention, the first derivative is positive. That is a reasonable assumption that the function has its upper bound in term of productivity. Consider, for instance, such a function of time as",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle f(t)=1-e^{-t}.}": {
    "before": "where g(N) is the production function, L is the value of on-the-job leisure from shirking, and p is the probability that an employee is caught shirking and sacked.  Assume that the production function has the upper limit and its second derivative with respect to N is negative. Not to mention, the first derivative is positive. That is a reasonable assumption that the function has its upper bound in term of productivity. Consider, for instance, such a function of time as",
    "after": "Obviously its first derivative is positive, and second derivative is negative.",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle {\\frac {\\partial \\pi }{\\partial N}}={\\frac {\\partial g(N)}{\\partial N}}-{\\frac {L}{p}}-M.} {\\displaystyle {\\frac {\\partial ^{2}\\pi }{\\partial N^{2}}}={\\frac {\\partial ^{2}g(N)}{\\partial N^{2}}}.}": {
    "before": "Let R be a measure of the difficulty of dismissing an employee who is caught shirking. Then p is a function of both R and M. The first and second derivatives of the profit with regard to N are:",
    "after": "The condition for the maximum of the profit is {\\displaystyle {\\frac {\\partial \\pi }{\\partial N}}=0} , and so we have",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle {\\frac {\\partial g(N)}{\\partial N}}={\\frac {L}{p}}+M.}": {
    "before": "The condition for the maximum of the profit is {\\displaystyle {\\frac {\\partial \\pi }{\\partial N}}=0} , and so we have",
    "after": "Thus differentiating its both sides with regard to R gives us",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle {\\frac {\\partial ^{2}g(N)}{\\partial N^{2}}}{\\frac {\\partial N}{\\partial R}}=-{\\frac {L}{p}}{\\frac {\\partial p}{\\partial R}}.}": {
    "before": "Thus differentiating its both sides with regard to R gives us",
    "after": "It turns out that {\\displaystyle {\\frac {\\partial N}{\\partial R}}} is negative, which means that the more difficult to sack a shirker the lower employment level. ",
    "url": "https://en.wikipedia.org/wiki/Shapiro–Stiglitz theory"
  },
  "{\\displaystyle {\\frac {V_{c}({\\hat {\\beta }})}{V({\\hat {\\beta }})}}=1+(n-1)\\rho }": {
    "before": "In the framework of the Moulton factor, an intuitive explanation of the small cluster problem can be derived from the formula for the Moulton factor. Assume for simplicity that the number of observations per cluster is fixed at n . Below, {\\displaystyle V_{c}(\\beta )} stands for the covariance matrix adjusted for clustering, {\\displaystyle V(\\beta )} stands for the covariance matrix not adjusted for clustering, and ρ stands for the intraclass correlation:",
    "after": "The ratio on the left-hand side indicates how much the unadjusted scenario overestimates the precision. Therefore, a high number means a strong downward bias of the estimated covariance matrix. A small cluster problem can be interpreted as a large n: when the data is fixed and the number of clusters is low, the number of data within a cluster can be high. It follows that inference, when the number of clusters is small, will not have the correct coverage. ",
    "url": "https://en.wikipedia.org/wiki/Cluster sampling"
  },
  "{\\displaystyle U(\\{c_{t}\\}_{t=t_{1}}^{t_{2}})=\\sum _{t=t_{1}}^{t_{2}}\\delta ^{t-t_{1}}(u(c_{t})),}": {
    "before": "In economics exponential discounting is a specific form of the discount function , used in the analysis of choice over time (with or without uncertainty ). Formally, exponential discounting occurs when total utility is given by",
    "after": "where c t is consumption at time t , {\\displaystyle \\delta } is the exponential discount factor , and u is the instantaneous utility function .",
    "url": "https://en.wikipedia.org/wiki/Exponential discounting"
  },
  "{\\displaystyle U(\\{c(t)\\}_{t=t_{1}}^{t_{2}})=\\int _{t_{1}}^{t_{2}}e^{-\\rho (t-t_{1})}u(c(t))\\,dt,}": {
    "before": "In continuous time , exponential discounting is given by",
    "after": "Exponential discounting implies that the marginal rate of substitution between consumption at any pair of points in time depends only on how far apart those two points are. Exponential discounting is not dynamically inconsistent . A key aspect of the exponential discounting assumption is the property of dynamic consistency— preferences are constant over time.  In other words, preferences do not change with the passage of time unless new information is presented. For example, consider an investment opportunity that has the following characteristics: pay a utility cost of C at date t=2 to earn a utility benefit of B at time t=3. At date t=1, this investment opportunity is considered favorable; hence, this function is: −δC + δ 2 B> 0. Now consider from the perspective of date t=2, this investment opportunity is still viewed as favorable given −C + δB> 0. To view this mathematically, observe that the new expression is the old expression multiplied by 1/δ. Therefore, the preferences at t=1 is preserved at t=2; thus, the exponential discount function demonstrates dynamically consistent preferences over time.",
    "url": "https://en.wikipedia.org/wiki/Exponential discounting"
  },
  "Constructibility (V=L)": {
    "before": "global",
    "after": "Determinacy",
    "url": "https://en.wikipedia.org/wiki/Bertrand Russell"
  },
  "Borda count (a=0, b=1): C=13, A=12, B=11, D=8, E=6. C wins.": {
    "before": "1 voter ranks [E>C>D>B>A].",
    "after": "Now, the voter who ranks [C>D>E>B>A] instead ranks [C>B>E>D>A]; and the voter who ranks [E>C>D>B>A] instead ranks [E>C>B>D>A]. They change their preferences only over the pairs [B, D], [B, E] and [D, E].",
    "url": "https://en.wikipedia.org/wiki/Independence of irrelevant alternatives"
  },
  "The new Borda count: B=14, C=13, A=12, E=6, D=5. B wins.": {
    "before": "Now, the voter who ranks [C>D>E>B>A] instead ranks [C>B>E>D>A]; and the voter who ranks [E>C>D>B>A] instead ranks [E>C>B>D>A]. They change their preferences only over the pairs [B, D], [B, E] and [D, E].",
    "after": "The social choice has changed the ranking of [B, A] and [B, C]. The changes in the social choice ranking are dependent on irrelevant changes in the preference profile. In particular, B now wins instead of C, even though no voter changed their preference over [B, C].",
    "url": "https://en.wikipedia.org/wiki/Independence of irrelevant alternatives"
  },
  "Round 1: A=2, B=1, C=2; B eliminated.": {
    "before": "1 voter ranks [B>A>C].",
    "after": "Round 2: A=3, C=2; A wins.",
    "url": "https://en.wikipedia.org/wiki/Independence of irrelevant alternatives"
  },
  "Round 2: A=3, C=2; A wins.": {
    "before": "Round 1: A=2, B=1, C=2; B eliminated.",
    "after": "Now, the two voters who rank [C>B>A] instead rank [B>C>A]. They change only their preferences over B and C.",
    "url": "https://en.wikipedia.org/wiki/Independence of irrelevant alternatives"
  },
  "Round 1: A=2, B=3, C=0; B wins with a majority of the vote.": {
    "before": "Now, the two voters who rank [C>B>A] instead rank [B>C>A]. They change only their preferences over B and C.",
    "after": "The social choice ranking of [A, B] is dependent on preferences over the irrelevant alternatives [B, C].",
    "url": "https://en.wikipedia.org/wiki/Independence of irrelevant alternatives"
  },
  "X = A": {
    "before": "2",
    "after": "Y = C",
    "url": "https://en.wikipedia.org/wiki/Independence of irrelevant alternatives"
  },
  "Y = B": {
    "before": "X = A",
    "after": "5",
    "url": "https://en.wikipedia.org/wiki/Independence of irrelevant alternatives"
  },
  "Y = C": {
    "before": "X = B",
    "after": "3",
    "url": "https://en.wikipedia.org/wiki/Independence of irrelevant alternatives"
  },
  "X = B": {
    "before": "4",
    "after": "Y = C",
    "url": "https://en.wikipedia.org/wiki/Independence of irrelevant alternatives"
  },
  "{\\displaystyle p(x)={\\frac {e^{-x/V}}{V}}.}": {
    "before": "This is because in the war of attrition any strategy that is unwavering and predictable is unstable, because it will ultimately be displaced by a mutant strategy which relies on the fact that it can best the existing predictable strategy by investing an extra small delta of waiting resource to ensure that it wins. Therefore, only a random unpredictable strategy can maintain itself in a population of bluffers. The contestants in effect choose an acceptable cost to be incurred related to the value of the resource being sought, effectively making a random bid as part of a mixed strategy (a strategy where a contestant has several, or even many, possible actions in their strategy). This implements a distribution of bids for a resource of specific value V, where the bid for any specific contest is chosen at random from that distribution. The distribution (an ESS) can be computed using the Bishop-Cannings theorem , which holds true for any mixed-strategy ESS.  The distribution function in these contests was determined by Parker and Thompson to be:",
    "after": "The result is that the cumulative population of quitters for any particular cost m in this \"mixed strategy\" solution is:",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "{\\displaystyle p(m)=1-e^{-m/V},}": {
    "before": "The result is that the cumulative population of quitters for any particular cost m in this \"mixed strategy\" solution is:",
    "after": "as shown in the adjacent graph. The intuitive sense that greater values of resource sought leads to greater waiting times is borne out. This is observed in nature, as in male dung flies contesting for mating sites, where the timing of disengagement in contests is as predicted by evolutionary theory mathematics. ",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "inclusive fitness=own contribution to fitness + contribution of all relatives .": {
    "before": "kin selectionis that:",
    "after": "Fitness is measured relative to the average population; for example, fitness=1 means growth at the average rate for the population, fitness < 1 means having a decreasing share in the population (dying out), fitness > 1 means an increasing share in the population (taking over).",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "{\\displaystyle w_{i}=a_{i}+\\sum _{j}r_{j}b_{j}.}": {
    "before": "The inclusive fitness of an individual w i is the sum of its specific fitness of itself a i plus the specific fitness of each and every relative weighted by the degree of relatedness which equates to the summation of all r j *b j ....... where r j is relatedness of a specific relative and b j is that specific relative's fitness – producing:",
    "after": "If individual a i sacrifices their \"own average equivalent fitness of 1\" by accepting a fitness cost C, and then to \"get that loss back\", w i must still be 1 (or greater than 1)...and using R*B to represent the summation results in:",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "Solution of the hawk dove game for V=2, C=10 and fitness starting base B=4. The fitness of a hawk for different population mixes is plotted as a black line, that of dove in red. An ESS (a stationary point) will exist when hawk and dove fitness are equal: Hawks are 20% of population and doves are 80% of the population.": {
    "before": "Hawk dove[edit]",
    "after": "Main article: Chicken (game)",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "if last_move_by_opponent == defect:": {
    "before": "\"\"\"Defect if opponent defects, else cooperate.\"\"\"",
    "after": "defect()",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "Let the chance of meeting a hawk=p so therefore the chance of meeting a dove is (1-p)": {
    "before": "The ESS state can be solved for by exploring either the dynamics of population change to determine an ESS, or by solving equations for the stable stationary point conditions which define an ESS. For example, in the hawk dove game we can look for whether there is a static population mix condition where the fitness of doves will be exactly the same as fitness of hawks (therefore both having equivalent growth rates – a static point).",
    "after": "Let Whawk equal the payoff for hawk.....",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "Whawk=payoff in the chance of meeting a dove + payoff in the chance of meeting a hawk": {
    "before": "Let Whawk equal the payoff for hawk.....",
    "after": "Taking the payoff matrix results and plugging them into the above equation:",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "Whawk= V·(1-p)+(V/2-C/2)·p": {
    "before": "Taking the payoff matrix results and plugging them into the above equation:",
    "after": "Similarly for a dove:",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "Wdove= V/2·(1-p)+0·(p)": {
    "before": "Similarly for a dove:",
    "after": "so....",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "Wdove= V/2·(1-p)": {
    "before": "so....",
    "after": "Equating the two fitnesses, hawk and dove",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "V·(1-p)+(V/2-C/2)·p= V/2·(1-p)": {
    "before": "Equating the two fitnesses, hawk and dove",
    "after": "... and solving for p",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "p= V/C": {
    "before": "... and solving for p",
    "after": "so for this \"static point\" where the population percent is an ESS solves to be ESS(percent Hawk)=V/C",
    "url": "https://en.wikipedia.org/wiki/Evolutionary game theory"
  },
  "{\\displaystyle {\\hat {y}}_{T+h|T}={\\bar {y}}=(y_{1}+...+y_{T})/T} ": {
    "before": "In this approach, the predictions of all future values are equal to the mean of the past data. This approach can be used with any sort of data where past data is available. In time series notation:",
    "after": "where {\\displaystyle y_{1},...,y_{T}} is the past data.",
    "url": "https://en.wikipedia.org/wiki/Forecasting"
  },
  "{\\displaystyle {\\hat {y}}_{T+h|T}=y_{T}}": {
    "before": "Naïve forecasts are the most cost-effective forecasting model, and provide a benchmark against which more sophisticated models can be compared. This forecasting method is only suitable for time series data .  Using the naïve approach, forecasts are produced that are equal to the last observed value. This method works quite well for economic and financial time series, which often have patterns that are difficult to reliably and accurately predict.  If the time series is believed to have seasonality, the seasonal naïve approach may be more appropriate where the forecasts are equal to the value from last season. In time series notation:",
    "after": "Drift method [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Forecasting"
  },
  "{\\displaystyle {\\hat {y}}_{T+h|T}=y_{T}+{\\frac {h}{T-1}}\\sum _{t=2}^{T}(y_{t}-y_{t-1})=y_{T}+h\\left({\\frac {y_{T}-y_{1}}{T-1}}\\right).} ": {
    "before": "A variation on the naïve method is to allow the forecasts to increase or decrease over time, where the amount of change over time (called the drift ) is set to be the average change seen in the historical data. So the forecast for time {\\displaystyle T+h} is given by",
    "after": "This is equivalent to drawing a line between the first and last observation, and extrapolating it into the future.",
    "url": "https://en.wikipedia.org/wiki/Forecasting"
  },
  "{\\displaystyle {\\hat {y}}_{T+h|T}=y_{T+h-m(k+1)}}": {
    "before": "The seasonal naïve method accounts for seasonality by setting each prediction to be equal to the last observed value of the same season. For example, the prediction value for all subsequent months of April will be equal to the previous value observed for April. The forecast for time {\\displaystyle T+h} is ",
    "after": "where {\\displaystyle m} =seasonal period and {\\displaystyle k} is the smallest integer greater than {\\displaystyle (h-1)/m} .",
    "url": "https://en.wikipedia.org/wiki/Forecasting"
  },
  "{\\displaystyle \\ E_{t}=Y_{t}-F_{t}}": {
    "before": "The forecast error (also known as a residual ) is the difference between the actual value and the forecast value for the corresponding period:",
    "after": "where E is the forecast error at period t, Y is the actual value at period t, and F is the forecast for period t.",
    "url": "https://en.wikipedia.org/wiki/Forecasting"
  },
  "where m=seasonal period or 1 if non-seasonal": {
    "before": "{\\displaystyle MASE={\\frac {\\sum _{t=1}^{N}|{\\frac {E_{t}}{{\\frac {1}{N-m}}\\sum _{t=m+1}^{N}|Y_{t}-Y_{t-m}|}}|}{N}}}",
    "after": "Other measures[edit]",
    "url": "https://en.wikipedia.org/wiki/Forecasting"
  },
  "Repeat the above step for i = 1,2,..., N where N is the total number of observations.": {
    "before": "Select observation i for the test set, and use the remaining observations in the training set. Compute the error on the test observation.",
    "after": "Compute the forecast accuracy measures based on the errors obtained.",
    "url": "https://en.wikipedia.org/wiki/Forecasting"
  },
  "Starting with i=1, select the observation k + i for the test set, and use the observations at times 1, 2, ..., k+i–1 to estimate the forecasting model. Compute the error on the forecast for k+i.": {
    "before": "For time series data, the training set can only include observations prior to the test set. Therefore, no future observations can be used in constructing the forecast. Suppose k observations are needed to produce a reliable forecast; then the process works as follows:",
    "after": "Repeat the above step for i = 2,...,T–k where T is the total number of observations.",
    "url": "https://en.wikipedia.org/wiki/Forecasting"
  },
  "Repeat the above step for i = 2,...,T–k where T is the total number of observations.": {
    "before": "Starting with i=1, select the observation k + i for the test set, and use the observations at times 1, 2, ..., k+i–1 to estimate the forecasting model. Compute the error on the forecast for k+i.",
    "after": "Compute the forecast accuracy over all errors.",
    "url": "https://en.wikipedia.org/wiki/Forecasting"
  },
  "{\\displaystyle (1-L)X_{t}=X_{t}-X_{t-1}=\\Delta X.}": {
    "before": "is a stationary process , where {\\displaystyle L} is the lag operator and {\\displaystyle 1-L} is the first difference, i.e.",
    "after": "In other words, a process is integrated to order d if taking repeated differences d times yields a stationary process.",
    "url": "https://en.wikipedia.org/wiki/Order of integration"
  },
  "{\\displaystyle \\Delta Z_{t}=X_{t},}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Order of integration"
  },
  "{\\displaystyle Y(t)=[K(t)]^{\\alpha }[A(t)L(t)]^{1-\\alpha }\\,}": {
    "before": "Solow assumed a very basic model of annual aggregate output over a year ( t ). He said that the output quantity would be governed by the amount of capital (the infrastructure), the amount of labour (the number of people in the workforce), and the productivity of that labour. He thought that the productivity of labour was the factor driving long-run GDP increases. An example economic model of this form is given below: ",
    "after": "where:Y ( t ) represents the total production in an economy (the GDP ) in some year, t . K ( t ) is capital in the productive economy – which might be measured through the combined value of all companies in a capitalist economy. L ( t ) is labour; this is simply the number of people in work, and since growth models are long run models they tend to ignore cyclical unemployment effects, assuming instead that the labour force is a constant fraction of an expanding population. A ( t ) represents multifactor productivity (often generalized as \" technology \"). The change in this figure from A (1960) to A (1980) is the key to estimating the growth in labour 'efficiency' and the Solow residual between 1960 and 1980, for instance.",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle {\\frac {\\partial Y}{\\partial t}}={\\frac {\\partial Y}{\\partial K}}{\\frac {\\partial K}{\\partial t}}+{\\frac {\\partial Y}{\\partial L}}{\\frac {\\partial L}{\\partial t}}+{\\frac {\\partial Y}{\\partial A}}{\\frac {\\partial A}{\\partial t}}}": {
    "before": "To measure or predict the change in output within this model, the equation above is differentiated in time ( t ), giving a formula in partial derivatives of the relationships: labour-to-output, capital-to-output, and productivity-to-output, as shown:",
    "after": "Observe: {\\displaystyle {\\frac {\\partial Y}{\\partial K}}={\\alpha }[K(t)]^{\\alpha -1}\\cdot [A(t)L(t)]^{1-\\alpha }={\\frac {{\\alpha }Y}{[K(t)]}}}",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle {\\frac {\\partial Y}{\\partial K}}={\\alpha }[K(t)]^{\\alpha -1}\\cdot [A(t)L(t)]^{1-\\alpha }={\\frac {{\\alpha }Y}{[K(t)]}}}": {
    "before": "{\\displaystyle {\\frac {\\partial Y}{\\partial t}}={\\frac {\\partial Y}{\\partial K}}{\\frac {\\partial K}{\\partial t}}+{\\frac {\\partial Y}{\\partial L}}{\\frac {\\partial L}{\\partial t}}+{\\frac {\\partial Y}{\\partial A}}{\\frac {\\partial A}{\\partial t}}} Observe:",
    "after": "Similarly: {\\displaystyle {\\frac {\\partial Y}{\\partial L}}={\\frac {(1-{\\alpha })Y}{[L(t)]}}{\\text{ and }}{\\frac {\\partial Y}{\\partial A}}={\\frac {(1-{\\alpha })Y}{[A(t)]}}}",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle {\\frac {\\partial Y}{\\partial L}}={\\frac {(1-{\\alpha })Y}{[L(t)]}}{\\text{ and }}{\\frac {\\partial Y}{\\partial A}}={\\frac {(1-{\\alpha })Y}{[A(t)]}}}": {
    "before": "{\\displaystyle {\\frac {\\partial Y}{\\partial K}}={\\alpha }[K(t)]^{\\alpha -1}\\cdot [A(t)L(t)]^{1-\\alpha }={\\frac {{\\alpha }Y}{[K(t)]}}} Similarly:",
    "after": "Therefore: {\\displaystyle {\\frac {\\partial Y}{\\partial t}}={\\frac {{\\alpha }Y}{[K(t)]}}{\\frac {\\partial K}{\\partial t}}+{\\frac {(1-{\\alpha })Y}{[L(t)]}}{\\frac {\\partial L}{\\partial t}}+{\\frac {(1-{\\alpha })Y}{[A(t)]}}{\\frac {\\partial A}{\\partial t}}}",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle {\\frac {\\partial Y}{\\partial t}}={\\frac {{\\alpha }Y}{[K(t)]}}{\\frac {\\partial K}{\\partial t}}+{\\frac {(1-{\\alpha })Y}{[L(t)]}}{\\frac {\\partial L}{\\partial t}}+{\\frac {(1-{\\alpha })Y}{[A(t)]}}{\\frac {\\partial A}{\\partial t}}}": {
    "before": "{\\displaystyle {\\frac {\\partial Y}{\\partial L}}={\\frac {(1-{\\alpha })Y}{[L(t)]}}{\\text{ and }}{\\frac {\\partial Y}{\\partial A}}={\\frac {(1-{\\alpha })Y}{[A(t)]}}} Therefore:",
    "after": "The growth factor in the economy is a proportion of the output last year, which is given (assuming small changes year-on-year) by dividing both sides of this equation by the output, Y :",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle {\\frac {\\frac {\\partial Y}{\\partial t}}{Y}}=\\alpha {\\frac {\\frac {\\partial K}{\\partial t}}{K(t)}}+(1-{\\alpha }){\\frac {\\frac {\\partial L}{\\partial t}}{L(t)}}+(1-{\\alpha }){\\frac {\\frac {\\partial A}{\\partial t}}{A(t)}}}": {
    "before": "The growth factor in the economy is a proportion of the output last year, which is given (assuming small changes year-on-year) by dividing both sides of this equation by the output, Y :",
    "after": "The first two terms on the right hand side of this equation are the proportional changes in labour and capital year-on-year, and the left hand side is the proportional output change. The remaining term on the right, giving the effect of productivity improvements on GDP is defined as the Solow residual:",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle SR(t)={\\frac {\\frac {\\partial Y}{\\partial t}}{Y}}-\\left(\\alpha {\\frac {\\frac {\\partial K}{\\partial t}}{K(t)}}+(1-{\\alpha }){\\frac {\\frac {\\partial L}{\\partial t}}{L(t)}}\\right)}": {
    "before": "The first two terms on the right hand side of this equation are the proportional changes in labour and capital year-on-year, and the left hand side is the proportional output change. The remaining term on the right, giving the effect of productivity improvements on GDP is defined as the Solow residual:",
    "after": "The residual, SR ( t ) is that part of growth not explicable by measurable changes in the amount of capital, K , and the number of workers, L . If output, capital, and labour all double every twenty years the residual will be zero, but in general it is higher than this: output goes up faster than growth in the input factors. The residual varies between periods and countries, but is almost always positive in peace-time capitalist countries. Some estimates of the post-war U.S. residual credited the country with a 3% productivity increase per-annum until the early 1970s when productivity growth appeared to stagnate.",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle \\ln(Y(t))=\\alpha \\ln(K(t))+(1-\\alpha )[\\ln(L(t))]+(1-\\alpha )[\\ln(A(t))]+\\varepsilon .\\,}": {
    "before": "The above relation gives a very simplified picture of the economy in a single year; what growth theory econometrics does is to look at a sequence of years to find a statistically significant pattern in the changes of the variables, and perhaps identify the existence and value of the \"Solow residual\". The most basic technique for doing this is to assume constant rates of change in all the variables (obscured by noise), and regress on the data to find the best estimate of these rates in the historical data available (using an Ordinary least squares regression ). Economists always do this by first taking the natural log of their equation (to separate out the variables on the right-hand-side of the equation); logging both sides of this production function produces a simple linear regression with an error term, {\\displaystyle \\varepsilon } :",
    "after": "A constant growth factor implies exponential growth in the above variables, so differentiating gives a linear relationship between the growth factors which can be deduced in a simple regression.",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle y=C+\\beta k+\\gamma \\ell +\\varepsilon \\,}": {
    "before": "In a regression analysis, the equation one would estimate is:",
    "after": "where:y is (log) output, ln(Y)",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle Y(t)=A(t)^{C}K(t)^{\\beta }L(t)^{\\gamma }}": {
    "before": "For calculation of the actual quantity/ level of technology {\\displaystyle A} we simply refer back to our equation in levels.",
    "after": "Knowing quantities of output {\\displaystyle Y(t)} , capital {\\displaystyle K(t)} , labor {\\displaystyle L(t)} and estimates for {\\displaystyle C} , {\\displaystyle \\beta } and {\\displaystyle \\gamma } we can solve for {\\displaystyle A(t)} as:",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle A(t)=\\left({\\frac {Y(t)}{K(t)^{\\beta }L(t)^{\\gamma }}}\\right)^{\\frac {1}{C}}}": {
    "before": "Knowing quantities of output {\\displaystyle Y(t)} , capital {\\displaystyle K(t)} , labor {\\displaystyle L(t)} and estimates for {\\displaystyle C} , {\\displaystyle \\beta } and {\\displaystyle \\gamma } we can solve for {\\displaystyle A(t)} as:",
    "after": "Mankiw, Romer, and Weil augmented the Solow-Swan model with a human capital term. The explicit inclusion of this term in the model transfers the effect of changes in human capital from the Solow residual to capital accumulation. As a consequence, the Solow residual is smaller in the augmented Solow model:",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle Y(t)=[K(t)]^{\\alpha }[H(t)]^{\\beta }[A(t)L(t)]^{1-\\alpha -\\beta }\\,}": {
    "before": "Mankiw, Romer, and Weil augmented the Solow-Swan model with a human capital term. The explicit inclusion of this term in the model transfers the effect of changes in human capital from the Solow residual to capital accumulation. As a consequence, the Solow residual is smaller in the augmented Solow model:",
    "after": "where:H ( t ) represents the human capital stock in an economy (the GDP ) in some year, t .",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle \\ln(Y(t))=\\alpha \\ln(K(t))+\\beta \\ln(H(t))+(1-\\alpha -\\beta )[\\ln(L(t))]+(1-\\alpha -\\beta )[\\ln(A(t))]+\\varepsilon .\\,}": {
    "before": "The associated regression to estimate this model is:",
    "after": "Breton estimates the Solow residual for the human capital-augmented version of the Solow-Swan model over the 20th century.  He finds that from 1910 to 2000 {\\displaystyle A(t)} in 42 of the world's leading economies increased at an average rate of 1%/year and {\\displaystyle A(t)^{1-\\alpha -\\beta }} increased at 0.3%/year.",
    "url": "https://en.wikipedia.org/wiki/Solow residual"
  },
  "{\\displaystyle V\\left(x_{n0}\\right)=\\max _{\\left\\{d_{nt}\\right\\}_{t=1}^{T}}\\mathbb {E} \\left(\\sum _{t^{\\prime }=t}^{T}\\sum _{i=1}^{J}\\beta ^{t'-t}\\left(d_{nt}=i\\right)U_{nit}\\left(x_{nt},\\varepsilon _{nit}\\right)\\right),}": {
    "before": "Agent {\\displaystyle n} 's maximization problem can be written mathematically as follows:",
    "after": "where {\\displaystyle x_{nt}} are state variables , with {\\displaystyle x_{n0}} the agent's initial condition {\\displaystyle d_{nt}} represents {\\displaystyle n} 's decision from among {\\displaystyle J} discrete alternatives {\\displaystyle \\beta \\in \\left(0,1\\right)} is the discount factor {\\displaystyle U_{nit}} is the flow utility {\\displaystyle n} receives from choosing alternative {\\displaystyle i} in period {\\displaystyle t} , and depends on both the state {\\displaystyle x_{nt}} and unobserved factors {\\displaystyle \\varepsilon _{nit}} {\\displaystyle T} is the time horizon The expectation {\\displaystyle \\mathbb {E} \\left(\\cdot \\right)} is taken over both the {\\displaystyle x_{nt}} 's and {\\displaystyle \\varepsilon _{nit}} 's in {\\displaystyle U_{nit}} . That is, the agent is uncertain about future transitions in the states, and is also uncertain about future realizations of unobserved factors.",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle {\\begin{alignedat}{5}U_{nit}\\left(x_{nt},\\varepsilon _{nit}\\right)&&\\;=\\;&&u_{nit}&&\\;+\\;&&\\varepsilon _{nit}\\\\&&\\;=\\;&&X_{nt}\\alpha _{i}&&\\;+\\;&&\\varepsilon _{nit}\\end{alignedat}}}": {
    "before": "The flow utility can be written as an additive sum, consisting of deterministic and stochastic elements. The deterministic component can be written as a linear function of the structural parameters .",
    "after": "2. The optimization problem can be written as a Bellman equation",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle V_{nt}(x_{nt})=\\mathbb {E} \\max _{i}\\left\\{u_{nit}(x_{nt})+\\varepsilon _{nit}+\\beta \\int _{x_{t+1}}V_{nt+1}(x_{nt+1})\\,dF\\left(x_{t+1}\\mid x_{t}\\right)\\right\\}}": {
    "before": "Define by {\\displaystyle V_{nt}(x_{nt})} the ex ante value function for individual {\\displaystyle n} in period {\\displaystyle t} just before {\\displaystyle \\varepsilon _{nt}} is revealed:",
    "after": "where the expectation operator {\\displaystyle \\mathbb {E} } is over the {\\displaystyle \\varepsilon } 's, and where {\\displaystyle dF\\left(x_{t+1}\\mid x_{t}\\right)} represents the probability distribution over {\\displaystyle x_{t+1}} conditional on {\\displaystyle x_{t}} . The expectation over state transitions is accomplished by taking the integral over this probability distribution.",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle V_{nt}(x_{nt})=\\mathbb {E} \\max _{i}\\left\\{v_{nit}(x_{nt})+\\varepsilon _{nit}\\right\\}}": {
    "before": "It is possible to decompose {\\displaystyle V_{nt}(x_{nt})} into deterministic and stochastic components:",
    "after": "where {\\displaystyle v_{nit}} is the value to choosing alternative {\\displaystyle i} at time {\\displaystyle t} and is written as",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle v_{nit}(x_{nt})=u_{nit}\\left(x_{nt}\\right)+\\beta \\int _{x_{t+1}}\\mathbb {E} \\max _{j}\\left\\{v_{njt+1}(x_{nt+1})+\\varepsilon _{njt+1}\\right\\}\\,dF(x_{t+1}\\mid x_{t})}": {
    "before": "where {\\displaystyle v_{nit}} is the value to choosing alternative {\\displaystyle i} at time {\\displaystyle t} and is written as",
    "after": "where now the expectation {\\displaystyle \\mathbb {E} } is taken over the {\\displaystyle \\varepsilon _{njt+1}} .",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle P_{nit}={\\frac {\\exp(v_{nit})}{\\sum _{j=1}^{J}\\exp(v_{njt})}}}": {
    "before": "For the case where {\\displaystyle \\varepsilon _{nit}} is multinomial logit (i.e. drawn iid from the Type I extreme value distribution ), the formulas for the choice probabilities would be:",
    "after": "Estimation [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle U(x_{t},\\xi _{t},d,\\theta )={\\begin{cases}-c(x_{t},\\theta )+\\xi _{t,{\\text{keep}}},&\\\\-RC-c(0,\\theta )+\\xi _{t,{\\text{replace}}},&\\end{cases}}=u(x_{t},d,\\theta )+{\\begin{cases}\\xi _{t,{\\text{keep}}},&{\\textrm {if}}\\;\\;d={\\text{keep}},\\\\\\xi _{t,{\\text{replace}}},&{\\textrm {if}}\\;\\;d={\\text{replace}},\\end{cases}}}": {
    "before": "Let {\\displaystyle x_{t}} denote the odometer reading (mileage) at period {\\displaystyle t} , {\\displaystyle c(x_{t},\\theta )} cost of operating the bus which depends on the vector of parameters {\\displaystyle \\theta } , {\\displaystyle RC} cost of replacing the engine, and {\\displaystyle \\beta } the discount factor . Then the per-period utility is given by",
    "after": "where {\\displaystyle d} denotes the decision (keep or replace) and {\\displaystyle \\xi _{t,{\\text{keep}}}} and {\\displaystyle \\xi _{t,{\\text{replace}}}} represent the component of the utility observed by Harold Zurcher, but not John Rust. It is assumed that {\\displaystyle \\xi _{t,{\\text{keep}}}} and {\\displaystyle \\xi _{t,{\\text{replace}}}} are independent and identically distributed with the Type I extreme value distribution , and that {\\displaystyle \\xi _{t,\\bullet }} are independent of {\\displaystyle \\xi _{t-1,\\bullet }} conditional on {\\displaystyle x_{t}} .",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle V(x,\\xi ,\\theta )=\\max _{d={\\text{keep}},{\\text{replace}}}\\left\\{u(x,d,\\theta )+\\xi _{d}+\\iint V(x',\\xi ',\\theta )q(d\\xi '\\mid x',\\theta )p(dx'\\mid x,d,\\theta )\\right\\}}": {
    "before": "Then the optimal decisions satisfy the Bellman equation",
    "after": "where {\\displaystyle p(dx'\\mid x,d,\\theta )} and {\\displaystyle q(d\\xi '\\mid x',\\theta )} are respectively transition densities for the observed and unobserved states variables. Time indices in the Bellman equation are dropped because the model is formulated in the infinite horizon settings, the unknown optimal policy is stationary , i.e. independent of time.",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle P(d\\mid x,\\theta )={\\frac {\\exp\\{u(x,d,\\theta )+\\beta EV(x,d,\\theta )\\}}{\\sum _{d'\\in D(x)}\\exp\\{u(x,d',\\theta )+\\beta EV(x,d',\\theta )\\}}}}": {
    "before": "Given the distributional assumption on {\\displaystyle q(d\\xi '\\mid x',\\theta )} , the probability of particular choice {\\displaystyle d} is given by",
    "after": "where {\\displaystyle EV(x,d,\\theta )} is a unique solution to the functional equation",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle EV(x,d,\\theta )=\\int \\left[\\log \\left(\\sum _{d={\\text{keep}},{\\text{replace}}}\\exp\\{u(x,d',\\theta )+\\beta EV(x',d',\\theta )\\}\\right)\\right]p(x'\\mid x,d,\\theta ).}": {
    "before": "where {\\displaystyle EV(x,d,\\theta )} is a unique solution to the functional equation",
    "after": "It can be shown that the latter functional equation defines a contraction mapping if the state space {\\displaystyle x_{t}} is bounded, so there will be a unique solution {\\displaystyle EV(x,d,\\theta )} for any {\\displaystyle \\theta } , and further the implicit function theorem holds, so {\\displaystyle EV(x,d,\\theta )} is also a smooth function of {\\displaystyle \\theta } for each {\\displaystyle (x,d)} .",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle L(\\theta )=\\sum _{i=1}^{N}\\sum _{t=1}^{T_{i}}\\log(P(d_{it}\\mid x_{it},\\theta ))+\\log(p(x_{it}\\mid x_{it-1},d_{it-1},\\theta )),}": {
    "before": "The contraction mapping above can be solved numerically for the fixed point {\\displaystyle EV(x,d,\\theta )} that yields choice probabilities {\\displaystyle P(d\\mid x,\\theta )} for any given value of {\\displaystyle \\theta } . The log-likelihood function can then be formulated as",
    "after": "where {\\displaystyle x_{i,t}} and {\\displaystyle d_{i,t}} represent data on state variables (odometer readings) and decision (keep or replace) for {\\displaystyle i=1,\\dots ,N} individual buses, each in {\\displaystyle t=1,\\dots ,T_{i}} periods.",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle {\\begin{aligned}\\max &\\qquad L(\\theta )&\\\\{\\text{subject to}}&\\qquad EV(x,d,\\theta )=\\int \\left[\\log \\left(\\sum _{d={\\text{keep}},{\\text{replace}}}\\exp\\{u(x,d',\\theta )+\\beta EV(x',d',\\theta )\\}\\right)\\right]p(x'\\mid x,d,\\theta )\\end{aligned}}}": {
    "before": "In the nested fixed point algorithm, {\\displaystyle P(d\\mid x,\\theta )} is recalculated for each guess of the parameters θ . The MPEC method instead solves the constrained optimization problem: ",
    "after": "This method is faster to compute than non-optimized implementations of the nested fixed point algorithm, and takes about as long as highly optimized implementations. ",
    "url": "https://en.wikipedia.org/wiki/Dynamic discrete choice"
  },
  "{\\displaystyle {\\begin{aligned}&{}\\quad F_{X_{n},X_{n+1},\\dots ,X_{n+N-1}}(x_{n},x_{n+1},\\dots ,x_{n+N-1})\\\\&=F_{X_{n+k},X_{n+k+1},\\dots ,X_{n+k+N-1}}(x_{n},x_{n+1},\\dots ,x_{n+N-1}),\\end{aligned}}}": {
    "before": "In probability theory – specifically in the theory of stochastic processes , a stationary sequence is a random sequence whose joint probability distribution is invariant over time. If a random sequence X j is stationary then the following holds:",
    "after": "where F is the joint cumulative distribution function of the random variables in the subscript.",
    "url": "https://en.wikipedia.org/wiki/Stationary sequence"
  },
  "{\\displaystyle E(X[n])=\\mu \\quad {\\text{for all }}n.}": {
    "before": "If a sequence is stationary then it has a constant mean (which may not be finite):",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Stationary sequence"
  },
  "{\\displaystyle U(\\{c_{t}\\}_{t=0}^{\\infty })=\\sum _{t=0}^{\\infty }{f(t)u(c_{t})}} .": {
    "before": "A discount function is used in economic models to describe the weights placed on rewards received at different points in time. For example, if time is discrete and utility is time-separable, with the discount function {\\displaystyle f(t)} having a negative first derivative and with {\\displaystyle c_{t}} (or {\\displaystyle c(t)} in continuous time) defined as consumption at time t , total utility from an infinite stream of consumption is given by",
    "after": "Total utility in the continuous-time case is given by",
    "url": "https://en.wikipedia.org/wiki/Discount function"
  },
  "{\\displaystyle U(\\{c(t)\\}_{t=0}^{\\infty })=\\int _{0}^{\\infty }{f(t)u(c(t))dt}}": {
    "before": "Total utility in the continuous-time case is given by",
    "after": "provided that this integral exists.",
    "url": "https://en.wikipedia.org/wiki/Discount function"
  },
  "{\\displaystyle \\operatorname {Var} \\left(\\operatorname {Re} ({\\tilde {X}}_{j})\\right)=\\operatorname {Var} \\left(\\operatorname {Im} ({\\tilde {X}}_{j})\\right)=S_{1}(f_{j})}": {
    "before": "Let {\\displaystyle X_{1},\\ldots ,X_{N}} be a stationary Gaussian time series with ( one-sided ) power spectral density {\\displaystyle S_{1}(f)} , where {\\displaystyle N} is even and samples are taken at constant sampling intervals {\\displaystyle \\Delta _{t}} . Let {\\displaystyle {\\tilde {X}}_{1},\\ldots ,{\\tilde {X}}_{N/2+1}} be the (complex-valued) discrete Fourier transform (DFT) of the time series. Then for the Whittle likelihood one effectively assumes independent zero-mean Gaussian distributions for all {\\displaystyle {\\tilde {X}}_{j}} with variances for the real and imaginary parts given by",
    "after": "where {\\displaystyle f_{j}={\\frac {j}{N\\,\\Delta _{t}}}} is the {\\displaystyle j} th Fourier frequency. This approximate model immediately leads to the (logarithmic) likelihood function",
    "url": "https://en.wikipedia.org/wiki/Whittle likelihood"
  },
  "{\\displaystyle value=mp+lt} ,": {
    "before": "",
    "after": "{\\displaystyle value}",
    "url": "https://en.wikipedia.org/wiki/Marxian economics"
  },
  "{\\displaystyle \\nu (W)=\\min\\{\\#W':W'\\subseteq W;\\cap W'=\\emptyset \\}}": {
    "before": "The Nakamura number {\\displaystyle \\nu (W)} of a simple game {\\displaystyle W} is the size (cardinal number) of the smallest collection of winning coalitions with empty intersection: ",
    "after": "if {\\displaystyle \\cap W=\\cap _{S\\in W}S=\\emptyset } (no veto player);  otherwise, {\\displaystyle \\nu (W)=+\\infty } (greater than any cardinal number).",
    "url": "https://en.wikipedia.org/wiki/Nakamura number"
  },
  "{\\displaystyle \\operatorname {R} _{\\mathbf {X} \\mathbf {Y} }={\\begin{bmatrix}\\operatorname {E} [X_{1}Y_{1}]&\\operatorname {E} [X_{1}Y_{2}]&\\cdots &\\operatorname {E} [X_{1}Y_{n}]\\\\\\\\\\operatorname {E} [X_{2}Y_{1}]&\\operatorname {E} [X_{2}Y_{2}]&\\cdots &\\operatorname {E} [X_{2}Y_{n}]\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\\\operatorname {E} [X_{m}Y_{1}]&\\operatorname {E} [X_{m}Y_{2}]&\\cdots &\\operatorname {E} [X_{m}Y_{n}]\\\\\\\\\\end{bmatrix}}}": {
    "before": "and has dimensions {\\displaystyle m\\times n} . Written component-wise:",
    "after": "The random vectors {\\displaystyle \\mathbf {X} } and {\\displaystyle \\mathbf {Y} } need not have the same dimension, and either might be a scalar value.",
    "url": "https://en.wikipedia.org/wiki/Cross-correlation matrix"
  },
  "{\\displaystyle \\operatorname {E} [\\mathbf {X} \\mathbf {Y} ^{\\rm {T}}]=\\operatorname {E} [\\mathbf {X} ]\\operatorname {E} [\\mathbf {Y} ]^{\\rm {T}}.}": {
    "before": "Two random vectors {\\displaystyle \\mathbf {X} =(X_{1},\\ldots ,X_{m})^{\\rm {T}}} and {\\displaystyle \\mathbf {Y} =(Y_{1},\\ldots ,Y_{n})^{\\rm {T}}} are called uncorrelated if",
    "after": "They are uncorrelated if and only if their cross-covariance matrix {\\displaystyle \\operatorname {K} _{\\mathbf {X} \\mathbf {Y} }} matrix is zero.",
    "url": "https://en.wikipedia.org/wiki/Cross-correlation matrix"
  },
  "{\\displaystyle \\operatorname {E} [\\mathbf {Z} \\mathbf {W} ^{\\rm {H}}]=\\operatorname {E} [\\mathbf {Z} ]\\operatorname {E} [\\mathbf {W} ]^{\\rm {H}}}": {
    "before": "In the case of two complex random vectors {\\displaystyle \\mathbf {Z} } and {\\displaystyle \\mathbf {W} } they are called uncorrelated if",
    "after": "and {\\displaystyle \\operatorname {E} [\\mathbf {Z} \\mathbf {W} ^{\\rm {T}}]=\\operatorname {E} [\\mathbf {Z} ]\\operatorname {E} [\\mathbf {W} ]^{\\rm {T}}.}",
    "url": "https://en.wikipedia.org/wiki/Cross-correlation matrix"
  },
  "{\\displaystyle \\operatorname {E} [\\mathbf {Z} \\mathbf {W} ^{\\rm {T}}]=\\operatorname {E} [\\mathbf {Z} ]\\operatorname {E} [\\mathbf {W} ]^{\\rm {T}}.}": {
    "before": "{\\displaystyle \\operatorname {E} [\\mathbf {Z} \\mathbf {W} ^{\\rm {H}}]=\\operatorname {E} [\\mathbf {Z} ]\\operatorname {E} [\\mathbf {W} ]^{\\rm {H}}} and",
    "after": "Properties [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Cross-correlation matrix"
  },
  "{\\displaystyle \\operatorname {K} _{\\mathbf {X} \\mathbf {Y} }=\\operatorname {E} [(\\mathbf {X} -\\operatorname {E} [\\mathbf {X} ])(\\mathbf {Y} -\\operatorname {E} [\\mathbf {Y} ])^{\\rm {T}}]=\\operatorname {R} _{\\mathbf {X} \\mathbf {Y} }-\\operatorname {E} [\\mathbf {X} ]\\operatorname {E} [\\mathbf {Y} ]^{\\rm {T}}} Respectively for complex random vectors: {\\displaystyle \\operatorname {K} _{\\mathbf {Z} \\mathbf {W} }=\\operatorname {E} [(\\mathbf {Z} -\\operatorname {E} [\\mathbf {Z} ])(\\mathbf {W} -\\operatorname {E} [\\mathbf {W} ])^{\\rm {H}}]=\\operatorname {R} _{\\mathbf {Z} \\mathbf {W} }-\\operatorname {E} [\\mathbf {Z} ]\\operatorname {E} [\\mathbf {W} ]^{\\rm {H}}}": {
    "before": "The cross-correlation is related to the cross-covariance matrix as follows:",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Cross-correlation matrix"
  },
  "{\\displaystyle m_{t}\\;=\\;M(u_{t},v_{t})\\;=\\;\\mu u_{t}^{a}v_{t}^{b}}": {
    "before": "A matching function is a mathematical relationship that describes the formation of new relationships (also called 'matches') from unmatched agents of the appropriate types. For example, in the context of job formation, matching functions are sometimes assumed to have the following ' Cobb–Douglas ' form:",
    "after": "where {\\displaystyle \\,\\mu \\,} , {\\displaystyle \\,a\\,} , and {\\displaystyle \\,b\\,} are positive constants. In this equation, {\\displaystyle \\,u_{t}\\,} represents the number of unemployed job seekers in the economy at a given time {\\displaystyle \\,t\\,} , and {\\displaystyle \\,v_{t}\\,} is the number of vacant jobs firms are trying to fill. The number of new relationships (matches) created (per unit of time) is given by {\\displaystyle \\,m_{t}\\,} .",
    "url": "https://en.wikipedia.org/wiki/Search and matching theory (economics)"
  },
  "{\\displaystyle n_{t+1}\\;=\\mu u_{t}^{a}v_{t}^{b}+(1-\\delta )n_{t}}": {
    "before": "If the fraction of jobs that separate (due to firing, quits, and so forth) from one period to the next is {\\displaystyle \\,\\delta \\,} , then to calculate the change in employment from one period to the next we must add the formation of new matches and subtract off the separation of old matches. A period may be treated as a week, a month, a quarter, or some other convenient period of time, depending on the data under consideration. (For simplicity, we are ignoring the entry of new workers into the labor force, and death or retirement of old workers, but these issues can be accounted for as well.) Suppose we write the number of workers employed in period {\\displaystyle \\,t\\,} as {\\displaystyle \\,n_{t}=L_{t}-u_{t}\\,} , where {\\displaystyle \\,L_{t}\\,} is the labor force in period {\\displaystyle \\,t\\,} . Then given the matching function described above, the dynamics of employment over time would be given by",
    "after": "For simplicity, many studies treat {\\displaystyle \\,\\delta \\,} as a fixed constant. But the fraction of workers separating per period of time can be determined endogenously if we assume that the value of being matched varies over time for each worker-firm pair (due, for example, to changes in productivity ). ",
    "url": "https://en.wikipedia.org/wiki/Search and matching theory (economics)"
  },
  "{\\displaystyle W=\\sum _{i=1}^{n}Y_{i}}": {
    "before": "The utilitarian or Benthamite social welfare function measures social welfare as the total or sum of individual incomes:",
    "after": "where {\\displaystyle W} is social welfare and {\\displaystyle Y_{i}} is the income of individual {\\displaystyle i} among {\\displaystyle n} individuals in society. In this case, maximizing the social welfare means maximizing the total income of the people in the society, without regard to how incomes are distributed in society. It does not distinguish between an income transfer from rich to poor and vice versa. If an income transfer from the poor to the rich results in a bigger increase in the utility of the rich than the decrease in the utility of the poor, the society is expected to accept such a transfer, because the total utility of the society has increased as a whole. Alternatively, society's welfare can also be measured under this function by taking the average of individual incomes:",
    "url": "https://en.wikipedia.org/wiki/Social welfare function"
  },
  "{\\displaystyle W={\\frac {1}{n}}\\sum _{i=1}^{n}Y_{i}={\\overline {Y}}}": {
    "before": "where {\\displaystyle W} is social welfare and {\\displaystyle Y_{i}} is the income of individual {\\displaystyle i} among {\\displaystyle n} individuals in society. In this case, maximizing the social welfare means maximizing the total income of the people in the society, without regard to how incomes are distributed in society. It does not distinguish between an income transfer from rich to poor and vice versa. If an income transfer from the poor to the rich results in a bigger increase in the utility of the rich than the decrease in the utility of the poor, the society is expected to accept such a transfer, because the total utility of the society has increased as a whole. Alternatively, society's welfare can also be measured under this function by taking the average of individual incomes:",
    "after": "In contrast, the max-min or Rawlsian social welfare function (based on the philosophical work of John Rawls ) measures the social welfare of society on the basis of the welfare of the least well-off individual member of society:",
    "url": "https://en.wikipedia.org/wiki/Social welfare function"
  },
  "{\\displaystyle W=\\min(Y_{1},Y_{2},\\cdots ,Y_{n})}": {
    "before": "In contrast, the max-min or Rawlsian social welfare function (based on the philosophical work of John Rawls ) measures the social welfare of society on the basis of the welfare of the least well-off individual member of society:",
    "after": "Here maximizing societal welfare would mean maximizing the income of the poorest person in society without regard for the income of other individuals.",
    "url": "https://en.wikipedia.org/wiki/Social welfare function"
  },
  "{\\displaystyle W_{\\mathrm {Gini} }={\\overline {Y}}(1-G)}": {
    "before": "These two social welfare functions express very different views about how a society would need to be organised in order to maximize welfare, with the first emphasizing total incomes and the second emphasizing the needs of the worst-off. The max-min welfare function can be seen as reflecting an extreme form of uncertainty aversion on the part of society as a whole, since it is concerned only with the worst conditions that a member of society could face.Amartya Sen proposed a welfare function in 1973:",
    "after": "The average per capita income of a measured group (e.g. nation) is multiplied with {\\displaystyle (1-G)} where {\\displaystyle G} is the Gini index , a relative inequality measure. James E. Foster (1996) proposed to use one of Atkinson 's Indexes, which is an entropy measure. Due to the relation between Atkinsons entropy measure and the Theil index , Foster's welfare function also can be computed directly using the Theil-L Index.",
    "url": "https://en.wikipedia.org/wiki/Social welfare function"
  },
  "{\\displaystyle W_{\\mathrm {Theil-L} }={\\overline {Y}}\\mathrm {e} ^{-T_{L}}}": {
    "before": "The average per capita income of a measured group (e.g. nation) is multiplied with {\\displaystyle (1-G)} where {\\displaystyle G} is the Gini index , a relative inequality measure. James E. Foster (1996) proposed to use one of Atkinson 's Indexes, which is an entropy measure. Due to the relation between Atkinsons entropy measure and the Theil index , Foster's welfare function also can be computed directly using the Theil-L Index.",
    "after": "The value yielded by this function has a concrete meaning. There are several possible incomes which could be earned by a person , who randomly is selected from a population with an unequal distribution of incomes. This welfare function marks the income, which a randomly selected person is most likely to have. Similar to the median , this income will be smaller than the average per capita income.",
    "url": "https://en.wikipedia.org/wiki/Social welfare function"
  },
  "{\\displaystyle W_{\\mathrm {Theil-T} }={\\overline {Y}}\\mathrm {e} ^{-T_{T}}}": {
    "before": "The value yielded by this function has a concrete meaning. There are several possible incomes which could be earned by a person , who randomly is selected from a population with an unequal distribution of incomes. This welfare function marks the income, which a randomly selected person is most likely to have. Similar to the median , this income will be smaller than the average per capita income.",
    "after": "Here the Theil-T index is applied. The inverse value yielded by this function has a concrete meaning as well. There are several possible incomes to which a Euro may belong, which is randomly picked from the sum of all unequally distributed incomes. This welfare function marks the income, which a randomly selected Euro most likely belongs to. The inverse value of that function will be larger than the average per capita income.",
    "url": "https://en.wikipedia.org/wiki/Social welfare function"
  },
  "{\\displaystyle W(u_{1},\\dots ,u_{n})=\\sum _{i=1}^{n}w(u_{i})}": {
    "before": "Every preference relation with properties 1–4 can be represented as by a function W which is a sum of the form:",
    "after": "where w is a continuous increasing function.",
    "url": "https://en.wikipedia.org/wiki/Social welfare function"
  },
  "Total volume (#) = Trial volume (#) + Repeat volume (#) ": {
    "before": "Volume projections combine trial volume and repeat volume, that is:",
    "after": "References [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Volume projections"
  },
  "{\\displaystyle \\Pi _{1}(Q)=p(Q)q_{1}-\\chi q_{1}} {\\displaystyle \\Pi _{2}(Q)=p(Q)q_{2}-\\chi q_{2}}": {
    "before": "Cournot's model of competition is typically presented for the case of a duopoly market structure; the following example provides a straightforward analysis of the Cournot model for the case of Duopoly. Therefore, suppose we have a market consisting of only two firms which we will call firm 1 and firm 2. For simplicity, we assume each firm faces the same marginal cost. That is, for a given firm {\\displaystyle i} 's output quantity, denoted {\\displaystyle q_{i}} where {\\displaystyle i\\in \\{1,2\\}} , firm {\\displaystyle i} 's cost of producing {\\displaystyle q_{i}} units of output is given by {\\displaystyle C(q_{i})=\\chi q_{i}} , where {\\displaystyle \\chi } is the marginal cost. This assumption tells us that both firms face the same cost-per-unit produced. Therefore, as each firm's profit is equal to its revenues minus costs, where revenue equals the number of units produced multiplied by the market price, we can denote the profit functions for firm 1 and firm 2 as follows:",
    "after": "Note that in the above profit functions we have price as a function of total output which we denote as {\\displaystyle Q} and for two firms we must have {\\displaystyle Q=q_{1}+q_{2}} . For example's sake, let us assume that price (inverse demand function) is linear and of the form {\\displaystyle p=a-bQ} . So, the inverse demand function can then be rewritten as {\\displaystyle p=a-bq_{1}-bq_{2}} .",
    "url": "https://en.wikipedia.org/wiki/Cournot competition"
  },
  "{\\displaystyle \\Pi _{1}(q_{1},q_{2})=(a-bq_{1}-bq_{2}-\\chi )q_{1}} {\\displaystyle \\Pi _{2}(q_{1},q_{2})=(a-bq_{1}-bq_{2}-\\chi )q_{2}}": {
    "before": "Now, substituting our equation for price in place of {\\displaystyle p(Q)} we can write each firm's profit function as:",
    "after": "As firms are assumed to be profit-maximizers, the first-order conditions (F.O.C.s) for each firm are:",
    "url": "https://en.wikipedia.org/wiki/Cournot competition"
  },
  "{\\displaystyle {\\frac {\\partial \\Pi _{1}(q_{1},q_{2})}{\\partial q_{1}}}=a-2bq_{1}-bq_{2}-\\chi =0} {\\displaystyle {\\frac {\\partial \\Pi _{2}(q_{1},q_{2})}{\\partial q_{2}}}=a-bq_{1}-2bq_{2}-\\chi =0}": {
    "before": "As firms are assumed to be profit-maximizers, the first-order conditions (F.O.C.s) for each firm are:",
    "after": "The F.O.C.s state that firm {\\displaystyle i} is producing at the profit-maximizing level of output when the marginal cost ( {\\displaystyle {\\text{MC}}} ) is equal to the marginal revenue ( {\\displaystyle {\\text{MR}}} ). Intuitively, this suggests that firms will produce up to the point where it remains profitable to do so, as any further production past this point will mean that {\\displaystyle {\\text{MC}}>{\\text{MR}}} , and therefore production beyond this point results in the firm losing money for each additional unit produced. Notice that at the profit-maximizing quantity where {\\displaystyle {\\text{MC}}={\\text{MR}}} , we must have {\\displaystyle {\\text{MC}}-{\\text{MR}}=0} which is why we set the above equations equal to zero.",
    "url": "https://en.wikipedia.org/wiki/Cournot competition"
  },
  "{\\displaystyle q_{1}={\\frac {a-\\chi }{2b}}-{\\frac {q_{2}}{2}}} {\\displaystyle q_{2}={\\frac {a-\\chi }{2b}}-{\\dfrac {q_{1}}{2}}}": {
    "before": "Now that we have two equations describing the states at which each firm is producing at the profit-maximizing quantity, we can simply solve this system of equations to obtain each firm's optimal level of output, {\\displaystyle q_{1},q_{2}} for firms 1 and 2 respectively. So, we obtain:",
    "after": "These functions describe each firm's optimal (profit-maximizing) quantity of output given the price firms face in the market, {\\displaystyle p} , the marginal cost, {\\displaystyle \\chi } , and output quantity of rival firms. The functions can be thought of as describing a firm's \"Best Response\" to the other firm's level of output.",
    "url": "https://en.wikipedia.org/wiki/Cournot competition"
  },
  "{\\displaystyle f(D_{1}+D_{2})+D_{1}f'(D_{1}+D_{2})=0} and {\\displaystyle f(D_{1}+D_{2})+D_{2}f'(D_{1}+D_{2})=0} .": {
    "before": "The revenues accruing to the two proprietors are {\\displaystyle pD_{1}} and {\\displaystyle pD_{2}} , i.e., {\\displaystyle f(D_{1}+D_{2})\\cdot D_{1}} and {\\displaystyle f(D_{1}+D_{2})\\cdot D_{2}} . The first proprietor maximizes profit by optimizing over the parameter {\\displaystyle D_{1}} under his control, giving the condition that the partial derivative of his profit with respect to {\\displaystyle D_{1}} should be 0, and the mirror-image reasoning applies to his or her rival. We thus get the equations:",
    "after": "The equlibirum position is found by solving these two equations simultaneously. This is most easily done by adding and subtracting them, turning them into:",
    "url": "https://en.wikipedia.org/wiki/Cournot competition"
  },
  "{\\displaystyle D_{1}=D_{2}} and {\\displaystyle 2f(D)+Df'(D)=0} , where {\\displaystyle D=D_{1}+D_{2}} .": {
    "before": "The equlibirum position is found by solving these two equations simultaneously. This is most easily done by adding and subtracting them, turning them into:",
    "after": "Thus, we see that the two proprietors supply equal quantities, and that the total quantity sold is the root of a single nonlinear equation in {\\displaystyle D} .",
    "url": "https://en.wikipedia.org/wiki/Cournot competition"
  },
  "{\\displaystyle f(D_{2})=0} and {\\displaystyle f(D_{2})+D_{2}f'(D_{2})=0} .": {
    "before": "Since proprietors move towards the equilibrium position it follows that the equilibrium is stable, but Cournot remarks that if the red and blue curves were interchanged then this would cease to be true. He adds that it is easy to see that the corresponding diagram would be inadmissible since, for instance, it is necessarily the case that {\\displaystyle m_{1}>m_{2}} . To verify this, notice that when {\\displaystyle D_{1}} is 0, the two equations reduce to:",
    "after": "The first of these corresponds to the quantity {\\displaystyle D_{2}} sold when the price is zero (which is the maximum quantity the public is willing to consume), while the second states that the derivative of {\\displaystyle D_{2}f(D_{2})} with respect to {\\displaystyle D_{2}} is 0, but {\\displaystyle D_{2}f(D_{2})} is the monetary value of an aggregate sales quantity {\\displaystyle D_{2}} , and the turning point of this value is a maximum. Evidently, the sales quantity which maximizes monetary value is reached before the maximum possible sales quantity (which corresponds to a value of 0). So, the root {\\displaystyle m_{1}} of the first equation is necessarily greater than the root {\\displaystyle m_{2}} of the second equation.",
    "url": "https://en.wikipedia.org/wiki/Cournot competition"
  },
  "{\\displaystyle V=(HH\\cdot TR\\cdot TU)+(HH\\cdot TR\\cdot MR\\cdot RR\\cdot RU)}": {
    "before": "The Fourt–Woodlock equation (sometimes misspelled Fort-Woodlock equation) is a market research tool to describe the total volume of consumer product purchases per year based on households which initially make trial purchases of the product and those households which make a repeat purchase within the first year. Since it includes the effects of initial trial and repeat rates, the equation is useful in new product development .The Fourt–Woodlock equation itself is",
    "after": "The left-hand-side of the equation is the volume of purchases per unit time (usually taken to be one year). On the right-hand-side, the first parentheses describes trial volume, and the second describes repeat volume.",
    "url": "https://en.wikipedia.org/wiki/Fourt–Woodlock equation"
  },
  "{\\displaystyle {\\begin{aligned}x(t+1)&=x(t)\\left[1+b{\\Big (}y(t),z(t){\\Big )}-d{\\Big (}y(t),z(t){\\Big )}\\right],\\\\y(t+1)&=y(t)\\left(1+\\gamma -(\\gamma +\\eta ){\\Big [}1-z(t){\\Big ]}^{\\lambda }\\right),\\\\z(t+1)&={\\frac {g{\\Big (}x(t),y(t),z(t),p(t){\\Big )}}{1+g{\\Big (}x(t),y(t),z(t),p(t){\\Big )}}},\\\\p(t+1)&=p(t)(1-\\chi ),\\\\\\ &\\ \\\\\\!\\!\\!{\\text{where,}}\\qquad &\\ \\\\\\ &\\ \\\\b(y,z)&=\\beta _{0}\\left[\\beta _{1}-\\left({\\frac {e^{\\beta y}}{1+e^{\\beta y}}}\\right)\\right],\\\\d(y,z)&=\\alpha _{0}\\left[\\alpha _{1}-\\left({\\frac {e^{\\alpha y}}{1+e^{\\alpha y}}}\\right)\\right]\\left[1+\\alpha _{2}(1-z)^{\\theta }\\right],\\\\g(x,y,z,p)&={\\frac {z}{1-z}}\\,e^{\\,\\delta z^{\\rho }-\\omega f(x,y,p)},\\ {\\text{and}}\\\\f(x,y,p)&=xyp.\\end{aligned}}}": {
    "before": "Denote the four state variables as: {\\displaystyle x(t)} – population, {\\displaystyle y(t)} – per capita output, {\\displaystyle z(t)} – stock of natural capital and {\\displaystyle p(t)} – pollution flow per unit of output. Let {\\displaystyle x,y\\in [0,\\infty )} and {\\displaystyle z,p\\in [0,1]} , then the state variables evolve in discrete time , according to the following recurrence relations ( Sanderson, 1994 ).",
    "after": "Altogether, these equations depend upon 15 parameters.",
    "url": "https://en.wikipedia.org/wiki/Wonderland model"
  },
  "{\\displaystyle {\\begin{aligned}y^{\\prime }=y-\\phi (1-z)^{\\mu }y\\end{aligned}}}": {
    "before": "Abating the effects of pollution draws funds from other sources to pay for cleaning up the environment ( Sanderson, 1994 ). This decreases the value of {\\displaystyle y} entering into the equations for birth, {\\displaystyle b} , and death, {\\displaystyle d} :",
    "after": "The time evolution of {\\displaystyle y(t)} is unaffected because those goods and services needed for pollution abatement must also be considered part of the overall output. The impact of these changes on the environment is expressed by changes to {\\displaystyle f} :",
    "url": "https://en.wikipedia.org/wiki/Wonderland model"
  },
  "{\\displaystyle {\\begin{aligned}f(x,y,p)=xyp-\\kappa {\\frac {e^{\\epsilon \\phi (1-z)^{\\mu }yx}}{1+e^{\\epsilon \\phi (1-z)^{\\mu }yx}}}\\end{aligned}}}": {
    "before": "The time evolution of {\\displaystyle y(t)} is unaffected because those goods and services needed for pollution abatement must also be considered part of the overall output. The impact of these changes on the environment is expressed by changes to {\\displaystyle f} :",
    "after": "These changes introduce three new parameters into the model:",
    "url": "https://en.wikipedia.org/wiki/Wonderland model"
  },
  "{\\displaystyle {\\begin{aligned}y(t+1)&=y(t)\\left(1+\\gamma -\\left(\\gamma +\\eta \\right){\\Big [}1-z(t){\\Big ]}^{\\lambda }-\\gamma _{0}\\,{\\frac {\\tau }{1-\\tau }}\\right),\\\\p(t+1)&=p(t)\\left(1-\\chi -\\chi _{0}{\\frac {\\tau }{1+\\tau }}\\right).\\\\\\end{aligned}}}": {
    "before": "Pollution avoidance aims to prevent pollution from entering into the environment, by making its production unprofitable. This is modeled by means of a pollution tax ( Herbert and Leeves, 1998 , Lempert, et al., 2003 ):",
    "after": "The new parameters for the pollution avoidance model are:",
    "url": "https://en.wikipedia.org/wiki/Wonderland model"
  },
  "follows from the I = PAT hypothesis.": {
    "before": "{\\displaystyle f(x,y,p)}",
    "after": "System behavior[edit]",
    "url": "https://en.wikipedia.org/wiki/Wonderland model"
  },
  "1 Communauté Financière Africaine franc (CFAF) = 100 centimes": {
    "before": "Currency:",
    "after": "Exchange rates:",
    "url": "https://en.wikipedia.org/wiki/Economy of Niger"
  },
  "x amount of qualified labour = y amounts of unskilled labour = z number of workers = p amount of money = q amount of goods.": {
    "before": "The abstraction is completed when a labour market is established which very exactly quantifies the money-price applying to all kinds of different occupational functions, permitting equations such as:",
    "after": "This is what Marx calls a value relationship (\"Wertverhältnis\" in German). It can also be calculated that it costs a certain amount of time and money to train a worker to perform a certain task, and how much value that adds to the workers' labour, giving rise to the notion of human capital.",
    "url": "https://en.wikipedia.org/wiki/Abstract labour and concrete labour"
  },
  "Step 1 Assume a time series of data {\\displaystyle u(1),u(2),\\ldots ,u(N)} . These are {\\displaystyle N} raw data values from measurements equally spaced in time. Step 2 Let {\\displaystyle m\\in \\mathbb {Z} ^{+}} be a positive integer , with {\\displaystyle m\\leq N} , which represents the length of a run of data (essentially a window ). Let {\\displaystyle r\\in \\mathbb {R} ^{+}} be a positive real number , which specifies a filtering level. Let {\\displaystyle n=N-m+1} . Step 3 Define {\\displaystyle \\mathbf {x} (i)={\\big [}u(i),u(i+1),\\ldots ,u(i+m-1){\\big ]}} for each {\\displaystyle i} where {\\displaystyle 1\\leq i\\leq n} . In other words, {\\displaystyle \\mathbf {x} (i)} is an {\\displaystyle m} -dimensional vector that contains the run of data starting with {\\displaystyle u(i)} . Define the distance between two vectors {\\displaystyle \\mathbf {x} (i)} and {\\displaystyle \\mathbf {x} (j)} as the maximum of the distances between their respective components, given by {\\displaystyle {\\begin{aligned}d[\\mathbf {x} (i),\\mathbf {x} (j)]&=\\max _{k}{\\big (}|\\mathbf {x} (i)_{k}-\\mathbf {x} (j)_{k}|{\\big )}\\\\&=\\max _{k}{\\big (}|u(i+k-1)-u(j+k-1)|{\\big )}\\\\\\end{aligned}}} for {\\displaystyle 1\\leq k\\leq m} . Step 4 Define a count {\\displaystyle C_{i}^{m}} as {\\displaystyle C_{i}^{m}(r)={({\\text{number of }}j{\\text{ such that }}d[\\mathbf {x} (i),\\mathbf {x} (j)]\\leq r) \\over n}} for each {\\displaystyle i} where {\\displaystyle 1\\leq i,j\\leq n} . Note that since {\\displaystyle j} takes on all values between 1 and {\\displaystyle n} , the match will be counted when {\\displaystyle j=i} (i.e. when the test subsequence, {\\displaystyle \\mathbf {x} (j)} , is matched against itself, {\\displaystyle \\mathbf {x} (i)} ). Step 5 Define {\\displaystyle \\phi ^{m}(r)={1 \\over n}\\sum _{i=1}^{n}\\log(C_{i}^{m}(r))} where {\\displaystyle \\log } is the natural logarithm , and for a fixed {\\displaystyle m} , {\\displaystyle r} , and {\\displaystyle n} as set in Step 2. Step 6 Define approximate entropy ( {\\displaystyle \\mathrm {ApEn} } ) as {\\displaystyle \\mathrm {ApEn} (m,r,N)(u)=\\phi ^{m}(r)-\\phi ^{m+1}(r)}": {
    "before": "A comprehensive step-by-step tutorial with an explanation of the theoretical foundations of Approximate Entropy is available.  The algorithm is:",
    "after": "Parameter selection Typically, choose {\\displaystyle m=2} or {\\displaystyle m=3} , whereas {\\displaystyle r} depends greatly on the application.",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle {\\begin{aligned}d[\\mathbf {x} (i),\\mathbf {x} (j)]&=\\max _{k}{\\big (}|\\mathbf {x} (i)_{k}-\\mathbf {x} (j)_{k}|{\\big )}\\\\&=\\max _{k}{\\big (}|u(i+k-1)-u(j+k-1)|{\\big )}\\\\\\end{aligned}}}": {
    "before": "as the maximum of the distances between their respective components, given by",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle C_{i}^{m}(r)={({\\text{number of }}j{\\text{ such that }}d[\\mathbf {x} (i),\\mathbf {x} (j)]\\leq r) \\over n}}": {
    "before": "{\\displaystyle C_{i}^{m}} as",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle \\phi ^{m}(r)={1 \\over n}\\sum _{i=1}^{n}\\log(C_{i}^{m}(r))}": {
    "before": "Define",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle \\mathrm {ApEn} (m,r,N)(u)=\\phi ^{m}(r)-\\phi ^{m+1}(r)}": {
    "before": "{\\displaystyle \\mathrm {ApEn} } ) as",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "Parameter selection Typically, choose {\\displaystyle m=2} or {\\displaystyle m=3} , whereas {\\displaystyle r} depends greatly on the application.": {
    "before": "Step 1 Assume a time series of data {\\displaystyle u(1),u(2),\\ldots ,u(N)} . These are {\\displaystyle N} raw data values from measurements equally spaced in time. Step 2 Let {\\displaystyle m\\in \\mathbb {Z} ^{+}} be a positive integer , with {\\displaystyle m\\leq N} , which represents the length of a run of data (essentially a window ). Let {\\displaystyle r\\in \\mathbb {R} ^{+}} be a positive real number , which specifies a filtering level. Let {\\displaystyle n=N-m+1} . Step 3 Define {\\displaystyle \\mathbf {x} (i)={\\big [}u(i),u(i+1),\\ldots ,u(i+m-1){\\big ]}} for each {\\displaystyle i} where {\\displaystyle 1\\leq i\\leq n} . In other words, {\\displaystyle \\mathbf {x} (i)} is an {\\displaystyle m} -dimensional vector that contains the run of data starting with {\\displaystyle u(i)} . Define the distance between two vectors {\\displaystyle \\mathbf {x} (i)} and {\\displaystyle \\mathbf {x} (j)} as the maximum of the distances between their respective components, given by {\\displaystyle {\\begin{aligned}d[\\mathbf {x} (i),\\mathbf {x} (j)]&=\\max _{k}{\\big (}|\\mathbf {x} (i)_{k}-\\mathbf {x} (j)_{k}|{\\big )}\\\\&=\\max _{k}{\\big (}|u(i+k-1)-u(j+k-1)|{\\big )}\\\\\\end{aligned}}} for {\\displaystyle 1\\leq k\\leq m} . Step 4 Define a count {\\displaystyle C_{i}^{m}} as {\\displaystyle C_{i}^{m}(r)={({\\text{number of }}j{\\text{ such that }}d[\\mathbf {x} (i),\\mathbf {x} (j)]\\leq r) \\over n}} for each {\\displaystyle i} where {\\displaystyle 1\\leq i,j\\leq n} . Note that since {\\displaystyle j} takes on all values between 1 and {\\displaystyle n} , the match will be counted when {\\displaystyle j=i} (i.e. when the test subsequence, {\\displaystyle \\mathbf {x} (j)} , is matched against itself, {\\displaystyle \\mathbf {x} (i)} ). Step 5 Define {\\displaystyle \\phi ^{m}(r)={1 \\over n}\\sum _{i=1}^{n}\\log(C_{i}^{m}(r))} where {\\displaystyle \\log } is the natural logarithm , and for a fixed {\\displaystyle m} , {\\displaystyle r} , and {\\displaystyle n} as set in Step 2. Step 6 Define approximate entropy ( {\\displaystyle \\mathrm {ApEn} } ) as {\\displaystyle \\mathrm {ApEn} (m,r,N)(u)=\\phi ^{m}(r)-\\phi ^{m+1}(r)}",
    "after": "An implementation on Physionet,  which is based on Pincus,  use {\\displaystyle d[\\mathbf {x} (i),\\mathbf {x} (j)]<r} instead of {\\displaystyle d[\\mathbf {x} (i),\\mathbf {x} (j)]\\leq r} in Step 4. While a concern for artificially constructed examples, it is usually not a concern in practice.",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle \\ S_{N}=\\{85,80,89,85,80,89,\\ldots \\}}": {
    "before": "Consider a sequence of {\\displaystyle N=51} samples of heart rate equally spaced in time:",
    "after": "Note the sequence is periodic with a period of 3. Let's choose {\\displaystyle m=2} and {\\displaystyle r=3} (the values of {\\displaystyle m} and {\\displaystyle r} can be varied without affecting the result).",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle {\\begin{aligned}\\mathbf {x} (1)&=[u(1)\\ u(2)]=[85\\ 80]\\\\\\mathbf {x} (2)&=[u(2)\\ u(3)]=[80\\ 89]\\\\\\mathbf {x} (3)&=[u(3)\\ u(4)]=[89\\ 85]\\\\\\mathbf {x} (4)&=[u(4)\\ u(5)]=[85\\ 80]\\\\&\\ \\ \\vdots \\end{aligned}}}": {
    "before": "Note the sequence is periodic with a period of 3. Let's choose {\\displaystyle m=2} and {\\displaystyle r=3} (the values of {\\displaystyle m} and {\\displaystyle r} can be varied without affecting the result).Form a sequence of vectors:",
    "after": "Distance is calculated repeatedly as follows. In the first calculation,",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle \\ d[\\mathbf {x} (1),\\mathbf {x} (1)]=\\max _{k}|\\mathbf {x} (1)_{k}-\\mathbf {x} (1)_{k}|=0} which is less than {\\displaystyle r} .": {
    "before": "Distance is calculated repeatedly as follows. In the first calculation,",
    "after": "In the second calculation, note that {\\displaystyle |u(2)-u(3)|>|u(1)-u(2)|} , so",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle \\ d[\\mathbf {x} (1),\\mathbf {x} (2)]=\\max _{k}|\\mathbf {x} (1)_{k}-\\mathbf {x} (2)_{k}|=|u(2)-u(3)|=9} which is greater than {\\displaystyle r} .": {
    "before": "In the second calculation, note that {\\displaystyle |u(2)-u(3)|>|u(1)-u(2)|} , so",
    "after": "Similarly, {\\displaystyle {\\begin{aligned}d[\\mathbf {x} (1)&,\\mathbf {x} (3)]=|u(2)-u(4)|=5>r\\\\d[\\mathbf {x} (1)&,\\mathbf {x} (4)]=|u(1)-u(4)|=|u(2)-u(5)|=0<r\\\\&\\vdots \\\\d[\\mathbf {x} (1)&,\\mathbf {x} (j)]=\\cdots \\\\&\\vdots \\\\\\end{aligned}}}",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle {\\begin{aligned}d[\\mathbf {x} (1)&,\\mathbf {x} (3)]=|u(2)-u(4)|=5>r\\\\d[\\mathbf {x} (1)&,\\mathbf {x} (4)]=|u(1)-u(4)|=|u(2)-u(5)|=0<r\\\\&\\vdots \\\\d[\\mathbf {x} (1)&,\\mathbf {x} (j)]=\\cdots \\\\&\\vdots \\\\\\end{aligned}}}": {
    "before": "{\\displaystyle \\ d[\\mathbf {x} (1),\\mathbf {x} (2)]=\\max _{k}|\\mathbf {x} (1)_{k}-\\mathbf {x} (2)_{k}|=|u(2)-u(3)|=9} which is greater than {\\displaystyle r} .Similarly,",
    "after": "The result is a total of 17 terms {\\displaystyle \\mathbf {x} (j)} such that {\\displaystyle d[\\mathbf {x} (1),\\mathbf {x} (j)]\\leq r} . These include {\\displaystyle \\mathbf {x} (1),\\mathbf {x} (4),\\mathbf {x} (7),\\ldots ,\\mathbf {x} (49)} . In these cases, {\\displaystyle C_{i}^{m}(r)} is",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle \\ C_{1}^{2}(3)={\\frac {17}{50}}} {\\displaystyle \\ C_{2}^{2}(3)={\\frac {17}{50}}} {\\displaystyle \\ C_{3}^{2}(3)={\\frac {16}{50}}} {\\displaystyle \\ C_{4}^{2}(3)={\\frac {17}{50}}\\ \\cdots }": {
    "before": "The result is a total of 17 terms {\\displaystyle \\mathbf {x} (j)} such that {\\displaystyle d[\\mathbf {x} (1),\\mathbf {x} (j)]\\leq r} . These include {\\displaystyle \\mathbf {x} (1),\\mathbf {x} (4),\\mathbf {x} (7),\\ldots ,\\mathbf {x} (49)} . In these cases, {\\displaystyle C_{i}^{m}(r)} is",
    "after": "Note in Step 4, {\\displaystyle 1\\leq i\\leq n} for {\\displaystyle \\mathbf {x} (i)} . So the terms {\\displaystyle \\mathbf {x} (j)} such that {\\displaystyle d[\\mathbf {x} (3),\\mathbf {x} (j)]\\leq r} include {\\displaystyle \\mathbf {x} (3),\\mathbf {x} (6),\\mathbf {x} (9),\\ldots ,\\mathbf {x} (48)} , and the total number is 16.",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle \\phi ^{2}(3)={1 \\over 50}\\sum _{i=1}^{50}\\log(C_{i}^{2}(3))\\approx -1.0982}": {
    "before": "Note in Step 4, {\\displaystyle 1\\leq i\\leq n} for {\\displaystyle \\mathbf {x} (i)} . So the terms {\\displaystyle \\mathbf {x} (j)} such that {\\displaystyle d[\\mathbf {x} (3),\\mathbf {x} (j)]\\leq r} include {\\displaystyle \\mathbf {x} (3),\\mathbf {x} (6),\\mathbf {x} (9),\\ldots ,\\mathbf {x} (48)} , and the total number is 16.At the end of these calculations, we have",
    "after": "Then we repeat the above steps for {\\displaystyle m=3} . First form a sequence of vectors:",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle {\\begin{aligned}\\mathbf {x} (1)&=[u(1)\\ u(2)\\ u(3)]=[85\\ 80\\ 89]\\\\\\mathbf {x} (2)&=[u(2)\\ u(3)\\ u(4)]=[80\\ 89\\ 85]\\\\\\mathbf {x} (3)&=[u(3)\\ u(4)\\ u(5)]=[89\\ 85\\ 80]\\\\\\mathbf {x} (4)&=[u(4)\\ u(5)\\ u(6)]=[85\\ 80\\ 89]\\\\&\\ \\ \\vdots \\end{aligned}}}": {
    "before": "Then we repeat the above steps for {\\displaystyle m=3} . First form a sequence of vectors:",
    "after": "By calculating distances between vector {\\displaystyle \\mathbf {x} (i),\\mathbf {x} (j),1\\leq i\\leq 49} , we find the vectors satisfying the filtering level have the following characteristic:",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle d[\\mathbf {x} (i),\\mathbf {x} (i+3)]=0<r}": {
    "before": "By calculating distances between vector {\\displaystyle \\mathbf {x} (i),\\mathbf {x} (j),1\\leq i\\leq 49} , we find the vectors satisfying the filtering level have the following characteristic:",
    "after": "Therefore, {\\displaystyle \\ C_{1}^{3}(3)={\\frac {17}{49}}} {\\displaystyle \\ C_{2}^{3}(3)={\\frac {16}{49}}} {\\displaystyle \\ C_{3}^{3}(3)={\\frac {16}{49}}} {\\displaystyle \\ C_{4}^{3}(3)={\\frac {17}{49}}\\ \\cdots }",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle \\ C_{1}^{3}(3)={\\frac {17}{49}}} {\\displaystyle \\ C_{2}^{3}(3)={\\frac {16}{49}}} {\\displaystyle \\ C_{3}^{3}(3)={\\frac {16}{49}}} {\\displaystyle \\ C_{4}^{3}(3)={\\frac {17}{49}}\\ \\cdots }": {
    "before": "{\\displaystyle d[\\mathbf {x} (i),\\mathbf {x} (i+3)]=0<r} Therefore,",
    "after": "At the end of these calculations, we have",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle \\phi ^{3}(3)={1 \\over 49}\\sum _{i=1}^{49}\\log(C_{i}^{3}(3))\\approx -1.0982}": {
    "before": "{\\displaystyle \\ C_{1}^{3}(3)={\\frac {17}{49}}} {\\displaystyle \\ C_{2}^{3}(3)={\\frac {16}{49}}} {\\displaystyle \\ C_{3}^{3}(3)={\\frac {16}{49}}} {\\displaystyle \\ C_{4}^{3}(3)={\\frac {17}{49}}\\ \\cdots } At the end of these calculations, we have",
    "after": "Finally, {\\displaystyle \\mathrm {ApEn} =\\phi ^{2}(3)-\\phi ^{3}(3)\\approx 0.000010997}",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle \\mathrm {ApEn} =\\phi ^{2}(3)-\\phi ^{3}(3)\\approx 0.000010997}": {
    "before": "{\\displaystyle \\phi ^{3}(3)={1 \\over 49}\\sum _{i=1}^{49}\\log(C_{i}^{3}(3))\\approx -1.0982} Finally,",
    "after": "The value is very small, so it implies the sequence is regular and predictable, which is consistent with the observation.",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]": {
    "before": "def _phi(m):",
    "after": "C = [",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "len([1 for x_j in x if _maxdist(x_i, x_j) <= r]) / (N - m + 1.0)": {
    "before": "C = [",
    "after": "for x_i in x",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "N = len(U)": {
    "before": "return (N - m + 1.0) ** (-1) * sum(np.log(C))",
    "after": "return abs(_phi(m + 1) - _phi(m))",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  ">>> U = np.array([85, 80, 89] * 17)": {
    "before": "Usage example:",
    "after": ">>> print(ApEn(U, 2, 3))",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  ">>> randU = np.random.choice([85, 80, 89], size=17*3)": {
    "before": "1.0996541105257052e-05",
    "after": ">>> print(ApEn(randU, 2, 3))",
    "url": "https://en.wikipedia.org/wiki/Approximate entropy"
  },
  "{\\displaystyle Y_{t}=f(t)+e_{t},}": {
    "before": "A process { Y } is said to be trend-stationary if ",
    "after": "where t is time, f is any function mapping from the reals to the reals, and { e } is a stationary process. The value {\\displaystyle f(t)} is said to be the trend value of the process at time t .",
    "url": "https://en.wikipedia.org/wiki/Trend-stationary process"
  },
  "{\\displaystyle Y_{t}=a\\cdot t+b+e_{t}}": {
    "before": "Simplest example: stationarity around a linear trend [ edit ]Suppose the variable Y evolves according to",
    "after": "where t is time and e t is the error term, which is hypothesized to be white noise or more generally to have been generated by any stationary process. Then one can use    linear regression to obtain an estimate {\\displaystyle {\\hat {a}}} of the true underlying trend slope {\\displaystyle a} and an estimate {\\displaystyle {\\hat {b}}} of the underlying intercept term b ; if the estimate {\\displaystyle {\\hat {a}}} is significantly different from zero, this is sufficient to show with high confidence that the variable Y is non-stationary. The residuals from this regression are given by",
    "url": "https://en.wikipedia.org/wiki/Trend-stationary process"
  },
  "{\\displaystyle {\\hat {e}}_{t}=Y_{t}-{\\hat {a}}\\cdot t-{\\hat {b}}.}": {
    "before": "where t is time and e t is the error term, which is hypothesized to be white noise or more generally to have been generated by any stationary process. Then one can use    linear regression to obtain an estimate {\\displaystyle {\\hat {a}}} of the true underlying trend slope {\\displaystyle a} and an estimate {\\displaystyle {\\hat {b}}} of the underlying intercept term b ; if the estimate {\\displaystyle {\\hat {a}}} is significantly different from zero, this is sufficient to show with high confidence that the variable Y is non-stationary. The residuals from this regression are given by",
    "after": "If these estimated residuals can be statistically shown to be stationary (more precisely, if one can reject the hypothesis that the true underlying errors are non-stationary), then the residuals are referred to as the detrended data,  and the original series { Y t } is said to be trend-stationary even though it is not stationary.",
    "url": "https://en.wikipedia.org/wiki/Trend-stationary process"
  },
  "{\\displaystyle {\\text{GDP}}_{t}=Be^{at}U_{t}}": {
    "before": "Many economic time series are characterized by exponential growth . For example, suppose that one hypothesizes that gross domestic product is characterized by stationary deviations from a trend involving a constant growth rate. Then it could be modeled as",
    "after": "with U t being hypothesized to be a stationary error process. To estimate the parameters {\\displaystyle a} and B , one first takes  the natural logarithm (ln) of both sides of this equation:",
    "url": "https://en.wikipedia.org/wiki/Trend-stationary process"
  },
  "{\\displaystyle \\ln({\\text{GDP}}_{t})=\\ln B+at+\\ln(U_{t}).}": {
    "before": "with U t being hypothesized to be a stationary error process. To estimate the parameters {\\displaystyle a} and B , one first takes  the natural logarithm (ln) of both sides of this equation:",
    "after": "This log-linear equation is in the same form as the previous linear trend equation and can be detrended in the same way, giving the estimated {\\displaystyle (\\ln U)_{t}} as the detrended value of {\\displaystyle (\\ln {\\text{GDP}})_{t}} , and hence the implied {\\displaystyle U_{t}} as the detrended value of {\\displaystyle {\\text{GDP}}_{t}} , assuming one can reject the hypothesis that {\\displaystyle (\\ln U)_{t}} is non-stationary.",
    "url": "https://en.wikipedia.org/wiki/Trend-stationary process"
  },
  "{\\displaystyle Y_{t}=a\\cdot t+c\\cdot t^{2}+b+e_{t}.}": {
    "before": "Trends do not have to be linear or log-linear. For example, a variable could have a quadratic trend:",
    "after": "This can be regressed linearly in the coefficients using t and t 2 as regressors; again, if the residuals are shown to be stationary then they are the detrended values of {\\displaystyle Y_{t}} .",
    "url": "https://en.wikipedia.org/wiki/Trend-stationary process"
  },
  "{\\displaystyle y_{i}=\\alpha +\\beta x_{i}+\\gamma z_{i}+u_{i}}": {
    "before": "In this case, the endogeneity comes from an uncontrolled confounding variable , a variable that is correlated with both the independent variable in the model and with the error term. (Equivalently, the omitted variable affects the independent variable and separately affects the dependent variable.)Assume that the \"true\" model to be estimated is",
    "after": "but {\\displaystyle z_{i}} is omitted from the regression model (perhaps because there is no way to measure it directly). Then the model that is actually estimated is",
    "url": "https://en.wikipedia.org/wiki/Endogeneity (econometrics)"
  },
  "{\\displaystyle y_{i}=\\alpha +\\beta x_{i}+\\varepsilon _{i}}": {
    "before": "but {\\displaystyle z_{i}} is omitted from the regression model (perhaps because there is no way to measure it directly). Then the model that is actually estimated is",
    "after": "where {\\displaystyle \\varepsilon _{i}=\\gamma z_{i}+u_{i}} (thus, the {\\displaystyle z_{i}} term has been absorbed into the error term).",
    "url": "https://en.wikipedia.org/wiki/Endogeneity (econometrics)"
  },
  "{\\displaystyle y_{i}=\\alpha +\\beta x_{i}^{*}+\\varepsilon _{i}}": {
    "before": "Suppose that a perfect measure of an independent variable is impossible. That is, instead of observing {\\displaystyle x_{i}^{*}} , what is actually observed is {\\displaystyle x_{i}=x_{i}^{*}+\\nu _{i}} where {\\displaystyle \\nu _{i}} is the measurement error or \"noise\". In this case, a model given by",
    "after": "can be written in terms of observables and error terms as",
    "url": "https://en.wikipedia.org/wiki/Endogeneity (econometrics)"
  },
  "{\\displaystyle {\\begin{aligned}y_{i}&=\\alpha +\\beta (x_{i}-\\nu _{i})+\\varepsilon _{i}\\\\[3pt]y_{i}&=\\alpha +\\beta x_{i}+(\\varepsilon _{i}-\\beta \\nu _{i})\\\\[3pt]y_{i}&=\\alpha +\\beta x_{i}+u_{i}\\quad ({\\text{where }}u_{i}=\\varepsilon _{i}-\\beta \\nu _{i})\\end{aligned}}}": {
    "before": "can be written in terms of observables and error terms as",
    "after": "Since both {\\displaystyle x_{i}} and {\\displaystyle u_{i}} depend on {\\displaystyle \\nu _{i}} , they are correlated, so the OLS estimation of {\\displaystyle \\beta } will be biased downward.",
    "url": "https://en.wikipedia.org/wiki/Endogeneity (econometrics)"
  },
  "{\\displaystyle y_{i}=\\beta _{1}x_{i}+\\gamma _{1}z_{i}+u_{i}} {\\displaystyle z_{i}=\\beta _{2}x_{i}+\\gamma _{2}y_{i}+v_{i}}": {
    "before": "Suppose that two variables are codetermined, with each affecting the other according to the following \"structural\" equations :",
    "after": "Estimating either equation by itself results in endogeneity. In the case of the first structural equation, {\\displaystyle E(z_{i}u_{i})\\neq 0} . Solving for {\\displaystyle z_{i}} while assuming that {\\displaystyle 1-\\gamma _{1}\\gamma _{2}\\neq 0} results in",
    "url": "https://en.wikipedia.org/wiki/Endogeneity (econometrics)"
  },
  "{\\displaystyle z_{i}={\\frac {\\beta _{2}+\\gamma _{2}\\beta _{1}}{1-\\gamma _{1}\\gamma _{2}}}x_{i}+{\\frac {1}{1-\\gamma _{1}\\gamma _{2}}}v_{i}+{\\frac {\\gamma _{2}}{1-\\gamma _{1}\\gamma _{2}}}u_{i}} .": {
    "before": "Estimating either equation by itself results in endogeneity. In the case of the first structural equation, {\\displaystyle E(z_{i}u_{i})\\neq 0} . Solving for {\\displaystyle z_{i}} while assuming that {\\displaystyle 1-\\gamma _{1}\\gamma _{2}\\neq 0} results in",
    "after": "Assuming that {\\displaystyle x_{i}} and {\\displaystyle \\gamma _{i}} are uncorrelated with {\\displaystyle u_{i}} ,",
    "url": "https://en.wikipedia.org/wiki/Endogeneity (econometrics)"
  },
  "{\\displaystyle \\operatorname {E} (z_{i}u_{i})={\\frac {\\gamma _{2}}{1-\\gamma _{1}\\gamma _{2}}}\\operatorname {E} (u_{i}u_{i})\\neq 0} .": {
    "before": "Assuming that {\\displaystyle x_{i}} and {\\displaystyle \\gamma _{i}} are uncorrelated with {\\displaystyle u_{i}} ,",
    "after": "Therefore, attempts at estimating either structural equation will be hampered by endogeneity.",
    "url": "https://en.wikipedia.org/wiki/Endogeneity (econometrics)"
  },
  "Let the model be y = f(x, z) + u. If the variable x is sequential exogenous for parameter": {
    "before": "The endogeneity problem is particularly relevant in the context of time series analysis of causal processes. It is common for some factors within a causal system to be dependent for their value in period t on the values of other factors in the causal system in period t − 1. Suppose that the level of pest infestation is independent of all other factors within a given period, but is influenced by the level of rainfall and fertilizer in the preceding period. In this instance it would be correct to say that infestation is exogenous within the period, but endogenous over time.",
    "after": "{\\displaystyle \\alpha }",
    "url": "https://en.wikipedia.org/wiki/Endogeneity (econometrics)"
  },
  "Visit rate from given zone = f(cost from given zone)": {
    "before": "The visit rate is regressed against travel cost in order to create a visit rate curve.",
    "after": "VR=a+b.C",
    "url": "https://en.wikipedia.org/wiki/Travel cost analysis"
  },
  "VR=a+b.C": {
    "before": "Visit rate from given zone = f(cost from given zone)",
    "after": "This curve can then be used to obtain estimates of visit rates given differing levels of total costs.",
    "url": "https://en.wikipedia.org/wiki/Travel cost analysis"
  },
  "{\\displaystyle d_{iu}={\\arg \\max _{d}}~U(d,E[x]).}": {
    "before": "When not including uncertainty, the optimal decision is found using only {\\displaystyle E[x]} , the expected value of the uncertain quantity. Hence, the decision ignoring uncertainty is given by:",
    "after": "The optimal decision taking uncertainty into account is the standard Bayes decision that maximizes expected utility :",
    "url": "https://en.wikipedia.org/wiki/Expected value of including uncertainty"
  },
  "{\\displaystyle d^{*}={\\arg \\max _{d}}{\\int U(d,x)f(x)\\,dx}.}": {
    "before": "The optimal decision taking uncertainty into account is the standard Bayes decision that maximizes expected utility :",
    "after": "The EVIU is the difference in expected utility between these two decisions:",
    "url": "https://en.wikipedia.org/wiki/Expected value of including uncertainty"
  },
  "{\\displaystyle EVIU=\\int _{X}\\left[U(d^{*},x)-U(d_{iu},x)\\right]f(x)\\,dx.}": {
    "before": "The EVIU is the difference in expected utility between these two decisions:",
    "after": "The uncertain quantity x and decision variable d may each be composed of many scalar variables, in which case the spaces X and D are each vector spaces.",
    "url": "https://en.wikipedia.org/wiki/Expected value of including uncertainty"
  },
  "{\\displaystyle EVIU=313.7-151=162.7{\\text{ minutes}}}": {
    "before": "When uncertainty is taken into account, the expected value smooths out (the blue curve), and the optimal action is to leave 140 minutes before the flight. The expected value curve, with a decision at 100 minutes before the flight, shows the expected cost when ignoring uncertainty to be 313.7 minutes, while the expected cost when one leaves 140 minute before the flight is 151 minutes. The difference between these two is the EVIU:",
    "after": "In other words, if uncertainty is explicitly taken into account when the decision is made, an average savings of 162.7 minutes will be realized.",
    "url": "https://en.wikipedia.org/wiki/Expected value of including uncertainty"
  },
  "Time_to_drive_to_airport := LogNormal(median:60,gsdev:1.3)": {
    "before": "The diagram at right is an influence diagram for deciding how early the decision maker should leave home in order to catch a flight at the airport. The single decision, in the green rectangle, is the number of minutes that one will decide to leave prior to the plane's departure time. Four uncertain variables appear on the diagram in cyan ovals: The time required to drive from home to the airport's parking garage (in minutes), time to get from the parking garage to the gate (in minutes), the time before departure that one must be at the gate, and the loss (in minutes) incurred if the flight is missed. Each of these nodes contains a probability distribution, viz:",
    "after": "Time_from_parking_to_gate := LogNormal(median:10,gsdev:1.3)",
    "url": "https://en.wikipedia.org/wiki/Expected value of including uncertainty"
  },
  "Time_from_parking_to_gate := LogNormal(median:10,gsdev:1.3)": {
    "before": "Time_to_drive_to_airport := LogNormal(median:60,gsdev:1.3)",
    "after": "Gate_time_before_departure := Triangular(min:20,mode:30,max:40)",
    "url": "https://en.wikipedia.org/wiki/Expected value of including uncertainty"
  },
  "Gate_time_before_departure := Triangular(min:20,mode:30,max:40)": {
    "before": "Time_from_parking_to_gate := LogNormal(median:10,gsdev:1.3)",
    "after": "Loss_if_miss_the_plane := LogNormal(median:400,stddev:100)",
    "url": "https://en.wikipedia.org/wiki/Expected value of including uncertainty"
  },
  "Loss_if_miss_the_plane := LogNormal(median:400,stddev:100)": {
    "before": "Gate_time_before_departure := Triangular(min:20,mode:30,max:40)",
    "after": "Each of these distributions is taken to be statistically independent. The probability distribution for the first uncertain variable, Time_to_drive_to_airport, with median 60 and a geometric standard deviation of 1.3, is depicted in this graph:",
    "url": "https://en.wikipedia.org/wiki/Expected value of including uncertainty"
  },
  "Time_from_home_to_gate := Time_to_drive_to_airport + Time_from_parking_to_gate + Loss_if_miss_the_plane": {
    "before": "The definitions for each of the computed variables is thus:",
    "after": "Value_per_minute_at_home := 1",
    "url": "https://en.wikipedia.org/wiki/Expected value of including uncertainty"
  },
  "Cost := Value_per_minute_at_home * Time_I_leave_home +": {
    "before": "Value_per_minute_at_home := 1",
    "after": "(If Time_I_leave_home < Time_from_home_to_gate Then Loss_if_miss_the_plane Else 0)",
    "url": "https://en.wikipedia.org/wiki/Expected value of including uncertainty"
  },
  "Posterior = Likelihood × Prior ÷ Evidence": {
    "before": "Part of a series onBayesian statistics",
    "after": "Background",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle \\max _{x\\in X}\\min _{y\\in Y}f(x,y)=\\min _{y\\in Y}\\max _{x\\in X}f(x,y).}": {
    "before": "{\\displaystyle f(\\cdot ,y):X\\to \\mathbb {R} } is concave for fixed {\\displaystyle y} , and {\\displaystyle f(x,\\cdot ):Y\\to \\mathbb {R} } is convex for fixed {\\displaystyle x} .Then we have that",
    "after": "Special case: Bilinear function [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Minimax theorem"
  },
  "{\\displaystyle \\max _{x\\in X}\\min _{y\\in Y}x^{\\mathsf {T}}Ay=\\min _{y\\in Y}\\max _{x\\in X}x^{\\mathsf {T}}Ay.}": {
    "before": "The theorem holds in particular if {\\displaystyle f(x,y)} is a linear function in both of its arguments (and therefore is bilinear ) since a linear function is both concave and convex. Thus, if {\\displaystyle f(x,y)=x^{\\mathsf {T}}Ay} for a finite matrix {\\displaystyle A\\in \\mathbb {R} ^{n\\times m}} , we have:",
    "after": "The bilinear special case is particularly important for zero-sum games , when the strategy set of each player consists of lotteries over actions ( mixed strategies ), and payoffs are induced by expected value . In the above formulation, {\\displaystyle A} is the payoff matrix .",
    "url": "https://en.wikipedia.org/wiki/Minimax theorem"
  },
  "The equation I (r ) = S (Y ) had been accepted by the classics, who had viewed it as the condition of equilibrium between supply and demand for investment funds and as determining the interest rate (see the classical theory of interest). But insofar as they had had a concept of aggregate demand, they had seen the demand for investment as being given by S (Y ), since for them saving was simply the indirect purchase of capital goods, with the result that aggregate demand was equal to total income as an identity rather than as an equilibrium condition. Keynes takes note of this view in Chapter 2, where he finds it present in the early writings of Alfred Marshall but adds that \"the doctrine is never stated to-day in this crude form\".": {
    "before": "The horizontal blue line I (r ) is the schedule of the marginal efficiency of capital whose value is independent of Y. The schedule of the marginal efficiency of capital is dependent on the interest rate, specifically the interest rate cost of a new investment. If the interest rate charged by the financial sector to the productive sector is below the marginal efficiency of capital at that level of technology and capital intensity then investment is positive and grows the lower the interest rate is, given the diminishing return of capital. If the interest rate is above the marginal efficiency of capital then investment is equal to zero. Keynes interprets this as the demand for investment and denotes the sum of demands for consumption and investment as \"aggregate demand\", plotted as a separate curve. Aggregate demand must equal total income, so equilibrium income must be determined by the point where the aggregate demand curve crosses the 45° line. This is the same horizontal position as the intersection of I (r ) with S (Y ).",
    "after": "The equation I (r ) = S (Y ) is accepted by Keynes for some or all of the following reasons:",
    "url": "https://en.wikipedia.org/wiki/Keynesian economics"
  },
  "The equation I (r ) = S (Y ) is accepted by Keynes for some or all of the following reasons:": {
    "before": "The equation I (r ) = S (Y ) had been accepted by the classics, who had viewed it as the condition of equilibrium between supply and demand for investment funds and as determining the interest rate (see the classical theory of interest). But insofar as they had had a concept of aggregate demand, they had seen the demand for investment as being given by S (Y ), since for them saving was simply the indirect purchase of capital goods, with the result that aggregate demand was equal to total income as an identity rather than as an equilibrium condition. Keynes takes note of this view in Chapter 2, where he finds it present in the early writings of Alfred Marshall but adds that \"the doctrine is never stated to-day in this crude form\".",
    "after": "As a consequence of the principle of effective demand, which asserts that aggregate demand must equal total income (Chapter 3).",
    "url": "https://en.wikipedia.org/wiki/Keynesian economics"
  },
  "V = Volatility: the nature and dynamics of change, and the nature and speed of change forces and change catalysts.": {
    "before": "The deeper meaning of each element of VUCA serves to enhance the strategic significance of VUCA foresight and insight as well as the behaviour of groups and individuals in organizations. It discusses systemic failures and behavioural failures, which are characteristic of organisational failure.",
    "after": "U = Uncertainty: the lack of predictability, the prospects for surprise, and the sense of awareness and understanding of issues and events.",
    "url": "https://en.wikipedia.org/wiki/Volatility, uncertainty, complexity and ambiguity"
  },
  "U = Uncertainty: the lack of predictability, the prospects for surprise, and the sense of awareness and understanding of issues and events.": {
    "before": "V = Volatility: the nature and dynamics of change, and the nature and speed of change forces and change catalysts.",
    "after": "C = Complexity: the multiplex of forces, the confounding of issues, no cause-and-effect chain and confusion that surrounds organization.",
    "url": "https://en.wikipedia.org/wiki/Volatility, uncertainty, complexity and ambiguity"
  },
  "C = Complexity: the multiplex of forces, the confounding of issues, no cause-and-effect chain and confusion that surrounds organization.": {
    "before": "U = Uncertainty: the lack of predictability, the prospects for surprise, and the sense of awareness and understanding of issues and events.",
    "after": "A = Ambiguity: the haziness of reality, the potential for misreads, and the mixed meanings of conditions; cause-and-effect confusion.",
    "url": "https://en.wikipedia.org/wiki/Volatility, uncertainty, complexity and ambiguity"
  },
  "A = Ambiguity: the haziness of reality, the potential for misreads, and the mixed meanings of conditions; cause-and-effect confusion.": {
    "before": "C = Complexity: the multiplex of forces, the confounding of issues, no cause-and-effect chain and confusion that surrounds organization.",
    "after": "These elements present the context in which organizations view their current and future state. They present boundaries for planning and policy management. They come together in ways that either confound decisions or sharpen the capacity to look ahead, plan ahead, and move ahead. VUCA sets the stage for managing and leading.",
    "url": "https://en.wikipedia.org/wiki/Volatility, uncertainty, complexity and ambiguity"
  },
  "{\\displaystyle A=\\{a_{1},\\ldots ,a_{i},\\ldots ,a_{j}\\}}": {
    "before": "The available alternatives are often expressed as a set of objects, for example a set of j exhaustive and exclusive actions:",
    "after": "For example, if a person can choose to vote for either Roger or Sara or to abstain, their set of possible alternatives is:",
    "url": "https://en.wikipedia.org/wiki/Rational choice theory"
  },
  "{\\displaystyle A=\\{{\\text{Vote for Roger, Vote for Sara, Abstain}}\\}}": {
    "before": "For example, if a person can choose to vote for either Roger or Sara or to abstain, their set of possible alternatives is:",
    "after": "The theory makes two technical assumptions about individuals' preferences over alternatives:",
    "url": "https://en.wikipedia.org/wiki/Rational choice theory"
  },
  "For i ∈ {1, ..., m}, vertex v gets the label i if xi = 0 at vertex v.": {
    "before": "{1,...,m + n} as follows.",
    "after": "For j ∈ {1, ..., n}, vertex v gets the label m + j if B1,jx1 + ... + Bm,jxm = 1.",
    "url": "https://en.wikipedia.org/wiki/Lemke–Howson algorithm"
  },
  "For j ∈ {1, ..., n}, vertex w gets the label m + j if xm+j = 0 at vertex w.": {
    "before": "{1, ..., m + n} as follows.",
    "after": "For i ∈ {1, ..., m}, vertex w gets the label i if",
    "url": "https://en.wikipedia.org/wiki/Lemke–Howson algorithm"
  },
  "JYB = Jewish Year Book": {
    "before": "References[edit]",
    "after": "Footnotes[edit]",
    "url": "https://en.wikipedia.org/wiki/List of Jewish economists"
  },
  "{\\displaystyle C_{t}=a+bY_{t-1}+e_{t},}": {
    "before": "A simple example of an econometric model is one that assumes that monthly spending by consumers is linearly dependent on consumers' income in the previous month. Then the model will consist of the equation",
    "after": "where C t is consumer spending in month t , Y t -1 is income during the previous month, and e t is an error term measuring the extent to which the model cannot fully explain consumption. Then one objective of the econometrician is to obtain estimates of the parameters a and b ; these estimated parameter values, when used in the model's equation, enable predictions for future values of consumption to be made contingent on the prior month's income.",
    "url": "https://en.wikipedia.org/wiki/Econometric model"
  },
  "{\\displaystyle x(k+1)=Ax(k)+Bu(k)}": {
    "before": "The state of a linear, time-invariant discrete-time system is assumed to satisfy",
    "after": "{\\displaystyle y(k)=Cx(k)+Du(k)}",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle y(k)=Cx(k)+Du(k)}": {
    "before": "The state of a linear, time-invariant discrete-time system is assumed to satisfy {\\displaystyle x(k+1)=Ax(k)+Bu(k)}",
    "after": "where, at time {\\displaystyle k} , {\\displaystyle x(k)} is the plant's state; {\\displaystyle u(k)} is its inputs; and {\\displaystyle y(k)} is its outputs. These equations simply say that the plant's current outputs and its future state are both determined solely by its current states and the current inputs. (Although these equations are expressed in terms of discrete time steps, very similar equations hold for continuous systems). If this system is observable then the output of the plant, {\\displaystyle y(k)} , can be used to steer the state of the state observer.",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\hat {x}}(k+1)=A{\\hat {x}}(k)+L\\left[y(k)-{\\hat {y}}(k)\\right]+Bu(k)}": {
    "before": "The observer model of the physical system is then typically derived from the above equations. Additional terms may be included in order to ensure that, on receiving successive measured values of the plant's inputs and outputs, the model's state converges to that of the plant. In particular, the output of the observer may be subtracted from the output of the plant and then multiplied by a matrix {\\displaystyle L} ; this is then added to the equations for the state of the observer to produce a so-called Luenberger observer , defined by the equations below. Note that the variables of a state observer are commonly denoted by a \"hat\": {\\displaystyle {\\hat {x}}(k)} and {\\displaystyle {\\hat {y}}(k)} to distinguish them from the variables of the equations satisfied by the physical system.",
    "after": "{\\displaystyle {\\hat {y}}(k)=C{\\hat {x}}(k)+Du(k)}",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\hat {y}}(k)=C{\\hat {x}}(k)+Du(k)}": {
    "before": "{\\displaystyle {\\hat {x}}(k+1)=A{\\hat {x}}(k)+L\\left[y(k)-{\\hat {y}}(k)\\right]+Bu(k)}",
    "after": "The observer is called asymptotically stable if the observer error {\\displaystyle e(k)={\\hat {x}}(k)-x(k)} converges to zero when {\\displaystyle k\\to \\infty } . For a Luenberger observer, the observer error satisfies {\\displaystyle e(k+1)=(A-LC)e(k)} . The Luenberger observer for this discrete-time system is therefore asymptotically stable when the matrix {\\displaystyle A-LC} has all the eigenvalues inside the unit circle.",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle u(k)=-K{\\hat {x}}(k)}": {
    "before": "For control purposes the output of the observer system is fed back to the input of both the observer and the plant through the gains matrix {\\displaystyle K} .",
    "after": "The observer equations then become:",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\hat {x}}(k+1)=A{\\hat {x}}(k)+L\\left(y(k)-{\\hat {y}}(k)\\right)-BK{\\hat {x}}(k)}": {
    "before": "{\\displaystyle u(k)=-K{\\hat {x}}(k)} The observer equations then become:",
    "after": "{\\displaystyle {\\hat {y}}(k)=C{\\hat {x}}(k)-DK{\\hat {x}}(k)}",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\hat {y}}(k)=C{\\hat {x}}(k)-DK{\\hat {x}}(k)}": {
    "before": "{\\displaystyle {\\hat {x}}(k+1)=A{\\hat {x}}(k)+L\\left(y(k)-{\\hat {y}}(k)\\right)-BK{\\hat {x}}(k)}",
    "after": "or, more simply,",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\hat {x}}(k+1)=\\left(A-BK\\right){\\hat {x}}(k)+L\\left(y(k)-{\\hat {y}}(k)\\right)}": {
    "before": "{\\displaystyle {\\hat {y}}(k)=C{\\hat {x}}(k)-DK{\\hat {x}}(k)} or, more simply,",
    "after": "{\\displaystyle {\\hat {y}}(k)=\\left(C-DK\\right){\\hat {x}}(k)}",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\hat {y}}(k)=\\left(C-DK\\right){\\hat {x}}(k)}": {
    "before": "{\\displaystyle {\\hat {x}}(k+1)=\\left(A-BK\\right){\\hat {x}}(k)+L\\left(y(k)-{\\hat {y}}(k)\\right)}",
    "after": "Due to the separation principle we know that we can choose {\\displaystyle K} and {\\displaystyle L} independently without harm to the overall stability of the systems. As a rule of thumb, the poles of the observer {\\displaystyle A-LC} are usually chosen to converge 10 times faster than the poles of the system {\\displaystyle A-BK} .",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {x}}=Ax+Bu,}": {
    "before": "The previous example was for an observer implemented in a discrete-time LTI system. However, the process is similar for the continuous-time case; the observer gains {\\displaystyle L} are chosen to make the continuous-time error dynamics converge to zero asymptotically (i.e., when {\\displaystyle A-LC} is a Hurwitz matrix ).For a continuous-time linear system",
    "after": "{\\displaystyle y=Cx+Du,}",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle y=Cx+Du,}": {
    "before": "For a continuous-time linear system {\\displaystyle {\\dot {x}}=Ax+Bu,}",
    "after": "where {\\displaystyle x\\in \\mathbb {R} ^{n},u\\in \\mathbb {R} ^{m},y\\in \\mathbb {R} ^{r}} , the observer looks similar to discrete-time case described above:",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {\\hat {x}}}=A{\\hat {x}}+Bu+L\\left(y-{\\hat {y}}\\right)} .": {
    "before": "where {\\displaystyle x\\in \\mathbb {R} ^{n},u\\in \\mathbb {R} ^{m},y\\in \\mathbb {R} ^{r}} , the observer looks similar to discrete-time case described above:",
    "after": "{\\displaystyle {\\hat {y}}=C{\\hat {x}}+Du,}",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\hat {y}}=C{\\hat {x}}+Du,}": {
    "before": "{\\displaystyle {\\dot {\\hat {x}}}=A{\\hat {x}}+Bu+L\\left(y-{\\hat {y}}\\right)} .",
    "after": "The observer error {\\displaystyle e=x-{\\hat {x}}} satisfies the equation",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {e}}=(A-LC)e} .": {
    "before": "The observer error for the transformed variable {\\displaystyle e={\\hat {z}}-z} satisfies the same equation as in classical linear case.",
    "after": "As shown by Gauthier, Hammouri, and Othman  and Hammouri and Kinnaert,  if there exists transformation {\\displaystyle z=\\Phi (x)} such that the system can be transformed into the form",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {x}}=f(x)}": {
    "before": "High gain, sliding mode and extended observers are the most common observers for nonlinear systems. To illustrate the application of sliding mode observers for nonlinear systems, first consider the no-input non-linear system:",
    "after": "where {\\displaystyle x\\in \\mathbb {R} ^{n}} . Also assume that there is a measurable output {\\displaystyle y\\in \\mathbb {R} } given by",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle y=h(x).}": {
    "before": "where {\\displaystyle x\\in \\mathbb {R} ^{n}} . Also assume that there is a measurable output {\\displaystyle y\\in \\mathbb {R} } given by",
    "after": "There are several non-approximate approaches for designing an observer. The two observers given below also apply to the case when the system has an input. That is,",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {x}}=f(x)+B(x)u} {\\displaystyle y=h(x).}": {
    "before": "There are several non-approximate approaches for designing an observer. The two observers given below also apply to the case when the system has an input. That is,",
    "after": "Linearizable error dynamics [ edit ]",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {z}}=Az+\\phi (y),} {\\displaystyle y=Cz.}": {
    "before": "One suggestion by Krener and Isidori  and Krener and Respondek  can be applied in a situation when there exists a linearizing transformation (i.e., a diffeomorphism , like the one used in feedback linearization ) {\\displaystyle z=\\Phi (x)} such that in new variables the system equations read",
    "after": "The Luenberger observer is then designed as",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {\\hat {z}}}=A{\\hat {z}}+\\phi (y)-L\\left(C{\\hat {z}}-y\\right)} .": {
    "before": "{\\displaystyle {\\dot {z}}=Az+\\phi (y),} {\\displaystyle y=Cz.} The Luenberger observer is then designed as",
    "after": "The observer error for the transformed variable {\\displaystyle e={\\hat {z}}-z} satisfies the same equation as in classical linear case.",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {z}}=A(u(t))z+\\phi (y,u(t)),} {\\displaystyle y=Cz,}": {
    "before": "As shown by Gauthier, Hammouri, and Othman  and Hammouri and Kinnaert,  if there exists transformation {\\displaystyle z=\\Phi (x)} such that the system can be transformed into the form",
    "after": "then the observer is designed as",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {\\hat {z}}}=A(u(t)){\\hat {z}}+\\phi (y,u(t))-L(t)\\left(C{\\hat {z}}-y\\right)} ,": {
    "before": "{\\displaystyle {\\dot {z}}=A(u(t))z+\\phi (y,u(t)),} {\\displaystyle y=Cz,} then the observer is designed as",
    "after": "where {\\displaystyle L(t)} is a time-varying observer gain.",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {\\hat {x}}}=\\left[{\\frac {\\partial H({\\hat {x}})}{\\partial x}}\\right]^{-1}M({\\hat {x}})\\operatorname {sgn}(V(t)-H({\\hat {x}}))}": {
    "before": "As suggested by Drakunov,  a sliding mode observer can also be designed for a class of non-linear systems. Such an observer can be written in terms of original variable estimate {\\displaystyle {\\hat {x}}} and has the form",
    "after": "where:The {\\displaystyle \\operatorname {sgn}({\\mathord {\\cdot }})} vector extends the scalar signum function to {\\displaystyle n} dimensions. That is, {\\displaystyle \\operatorname {sgn}(z)={\\begin{bmatrix}\\operatorname {sgn}(z_{1})\\\\\\operatorname {sgn}(z_{2})\\\\\\vdots \\\\\\operatorname {sgn}(z_{i})\\\\\\vdots \\\\\\operatorname {sgn}(z_{n})\\end{bmatrix}}} for the vector {\\displaystyle z\\in \\mathbb {R} ^{n}} . The vector {\\displaystyle H(x)} has components that are the output function {\\displaystyle h(x)} and its repeated Lie derivatives. In particular, {\\displaystyle H(x)\\triangleq {\\begin{bmatrix}h_{1}(x)\\\\h_{2}(x)\\\\h_{3}(x)\\\\\\vdots \\\\h_{n}(x)\\end{bmatrix}}\\triangleq {\\begin{bmatrix}h(x)\\\\L_{f}h(x)\\\\L_{f}^{2}h(x)\\\\\\vdots \\\\L_{f}^{n-1}h(x)\\end{bmatrix}}} where {\\displaystyle L_{f}^{i}h} is the i th Lie derivative of output function {\\displaystyle h} along the vector field {\\displaystyle f} (i.e., along {\\displaystyle x} trajectories of the non-linear system). In the special case where the system has no input or has a relative degree of n , {\\displaystyle H(x(t))} is a collection of the output {\\displaystyle y(t)=h(x(t))} and its {\\displaystyle n-1} derivatives. Because the inverse of the Jacobian linearization of {\\displaystyle H(x)} must exist for this observer to be well defined, the transformation {\\displaystyle H(x)} is guaranteed to be a local diffeomorphism . The diagonal matrix {\\displaystyle M({\\hat {x}})} of gains is such that {\\displaystyle M({\\hat {x}})\\triangleq \\operatorname {diag} (m_{1}({\\hat {x}}),m_{2}({\\hat {x}}),\\ldots ,m_{n}({\\hat {x}}))={\\begin{bmatrix}m_{1}({\\hat {x}})&&&&&\\\\&m_{2}({\\hat {x}})&&&&\\\\&&\\ddots &&&\\\\&&&m_{i}({\\hat {x}})&&\\\\&&&&\\ddots &\\\\&&&&&m_{n}({\\hat {x}})\\end{bmatrix}}} where, for each {\\displaystyle i\\in \\{1,2,\\dots ,n\\}} , element {\\displaystyle m_{i}({\\hat {x}})>0} and suitably large to ensure reachability of the sliding mode. The observer vector {\\displaystyle V(t)} is such that {\\displaystyle V(t)\\triangleq {\\begin{bmatrix}v_{1}(t)\\\\v_{2}(t)\\\\v_{3}(t)\\\\\\vdots \\\\v_{i}(t)\\\\\\vdots \\\\v_{n}(t)\\end{bmatrix}}\\triangleq {\\begin{bmatrix}y(t)\\\\\\{m_{1}({\\hat {x}})\\operatorname {sgn}(v_{1}(t)-h_{1}({\\hat {x}}(t)))\\}_{\\text{eq}}\\\\\\{m_{2}({\\hat {x}})\\operatorname {sgn}(v_{2}(t)-h_{2}({\\hat {x}}(t)))\\}_{\\text{eq}}\\\\\\vdots \\\\\\{m_{i-1}({\\hat {x}})\\operatorname {sgn}(v_{i-1}(t)-h_{i-1}({\\hat {x}}(t)))\\}_{\\text{eq}}\\\\\\vdots \\\\\\{m_{n-1}({\\hat {x}})\\operatorname {sgn}(v_{n-1}(t)-h_{n-1}({\\hat {x}}(t)))\\}_{\\text{eq}}\\end{bmatrix}}} where {\\displaystyle \\operatorname {sgn}({\\mathord {\\cdot }})} here is the normal signum function defined for scalars, and {\\displaystyle \\{\\ldots \\}_{\\text{eq}}} denotes an \"equivalent value operator\" of a discontinuous function in sliding mode.",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle \\operatorname {sgn}(z)={\\begin{bmatrix}\\operatorname {sgn}(z_{1})\\\\\\operatorname {sgn}(z_{2})\\\\\\vdots \\\\\\operatorname {sgn}(z_{i})\\\\\\vdots \\\\\\operatorname {sgn}(z_{n})\\end{bmatrix}}} for the vector {\\displaystyle z\\in \\mathbb {R} ^{n}} .": {
    "before": "{\\displaystyle n} dimensions. That is,",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle \\operatorname {sgn}(z)={\\begin{bmatrix}\\operatorname {sgn}(z_{1})\\\\\\operatorname {sgn}(z_{2})\\\\\\vdots \\\\\\operatorname {sgn}(z_{i})\\\\\\vdots \\\\\\operatorname {sgn}(z_{n})\\end{bmatrix}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle H(x)\\triangleq {\\begin{bmatrix}h_{1}(x)\\\\h_{2}(x)\\\\h_{3}(x)\\\\\\vdots \\\\h_{n}(x)\\end{bmatrix}}\\triangleq {\\begin{bmatrix}h(x)\\\\L_{f}h(x)\\\\L_{f}^{2}h(x)\\\\\\vdots \\\\L_{f}^{n-1}h(x)\\end{bmatrix}}} where {\\displaystyle L_{f}^{i}h} is the i th Lie derivative of output function {\\displaystyle h} along the vector field {\\displaystyle f} (i.e., along {\\displaystyle x} trajectories of the non-linear system). In the special case where the system has no input or has a relative degree of n , {\\displaystyle H(x(t))} is a collection of the output {\\displaystyle y(t)=h(x(t))} and its {\\displaystyle n-1} derivatives. Because the inverse of the Jacobian linearization of {\\displaystyle H(x)} must exist for this observer to be well defined, the transformation {\\displaystyle H(x)} is guaranteed to be a local diffeomorphism .": {
    "before": "{\\displaystyle h(x)} and its repeated Lie derivatives. In particular,",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle M({\\hat {x}})\\triangleq \\operatorname {diag} (m_{1}({\\hat {x}}),m_{2}({\\hat {x}}),\\ldots ,m_{n}({\\hat {x}}))={\\begin{bmatrix}m_{1}({\\hat {x}})&&&&&\\\\&m_{2}({\\hat {x}})&&&&\\\\&&\\ddots &&&\\\\&&&m_{i}({\\hat {x}})&&\\\\&&&&\\ddots &\\\\&&&&&m_{n}({\\hat {x}})\\end{bmatrix}}} where, for each {\\displaystyle i\\in \\{1,2,\\dots ,n\\}} , element {\\displaystyle m_{i}({\\hat {x}})>0} and suitably large to ensure reachability of the sliding mode.": {
    "before": "{\\displaystyle M({\\hat {x}})} of gains is such that",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle M({\\hat {x}})\\triangleq \\operatorname {diag} (m_{1}({\\hat {x}}),m_{2}({\\hat {x}}),\\ldots ,m_{n}({\\hat {x}}))={\\begin{bmatrix}m_{1}({\\hat {x}})&&&&&\\\\&m_{2}({\\hat {x}})&&&&\\\\&&\\ddots &&&\\\\&&&m_{i}({\\hat {x}})&&\\\\&&&&\\ddots &\\\\&&&&&m_{n}({\\hat {x}})\\end{bmatrix}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\begin{aligned}{\\dot {e}}&={\\frac {\\mathrm {d} }{\\mathrm {d} t}}H(x)-{\\frac {\\mathrm {d} }{\\mathrm {d} t}}H({\\hat {x}})\\\\&={\\frac {\\mathrm {d} }{\\mathrm {d} t}}H(x)-M({\\hat {x}})\\,\\operatorname {sgn}(V(t)-H({\\hat {x}}(t))),\\end{aligned}}}": {
    "before": "The modified observation error can be written in the transformed states {\\displaystyle e=H(x)-H({\\hat {x}})} . In particular,",
    "after": "and so {\\displaystyle {\\begin{aligned}{\\begin{bmatrix}{\\dot {e}}_{1}\\\\{\\dot {e}}_{2}\\\\\\vdots \\\\{\\dot {e}}_{i}\\\\\\vdots \\\\{\\dot {e}}_{n-1}\\\\{\\dot {e}}_{n}\\end{bmatrix}}&={\\mathord {\\overbrace {\\begin{bmatrix}{\\dot {h}}_{1}(x)\\\\{\\dot {h}}_{2}(x)\\\\\\vdots \\\\{\\dot {h}}_{i}(x)\\\\\\vdots \\\\{\\dot {h}}_{n-1}(x)\\\\{\\dot {h}}_{n}(x)\\end{bmatrix}} ^{{\\tfrac {\\mathrm {d} }{\\mathrm {d} t}}H(x)}}}-{\\mathord {\\overbrace {M({\\hat {x}})\\,\\operatorname {sgn}(V(t)-H({\\hat {x}}(t)))} ^{{\\tfrac {\\mathrm {d} }{\\mathrm {d} t}}H({\\hat {x}})}}}={\\begin{bmatrix}h_{2}(x)\\\\h_{3}(x)\\\\\\vdots \\\\h_{i+1}(x)\\\\\\vdots \\\\h_{n}(x)\\\\L_{f}^{n}h(x)\\end{bmatrix}}-{\\begin{bmatrix}m_{1}\\operatorname {sgn}(v_{1}(t)-h_{1}({\\hat {x}}(t)))\\\\m_{2}\\operatorname {sgn}(v_{2}(t)-h_{2}({\\hat {x}}(t)))\\\\\\vdots \\\\m_{i}\\operatorname {sgn}(v_{i}(t)-h_{i}({\\hat {x}}(t)))\\\\\\vdots \\\\m_{n-1}\\operatorname {sgn}(v_{n-1}(t)-h_{n-1}({\\hat {x}}(t)))\\\\m_{n}\\operatorname {sgn}(v_{n}(t)-h_{n}({\\hat {x}}(t)))\\end{bmatrix}}\\\\&={\\begin{bmatrix}h_{2}(x)-m_{1}({\\hat {x}})\\operatorname {sgn}({\\mathord {\\overbrace {{\\mathord {\\overbrace {v_{1}(t)} ^{v_{1}(t)=y(t)=h_{1}(x)}}}-h_{1}({\\hat {x}}(t))} ^{e_{1}}}})\\\\h_{3}(x)-m_{2}({\\hat {x}})\\operatorname {sgn}(v_{2}(t)-h_{2}({\\hat {x}}(t)))\\\\\\vdots \\\\h_{i+1}(x)-m_{i}({\\hat {x}})\\operatorname {sgn}(v_{i}(t)-h_{i}({\\hat {x}}(t)))\\\\\\vdots \\\\h_{n}(x)-m_{n-1}({\\hat {x}})\\operatorname {sgn}(v_{n-1}(t)-h_{n-1}({\\hat {x}}(t)))\\\\L_{f}^{n}h(x)-m_{n}({\\hat {x}})\\operatorname {sgn}(v_{n}(t)-h_{n}({\\hat {x}}(t)))\\end{bmatrix}}.\\end{aligned}}}",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\begin{aligned}{\\begin{bmatrix}{\\dot {e}}_{1}\\\\{\\dot {e}}_{2}\\\\\\vdots \\\\{\\dot {e}}_{i}\\\\\\vdots \\\\{\\dot {e}}_{n-1}\\\\{\\dot {e}}_{n}\\end{bmatrix}}&={\\mathord {\\overbrace {\\begin{bmatrix}{\\dot {h}}_{1}(x)\\\\{\\dot {h}}_{2}(x)\\\\\\vdots \\\\{\\dot {h}}_{i}(x)\\\\\\vdots \\\\{\\dot {h}}_{n-1}(x)\\\\{\\dot {h}}_{n}(x)\\end{bmatrix}} ^{{\\tfrac {\\mathrm {d} }{\\mathrm {d} t}}H(x)}}}-{\\mathord {\\overbrace {M({\\hat {x}})\\,\\operatorname {sgn}(V(t)-H({\\hat {x}}(t)))} ^{{\\tfrac {\\mathrm {d} }{\\mathrm {d} t}}H({\\hat {x}})}}}={\\begin{bmatrix}h_{2}(x)\\\\h_{3}(x)\\\\\\vdots \\\\h_{i+1}(x)\\\\\\vdots \\\\h_{n}(x)\\\\L_{f}^{n}h(x)\\end{bmatrix}}-{\\begin{bmatrix}m_{1}\\operatorname {sgn}(v_{1}(t)-h_{1}({\\hat {x}}(t)))\\\\m_{2}\\operatorname {sgn}(v_{2}(t)-h_{2}({\\hat {x}}(t)))\\\\\\vdots \\\\m_{i}\\operatorname {sgn}(v_{i}(t)-h_{i}({\\hat {x}}(t)))\\\\\\vdots \\\\m_{n-1}\\operatorname {sgn}(v_{n-1}(t)-h_{n-1}({\\hat {x}}(t)))\\\\m_{n}\\operatorname {sgn}(v_{n}(t)-h_{n}({\\hat {x}}(t)))\\end{bmatrix}}\\\\&={\\begin{bmatrix}h_{2}(x)-m_{1}({\\hat {x}})\\operatorname {sgn}({\\mathord {\\overbrace {{\\mathord {\\overbrace {v_{1}(t)} ^{v_{1}(t)=y(t)=h_{1}(x)}}}-h_{1}({\\hat {x}}(t))} ^{e_{1}}}})\\\\h_{3}(x)-m_{2}({\\hat {x}})\\operatorname {sgn}(v_{2}(t)-h_{2}({\\hat {x}}(t)))\\\\\\vdots \\\\h_{i+1}(x)-m_{i}({\\hat {x}})\\operatorname {sgn}(v_{i}(t)-h_{i}({\\hat {x}}(t)))\\\\\\vdots \\\\h_{n}(x)-m_{n-1}({\\hat {x}})\\operatorname {sgn}(v_{n-1}(t)-h_{n-1}({\\hat {x}}(t)))\\\\L_{f}^{n}h(x)-m_{n}({\\hat {x}})\\operatorname {sgn}(v_{n}(t)-h_{n}({\\hat {x}}(t)))\\end{bmatrix}}.\\end{aligned}}}": {
    "before": "{\\displaystyle {\\begin{aligned}{\\dot {e}}&={\\frac {\\mathrm {d} }{\\mathrm {d} t}}H(x)-{\\frac {\\mathrm {d} }{\\mathrm {d} t}}H({\\hat {x}})\\\\&={\\frac {\\mathrm {d} }{\\mathrm {d} t}}H(x)-M({\\hat {x}})\\,\\operatorname {sgn}(V(t)-H({\\hat {x}}(t))),\\end{aligned}}} and so",
    "after": "So:As long as {\\displaystyle m_{1}({\\hat {x}})\\geq |h_{2}(x(t))|} , the first row of the error dynamics, {\\displaystyle {\\dot {e}}_{1}=h_{2}({\\hat {x}})-m_{1}({\\hat {x}})\\operatorname {sgn}(e_{1})} , will meet sufficient conditions to enter the {\\displaystyle e_{1}=0} sliding mode in finite time. Along the {\\displaystyle e_{1}=0} surface, the corresponding {\\displaystyle v_{2}(t)=\\{m_{1}({\\hat {x}})\\operatorname {sgn}(e_{1})\\}_{\\text{eq}}} equivalent control will be equal to {\\displaystyle h_{2}(x)} , and so {\\displaystyle v_{2}(t)-h_{2}({\\hat {x}})=h_{2}(x)-h_{2}({\\hat {x}})=e_{2}} . Hence, so long as {\\displaystyle m_{2}({\\hat {x}})\\geq |h_{3}(x(t))|} , the second row of the error dynamics, {\\displaystyle {\\dot {e}}_{2}=h_{3}({\\hat {x}})-m_{2}({\\hat {x}})\\operatorname {sgn}(e_{2})} , will enter the {\\displaystyle e_{2}=0} sliding mode in finite time. Along the {\\displaystyle e_{i}=0} surface, the corresponding {\\displaystyle v_{i+1}(t)=\\{\\ldots \\}_{\\text{eq}}} equivalent control will be equal to {\\displaystyle h_{i+1}(x)} . Hence, so long as {\\displaystyle m_{i+1}({\\hat {x}})\\geq |h_{i+2}(x(t))|} , the {\\displaystyle (i+1)} th row of the error dynamics, {\\displaystyle {\\dot {e}}_{i+1}=h_{i+2}({\\hat {x}})-m_{i+1}({\\hat {x}})\\operatorname {sgn}(e_{i+1})} , will enter the {\\displaystyle e_{i+1}=0} sliding mode in finite time.",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {\\hat {x}}}=\\left[{\\frac {\\partial H({\\hat {x}})}{\\partial x}}\\right]^{-1}M({\\hat {x}})\\operatorname {sgn}(V(t)-H({\\hat {x}}))+B({\\hat {x}})u.}": {
    "before": "{\\displaystyle {\\frac {\\partial H(x)}{\\partial x}}B(x)} does not depend on time. The observer is then",
    "after": "Multi-observer [ edit ]",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\dot {\\hat {x}}}_{k}(t)=A{\\hat {x_{k}}}(t)+B\\phi _{0}({\\hat {x}}(t),u(t))-L({\\hat {y_{k}}}(t)-y(t))} {\\displaystyle {\\hat {y_{k}}}(t)=C{\\hat {x_{k}}}(t)}": {
    "before": "Assuming that the number of high-gain observers equals {\\displaystyle n+1} ,",
    "after": "where {\\displaystyle k=1,\\dots ,n+1} is the observer index. The first layer observers consists of the same gain {\\displaystyle L} but they differ with the initial state {\\displaystyle x_{k}(0)} . In the second layer all {\\displaystyle x_{k}(t)} from {\\displaystyle k=1...n+1} observers are combined into one to obtain single state vector estimation",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle {\\hat {y_{k}}}(t)=\\sum \\limits _{k=1}^{n+1}\\alpha _{k}(t){\\hat {x_{k}}}(t)}": {
    "before": "where {\\displaystyle k=1,\\dots ,n+1} is the observer index. The first layer observers consists of the same gain {\\displaystyle L} but they differ with the initial state {\\displaystyle x_{k}(0)} . In the second layer all {\\displaystyle x_{k}(t)} from {\\displaystyle k=1...n+1} observers are combined into one to obtain single state vector estimation",
    "after": "where {\\displaystyle \\alpha _{k}\\in \\mathbb {R} } are weight factors. These factors are changed to provide the estimation in the second layer and to improve the observation process.",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle \\sum \\limits _{k=1}^{n+1}\\alpha _{k}(t)\\xi _{k}(t)=0}": {
    "before": "where {\\displaystyle \\alpha _{k}\\in \\mathbb {R} } are weight factors. These factors are changed to provide the estimation in the second layer and to improve the observation process.Let assume that",
    "after": "and {\\displaystyle \\sum \\limits _{k=1}^{n+1}\\alpha _{k}(t)=1}",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle \\sum \\limits _{k=1}^{n+1}\\alpha _{k}(t)=1}": {
    "before": "{\\displaystyle \\sum \\limits _{k=1}^{n+1}\\alpha _{k}(t)\\xi _{k}(t)=0} and",
    "after": "where {\\displaystyle \\xi _{k}\\in \\mathbb {R} ^{n\\times 1}} is some vector that depends on {\\displaystyle kth} observer error {\\displaystyle e_{k}(t)} .",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle [-\\xi _{n+1}(t)]=[\\xi _{1}(t)-\\xi _{n+1}(t)\\dots \\xi _{k}(t)-\\xi _{n+1}(t)\\dots \\xi _{n}(t)-\\xi _{n+1}(t)]^{T}{\\begin{bmatrix}\\alpha _{1}(t)\\\\\\vdots \\\\\\alpha _{k}(t)\\\\\\vdots \\\\\\alpha _{n}(t)\\end{bmatrix}}}": {
    "before": "Some transformation yields to linear regression problem",
    "after": "This formula gives possibility to estimate {\\displaystyle \\alpha _{k}(t)} . To construct manifold we need mapping {\\displaystyle m:\\mathbb {R} ^{n}\\to \\mathbb {R} ^{n}} between {\\displaystyle \\xi _{k}(t)=m(e_{k}(t))} and ensurance that {\\displaystyle \\xi _{k}(t)} is calculable relying on measurable signals. First thing is to eliminate parking phenomenon for {\\displaystyle \\alpha _{k}(t)} from observer error",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle e_{\\sigma }(t)=\\sum \\limits _{k=1}^{n+1}\\alpha _{k}(t)e_{k}(t)} .": {
    "before": "This formula gives possibility to estimate {\\displaystyle \\alpha _{k}(t)} . To construct manifold we need mapping {\\displaystyle m:\\mathbb {R} ^{n}\\to \\mathbb {R} ^{n}} between {\\displaystyle \\xi _{k}(t)=m(e_{k}(t))} and ensurance that {\\displaystyle \\xi _{k}(t)} is calculable relying on measurable signals. First thing is to eliminate parking phenomenon for {\\displaystyle \\alpha _{k}(t)} from observer error",
    "after": "Calculate {\\displaystyle n} times derivative on {\\displaystyle \\eta _{k}(t)={\\hat {y}}_{k}(t)-y(t)} to find mapping m lead to {\\displaystyle \\xi _{k}(t)} defined as",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle \\xi _{k}(t)={\\begin{bmatrix}1&0&0&\\cdots &0\\\\CL&1&0&\\cdots &0\\\\CAL&CL&1&\\cdots &0\\\\CA^{2}L&CAL&CL&\\cdots &0\\\\\\vdots &\\vdots &\\vdots &\\ddots \\\\CA^{n-2}L&CA^{n-3}L&CA^{n-4}L&\\cdots &1\\end{bmatrix}}{\\begin{bmatrix}\\int \\limits _{t-t_{d}}^{t}{{n-1} \\atop \\cdots }\\int \\limits _{t-t_{d}}^{t}\\eta _{k}(\\tau )d\\tau \\\\\\vdots \\\\\\eta (t)-\\eta (t-(n-1)t_{d})\\end{bmatrix}}}": {
    "before": "Calculate {\\displaystyle n} times derivative on {\\displaystyle \\eta _{k}(t)={\\hat {y}}_{k}(t)-y(t)} to find mapping m lead to {\\displaystyle \\xi _{k}(t)} defined as",
    "after": "where {\\displaystyle t_{d}>0} is some time constant. Note that {\\displaystyle \\xi _{k}(t)} relays on both {\\displaystyle \\eta _{k}(t)} and its integrals hence it is easily available in the control system. Further {\\displaystyle \\alpha _{k}(t)} is specified by estimation law; and thus it proves that manifold is measurable. In the second layer {\\displaystyle {\\hat {\\alpha }}_{k}(t)} for {\\displaystyle k=1\\dots n+1} is introduced as estimates of {\\displaystyle \\alpha _{k}(t)} coefficients. The mapping error is specified as",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle e_{\\xi }(t)=\\sum \\limits _{k=1}^{n+1}{\\hat {\\alpha }}_{k}(t)\\xi _{k}(t)}": {
    "before": "where {\\displaystyle t_{d}>0} is some time constant. Note that {\\displaystyle \\xi _{k}(t)} relays on both {\\displaystyle \\eta _{k}(t)} and its integrals hence it is easily available in the control system. Further {\\displaystyle \\alpha _{k}(t)} is specified by estimation law; and thus it proves that manifold is measurable. In the second layer {\\displaystyle {\\hat {\\alpha }}_{k}(t)} for {\\displaystyle k=1\\dots n+1} is introduced as estimates of {\\displaystyle \\alpha _{k}(t)} coefficients. The mapping error is specified as",
    "after": "where {\\displaystyle e_{\\xi }(t)\\in \\mathbb {R} ^{n\\times 1},{\\hat {\\alpha }}_{k}(t)\\in \\mathbb {R} } . If coefficients {\\displaystyle {\\hat {\\alpha }}(t)} are equal to {\\displaystyle \\alpha _{k}(t)} , then mapping error {\\displaystyle e_{\\xi }(t)=0} Now it is possible to calculate {\\displaystyle {\\hat {x}}} from above equation and hence the peaking phenomenon is reduced thanks to properties of manifold. The created mapping gives a lot of flexibility in the estimation process. Even it is possible to estimate the value of {\\displaystyle x(t)} in the second layer and to calculate the state {\\displaystyle x} . ",
    "url": "https://en.wikipedia.org/wiki/State observer"
  },
  "{\\displaystyle \\mathrm {MSE} =E\\left[({\\widehat {\\theta }}(x)-\\theta )^{2}\\right],}": {
    "before": "The most common risk function used for Bayesian estimation is the mean square error (MSE), also called squared error risk . The MSE is defined by",
    "after": "where the expectation is taken over the joint distribution of {\\displaystyle \\theta } and {\\displaystyle x} .",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle {\\widehat {\\theta }}(x)=E[\\theta |x]=\\int \\theta \\,p(\\theta |x)\\,d\\theta .}": {
    "before": "Using the MSE as risk, the Bayes estimate of the unknown parameter is simply the mean of the posterior distribution , ",
    "after": "This is known as the minimum mean square error (MMSE) estimator.",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle {\\widehat {\\theta }}(x)={\\frac {\\sigma ^{2}}{\\sigma ^{2}+\\tau ^{2}}}\\mu +{\\frac {\\tau ^{2}}{\\sigma ^{2}+\\tau ^{2}}}x.}": {
    "before": "If {\\displaystyle x|\\theta } is Normal , {\\displaystyle x|\\theta \\sim N(\\theta ,\\sigma ^{2})} , and the prior is normal, {\\displaystyle \\theta \\sim N(\\mu ,\\tau ^{2})} , then the posterior is also Normal and the Bayes estimator under MSE is given by",
    "after": "If {\\displaystyle x_{1},...,x_{n}} are iid Poisson random variables {\\displaystyle x_{i}|\\theta \\sim P(\\theta )} , and if the prior is Gamma distributed {\\displaystyle \\theta \\sim G(a,b)} , then the posterior is also Gamma distributed, and the Bayes estimator under MSE is given by",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle {\\widehat {\\theta }}(X)={\\frac {n{\\overline {X}}+a}{n+b}}.}": {
    "before": "If {\\displaystyle x_{1},...,x_{n}} are iid Poisson random variables {\\displaystyle x_{i}|\\theta \\sim P(\\theta )} , and if the prior is Gamma distributed {\\displaystyle \\theta \\sim G(a,b)} , then the posterior is also Gamma distributed, and the Bayes estimator under MSE is given by",
    "after": "If {\\displaystyle x_{1},...,x_{n}} are iid uniformly distributed {\\displaystyle x_{i}|\\theta \\sim U(0,\\theta )} , and if the prior is Pareto distributed {\\displaystyle \\theta \\sim Pa(\\theta _{0},a)} , then the posterior is also Pareto distributed, and the Bayes estimator under MSE is given by",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle {\\widehat {\\theta }}(X)={\\frac {(a+n)\\max {(\\theta _{0},x_{1},...,x_{n})}}{a+n-1}}.}": {
    "before": "If {\\displaystyle x_{1},...,x_{n}} are iid uniformly distributed {\\displaystyle x_{i}|\\theta \\sim U(0,\\theta )} , and if the prior is Pareto distributed {\\displaystyle \\theta \\sim Pa(\\theta _{0},a)} , then the posterior is also Pareto distributed, and the Bayes estimator under MSE is given by",
    "after": "Alternative risk functions [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle L(\\theta ,{\\widehat {\\theta }})=a|\\theta -{\\widehat {\\theta }}|} {\\displaystyle F({\\widehat {\\theta }}(x)|X)={\\tfrac {1}{2}}.}": {
    "before": "A \"linear\" loss function, with {\\displaystyle a>0} , which yields the posterior median as the Bayes' estimate:",
    "after": "Another \"linear\" loss function, which assigns different \"weights\" {\\displaystyle a,b>0} to over or sub estimation. It yields a quantile from the posterior distribution, and is a generalization of the previous loss function:",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle L(\\theta ,{\\widehat {\\theta }})={\\begin{cases}a|\\theta -{\\widehat {\\theta }}|,&{\\mbox{for }}\\theta -{\\widehat {\\theta }}\\geq 0\\\\b|\\theta -{\\widehat {\\theta }}|,&{\\mbox{for }}\\theta -{\\widehat {\\theta }}<0\\end{cases}}} {\\displaystyle F({\\widehat {\\theta }}(x)|X)={\\frac {a}{a+b}}.}": {
    "before": "Another \"linear\" loss function, which assigns different \"weights\" {\\displaystyle a,b>0} to over or sub estimation. It yields a quantile from the posterior distribution, and is a generalization of the previous loss function:",
    "after": "Posterior mode [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle L(\\theta ,{\\widehat {\\theta }})={\\begin{cases}0,&{\\mbox{for }}|\\theta -{\\widehat {\\theta }}|<K\\\\L,&{\\mbox{for }}|\\theta -{\\widehat {\\theta }}|\\geq K.\\end{cases}}}": {
    "before": "The following loss function is trickier: it yields either the posterior mode , or a point close to it depending on the curvature and properties of the posterior distribution. Small values of the parameter {\\displaystyle K>0} are recommended, in order to use the mode as an approximation ( {\\displaystyle L>0} ):",
    "after": "Other loss functions can be conceived, although the mean squared error is the most widely used and validated. Other loss functions are used in statistics, particularly in robust statistics .",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle \\int {p(\\theta )d\\theta }=\\infty .}": {
    "before": "However, occasionally this can be a restrictive requirement. For example, there is no distribution (covering the set, R , of all real numbers) for which every real number is equally likely. Yet, in some sense, such a \"distribution\" seems like a natural choice for a non-informative prior , i.e., a prior distribution which does not imply a preference for any particular value of the unknown parameter. One can still define a function {\\displaystyle p(\\theta )=1} , but this would not be a proper probability distribution since it has infinite mass,",
    "after": "Such measures {\\displaystyle p(\\theta )} , which are not probability distributions, are referred to as improper priors .",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle p(\\theta |x)={\\frac {p(x|\\theta )p(\\theta )}{\\int p(x|\\theta )p(\\theta )d\\theta }}.}": {
    "before": "The use of an improper prior means that the Bayes risk is undefined (since the prior is not a probability distribution and we cannot take an expectation under it). As a consequence, it is no longer meaningful to speak of a Bayes estimator that minimizes the Bayes risk. Nevertheless, in many cases, one can define the posterior distribution",
    "after": "This is a definition, and not an application of Bayes' theorem , since Bayes' theorem can only be applied when all distributions are proper. However, it is not uncommon for the resulting \"posterior\" to be a valid probability distribution. In this case, the posterior expected loss",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle p(\\theta |x)={\\frac {p(x|\\theta )p(\\theta )}{p(x)}}={\\frac {f(x-\\theta )}{p(x)}}}": {
    "before": "It is common to use the improper prior {\\displaystyle p(\\theta )=1} in this case, especially when no other more subjective information is available. This yields",
    "after": "so the posterior expected loss",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle E[L(a-\\theta )|x]=\\int {L(a-\\theta )p(\\theta |x)d\\theta }={\\frac {1}{p(x)}}\\int L(a-\\theta )f(x-\\theta )d\\theta .}": {
    "before": "{\\displaystyle p(\\theta |x)={\\frac {p(x|\\theta )p(\\theta )}{p(x)}}={\\frac {f(x-\\theta )}{p(x)}}} so the posterior expected loss",
    "after": "The generalized Bayes estimator is the value {\\displaystyle a(x)} that minimizes this expression for a given {\\displaystyle x} . This is equivalent to minimizing",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle \\int L(a-\\theta )f(x_{1}-\\theta )d\\theta =\\int L(a-x_{1}-\\theta ')f(-\\theta ')d\\theta '.} (2)": {
    "before": "In this case it can be shown that the generalized Bayes estimator has the form {\\displaystyle x+a_{0}} , for some constant {\\displaystyle a_{0}} . To see this, let {\\displaystyle a_{0}} be the value minimizing (1) when {\\displaystyle x=0} . Then, given a different value {\\displaystyle x_{1}} , we must minimize",
    "after": "This is identical to (1), except that {\\displaystyle a} has been replaced by {\\displaystyle a-x_{1}} . Thus, the expression minimizing is given by {\\displaystyle a-x_{1}=a_{0}} , so that the optimal estimator has the form",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle a(x)=a_{0}+x.\\,\\!}": {
    "before": "This is identical to (1), except that {\\displaystyle a} has been replaced by {\\displaystyle a-x_{1}} . Thus, the expression minimizing is given by {\\displaystyle a-x_{1}=a_{0}} , so that the optimal estimator has the form",
    "after": "Empirical Bayes estimators [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle {\\widehat {\\mu }}_{m}={\\frac {1}{n}}\\sum {x_{i}},} {\\displaystyle {\\widehat {\\sigma }}_{m}^{2}={\\frac {1}{n}}\\sum {(x_{i}-{\\widehat {\\mu }}_{m})^{2}}.}": {
    "before": "First, we estimate the mean {\\displaystyle \\mu _{m}\\,\\!} and variance {\\displaystyle \\sigma _{m}\\,\\!} of the marginal distribution of {\\displaystyle x_{1},\\ldots ,x_{n}} using the maximum likelihood approach:",
    "after": "Next, we use the law of total expectation to compute {\\displaystyle \\mu _{m}} and the law of total variance to compute {\\displaystyle \\sigma _{m}^{2}} such that",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle \\mu _{m}=E_{\\pi }[\\mu _{f}(\\theta )]\\,\\!,} {\\displaystyle \\sigma _{m}^{2}=E_{\\pi }[\\sigma _{f}^{2}(\\theta )]+E_{\\pi }[(\\mu _{f}(\\theta )-\\mu _{m})^{2}],}": {
    "before": "Next, we use the law of total expectation to compute {\\displaystyle \\mu _{m}} and the law of total variance to compute {\\displaystyle \\sigma _{m}^{2}} such that",
    "after": "where {\\displaystyle \\mu _{f}(\\theta )} and {\\displaystyle \\sigma _{f}(\\theta )} are the moments of the conditional distribution {\\displaystyle f(x_{i}|\\theta _{i})} , which are assumed to be known. In particular, suppose that {\\displaystyle \\mu _{f}(\\theta )=\\theta } and that {\\displaystyle \\sigma _{f}^{2}(\\theta )=K} ; we then have",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle \\mu _{\\pi }=\\mu _{m}\\,\\!,} {\\displaystyle \\sigma _{\\pi }^{2}=\\sigma _{m}^{2}-\\sigma _{f}^{2}=\\sigma _{m}^{2}-K.}": {
    "before": "where {\\displaystyle \\mu _{f}(\\theta )} and {\\displaystyle \\sigma _{f}(\\theta )} are the moments of the conditional distribution {\\displaystyle f(x_{i}|\\theta _{i})} , which are assumed to be known. In particular, suppose that {\\displaystyle \\mu _{f}(\\theta )=\\theta } and that {\\displaystyle \\sigma _{f}^{2}(\\theta )=K} ; we then have",
    "after": "Finally, we obtain the estimated moments of the prior,",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle {\\widehat {\\mu }}_{\\pi }={\\widehat {\\mu }}_{m},} {\\displaystyle {\\widehat {\\sigma }}_{\\pi }^{2}={\\widehat {\\sigma }}_{m}^{2}-K.}": {
    "before": "Finally, we obtain the estimated moments of the prior,",
    "after": "For example, if {\\displaystyle x_{i}|\\theta _{i}\\sim N(\\theta _{i},1)} , and if we assume a normal prior (which is a conjugate prior in this case), we conclude that {\\displaystyle \\theta _{n+1}\\sim N({\\widehat {\\mu }}_{\\pi },{\\widehat {\\sigma }}_{\\pi }^{2})} , from which the Bayes estimator of {\\displaystyle \\theta _{n+1}} based on {\\displaystyle x_{n+1}} can be calculated.",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle \\delta _{n}(x)=E[\\theta |x]={\\frac {a+x}{a+b+n}}.}": {
    "before": "Consider the estimator of θ based on binomial sample x ~b(θ, n ) where θ denotes the probability for success. Assuming θ is distributed according to the conjugate prior, which in this case is the Beta distribution B( a , b ), the posterior distribution is known to be B(a+x,b+n-x). Thus, the Bayes estimator under MSE is",
    "after": "The MLE in this case is x/n and so we get,",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle \\delta _{n}(x)={\\frac {a+b}{a+b+n}}E[\\theta ]+{\\frac {n}{a+b+n}}\\delta _{MLE}.}": {
    "before": "{\\displaystyle \\delta _{n}(x)=E[\\theta |x]={\\frac {a+x}{a+b+n}}.} The MLE in this case is x/n and so we get,",
    "after": "The last equation implies that, for n → ∞, the Bayes estimator (in the described problem) is close to the MLE.",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle W={Rv+Cm \\over v+m}\\ }": {
    "before": "The Internet Movie Database uses a formula for calculating and comparing the ratings of films by its users, including their Top Rated 250 Titles which is claimed to give \"a true Bayesian estimate\".  The following Bayesian formula was initially used to calculate a weighted average score for the Top 250, though the formula has since changed:",
    "after": "where: {\\displaystyle W\\ } = weighted rating {\\displaystyle R\\ } = average rating for the movie as a number from 1 to 10 (mean) = (Rating) {\\displaystyle v\\ } = number of votes/ratings for the movie = (votes) {\\displaystyle m\\ } = weight given to the prior estimate (in this case, the number of votes IMDB deemed necessary for average rating to approach statistical validity) {\\displaystyle C\\ } = the mean vote across the whole pool (currently 7.0)",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle W\\ } = weighted rating {\\displaystyle R\\ } = average rating for the movie as a number from 1 to 10 (mean) = (Rating) {\\displaystyle v\\ } = number of votes/ratings for the movie = (votes) {\\displaystyle m\\ } = weight given to the prior estimate (in this case, the number of votes IMDB deemed necessary for average rating to approach statistical validity) {\\displaystyle C\\ } = the mean vote across the whole pool (currently 7.0)": {
    "before": "{\\displaystyle W={Rv+Cm \\over v+m}\\ } where:",
    "after": "Note that W is just the weighted arithmetic mean of R and C with weight vector (v, m) . As the number of ratings surpasses m , the confidence of the average rating surpasses the confidence of the mean vote for all films (C), and the weighted bayesian rating (W) approaches a straight average (R). The closer v (the number of ratings for the film) is to zero, the closer W is to C , where W is the weighted rating and C is the average rating of all films. So, in simpler terms, the fewer ratings/votes cast for a film, the more that film's Weighted Rating will skew towards the average across all films, while films with many ratings/votes will have a rating approaching its pure arithmetic average rating.",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "For example, if Σ=σ/2, then the deviation of 4 measurements combined matches the deviation of the prior (assuming that errors of measurements are independent). And the weights α,β in the formula for posterior match this: the weight of the prior is 4 times the weight of the measurement. Combining this prior with n measurements with average v results in the posterior centered at": {
    "before": ", with weights in this weighted average being α=σ², β=Σ². Moreover, the squared posterior deviation is Σ²+σ². In other words, the prior is combined with the measurement in exactly the same way as if it were an extra measurement to take into account.",
    "after": "{\\displaystyle {\\frac {4}{4+n}}V+{\\frac {n}{4+n}}v}",
    "url": "https://en.wikipedia.org/wiki/Bayes action"
  },
  "{\\displaystyle V_{1}^{N}=\\{v_{1},v_{2},\\dots ,v_{N}\\},}": {
    "before": "Dynamic mode decomposition was first introduced by Schmid as a numerical procedure for extracting dynamical features from flow data.  The data takes the form of a snapshot sequence",
    "after": "where {\\displaystyle v_{i}\\in \\mathbb {R} ^{M}} is the {\\displaystyle i} -th snapshot of the flow field, and {\\displaystyle V_{1}^{N}\\in \\mathbb {R} ^{M\\times N}} is a data matrix whose columns are the individual snapshots. These snapshots are assumed to be related via a linear mapping that defines a linear dynamical system",
    "url": "https://en.wikipedia.org/wiki/Dynamic mode decomposition"
  },
  "{\\displaystyle v_{i+1}=Av_{i},}": {
    "before": "where {\\displaystyle v_{i}\\in \\mathbb {R} ^{M}} is the {\\displaystyle i} -th snapshot of the flow field, and {\\displaystyle V_{1}^{N}\\in \\mathbb {R} ^{M\\times N}} is a data matrix whose columns are the individual snapshots. These snapshots are assumed to be related via a linear mapping that defines a linear dynamical system",
    "after": "that remains approximately the same over the duration of the sampling period. Written in matrix form, this implies that",
    "url": "https://en.wikipedia.org/wiki/Dynamic mode decomposition"
  },
  "{\\displaystyle V_{2}^{N}=AV_{1}^{N-1}+re_{N-1}^{T},}": {
    "before": "that remains approximately the same over the duration of the sampling period. Written in matrix form, this implies that",
    "after": "where {\\displaystyle r} is the vector of residuals that accounts for behaviors that cannot be described completely by {\\displaystyle A} , {\\displaystyle e_{N-1}=\\{0,0,\\ldots ,1\\}\\in \\mathbb {R} ^{N-1}} , {\\displaystyle V_{1}^{N-1}=\\{v_{1},v_{2},\\dots ,v_{N-1}\\}} , and {\\displaystyle V_{2}^{N}=\\{v_{2},v_{3},\\dots ,v_{N}\\}} . Regardless of the approach, the output of DMD is the eigenvalues and eigenvectors of {\\displaystyle A} , which are referred to as the DMD eigenvalues and DMD modes respectively.",
    "url": "https://en.wikipedia.org/wiki/Dynamic mode decomposition"
  },
  "{\\displaystyle v_{N}=a_{1}v_{1}+a_{2}v_{2}+\\dots +a_{N-1}v_{N-1}+r=V_{1}^{N-1}a+r,}": {
    "before": "In fluids applications, the size of a snapshot, {\\displaystyle M} , is assumed to be much larger than the number of snapshots {\\displaystyle N} , so there are many equally valid choices of {\\displaystyle A} . The original DMD algorithm picks {\\displaystyle A} so that each of the snapshots in {\\displaystyle V_{2}^{N}} can be expressed as linear combinations of the snapshots in {\\displaystyle V_{1}^{N-1}} . Because most of the snapshots appear in both data sets, this representation is error free for all snapshots except {\\displaystyle v_{N}} , which is written as",
    "after": "where {\\displaystyle a={a_{1},a_{2},\\dots ,a_{N-1}}} is a set of coefficients DMD must identify and {\\displaystyle r} is the residual. In total,",
    "url": "https://en.wikipedia.org/wiki/Dynamic mode decomposition"
  },
  "{\\displaystyle V_{2}^{N}=AV_{1}^{N-1}+re_{N-1}^{T}=V_{1}^{N-1}S+re_{N-1}^{T},}": {
    "before": "where {\\displaystyle a={a_{1},a_{2},\\dots ,a_{N-1}}} is a set of coefficients DMD must identify and {\\displaystyle r} is the residual. In total,",
    "after": "where {\\displaystyle S} is the companion matrix",
    "url": "https://en.wikipedia.org/wiki/Dynamic mode decomposition"
  },
  "{\\displaystyle S={\\begin{pmatrix}0&0&\\dots &0&a_{1}\\\\1&0&\\dots &0&a_{2}\\\\0&1&\\dots &0&a_{3}\\\\\\vdots &\\vdots &\\ddots &\\vdots &\\vdots \\\\0&0&\\dots &1&a_{N-1}\\end{pmatrix}}.}": {
    "before": "where {\\displaystyle S} is the companion matrix",
    "after": "The vector {\\displaystyle a} can be computed by solving a least squares problem, which minimizes the overall residual. In particular if we take the QR decomposition of {\\displaystyle V_{1}^{N-1}=QR} , then {\\displaystyle a=R^{-1}Q^{T}v_{N}} .",
    "url": "https://en.wikipedia.org/wiki/Dynamic mode decomposition"
  },
  "{\\displaystyle V_{2}^{N}=AV_{1}^{N-1}+re_{N-1}^{T}=AU\\Sigma W^{T}+re_{N-1}^{T}.}": {
    "before": "Instead of computing the companion matrix {\\displaystyle S} , the SVD-based approach yields the matrix {\\displaystyle {\\tilde {S}}} that is related to {\\displaystyle A} via a similarity transform. To do this, assume we have the SVD of {\\displaystyle V_{1}^{N-1}=U\\Sigma W^{T}} . Then",
    "after": "Equivalent to the assumption made by the Arnoldi-based approach, we choose {\\displaystyle A} such that the snapshots in {\\displaystyle V_{2}^{N}} can be written as the linear superposition of the columns in {\\displaystyle U} , which is equivalent to requiring that they can be written as the superposition of POD modes . With this restriction, minimizing the residual requires that it is orthogonal to the POD basis (i.e., {\\displaystyle U^{T}r=0} ). Then multiplying both sides of the equation above by {\\displaystyle U^{T}} yields {\\displaystyle U^{T}V_{2}^{N}=U^{T}AU\\Sigma W^{T}} , which can be manipulated to obtain",
    "url": "https://en.wikipedia.org/wiki/Dynamic mode decomposition"
  },
  "{\\displaystyle U^{T}AU=U^{T}V_{2}^{N}W\\Sigma ^{-1}\\equiv {\\tilde {S}}.}": {
    "before": "Equivalent to the assumption made by the Arnoldi-based approach, we choose {\\displaystyle A} such that the snapshots in {\\displaystyle V_{2}^{N}} can be written as the linear superposition of the columns in {\\displaystyle U} , which is equivalent to requiring that they can be written as the superposition of POD modes . With this restriction, minimizing the residual requires that it is orthogonal to the POD basis (i.e., {\\displaystyle U^{T}r=0} ). Then multiplying both sides of the equation above by {\\displaystyle U^{T}} yields {\\displaystyle U^{T}V_{2}^{N}=U^{T}AU\\Sigma W^{T}} , which can be manipulated to obtain",
    "after": "Because {\\displaystyle A} and {\\displaystyle {\\tilde {S}}} are related via similarity transform, the eigenvalues of {\\displaystyle S} are the eigenvalues of {\\displaystyle A} , and if {\\displaystyle y} is an eigenvector of {\\displaystyle {\\tilde {S}}} , then {\\displaystyle Uy} is an eigenvector of {\\displaystyle A} .",
    "url": "https://en.wikipedia.org/wiki/Dynamic mode decomposition"
  },
  "{\\displaystyle q(x,y,t)=e^{-i\\omega t}{\\hat {q}}(x,t)e^{-(y/b)^{2}}\\Re \\left\\{e^{i(kx-\\omega t)}\\right\\}+{\\text{random noise}}}": {
    "before": "The DMD analysis assumes a pattern of the form {\\displaystyle q(x_{1},x_{2},x_{3},\\ldots )=e^{cx_{1}}{\\hat {q}}(x_{2},x_{3},\\ldots )} where {\\displaystyle x_{1}} is any of the independent variables of the problem, but has to be selected in advance. Take for example the pattern",
    "after": "With the time as the preselected exponential factor.",
    "url": "https://en.wikipedia.org/wiki/Dynamic mode decomposition"
  },
  "{\\displaystyle MRS_{xy}=-m_{\\mathrm {indif} }=-(dy/dx)\\,} {\\displaystyle MRS_{xy}=MU_{x}/MU_{y}\\,}": {
    "before": "Under the standard assumption of neoclassical economics that goods and services are continuously divisible, the marginal rates of substitution will be the same regardless of the direction of exchange, and will correspond to the slope of an indifference curve (more precisely, to the slope multiplied by −1) passing through the consumption bundle in question, at that point: mathematically, it is the implicit derivative . MRS of X for Y is the amount of Y which a consumer can exchange for one unit of X locally. The MRS is different at each point along the indifference curve thus it is important to keep locus in the definition. Further on this assumption, or otherwise on the assumption that utility is quantified , the marginal rate of substitution of good or service X for good or service Y (MRS xy ) is also equivalent to the marginal utility of X over the marginal utility of Y. Formally,",
    "after": "It is important to note that when comparing bundles of goods X and Y that give a constant utility (points along an indifference curve ), the marginal utility of X is measured in terms of units of Y that is being given up.",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "{\\displaystyle \\ MU_{x}=\\partial U/\\partial x} {\\displaystyle \\ MU_{y}=\\partial U/\\partial y}": {
    "before": "Assume the consumer utility function is defined by {\\displaystyle U(x,y)} , where U is consumer utility, x and y are goods. Then the marginal rate of substitution can be computed via partial differentiation , as follows.Also, note that:",
    "after": "where {\\displaystyle \\ MU_{x}} is the marginal utility with respect to good x and {\\displaystyle \\ MU_{y}} is the marginal utility with respect to good y .",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "{\\displaystyle \\ dU=(\\partial U/\\partial x)dx+(\\partial U/\\partial y)dy} , or substituting from above,": {
    "before": "By taking the total differential of the utility function equation, we obtain the following results:",
    "after": "{\\displaystyle \\ dU=MU_{x}dx+MU_{y}dy} , or, without loss of generality, the total derivative of the utility function with respect to good x , {\\displaystyle {\\frac {dU}{dx}}=MU_{x}{\\frac {dx}{dx}}+MU_{y}{\\frac {dy}{dx}}} , that is, {\\displaystyle {\\frac {dU}{dx}}=MU_{x}+MU_{y}{\\frac {dy}{dx}}} .",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "{\\displaystyle \\ dU=MU_{x}dx+MU_{y}dy} , or, without loss of generality, the total derivative of the utility function with respect to good x , {\\displaystyle {\\frac {dU}{dx}}=MU_{x}{\\frac {dx}{dx}}+MU_{y}{\\frac {dy}{dx}}} , that is, {\\displaystyle {\\frac {dU}{dx}}=MU_{x}+MU_{y}{\\frac {dy}{dx}}} .": {
    "before": "{\\displaystyle \\ dU=(\\partial U/\\partial x)dx+(\\partial U/\\partial y)dy} , or substituting from above,",
    "after": "Through any point on the indifference curve, dU/dx = 0, because U = c , where c is a constant. It follows from the above equation that:",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "{\\displaystyle 0=MU_{x}+MU_{y}{\\frac {dy}{dx}}} , or rearranging {\\displaystyle -{\\frac {dy}{dx}}={\\frac {MU_{x}}{MU_{y}}}}": {
    "before": "Through any point on the indifference curve, dU/dx = 0, because U = c , where c is a constant. It follows from the above equation that:",
    "after": "The marginal rate of substitution is defined as the absolute value of the slope of the indifference curve at whichever commodity bundle quantities are of interest. That turns out to equal the ratio of the marginal utilities:",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "{\\displaystyle 0=MU_{x}+MU_{y}{\\frac {dy}{dx}}} , or rearranging": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "{\\displaystyle \\ MRS_{xy}=MU_{x}/MU_{y}.\\,} .": {
    "before": "The marginal rate of substitution is defined as the absolute value of the slope of the indifference curve at whichever commodity bundle quantities are of interest. That turns out to equal the ratio of the marginal utilities:",
    "after": "When consumers maximize utility with respect to a budget constraint, the indifference curve is tangent to the budget line , therefore, with m representing slope:",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "{\\displaystyle \\ m_{\\mathrm {indif} }=m_{\\mathrm {budget} }} {\\displaystyle \\ -(MRS_{xy})=-(P_{x}/P_{y})} {\\displaystyle \\ MRS_{xy}=P_{x}/P_{y}}": {
    "before": "When consumers maximize utility with respect to a budget constraint, the indifference curve is tangent to the budget line , therefore, with m representing slope:",
    "after": "Therefore, when the consumer is choosing his utility maximized market basket on his budget line,",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "{\\displaystyle \\ MU_{x}/MU_{y}=P_{x}/P_{y}} {\\displaystyle \\ MU_{x}/P_{x}=MU_{y}/P_{y}}": {
    "before": "Therefore, when the consumer is choosing his utility maximized market basket on his budget line,",
    "after": "This important result tells us that utility is maximized when the consumer's budget is allocated so that the marginal utility per unit of money spent is equal for each good. If this equality did not hold, the consumer could increase his/her utility by cutting spending on the good with lower marginal utility per unit of money and increase spending on the other good. To decrease the marginal rate of substitution, the consumer must buy more of the good for which he/she wishes the marginal utility to fall for (due to the law of diminishing marginal utility).",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "{\\displaystyle \\ {\\frac {dMRS_{xy}}{dx}}<0{\\text{ Strict Convexity of Utility Function}}} {\\displaystyle \\ {\\frac {dMRS_{xy}}{dx}}=0{\\text{ Weak Convexity of Utility Function}}} {\\displaystyle \\ {\\frac {dMRS_{xy}}{dx}}>0{\\text{ Non Convexity of Utility Function}}}": {
    "before": "When analyzing the utility function of consumer's in terms of determining if they are convex or not. For the horizon of two goods we can apply a quick derivative test (take the derivative of MRS) to determine if our consumer's preferences are convex. If the derivative of MRS is negative the utility curve would be concave down meaning that it has a maximum and then decreases on either side of the maximum. This utility curve may have an appearance similar to that of a lower case n. If the derivative of MRS is equal to 0 the utility curve would be linear, the slope would stay constant throughout the utility curve. If the derivative of MRS is positive the utility curve would be convex up meaning that it has a minimum and then increases on either side of the minimum. This utility curve may have an appearance similar to that of a u. These statements are shown mathematically below.",
    "after": "For more than two variables, the use of the Hessian matrix is required.",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "For example, if the MRSxy = 2, the consumer will give up 2 units of Y to obtain 1 additional unit of X.": {
    "before": "It is important to note that when comparing bundles of goods X and Y that give a constant utility (points along an indifference curve), the marginal utility of X is measured in terms of units of Y that is being given up.",
    "after": "As one moves down a (standardly convex) indifference curve, the marginal rate of substitution decreases (as measured by the absolute value of the slope of the indifference curve, which decreases). This is known as the law of diminishing marginal rate of substitution.",
    "url": "https://en.wikipedia.org/wiki/Marginal rate of substitution"
  },
  "{\\displaystyle W_{a}(x):=\\sum _{i=1}^{n}a_{i}u_{i}(x).}": {
    "before": "Suppose each agent i is assigned a positive weight a i . For every allocation x , define the welfare of x as the weighted sum of utilities of all agents in x :",
    "after": "Let x a be an allocation that maximizes the welfare over all allocations:",
    "url": "https://en.wikipedia.org/wiki/Pareto efficiency"
  },
  "{\\displaystyle Y=Y(L,P,K).} ( 1 )": {
    "before": "Economic events are considered as processes of creation, motion and distribution of value that is firstly measured as exchange value . The factor interpretation of the exchange value, accepted by Econodynamics, is based on the Smith-Marx's labour theory of value , according to which efforts of workers {\\displaystyle L} are the most essential production factor. The theory is completed by the law of substitution , which states that the workers efforts in production of value could be substituted by work of production equipment driven with outer sources of power. Econodynamics introduces a concept of substitutive work {\\displaystyle P} , which is true work of production equipment, to characterize the functional role of machinery in production processes. The amount of production equipment is treated as physical capital {\\displaystyle K} , measured by its value; the variable {\\displaystyle P} can be considered as a capital service , a concept that was discussed by Robert Solow .  Production of value {\\displaystyle Y} can be considered as a function of the three production factors",
    "after": "Note that, in contrast to the conventional neoclassical theory , capital service {\\displaystyle P} is considered to be an independent production factor, while labour efforts {\\displaystyle L} are replaced with work of production equipment {\\displaystyle P} , not with the passive production factor -- capital {\\displaystyle K} .",
    "url": "https://en.wikipedia.org/wiki/Econodynamics"
  },
  "{\\displaystyle Y=\\left\\{{\\begin{array}{lll}\\xi K,&\\quad &\\xi >0\\\\[2mm]\\displaystyle {Y_{0}\\,{\\frac {L}{L_{0}}}\\left({\\frac {L_{0}}{L}}{\\frac {P}{P_{0}}}\\right)^{\\alpha }},&\\quad &0<\\alpha <1\\end{array}}\\right.,} ( 2 )": {
    "before": "The technological description assumes that work {\\displaystyle P} and labor {\\displaystyle L} should be considered as substituting each other, and the amount of production equipment, universally measured by its value {\\displaystyle K} , should be considered complementary to the work ( {\\displaystyle L} and {\\displaystyle P} ) of production equipment. Considering that the description should be valid for any starting point of time (the principle of universality), and assuming also that production is homogeneous, that is, the law of production of value does not change when the scale of production changes, we write the production function (1), which is the expression for production of value, in the form of two alternative relations",
    "after": "where {\\displaystyle L_{0}} and {\\displaystyle P_{0}} factors. Time-dependent values of {\\displaystyle \\alpha } and {\\displaystyle \\xi } are interrelated internal characteristics of the production system.",
    "url": "https://en.wikipedia.org/wiki/Econodynamics"
  },
  "{\\displaystyle \\lambda ={\\frac {\\Delta L}{\\Delta K}},\\quad \\varepsilon ={\\frac {\\Delta P}{\\Delta K}}.} ( 3 )": {
    "before": "The function of production equipment {\\displaystyle K} is to provide various means to attract labor {\\displaystyle L} and substitutive work {\\displaystyle P} to production. The characteristic of this ability of capital is the amount of labor and energy per unit (by value) of production equipment",
    "after": "These quantities determine the necessary amounts, respectively, of labor and productive energy consumption per unit (in value measure) of the equipment introduced, and, therefore, are universal technological characteristics of the production equipment. Note that the combination of technological coefficients (3) (in dimensionless form) determines the index {\\displaystyle \\alpha } in the relations (2)",
    "url": "https://en.wikipedia.org/wiki/Econodynamics"
  },
  "{\\displaystyle \\alpha ={\\frac {1-{\\overline {\\lambda }}}{{\\overline {\\varepsilon }}-{\\overline {\\lambda }}}}.} ( 4 )": {
    "before": "These quantities determine the necessary amounts, respectively, of labor and productive energy consumption per unit (in value measure) of the equipment introduced, and, therefore, are universal technological characteristics of the production equipment. Note that the combination of technological coefficients (3) (in dimensionless form) determines the index {\\displaystyle \\alpha } in the relations (2)",
    "after": "The technological index {\\displaystyle \\alpha } in equation (2) appears to be connected with technological characteristics, which can be evaluated independently, and, therefore, in contrast to the neoclassical theory , the production function (2) does not contain arbitrary parameters.",
    "url": "https://en.wikipedia.org/wiki/Econodynamics"
  },
  "{\\displaystyle dW=\\sum _{j=1}^{n}p_{j}\\,dQ_{j}.} ( 6 )": {
    "before": "Econodynamics establishes relationship between the real wealth and abstract concepts of value , utility and entropy . The artificial products created by humans: buildings, machines, vehicles, sanitation, clothes, home appliances and so on, can be sorted and counted, so that one consider the amounts of quantities in natural units of measurement {\\displaystyle Q_{1},Q_{2},...,Q_{n}} and the prices of all products {\\displaystyle p_{1},p_{2},...,p_{n}} to be given, so that one can define increase in value of a stock of products as",
    "after": "Due to dependence of prices on the amounts of products {\\displaystyle p_{i}=p_{i}(Q_{1},Q_{2},...,Q_{n})} , one can hardly expect that form (6) is a total differential of any function. In other words, one cannot say that {\\displaystyle W} is a characteristic of the set of the products which is independent of the history of their creation. However, a function of a state, which is called utility function , can be introduced on the basis of relation (6). Indeed, the linear form (6) can be multiplied by a certain function, which is called integration factor {\\displaystyle \\phi =\\phi (Q_{1},Q_{2},...,Q_{n})} , so that, instead of form (6), one has a total differential of a new function",
    "url": "https://en.wikipedia.org/wiki/Econodynamics"
  },
  "{\\displaystyle dU=\\sum _{j=1}^{n}\\phi (Q_{1},Q_{2},...,Q_{n})\\,p_{j}(Q_{1},Q_{2},...,Q_{n})\\,dQ_{j}.} ( 7 )": {
    "before": "Due to dependence of prices on the amounts of products {\\displaystyle p_{i}=p_{i}(Q_{1},Q_{2},...,Q_{n})} , one can hardly expect that form (6) is a total differential of any function. In other words, one cannot say that {\\displaystyle W} is a characteristic of the set of the products which is independent of the history of their creation. However, a function of a state, which is called utility function , can be introduced on the basis of relation (6). Indeed, the linear form (6) can be multiplied by a certain function, which is called integration factor {\\displaystyle \\phi =\\phi (Q_{1},Q_{2},...,Q_{n})} , so that, instead of form (6), one has a total differential of a new function",
    "after": "The introduced function {\\displaystyle U} is called utility function (objective), taking into account that the properties of function {\\displaystyle U} coincide with those of the conventional utility function, which is introduced as {subjective} utility function connected with sensation of preference of one aggregate of products as against another. The above transformation of value to utility reminds us transformation of heat to entropy in thermodynamics. In other terms, analogy between theory of utility and theory of heat was discussed by von Neumann and Morgenstern  (see item 3.2.1 of their work).",
    "url": "https://en.wikipedia.org/wiki/Econodynamics"
  },
  "{\\displaystyle dU\\approx -dS={\\frac {1}{T}}(L+P).} ( 8 )": {
    "before": "The artificial objects can be considered, as it was explained by Prigogine with collaborators,   as far-from-equilibrium objects (dissipative structures), and to create and maintain them, the fluxes of matter and energy are necessary to run through the system. In our case, energy comes in the form of human efforts {\\displaystyle L} and work of external sources {\\displaystyle P} that can be used by means of the appropriate equipment. The creation of dissipative structures leads to decrease in entropy, and utility {\\displaystyle U} can be considered as a close relation to entropy {\\displaystyle S} , though does not coincides with it. Considering that changes of internal energy in production of things can be neglected, one can write a thermodynamic relation",
    "after": "Reconciliation of the two points of view on the phenomenon of production leads to a unified picture that enables us to relate some aspects of our observations of economic phenomena to physical principles. A flux of information and work eventually determines new organisation of matter, which acquires forms of different commodities (complexity), whereby the production process is considered as a process of materialisation of information. The cost of materialisation of information is the work of production system. To maintain complexity in a thermodynamic system, fluxes of matter and energy must flow through the system.",
    "url": "https://en.wikipedia.org/wiki/Econodynamics"
  },
  "{\\displaystyle A(t)=\\,\\left({\\frac {K_{0}}{K}}{\\frac {P}{P_{0}}}\\right)^{\\alpha },\\quad 0<\\alpha <1} ( 9 )": {
    "before": "The earlier version of neoclassical production function  ignores the technological progress at all. It was introduced later into neo-classical theory by hand, as a time-dependent factor {\\displaystyle A(t)} ( growth accounting ). In contrast to this, the technological progress appears to be an internal property of the theory of ecodynamics. It is understood, first of all, as a progress in substitution of labour with work of production equipment in technological processes; the theory gives the expression",
    "after": "The exogenous, according to the neo-classical theory, technological progress {\\displaystyle A(t)} appears to be connected with the ratio of substitutive work to stock of capital {\\displaystyle P/K} , which can be considered as a measure of technological progress itself, independent on the assumption made in the neo-classical theory. Sometimes it is convenient to use the non-dimensional ratio of substitutive work to labour efforts {\\displaystyle P/L} as a characteristic of technological progress; this quantity can be interpreted as the number of 'mechanical workers', operating in the production processes, in line with an 'alive worker'. To the end of the last century, this ratio reaches, for example, 12 for the USA.  Apart of this, equation (9) contains the technological index {\\displaystyle \\alpha } , which, due to relation (2), determines effectiveness of usage of production factors {\\displaystyle L} and {\\displaystyle P} .",
    "url": "https://en.wikipedia.org/wiki/Econodynamics"
  },
  "{\\displaystyle P(AB)=P(A|B)P(B)=P(B|A)P(A)}": {
    "before": "Bayesian probability specifies that there is some prior probability . Bayesian statisticians can use both an objective and a subjective approach when interpreting the prior probability, which is then updated in light of new relevant information. The concept is a manipulation of conditional probabilities : ",
    "after": "Alternatively, a more simple understanding of the formula may be reached by substituting the events {\\displaystyle A} and {\\displaystyle B} to become respectively the hypothesis {\\displaystyle (H)} and the data {\\displaystyle (D)} . The rule allows for a judgment of the relative truth of the hypothesis given the data. ",
    "url": "https://en.wikipedia.org/wiki/Bayesian inference in marketing"
  },
  "{\\displaystyle P(H|D)={\\frac {P(D|H)P(H)}{P(D)}}}": {
    "before": "This is done through the calculation shown below, where {\\displaystyle P(D|H)} is the likelihood function . This assesses the probability of the observed data {\\displaystyle (D)} arising from the hypothesis {\\displaystyle (H)} ; {\\displaystyle P(H)} is the assigned prior probability or initial belief about the hypothesis; the denominator {\\displaystyle P(D)} is formed by the integrating or summing of {\\displaystyle P(D|H)P(H)} ; {\\displaystyle P(H|D)} is known as the posterior which is the recalculated probability, or updated belief about the hypothesis. It is a result of the prior beliefs as well as sample information. The posterior is a conditional distribution as the result of collecting or in consideration of new relevant data. ",
    "after": "To sum up this formula: the posterior probability of the hypothesis is equal to the prior probability of the hypothesis multiplied by the conditional probability of the evidence given the hypothesis, divided by the probability of the new evidence. ",
    "url": "https://en.wikipedia.org/wiki/Bayesian inference in marketing"
  },
  "{\\displaystyle \\max _{c}\\int _{0}^{\\infty }e^{-(\\rho -n)t}u(c)\\,\\mathrm {d} t} {\\displaystyle {\\text{subject to}}\\quad c=f(k)-(n+\\delta )k-{\\dot {k}}}": {
    "before": ".Thus we have the social planner's problem:",
    "after": "where an initial non-zero capital stock {\\displaystyle k(0)=k_{0}>0} is given.",
    "url": "https://en.wikipedia.org/wiki/Ramsey–Cass–Koopmans model"
  },
  "{\\displaystyle f_{k}\\left(k^{\\ast }\\right)=\\delta +\\rho \\quad {\\text{and}}\\quad c^{\\ast }=f\\left(k^{\\ast }\\right)-(n+\\delta )k^{\\ast }} {\\displaystyle (0,0)} {\\displaystyle f(k^{*})=(n+\\delta )k^{*}{\\text{ with }}k^{*}>0,c^{*}=0}": {
    "before": "A steady state {\\displaystyle (k^{\\ast },c^{\\ast })} for the system is found by setting {\\displaystyle {\\dot {k}}} and {\\displaystyle {\\dot {c}}} equal to zero. There are three solutions:",
    "after": "The first is the only solution in the interior of the upper quadrant. It is a saddle point (as shown below). The second is a repelling point. The third is a degenerate stable equilibrium.",
    "url": "https://en.wikipedia.org/wiki/Ramsey–Cass–Koopmans model"
  },
  "{\\displaystyle \\mathbf {J} \\left(k^{\\ast },c^{\\ast }\\right)={\\begin{bmatrix}\\rho -n&-1\\\\{\\frac {1}{\\sigma }}f_{kk}(k)\\cdot c^{\\ast }&0\\end{bmatrix}}}": {
    "before": "where {\\displaystyle \\mathbf {J} (k^{\\ast },c^{\\ast })} is the Jacobian matrix evaluated at steady state, [note 5] given by",
    "after": "which has determinant {\\displaystyle \\left|\\mathbf {J} \\left(k^{\\ast },c^{\\ast }\\right)\\right|={\\frac {1}{\\sigma }}f_{kk}(k)\\cdot c^{\\ast }<0} since {\\displaystyle c^{*}>0} , {\\displaystyle \\sigma } is positive by assumption, and {\\displaystyle f_{kk}<0} since {\\displaystyle f} is concave (Inada condition). Since the determinant equals the product of the eigenvalues , the eigenvalues must be real and opposite in sign. ",
    "url": "https://en.wikipedia.org/wiki/Ramsey–Cass–Koopmans model"
  },
  "{\\displaystyle H=e^{-\\rho t}u(c)+\\mu \\left[f(k)-(n+\\delta )k-c\\right]}": {
    "before": "The Hamiltonian for the Ramsey–Cass–Koopmans problem is",
    "after": "where {\\displaystyle \\mu }",
    "url": "https://en.wikipedia.org/wiki/Ramsey–Cass–Koopmans model"
  },
  "{\\displaystyle \\mathbf {J} \\left(k,c\\right)={\\begin{bmatrix}{\\frac {\\partial {\\dot {k}}}{\\partial k}}&{\\frac {\\partial {\\dot {k}}}{\\partial c}}\\\\{\\frac {\\partial {\\dot {c}}}{\\partial k}}&{\\frac {\\partial {\\dot {c}}}{\\partial c}}\\end{bmatrix}}={\\begin{bmatrix}f_{k}(k)-(n+\\delta )&-1\\\\{\\frac {1}{\\sigma }}f_{kk}(k)\\cdot c&{\\frac {1}{\\sigma }}\\left[f_{k}(k)-\\delta -\\rho \\right]\\end{bmatrix}}}": {
    "before": "The Jacobian matrix of the Ramsey–Cass–Koopmans system is",
    "after": "SeeAfonso, Oscar; Vasconcelos, Paulo B. (2016). Computational Economics : A Concise Introduction . New York: Routledge. p. 163. ISBN 978-1-138-85965-4 .",
    "url": "https://en.wikipedia.org/wiki/Ramsey–Cass–Koopmans model"
  },
  "{\\displaystyle {\\dot {k}}=f(k)-(n+\\delta )k-c}": {
    "before": "{\\displaystyle {\\dot {k}}=f(k)-(n+\\delta )k-c}",
    "after": "{\\displaystyle {\\dot {k}}=f(k)-(n+\\delta )k-c}",
    "url": "https://en.wikipedia.org/wiki/Ramsey–Cass–Koopmans model"
  },
  "{\\displaystyle {\\dot {c}}=\\sigma (c)\\left[f_{k}(k)-\\delta -\\rho \\right]\\cdot c}": {
    "before": "{\\displaystyle {\\dot {c}}=\\sigma (c)\\left[f_{k}(k)-\\delta -\\rho \\right]\\cdot c}",
    "after": "{\\displaystyle {\\dot {c}}=\\sigma (c)\\left[f_{k}(k)-\\delta -\\rho \\right]\\cdot c}",
    "url": "https://en.wikipedia.org/wiki/Ramsey–Cass–Koopmans model"
  },
  "{\\displaystyle {\\begin{cases}{\\dot {k}}=f(k)-(n+\\delta )k-c\\\\{\\dot {c}}=\\sigma (c)\\left[f_{k}(k)-\\delta -\\rho \\right]\\cdot c\\end{cases}}}": {
    "before": "{\\displaystyle {\\begin{cases}{\\dot {k}}=f(k)-(n+\\delta )k-c\\\\{\\dot {c}}=\\sigma (c)\\left[f_{k}(k)-\\delta -\\rho \\right]\\cdot c\\end{cases}}}",
    "after": "{\\displaystyle {\\begin{cases}{\\dot {k}}=f(k)-(n+\\delta )k-c\\\\{\\dot {c}}=\\sigma (c)\\left[f_{k}(k)-\\delta -\\rho \\right]\\cdot c\\end{cases}}}",
    "url": "https://en.wikipedia.org/wiki/Ramsey–Cass–Koopmans model"
  },
  "Recency = 10 – the number of months that have passed since the customer last purchased ": {
    "before": "Customer purchases may be represented by a table with columns for the customer name, date of purchase and purchase value. There are many approaches to quantitatively defining RFM values, and the best approaches will be dependent on customer journey and business model. One approach to RFM is to assign a score for each dimension on a scale from 1 to 10. The maximum score represents the preferred behavior and a formula could be used to calculate the three scores for each customer. For example, a service-based business could use these calculations:",
    "after": "Frequency = the maximum of \"the number of purchases by the customer in the last 12 months (with a limit of 10)\" and 1",
    "url": "https://en.wikipedia.org/wiki/RFM (market research)"
  },
  "Frequency = the maximum of \"the number of purchases by the customer in the last 12 months (with a limit of 10)\" and 1": {
    "before": "Recency = 10 – the number of months that have passed since the customer last purchased ",
    "after": "Monetary = the highest value of all purchases by the customer expressed in relation to some benchmark value",
    "url": "https://en.wikipedia.org/wiki/RFM (market research)"
  },
  "Monetary = the highest value of all purchases by the customer expressed in relation to some benchmark value": {
    "before": "Frequency = the maximum of \"the number of purchases by the customer in the last 12 months (with a limit of 10)\" and 1",
    "after": "For example, if the monetary benchmark allocated a score of 10 to annual spend over $500, for a customer who had made three purchases in the last year, the most recent being 3 months ago, and spent $600 in the year, their scores would be: R=7; F=3; M=10. Alternatively, categories can be defined for each attribute, e.g. recency might be broken into three categories: customers with purchases within the last 90 days; between 91 and 365 days; and longer than 365 days. Such categories may be derived from business rules or using data mining techniques to find meaningful breaks.",
    "url": "https://en.wikipedia.org/wiki/RFM (market research)"
  },
  "{\\displaystyle {\\underline {v_{i}}}=\\max _{a_{i}}\\min _{a_{-i}}{v_{i}(a_{i},a_{-i})}}": {
    "before": "The maximin value is the highest value that the player can be sure to get without knowing the actions of the other players; equivalently, it is the lowest value the other players can force the player to receive when they know the player's action. Its formal definition is: ",
    "after": "Where:i is the index of the player of interest. {\\displaystyle -i} denotes all other players except player i . {\\displaystyle a_{i}} is the action taken by player i . {\\displaystyle a_{-i}} denotes the actions taken by all other players. {\\displaystyle v_{i}} is the value function of player i .",
    "url": "https://en.wikipedia.org/wiki/Minimax"
  },
  "{\\displaystyle {\\overline {v_{i}}}=\\min _{a_{-i}}\\max _{a_{i}}{v_{i}(a_{i},a_{-i})}}": {
    "before": "The minimax value of a player is the smallest value that the other players can force the player to receive, without knowing the player's actions; equivalently, it is the largest value the player can be sure to get when they know the actions of the other players. Its formal definition is: ",
    "after": "The definition is very similar to that of the maximin value – only the order of the maximum and minimum operators is inverse. In the above example:",
    "url": "https://en.wikipedia.org/wiki/Minimax"
  },
  "{\\displaystyle {\\overline {v_{i}}}=\\min _{a_{-i}}\\max _{a_{i}}{v_{i}(a_{i},a_{-i})}=\\min _{a_{-i}}{\\Big (}\\max _{a_{i}}{v_{i}(a_{i},a_{-i})}{\\Big )}}": {
    "before": "Another way to understand the notation is by reading from right to left: When we write",
    "after": "the initial set of outcomes {\\displaystyle \\ v_{i}(a_{i},a_{-i})\\ } depends on both {\\displaystyle \\ {a_{i}}\\ } and {\\displaystyle \\ {a_{-i}}\\ .} We first marginalize away {\\displaystyle {a_{i}}} from {\\displaystyle v_{i}(a_{i},a_{-i})} , by maximizing over {\\displaystyle \\ {a_{i}}\\ } (for every possible value of {\\displaystyle {a_{-i}}} ) to yield a set of marginal outcomes {\\displaystyle \\ v'_{i}(a_{-i})\\,,} which depends only on {\\displaystyle \\ {a_{-i}}\\ .} We then minimize over {\\displaystyle \\ {a_{-i}}\\ } over these outcomes. (Conversely for maximin.)",
    "url": "https://en.wikipedia.org/wiki/Minimax"
  },
  "{\\displaystyle \\sup _{\\theta }R(\\theta ,{\\tilde {\\delta }})=\\inf _{\\delta }\\ \\sup _{\\theta }\\ R(\\theta ,\\delta )\\ .}": {
    "before": "In classical statistical decision theory , we have an estimator {\\displaystyle \\ \\delta \\ } that is used to estimate a parameter {\\displaystyle \\ \\theta \\in \\Theta \\ .} We also assume a risk function {\\displaystyle \\ R(\\theta ,\\delta )\\ .} usually specified as the integral of a loss function . In this framework, {\\displaystyle \\ {\\tilde {\\delta }}\\ } is called minimax if it satisfies",
    "after": "An alternative criterion in the decision theoretic framework is the Bayes estimator in the presence of a prior distribution {\\displaystyle \\Pi \\ .} An estimator is Bayes if it minimizes the average risk",
    "url": "https://en.wikipedia.org/wiki/Minimax"
  },
  "if depth = 0 or node is a terminal node then": {
    "before": "function minimax(node, depth, maximizingPlayer) is",
    "after": "return the heuristic value of node",
    "url": "https://en.wikipedia.org/wiki/Minimax"
  },
  "value := max(value, minimax(child, depth − 1, FALSE))": {
    "before": "for each child of node do",
    "after": "return value",
    "url": "https://en.wikipedia.org/wiki/Minimax"
  },
  "value := min(value, minimax(child, depth − 1, TRUE))": {
    "before": "for each child of node do",
    "after": "return value",
    "url": "https://en.wikipedia.org/wiki/Minimax"
  },
  "{\\displaystyle F_{ij}=G\\cdot {\\frac {M_{i}M_{j}}{D_{ij}}}.}": {
    "before": "The model was first introduced in economics world by Walter Isard in 1954.  The basic model for trade between two countries ( i and j ) takes the form of",
    "after": "In this formula G is a constant, F stands for trade flow, D stands for the distance and M stands for the economic dimensions of the countries that are being measured. The equation can be changed into a linear form for the purpose of econometric analyses by employing logarithms. The model has been used by economists to analyse the determinants of bilateral trade flows such as common borders, common languages, common legal systems, common currencies, common colonial legacies, and it has been used to test the effectiveness of trade agreements and organizations such as the North American Free Trade Agreement (NAFTA) and the World Trade Organization (WTO) (Head and Mayer 2014). The model has also been used in international relations to evaluate the impact of treaties and alliances on trade (Head and Mayer).",
    "url": "https://en.wikipedia.org/wiki/Gravity model of trade"
  },
  "{\\displaystyle F_{ij}=G{\\frac {M_{i}^{\\beta _{1}}M_{j}^{\\beta _{2}}}{D_{ij}^{\\beta _{3}}}}\\eta _{ij}}": {
    "before": "Since the gravity model for trade does not hold exactly, in econometric applications it is customary to specify",
    "after": "where {\\displaystyle F_{ij}} represents volume of trade from country {\\displaystyle i} to country {\\displaystyle j} , {\\displaystyle M_{i}} and {\\displaystyle M_{j}} typically represent the GDPs for countries {\\displaystyle i} and {\\displaystyle j} , {\\displaystyle D_{ij}} denotes the distance between the two countries, and {\\displaystyle \\eta } represents an error term with expectation equal to 1.",
    "url": "https://en.wikipedia.org/wiki/Gravity model of trade"
  },
  "{\\displaystyle \\ln(F_{ij})=\\beta _{0}+\\beta _{1}\\ln(M_{i})+\\beta _{2}\\ln(M_{j})-\\beta _{3}\\ln(D_{ij})+\\varepsilon _{ij}.}": {
    "before": "The traditional approach to estimating this equation consists in taking logs of both sides, leading to a log-log model of the form (note: constant G becomes part of {\\displaystyle \\beta _{0}} ):",
    "after": "However, this approach has two major problems. First, it obviously cannot be used when there are observations for which {\\displaystyle F_{ij}} is equal to zero. Second, Santos Silva and Tenreyro (2006) argued that estimating the log-linearized equation by least squares (OLS) can lead to significant biases if the researcher believes the true model to be nonlinear in its parameters. As an alternative, these authors have suggested that the model should be estimated in its multiplicative form, i.e.,",
    "url": "https://en.wikipedia.org/wiki/Gravity model of trade"
  },
  "{\\displaystyle F_{ij}=\\exp[\\beta _{0}+\\beta _{1}\\ln(M_{i})+\\beta _{2}\\ln(M_{j})-\\beta _{3}\\ln(D_{ij})]\\eta _{ij},}": {
    "before": "However, this approach has two major problems. First, it obviously cannot be used when there are observations for which {\\displaystyle F_{ij}} is equal to zero. Second, Santos Silva and Tenreyro (2006) argued that estimating the log-linearized equation by least squares (OLS) can lead to significant biases if the researcher believes the true model to be nonlinear in its parameters. As an alternative, these authors have suggested that the model should be estimated in its multiplicative form, i.e.,",
    "after": "using a Poisson pseudo-maximum likelihood (PPML) estimator based on the Poisson model usually used for count data. As shown by Santos Silva and Tenreyro (2006), PPML estimates of common gravity variables can be different from their OLS counterparts. In particular, they found that the trade-reducing effects of distance were smaller and that the effects of colonial ties were statistically insignificant.",
    "url": "https://en.wikipedia.org/wiki/Gravity model of trade"
  },
  "{\\displaystyle \\mathrm {MASE} =\\mathrm {mean} \\left({\\frac {\\left|e_{j}\\right|}{{\\frac {1}{T-1}}\\sum _{t=2}^{T}\\left|Y_{t}-Y_{t-1}\\right|}}\\right)={\\frac {{\\frac {1}{J}}\\sum _{j}\\left|e_{j}\\right|}{{\\frac {1}{T-1}}\\sum _{t=2}^{T}\\left|Y_{t}-Y_{t-1}\\right|}}} ": {
    "before": "For a non-seasonal time series,  the mean absolute scaled error is estimated by",
    "after": "where the numerator e j is the forecast error for a given period (with J , the number of forecasts), defined as the actual value ( Y j ) minus the forecast value ( F j ) for that period: e j = Y j − F j , and the denominator is the mean absolute error of the one-step \" naive forecast method \" on the training set (here defined as t = 1..T ),  which uses the actual value from the prior period as the forecast: F t = Y t −1 ",
    "url": "https://en.wikipedia.org/wiki/Mean absolute scaled error"
  },
  "{\\displaystyle \\mathrm {MASE} =\\mathrm {mean} \\left({\\frac {\\left|e_{j}\\right|}{{\\frac {1}{J}}\\sum _{j=1}^{J}\\left|Y_{j}-{\\bar {Y}}\\right|}}\\right)={\\frac {{\\frac {1}{J}}\\sum _{j}\\left|e_{j}\\right|}{{\\frac {1}{J}}\\sum _{j}\\left|Y_{j}-{\\bar {Y}}\\right|}}}": {
    "before": "For non-time series data, the mean of the data ( {\\displaystyle {\\bar {Y}}} ) can be used as the \"base\" forecast. ",
    "after": "In this case the MASE is the Mean absolute error divided by the Mean Absolute Deviation .",
    "url": "https://en.wikipedia.org/wiki/Mean absolute scaled error"
  },
  "{\\displaystyle S(f)=\\int _{-\\infty }^{\\infty }s(t)\\cdot e^{-i2\\pi ft}\\,dt.}": {
    "before": "Most often, the unqualified term Fourier transform refers to the transform of functions of a continuous real argument, and it produces a continuous function of frequency, known as a frequency distribution . One function is transformed into another, and the operation is reversible. When the domain of the input (initial) function is time ( t ), and the domain of the output (final) function is ordinary frequency , the transform of function s ( t ) at frequency f is given by the complex number:",
    "after": "Evaluating this quantity for all values of f produces the frequency-domain function. Then s ( t ) can be represented as a recombination of complex exponentials of all possible frequencies:",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle s(t)=\\int _{-\\infty }^{\\infty }S(f)\\cdot e^{i2\\pi ft}\\,df,}": {
    "before": "Evaluating this quantity for all values of f produces the frequency-domain function. Then s ( t ) can be represented as a recombination of complex exponentials of all possible frequencies:",
    "after": "which is the inverse transform formula. The complex number, S ( f ) , conveys both amplitude and phase of frequency f .",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle S[k]={\\frac {1}{P}}\\int _{P}s_{P}(t)\\cdot e^{-i2\\pi {\\frac {k}{P}}t}\\,dt,\\quad k\\in \\mathbb {Z} ,} (where ∫ P is the integral over any interval of length P ).": {
    "before": "The Fourier transform of a periodic function, s P ( t ) , with period P , becomes a Dirac comb function, modulated by a sequence of complex coefficients :",
    "after": "The inverse transform, known as Fourier series , is a representation of s P ( t ) in terms of a summation of a potentially infinite number of harmonically related sinusoids or complex exponential functions, each with an amplitude and phase specified by one of the coefficients:",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle s_{P}(t)\\ \\ =\\ \\ {\\mathcal {F}}^{-1}\\left\\{\\sum _{k=-\\infty }^{+\\infty }S[k]\\,\\delta \\left(f-{\\frac {k}{P}}\\right)\\right\\}\\ \\ =\\ \\ \\sum _{k=-\\infty }^{\\infty }S[k]\\cdot e^{i2\\pi {\\frac {k}{P}}t}.}": {
    "before": "The inverse transform, known as Fourier series , is a representation of s P ( t ) in terms of a summation of a potentially infinite number of harmonically related sinusoids or complex exponential functions, each with an amplitude and phase specified by one of the coefficients:",
    "after": "Any s P ( t ) can be expressed as a periodic summation of another function, s ( t ) :",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle s_{P}(t)\\,\\triangleq \\,\\sum _{m=-\\infty }^{\\infty }s(t-mP),}": {
    "before": "Any s P ( t ) can be expressed as a periodic summation of another function, s ( t ) :",
    "after": "and the coefficients are proportional to samples of S ( f ) at discrete intervals of 1 / P :",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle S[k]={\\frac {1}{P}}\\cdot S\\left({\\frac {k}{P}}\\right).} [A]": {
    "before": "and the coefficients are proportional to samples of S ( f ) at discrete intervals of 1 / P :",
    "after": "Note that any s ( t ) whose transform has the same discrete sample values can be used in the periodic summation. A sufficient condition for recovering s ( t ) (and therefore S ( f ) ) from just these samples (i.e. from the Fourier series) is that the non-zero portion of s ( t ) be confined to a known interval of duration P , which is the frequency domain dual of the Nyquist–Shannon sampling theorem .",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle S_{\\frac {1}{T}}(f)\\ \\triangleq \\ \\underbrace {\\sum _{k=-\\infty }^{\\infty }S\\left(f-{\\frac {k}{T}}\\right)\\equiv \\overbrace {\\sum _{n=-\\infty }^{\\infty }s[n]\\cdot e^{-i2\\pi fnT}} ^{\\text{Fourier series (DTFT)}}} _{\\text{Poisson summation formula}}={\\mathcal {F}}\\left\\{\\sum _{n=-\\infty }^{\\infty }s[n]\\ \\delta (t-nT)\\right\\},\\,}": {
    "before": "The DTFT is the mathematical dual of the time-domain Fourier series. Thus, a convergent periodic summation in the frequency domain can be represented by a Fourier series, whose coefficients are samples of a related continuous time function:",
    "after": "which is known as the DTFT. Thus the DTFT of the s [ n ] sequence is also the Fourier transform of the modulated Dirac comb function. [B]",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle s[n]\\ \\triangleq \\ T\\int _{\\frac {1}{T}}S_{\\frac {1}{T}}(f)\\cdot e^{i2\\pi fnT}\\,df=T\\underbrace {\\int _{-\\infty }^{\\infty }S(f)\\cdot e^{i2\\pi fnT}\\,df} _{\\triangleq \\,s(nT)}.}": {
    "before": "The Fourier series coefficients (and inverse transform), are defined by:",
    "after": "Parameter T corresponds to the sampling interval, and this Fourier series can now be recognized as a form of the Poisson summation formula . Thus we have the important result that when a discrete data sequence, s [ n ] , is proportional to samples of an underlying continuous function, s ( t ) , one can observe a periodic summation of the continuous Fourier transform, S ( f ) . Note that any s ( t ) with the same discrete sample values produces the same DTFT But under certain idealized conditions one can theoretically recover S ( f ) and s ( t ) exactly. A sufficient condition for perfect recovery is that the non-zero portion of S ( f ) be confined to a known frequency interval of width 1 / T . When that interval is [− 1 / 2 T , 1 / 2 T ] , the applicable reconstruction formula is the Whittaker–Shannon interpolation formula . This is a cornerstone in the foundation of digital signal processing .",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle S[k]=\\sum _{n}s_{N}[n]\\cdot e^{-i2\\pi {\\frac {k}{N}}n},\\quad k\\in \\mathbb {Z} ,} (where Σ n is the sum over any sequence of length N ).": {
    "before": "Similar to a Fourier series, the DTFT of a periodic sequence, {\\displaystyle s_{N}[n]} , with period {\\displaystyle N} , becomes a Dirac comb function, modulated by a sequence of complex coefficients (see DTFT § Periodic data ):",
    "after": "The S [ k ] sequence is what is customarily known as the DFT of one cycle of s N . It is also N -periodic, so it is never necessary to compute more than N coefficients. The inverse transform, also known as a discrete Fourier series , is given by:",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle s_{N}[n]={\\frac {1}{N}}\\sum _{k}S[k]\\cdot e^{i2\\pi {\\frac {n}{N}}k},} where Σ k is the sum over any sequence of length N .": {
    "before": "The S [ k ] sequence is what is customarily known as the DFT of one cycle of s N . It is also N -periodic, so it is never necessary to compute more than N coefficients. The inverse transform, also known as a discrete Fourier series , is given by:",
    "after": "When s N [ n ] is expressed as a periodic summation of another function:",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle s_{N}[n]\\,\\triangleq \\,\\sum _{m=-\\infty }^{\\infty }s[n-mN],} and {\\displaystyle s[n]\\,\\triangleq \\,s(nT),} [C]": {
    "before": "When s N [ n ] is expressed as a periodic summation of another function:",
    "after": "the coefficients are proportional to samples of S 1/ T ( f ) at disrete intervals of 1 / P = 1 / NT :",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle S[k]={\\frac {1}{T}}\\cdot S_{\\frac {1}{T}}\\left({\\frac {k}{P}}\\right).} [D]": {
    "before": "the coefficients are proportional to samples of S 1/ T ( f ) at disrete intervals of 1 / P = 1 / NT :",
    "after": "Conversely, when one wants to compute an arbitrary number ( N ) of discrete samples of one cycle of a continuous DTFT, S 1/ T ( f ) , it can be done by computing the relatively simple DFT of s N [ n ] , as defined above. In most cases, N is chosen equal to the length of non-zero portion of s [ n ] . Increasing N , known as zero-padding or interpolation , results in more closely spaced samples of one cycle of S 1/ T ( f ) . Decreasing N , causes overlap (adding) in the time-domain (analogous to aliasing ), which corresponds to decimation in the frequency domain. (see Discrete-time Fourier transform § L=N×I ) In most cases of practical interest, the s [ n ] sequence represents a longer sequence that was truncated by the application of a finite-length window function or FIR filter array.",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle {\\begin{array}{rccccccccc}{\\text{Time domain}}&s&=&s_{_{\\text{RE}}}&+&s_{_{\\text{RO}}}&+&is_{_{\\text{IE}}}&+&\\underbrace {i\\ s_{_{\\text{IO}}}} \\\\&{\\Bigg \\Updownarrow }{\\mathcal {F}}&&{\\Bigg \\Updownarrow }{\\mathcal {F}}&&\\ \\ {\\Bigg \\Updownarrow }{\\mathcal {F}}&&\\ \\ {\\Bigg \\Updownarrow }{\\mathcal {F}}&&\\ \\ {\\Bigg \\Updownarrow }{\\mathcal {F}}\\\\{\\text{Frequency domain}}&S&=&S_{\\text{RE}}&+&\\overbrace {\\,i\\ S_{\\text{IO}}\\,} &+&iS_{\\text{IE}}&+&S_{\\text{RO}}\\end{array}}}": {
    "before": "When the real and imaginary parts of a complex function are decomposed into their even and odd parts , there are four components, denoted below by the subscripts RE, RO, IE, and IO. And there is a one-to-one mapping between the four components of a complex time function and the four components of its complex frequency transform: ",
    "after": "From this, various relationships are apparent, for example:",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle {\\begin{aligned}r_{1}&=x_{1}+x_{2}+x_{3}\\\\r_{2}&=x_{1}+\\zeta x_{2}+\\zeta ^{2}x_{3}\\\\r_{3}&=x_{1}+\\zeta ^{2}x_{2}+\\zeta x_{3}\\end{aligned}}}": {
    "before": "An early modern development toward Fourier analysis was the 1770 paper Réflexions sur la résolution algébrique des équations by Lagrange, which in the method of Lagrange resolvents used a complex Fourier decomposition to study the solution of a cubic:  Lagrange transformed the roots x 1 , x 2 , x 3 into the resolvents:",
    "after": "where ζ is a cubic root of unity , which is the DFT of order 3.",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle {\\begin{aligned}\\sum _{n=-\\infty }^{+\\infty }T\\cdot s(nT)\\delta (t-nT)&=\\sum _{n=-\\infty }^{+\\infty }T\\cdot s(t)\\delta (t-nT)\\\\&=s(t)\\cdot T\\sum _{n=-\\infty }^{+\\infty }\\delta (t-nT).\\end{aligned}}}": {
    "before": "We may also note that:",
    "after": "Consequently, a common practice is to model \"sampling\" as a multiplication by the",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle s(t)=\\int _{-\\infty }^{\\infty }S(f)\\cdot e^{i2\\pi ft}\\,df}": {
    "before": "Inverse",
    "after": "{\\displaystyle \\underbrace {s_{P}(t)=\\sum _{k=-\\infty }^{\\infty }S[k]\\cdot e^{i2\\pi {\\frac {k}{P}}t}} _{\\text{Poisson summation formula (Fourier series)}}\\,}",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle \\underbrace {s_{P}(t)=\\sum _{k=-\\infty }^{\\infty }S[k]\\cdot e^{i2\\pi {\\frac {k}{P}}t}} _{\\text{Poisson summation formula (Fourier series)}}\\,}": {
    "before": "{\\displaystyle s(t)=\\int _{-\\infty }^{\\infty }S(f)\\cdot e^{i2\\pi ft}\\,df}",
    "after": "s ( nT ) transforms (discrete-time) Continuous frequency Discrete frequencies Transform {\\displaystyle \\underbrace {{\\frac {1}{T}}S_{\\frac {1}{T}}(f)\\,\\triangleq \\,\\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot e^{-i2\\pi fnT}} _{\\text{Poisson summation formula (DTFT)}}} {\\displaystyle {\\begin{aligned}\\overbrace {{\\frac {1}{T}}S_{\\frac {1}{T}}\\left({\\frac {k}{NT}}\\right)} ^{S[k]}\\,&\\triangleq \\,\\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot e^{-i2\\pi {\\frac {kn}{N}}}\\\\&\\equiv \\underbrace {\\sum _{n}s_{P}(nT)\\cdot e^{-i2\\pi {\\frac {kn}{N}}}} _{\\text{DFT}}\\,\\end{aligned}}} Inverse {\\displaystyle s(nT)=T\\int _{\\frac {1}{T}}{\\frac {1}{T}}S_{\\frac {1}{T}}(f)\\cdot e^{i2\\pi fnT}\\,df} {\\displaystyle \\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot \\delta (t-nT)=\\underbrace {\\int _{-\\infty }^{\\infty }{\\frac {1}{T}}\\ S_{\\frac {1}{T}}(f)\\cdot e^{i2\\pi ft}\\,df} _{\\text{inverse Fourier transform}}\\,} {\\displaystyle {\\begin{aligned}s_{P}(nT)&=\\overbrace {{\\frac {1}{N}}\\sum _{k}S[k]\\cdot e^{i2\\pi {\\frac {kn}{N}}}} ^{\\text{inverse DFT}}\\\\&={\\tfrac {1}{P}}\\sum _{k}S_{\\frac {1}{T}}\\left({\\frac {k}{P}}\\right)\\cdot e^{i2\\pi {\\frac {kn}{N}}}\\end{aligned}}}",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle \\underbrace {{\\frac {1}{T}}S_{\\frac {1}{T}}(f)\\,\\triangleq \\,\\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot e^{-i2\\pi fnT}} _{\\text{Poisson summation formula (DTFT)}}}": {
    "before": "Transform",
    "after": "{\\displaystyle {\\begin{aligned}\\overbrace {{\\frac {1}{T}}S_{\\frac {1}{T}}\\left({\\frac {k}{NT}}\\right)} ^{S[k]}\\,&\\triangleq \\,\\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot e^{-i2\\pi {\\frac {kn}{N}}}\\\\&\\equiv \\underbrace {\\sum _{n}s_{P}(nT)\\cdot e^{-i2\\pi {\\frac {kn}{N}}}} _{\\text{DFT}}\\,\\end{aligned}}}",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle {\\begin{aligned}\\overbrace {{\\frac {1}{T}}S_{\\frac {1}{T}}\\left({\\frac {k}{NT}}\\right)} ^{S[k]}\\,&\\triangleq \\,\\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot e^{-i2\\pi {\\frac {kn}{N}}}\\\\&\\equiv \\underbrace {\\sum _{n}s_{P}(nT)\\cdot e^{-i2\\pi {\\frac {kn}{N}}}} _{\\text{DFT}}\\,\\end{aligned}}}": {
    "before": "{\\displaystyle {\\begin{aligned}\\overbrace {{\\frac {1}{T}}S_{\\frac {1}{T}}\\left({\\frac {k}{NT}}\\right)} ^{S[k]}\\,&\\triangleq \\,\\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot e^{-i2\\pi {\\frac {kn}{N}}}\\\\&\\equiv \\underbrace {\\sum _{n}s_{P}(nT)\\cdot e^{-i2\\pi {\\frac {kn}{N}}}} _{\\text{DFT}}\\,\\end{aligned}}}",
    "after": "{\\displaystyle {\\begin{aligned}\\overbrace {{\\frac {1}{T}}S_{\\frac {1}{T}}\\left({\\frac {k}{NT}}\\right)} ^{S[k]}\\,&\\triangleq \\,\\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot e^{-i2\\pi {\\frac {kn}{N}}}\\\\&\\equiv \\underbrace {\\sum _{n}s_{P}(nT)\\cdot e^{-i2\\pi {\\frac {kn}{N}}}} _{\\text{DFT}}\\,\\end{aligned}}}",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle \\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot \\delta (t-nT)=\\underbrace {\\int _{-\\infty }^{\\infty }{\\frac {1}{T}}\\ S_{\\frac {1}{T}}(f)\\cdot e^{i2\\pi ft}\\,df} _{\\text{inverse Fourier transform}}\\,}": {
    "before": "{\\displaystyle s(nT)=T\\int _{\\frac {1}{T}}{\\frac {1}{T}}S_{\\frac {1}{T}}(f)\\cdot e^{i2\\pi fnT}\\,df}",
    "after": "{\\displaystyle s(nT)=T\\int _{\\frac {1}{T}}{\\frac {1}{T}}S_{\\frac {1}{T}}(f)\\cdot e^{i2\\pi fnT}\\,df} {\\displaystyle \\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot \\delta (t-nT)=\\underbrace {\\int _{-\\infty }^{\\infty }{\\frac {1}{T}}\\ S_{\\frac {1}{T}}(f)\\cdot e^{i2\\pi ft}\\,df} _{\\text{inverse Fourier transform}}\\,}",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle {\\begin{aligned}s_{P}(nT)&=\\overbrace {{\\frac {1}{N}}\\sum _{k}S[k]\\cdot e^{i2\\pi {\\frac {kn}{N}}}} ^{\\text{inverse DFT}}\\\\&={\\tfrac {1}{P}}\\sum _{k}S_{\\frac {1}{T}}\\left({\\frac {k}{P}}\\right)\\cdot e^{i2\\pi {\\frac {kn}{N}}}\\end{aligned}}}": {
    "before": "{\\displaystyle {\\begin{aligned}s_{P}(nT)&=\\overbrace {{\\frac {1}{N}}\\sum _{k}S[k]\\cdot e^{i2\\pi {\\frac {kn}{N}}}} ^{\\text{inverse DFT}}\\\\&={\\tfrac {1}{P}}\\sum _{k}S_{\\frac {1}{T}}\\left({\\frac {k}{P}}\\right)\\cdot e^{i2\\pi {\\frac {kn}{N}}}\\end{aligned}}}",
    "after": "{\\displaystyle {\\begin{aligned}s_{P}(nT)&=\\overbrace {{\\frac {1}{N}}\\sum _{k}S[k]\\cdot e^{i2\\pi {\\frac {kn}{N}}}} ^{\\text{inverse DFT}}\\\\&={\\tfrac {1}{P}}\\sum _{k}S_{\\frac {1}{T}}\\left({\\frac {k}{P}}\\right)\\cdot e^{i2\\pi {\\frac {kn}{N}}}\\end{aligned}}}",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle \\int _{P}\\left(\\sum _{m=-\\infty }^{\\infty }s(t-mP)\\right)\\cdot e^{-i2\\pi {\\frac {k}{P}}t}\\,dt=\\underbrace {\\int _{-\\infty }^{\\infty }s(t)\\cdot e^{-i2\\pi {\\frac {k}{P}}t}\\,dt} _{\\triangleq \\,S\\left({\\frac {k}{P}}\\right)}}": {
    "before": "^",
    "after": "^ {\\displaystyle \\int _{P}\\left(\\sum _{m=-\\infty }^{\\infty }s(t-mP)\\right)\\cdot e^{-i2\\pi {\\frac {k}{P}}t}\\,dt=\\underbrace {\\int _{-\\infty }^{\\infty }s(t)\\cdot e^{-i2\\pi {\\frac {k}{P}}t}\\,dt} _{\\triangleq \\,S\\left({\\frac {k}{P}}\\right)}}",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "{\\displaystyle \\sum _{n=0}^{N-1}\\left(\\sum _{m=-\\infty }^{\\infty }s([n-mN]T)\\right)\\cdot e^{-i2\\pi {\\frac {k}{N}}n}=\\underbrace {\\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot e^{-i2\\pi {\\frac {k}{N}}n}} _{\\triangleq \\,{\\frac {1}{T}}S_{\\frac {1}{T}}\\left({\\frac {k}{NT}}\\right)}}": {
    "before": "^",
    "after": "^ {\\displaystyle \\sum _{n=0}^{N-1}\\left(\\sum _{m=-\\infty }^{\\infty }s([n-mN]T)\\right)\\cdot e^{-i2\\pi {\\frac {k}{N}}n}=\\underbrace {\\sum _{n=-\\infty }^{\\infty }s(nT)\\cdot e^{-i2\\pi {\\frac {k}{N}}n}} _{\\triangleq \\,{\\frac {1}{T}}S_{\\frac {1}{T}}\\left({\\frac {k}{NT}}\\right)}}",
    "url": "https://en.wikipedia.org/wiki/Fourier analysis"
  },
  "NB = \"Not built\" (No capacity additions are expected.)": {
    "before": "Note: Projected LCOE are adjusted for inflation and calculated on constant dollars based on two years prior to the release year of the estimate.Estimates given without any subsidies. Transmission cost for non-dispatchable sources are on average much higher.",
    "after": "See also[edit]",
    "url": "https://en.wikipedia.org/wiki/Cost of electricity by source"
  },
  "Nozick's four conditions for S's knowing that P were (S=Subject / P=Proposition):": {
    "before": "In Philosophical Explanations (1981), which received the Phi Beta Kappa Society's Ralph Waldo Emerson Award, Nozick provided novel accounts of knowledge, free will, personal identity, the nature of value, and the meaning of life. He also put forward an epistemological system which attempted to deal with both the Gettier problem and those posed by skepticism. This highly influential argument eschewed justification as a necessary requirement for knowledge.: ch. 7",
    "after": "P is true",
    "url": "https://en.wikipedia.org/wiki/Robert Nozick"
  },
  "(July 2009). |quote=Deleuze let it be known around town that he considered Baudrillard the shame of the profession. Felix condemned his fatalism and irresponsible politics, not realizing that Jean was political, if in very different ways": {
    "before": "^ a b Lotringer, Sylvère. “On Jean Baudrillard.” International Journal of Baudrillard Studies 6, no. 2",
    "after": "^ a b c Poster, Mark. 2002. \"Introduction\" in Jean Baudrillard: Selected Writings (2nd ed.), edited by M. Poster. Stanford: Stanford University Press. ISBN 978-0804742733.",
    "url": "https://en.wikipedia.org/wiki/Jean Baudrillard"
  },
  "{\\displaystyle {\\text{real cost (production)}}=M\\cdot {\\cfrac {\\int _{T_{1}}^{T_{2}}{\\frac {dC}{dt}}\\,dt}{\\int _{T_{1}}^{T_{2}}{\\frac {dP}{dt}}\\,dt}}}": {
    "before": "The price rebate is based upon the observation that the real cost of production is the mean rate of consumption over the mean rate of production for an equivalent period of time.",
    "after": "whereM = money distributed for a given programme of production, C = consumption, P = production.",
    "url": "https://en.wikipedia.org/wiki/Social credit"
  },
  "{\\displaystyle {\\text{true price }}(\\$)={\\text{cost }}(\\$)\\cdot {\\dfrac {{\\text{consumption }}(\\$)+{\\text{depreciation }}(\\$)}{{\\text{credit }}(\\$)+{\\text{production }}(\\$)}}}": {
    "before": "The physical cost of producing something is the materials and capital that were consumed in its production, plus that amount of consumer goods labour consumed during its production. This total consumption represents the physical, or real, cost of production.",
    "after": "whereConsumption = cost of consumer goods, Depreciation = depreciation of real capital, Credit = Credit Created, Production = cost of total production",
    "url": "https://en.wikipedia.org/wiki/Social credit"
  },
  "In symbols if B1/A1 = k1 and B2/A2 = k2 both k1 and k2 are increasing.": {
    "before": "Let A1+B1 be the costs in a period to time of articles produced by factories making consumable goods divided up into A1 costs which refer to money paid to individuals by means of salaries, wages, dividends, etc., and B1 costs which refer to money paid to other institutions. Let A2, B2 be the corresponding costs of factories producing capital equipment. The money distributed to individuals is A1+A2 and the cost of the final consumable goods is A1+B1. If money in the hands of the public is to be equal to the costs of consumable articles produced then A1+A2 = A1+B1 and therefore A2=B1. Now modern science has brought us to the stage where machines are more and more taking the place of human labour in producing goods, i.e. A1 is becoming less important relatively to B1 and A2 less important relatively to B2.",
    "after": "Since A2=B1 this means that (A2+B2)/(A1+B1)= (1+k2)*A2/(1+1/k1)*B1 = (1+k2)/(1+1/k1) which is increasing.",
    "url": "https://en.wikipedia.org/wiki/Social credit"
  },
  "Since A2=B1 this means that (A2+B2)/(A1+B1)= (1+k2)*A2/(1+1/k1)*B1 = (1+k2)/(1+1/k1) which is increasing.": {
    "before": "In symbols if B1/A1 = k1 and B2/A2 = k2 both k1 and k2 are increasing.",
    "after": "Thus in order that the economic system should keep working it is essential that capital goods should be produced in ever increasing quantity relatively to consumable goods. As soon as the ratio of capital goods to consumable goods slackens, costs exceed money distributed, i.e. the consumer is unable to purchase the consumable goods coming on the market.\"",
    "url": "https://en.wikipedia.org/wiki/Social credit"
  },
  "{\\displaystyle E[U]=\\max _{d\\in D}~\\int _{X}U(d,x)p(x)~dx.}": {
    "before": "The utility from the optimal decision based only on the prior, without making any further observations, is given by",
    "after": "If the decision-maker could gain access to a single sample, {\\displaystyle z} , the optimal posterior utility would be",
    "url": "https://en.wikipedia.org/wiki/Expected value of sample information"
  },
  "{\\displaystyle E[U|z]=\\max _{d\\in D}~\\int _{X}U(d,x)p(x|z)~dx}": {
    "before": "If the decision-maker could gain access to a single sample, {\\displaystyle z} , the optimal posterior utility would be",
    "after": "where {\\displaystyle p(x|z)} is obtained from Bayes' rule :",
    "url": "https://en.wikipedia.org/wiki/Expected value of sample information"
  },
  "{\\displaystyle p(x|z)={{p(z|x)p(x)} \\over {p(z)}};} {\\displaystyle p(z)=\\int p(z|x)p(x)~dx.}": {
    "before": "where {\\displaystyle p(x|z)} is obtained from Bayes' rule :",
    "after": "Since they don't know what sample would actually be obtained if one were obtained, they must average over all possible samples to obtain the expected utility given a sample:",
    "url": "https://en.wikipedia.org/wiki/Expected value of sample information"
  },
  "{\\displaystyle E[U|SI]=\\int _{Z}E[U|z]p(z)dz=\\int _{Z}\\max _{d\\in D}~\\int _{X}U(d,x)p(z|x)p(x)~dx~dz.}": {
    "before": "Since they don't know what sample would actually be obtained if one were obtained, they must average over all possible samples to obtain the expected utility given a sample:",
    "after": "The expected value of sample information is then defined as",
    "url": "https://en.wikipedia.org/wiki/Expected value of sample information"
  },
  "{\\displaystyle {\\begin{array}{rl}EVSI&=E[U|SI]-E[U]\\\\&=\\left(\\int _{Z}\\max _{d\\in D}~\\int _{X}U(d,x)p(z|x)p(x)~dx~dz\\right)-\\left(\\max _{d\\in D}~\\int _{X}U(d,x)p(x)~dx\\right).\\end{array}}}": {
    "before": "The expected value of sample information is then defined as",
    "after": "Computation [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Expected value of sample information"
  },
  "{\\displaystyle Z_{i}=} {\"Cure\", \"Improvement\", \"Ineffective\", \"Mild side-effect\", \"Serious side-effect\"}": {
    "before": "The model classifies the outcome for any given subject into one of five categories:",
    "after": "And for each of these outcomes, assigns a utility equal to an estimated patient-equivalent monetary value of the outcome.",
    "url": "https://en.wikipedia.org/wiki/Expected value of sample information"
  },
  "AM = Alejandro Maldonado": {
    "before": "Note: the timeline actually begins before the start of the wave in order to represent graphically the increase of conservative governments along the years.",
    "after": "MM = Manuel Merino",
    "url": "https://en.wikipedia.org/wiki/Conservative wave"
  },
  "MM = Manuel Merino": {
    "before": "AM = Alejandro Maldonado",
    "after": "JQ = Jorge Quiroga",
    "url": "https://en.wikipedia.org/wiki/Conservative wave"
  },
  "JQ = Jorge Quiroga": {
    "before": "MM = Manuel Merino",
    "after": "See also[edit]",
    "url": "https://en.wikipedia.org/wiki/Conservative wave"
  },
  "« National Sections » = groups of professionally qualified individuals, in member, or non-member, countries of IIAS, interested in the objectives of IIAS and desirous of working closely with it": {
    "before": "any non-governmental international organisation",
    "after": "« Corporate Members » = institutions or associations duly set up having activities in the field of public administration on the national, international, or regional levels",
    "url": "https://en.wikipedia.org/wiki/International Institute of Administrative Sciences"
  },
  "« Corporate Members » = institutions or associations duly set up having activities in the field of public administration on the national, international, or regional levels": {
    "before": "« National Sections » = groups of professionally qualified individuals, in member, or non-member, countries of IIAS, interested in the objectives of IIAS and desirous of working closely with it",
    "after": "Organisation of IIAS[edit]",
    "url": "https://en.wikipedia.org/wiki/International Institute of Administrative Sciences"
  },
  "In an essay called “Anarchism = Zerzan?”, socialist economist Michael Albert critiques Zerzan’s perspectives on concepts such as language, division of labour, and technology, instead saying that Zerzan’s argument rests on these concepts being inherently wrong, instead of, as Albert argues, being neutral concepts that can be utilised morally or immorally.": {
    "before": "In his essay \"Listen Anarchist!\", Chaz Bufe criticized the primitivist position from an anarchist perspective, pointing out that primitivists are extremely vague about exactly which technologies they advocate keeping and which they seek to abolish, noting that smallpox had been eradicated thanks to medical technology.",
    "after": "Selected works[edit]",
    "url": "https://en.wikipedia.org/wiki/John Zerzan"
  },
  "{\\displaystyle {\\vec {x}}^{\\mathrm {T} }\\Sigma _{0}^{-1}{\\vec {x}}={\\vec {x}}^{\\mathrm {T} }\\Sigma _{1}^{-1}{\\vec {x}}} {\\displaystyle {\\vec {x}}^{\\mathrm {T} }{\\Sigma _{i}}^{-1}{\\vec {\\mu }}_{i}={{\\vec {\\mu }}_{i}}^{\\mathrm {T} }{\\Sigma _{i}}^{-1}{\\vec {x}}} because {\\displaystyle \\Sigma _{i}} is Hermitian": {
    "before": "LDA instead makes the additional simplifying homoscedasticity assumption ( i.e. that the class covariances are identical, so {\\displaystyle \\Sigma _{0}=\\Sigma _{1}=\\Sigma } ) and that the covariances have full rank. In this case, several terms cancel:",
    "after": "and the above decision criterion becomes a threshold on the dot product",
    "url": "https://en.wikipedia.org/wiki/Linear discriminant analysis"
  },
  "{\\displaystyle {\\vec {w}}=\\Sigma ^{-1}({\\vec {\\mu }}_{1}-{\\vec {\\mu }}_{0})} {\\displaystyle c={\\frac {1}{2}}\\,{\\vec {w}}^{\\mathrm {T} }({\\vec {\\mu }}_{1}+{\\vec {\\mu }}_{0})}": {
    "before": "{\\displaystyle {\\vec {w}}^{\\mathrm {T} }{\\vec {x}}>c} for some threshold constant c , where",
    "after": "This means that the criterion of an input {\\displaystyle {\\vec {x}}} being in a class {\\displaystyle y} is purely a function of this linear combination of the known observations.",
    "url": "https://en.wikipedia.org/wiki/Linear discriminant analysis"
  },
  "{\\displaystyle S={\\frac {\\sigma _{\\text{between}}^{2}}{\\sigma _{\\text{within}}^{2}}}={\\frac {({\\vec {w}}\\cdot {\\vec {\\mu }}_{1}-{\\vec {w}}\\cdot {\\vec {\\mu }}_{0})^{2}}{{\\vec {w}}^{\\mathrm {T} }\\Sigma _{1}{\\vec {w}}+{\\vec {w}}^{\\mathrm {T} }\\Sigma _{0}{\\vec {w}}}}={\\frac {({\\vec {w}}\\cdot ({\\vec {\\mu }}_{1}-{\\vec {\\mu }}_{0}))^{2}}{{\\vec {w}}^{\\mathrm {T} }(\\Sigma _{0}+\\Sigma _{1}){\\vec {w}}}}}": {
    "before": "Suppose two classes of observations have means {\\displaystyle {\\vec {\\mu }}_{0},{\\vec {\\mu }}_{1}} and covariances {\\displaystyle \\Sigma _{0},\\Sigma _{1}} . Then the linear combination of features {\\displaystyle {\\vec {w}}^{\\mathrm {T} }{\\vec {x}}} will have means {\\displaystyle {\\vec {w}}^{\\mathrm {T} }{\\vec {\\mu }}_{i}} and variances {\\displaystyle {\\vec {w}}^{\\mathrm {T} }\\Sigma _{i}{\\vec {w}}} for {\\displaystyle i=0,1} . Fisher defined the separation between these two distributions to be the ratio of the variance between the classes to the variance within the classes:",
    "after": "This measure is, in some sense, a measure of the signal-to-noise ratio for the class labelling. It can be shown that the maximum separation occurs when",
    "url": "https://en.wikipedia.org/wiki/Linear discriminant analysis"
  },
  "{\\displaystyle c={\\vec {w}}\\cdot {\\frac {1}{2}}({\\vec {\\mu }}_{0}+{\\vec {\\mu }}_{1})={\\frac {1}{2}}{\\vec {\\mu }}_{1}^{\\mathrm {T} }\\Sigma _{1}^{-1}{\\vec {\\mu }}_{1}-{\\frac {1}{2}}{\\vec {\\mu }}_{0}^{\\mathrm {T} }\\Sigma _{0}^{-1}{\\vec {\\mu }}_{0}} .": {
    "before": "Generally, the data points to be discriminated are projected onto {\\displaystyle {\\vec {w}}} ; then the threshold that best separates the data is chosen from analysis of the one-dimensional distribution. There is no general rule for the threshold. However, if projections of points from both classes exhibit approximately the same distributions, a good choice would be the hyperplane between projections of the two means, {\\displaystyle {\\vec {w}}\\cdot {\\vec {\\mu }}_{0}} and {\\displaystyle {\\vec {w}}\\cdot {\\vec {\\mu }}_{1}} . In this case the parameter c in threshold condition {\\displaystyle {\\vec {w}}\\cdot {\\vec {x}}>c} can be found explicitly:",
    "after": "Otsu's method is related to Fisher's linear discriminant, and was created to binarize the histogram of pixels in a grayscale image by optimally picking the black/white threshold that minimizes intra-class variance and maximizes inter-class variance within/between grayscales assigned to black and white pixel classes.",
    "url": "https://en.wikipedia.org/wiki/Linear discriminant analysis"
  },
  "{\\displaystyle \\Sigma _{b}={\\frac {1}{C}}\\sum _{i=1}^{C}(\\mu _{i}-\\mu )(\\mu _{i}-\\mu )^{\\mathrm {T} }}": {
    "before": "In the case where there are more than two classes, the analysis used in the derivation of the Fisher discriminant can be extended to find a subspace which appears to contain all of the class variability.  This generalization is due to C. R. Rao .  Suppose that each of C classes has a mean {\\displaystyle \\mu _{i}} and the same covariance {\\displaystyle \\Sigma } . Then the scatter between class variability may be defined by the sample covariance of the class means",
    "after": "where {\\displaystyle \\mu } is the mean of the class means. The class separation in a direction {\\displaystyle {\\vec {w}}} in this case will be given by",
    "url": "https://en.wikipedia.org/wiki/Linear discriminant analysis"
  },
  "{\\displaystyle S={\\frac {{\\vec {w}}^{\\mathrm {T} }\\Sigma _{b}{\\vec {w}}}{{\\vec {w}}^{\\mathrm {T} }\\Sigma {\\vec {w}}}}}": {
    "before": "where {\\displaystyle \\mu } is the mean of the class means. The class separation in a direction {\\displaystyle {\\vec {w}}} in this case will be given by",
    "after": "This means that when {\\displaystyle {\\vec {w}}} is an eigenvector of {\\displaystyle \\Sigma ^{-1}\\Sigma _{b}} the separation will be equal to the corresponding eigenvalue .",
    "url": "https://en.wikipedia.org/wiki/Linear discriminant analysis"
  },
  "{\\displaystyle \\Sigma =(1-\\lambda )\\Sigma +\\lambda I\\,}": {
    "before": "Another complication in applying LDA and Fisher's discriminant to real data occurs when the number of measurements of each sample (i.e., the dimensionality of each data vector) exceeds the number of samples in each class.  In this case, the covariance estimates do not have full rank, and so cannot be inverted. There are a number of ways to deal with this. One is to use a pseudo inverse instead of the usual matrix inverse in the above formulae. However, better numeric stability may be achieved by first projecting the problem onto the subspace spanned by {\\displaystyle \\Sigma _{b}} .  Another strategy to deal with small sample size is to use a shrinkage estimator of the covariance matrix, which can be expressed mathematically as",
    "after": "where {\\displaystyle I} is the identity matrix, and {\\displaystyle \\lambda } is the shrinkage intensity or regularisation parameter . This leads to the framework of regularized discriminant analysis  or shrinkage discriminant analysis. ",
    "url": "https://en.wikipedia.org/wiki/Linear discriminant analysis"
  },
  "{\\displaystyle N_{g}}= number of groups, or": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Linear discriminant analysis"
  },
  "{\\displaystyle v^{*}(S)=v(N)-v(N\\setminus S),\\forall ~S\\subseteq N.}": {
    "before": "Let {\\displaystyle v} be a profit game. The dual game of {\\displaystyle v} is the cost game {\\displaystyle v^{*}} defined as",
    "after": "Intuitively, the dual game represents the opportunity cost for a coalition {\\displaystyle S} of not joining the grand coalition {\\displaystyle N} . A dual profit game {\\displaystyle c^{*}} can be defined identically for a cost game {\\displaystyle c} . A cooperative game and its dual are in some sense equivalent, and they share many properties. For example, the core of a game and its dual are equal. For more details on cooperative game duality, see for instance ( Bilbao 2000 ).",
    "url": "https://en.wikipedia.org/wiki/Cooperative game theory"
  },
  "{\\displaystyle v_{S}(T)=v(T),\\forall ~T\\subseteq S.}": {
    "before": "Let {\\displaystyle S\\subsetneq N} be a non-empty coalition of players. The subgame {\\displaystyle v_{S}:2^{S}\\to \\mathbb {R} } on {\\displaystyle S} is naturally defined as",
    "after": "In other words, we simply restrict our attention to coalitions contained in {\\displaystyle S} . Subgames are useful because they allow us to apply solution concepts defined for the grand coalition on smaller coalitions.",
    "url": "https://en.wikipedia.org/wiki/Cooperative game theory"
  },
  "{\\displaystyle C(v)=\\left\\{x\\in \\mathbb {R} ^{N}:\\sum _{i\\in N}x_{i}=v(N);\\quad \\sum _{i\\in S}x_{i}\\geq v(S),\\forall ~S\\subseteq N\\right\\}.}": {
    "before": "Let {\\displaystyle v} be a game. The core of {\\displaystyle v} is the set of payoff vectors",
    "after": "In words, the core is the set of imputations under which no coalition has a value greater than the sum of its members' payoffs. Therefore, no coalition has incentive to leave the grand coalition and receive a larger payoff.",
    "url": "https://en.wikipedia.org/wiki/Cooperative game theory"
  },
  "{\\displaystyle C_{\\varepsilon }(v)=\\left\\{x\\in \\mathbb {R} ^{N}:\\sum _{i\\in N}x_{i}=v(N);\\quad \\sum _{i\\in S}x_{i}\\geq v(S)-\\varepsilon ,\\forall ~S\\subseteq N\\right\\}.}": {
    "before": "Because the core may be empty, a generalization was introduced in ( Shapley & Shubik 1966 ). The strong {\\displaystyle \\varepsilon } -core for some number {\\displaystyle \\varepsilon \\in \\mathbb {R} } is the set of payoff vectors",
    "after": "In economic terms, the strong {\\displaystyle \\varepsilon } -core is the set of pre-imputations where no coalition can improve its payoff by leaving the grand coalition, if it must pay a penalty of {\\displaystyle \\varepsilon } for leaving. Note that {\\displaystyle \\varepsilon } may be negative, in which case it represents a bonus for leaving the grand coalition. Clearly, regardless of whether the core is empty, the strong {\\displaystyle \\varepsilon } -core will be non-empty for a large enough value of {\\displaystyle \\varepsilon } and empty for a small enough (possibly negative) value of {\\displaystyle \\varepsilon } . Following this line of reasoning, the least-core , introduced in ( Maschler, Peleg & Shapley 1979 ), is the intersection of all non-empty strong {\\displaystyle \\varepsilon } -cores. It can also be viewed as the strong {\\displaystyle \\varepsilon } -core for the smallest value of {\\displaystyle \\varepsilon } that makes the set non-empty ( Bilbao 2000 ).",
    "url": "https://en.wikipedia.org/wiki/Cooperative game theory"
  },
  "{\\displaystyle s_{ij}^{v}(x)=\\max \\left\\{v(S)-\\sum _{k\\in S}x_{k}:S\\subseteq N\\setminus \\{j\\},i\\in S\\right\\},}": {
    "before": "Let {\\displaystyle v:2^{N}\\to \\mathbb {R} } be a game, and let {\\displaystyle x\\in \\mathbb {R} ^{N}} be an efficient payoff vector. The maximum surplus of player i over player j with respect to x is",
    "after": "the maximal amount player i can gain without the cooperation of player j by withdrawing from the grand coalition N under payoff vector x , assuming that the other players in i' s withdrawing coalition are satisfied with their payoffs under x . The maximum surplus is a way to measure one player's bargaining power over another. The kernel of {\\displaystyle v} is the set of imputations x that satisfy",
    "url": "https://en.wikipedia.org/wiki/Cooperative game theory"
  },
  "{\\displaystyle {\\begin{aligned}d_{v}(\\{i\\})&=v(\\{i\\})\\\\d_{v}(\\{i,j\\})&=v(\\{i,j\\})-d_{v}(\\{i\\})-d_{v}(\\{j\\})\\\\d_{v}(\\{i,j,k\\})&=v(\\{i,j,k\\})-d_{v}(\\{i,j\\})-d_{v}(\\{i,k\\})-d_{x}(\\{j,k\\})-d_{v}(\\{i\\})-d_{v}(\\{j\\})-d_{v}(\\{k\\})\\\\&\\vdots \\\\d_{v}(S)&=v(S)-\\sum _{T\\subsetneq S}d_{v}(T)\\end{aligned}}}": {
    "before": "The Harsanyi dividend (named after John Harsanyi , who used it to generalize the Shapley value in 1963  ) identifies the surplus that is created by a coalition of players in a cooperative game. To specify this surplus, the worth of this coalition is corrected by the surplus that is already created by subcoalitions. To this end, the dividend {\\displaystyle d_{v}(S)} of coalition {\\displaystyle S} in game {\\displaystyle v} is recursively determined by",
    "after": "An explicit formula for the dividend is given by {\\textstyle d_{v}(S)=\\sum _{T\\subseteq S}(-1)^{|S\\setminus T|}v(T)} . The function {\\displaystyle d_{v}:2^{N}\\to \\mathbb {R} } is also known as the Möbius inverse of {\\displaystyle v:2^{N}\\to \\mathbb {R} } .  Indeed, we can recover {\\displaystyle v} from {\\displaystyle d_{v}} by help of the formula {\\textstyle v(S)=d_{v}(S)+\\sum _{T\\subsetneq S}d_{v}(T)} .",
    "url": "https://en.wikipedia.org/wiki/Cooperative game theory"
  },
  "{\\textstyle \\phi _{i}(v)=\\sum _{S\\subset N:i\\in S}{d_{v}(S)}/{|S|}}": {
    "before": "is given by summing up a player's share of the dividends of all coalitions that she belongs to,",
    "after": ".",
    "url": "https://en.wikipedia.org/wiki/Cooperative game theory"
  },
  "{\\displaystyle VP_{n}=C_{c}+C_{f}+V+S=} Gross Output": {
    "before": "If variable capital paid {\\displaystyle =V} , circulating constant capital consumed {\\displaystyle =C_{c}} , fixed capital consumed {\\displaystyle =C_{f}} , and surplus value produced {\\displaystyle =S} , then:",
    "after": "and {\\displaystyle VP=V+S=} true new value added",
    "url": "https://en.wikipedia.org/wiki/Value product"
  },
  "{\\displaystyle VP=V+S=} true new value added": {
    "before": "{\\displaystyle VP_{n}=C_{c}+C_{f}+V+S=} Gross Outputand",
    "after": "So, Marx's \"value product\" really expressed his view of the true total new value added or the net product. In his view, this total is equal to the value of wage payments + surplus value, the latter which would include, apart from net profit, interest and rent, the net tax levy and royalty-type fees paid in respect of incomes generated by production of output, plus the surplus-value component of unsold inventories of new output. Marx himself never discussed taxation and royalty-income in detail; they were only a small portion of the total national income when he lived (around 5-10% or so).",
    "url": "https://en.wikipedia.org/wiki/Value product"
  },
  "{\\displaystyle R(a_{i}\\mid [x])=\\sum _{j=1}^{s}\\lambda (a_{i}\\mid w_{j})P(w_{j}\\mid [x]).}": {
    "before": "Using the Bayesian decision procedure, the decision-theoretic rough set (DTRS) approach allows for minimum-risk decision making based on observed evidence. Let {\\displaystyle \\textstyle A=\\{a_{1},\\ldots ,a_{m}\\}} be a finite set of {\\displaystyle \\textstyle m} possible actions and let {\\displaystyle \\textstyle \\Omega =\\{w_{1},\\ldots ,w_{s}\\}} be a finite set of {\\displaystyle s} states. {\\displaystyle \\textstyle P(w_{j}\\mid [x])} is calculated as the conditional probability of an object {\\displaystyle \\textstyle x} being in state {\\displaystyle \\textstyle w_{j}} given the object description {\\displaystyle \\textstyle [x]} . {\\displaystyle \\textstyle \\lambda (a_{i}\\mid w_{j})} denotes the loss, or cost, for performing action {\\displaystyle \\textstyle a_{i}} when the state is {\\displaystyle \\textstyle w_{j}} . The expected loss (conditional risk) associated with taking action {\\displaystyle \\textstyle a_{i}} is given by:",
    "after": "Object classification with the approximation operators can be fitted into the Bayesian decision framework. The set of actions is given by {\\displaystyle \\textstyle A=\\{a_{P},a_{N},a_{B}\\}} , where {\\displaystyle \\textstyle a_{P}} , {\\displaystyle \\textstyle a_{N}} , and {\\displaystyle \\textstyle a_{B}} represent the three actions in classifying an object into POS( {\\displaystyle \\textstyle A} ), NEG( {\\displaystyle \\textstyle A} ), and BND( {\\displaystyle \\textstyle A} ) respectively. To indicate whether an element is in {\\displaystyle \\textstyle A} or not in {\\displaystyle \\textstyle A} , the set of states is given by {\\displaystyle \\textstyle \\Omega =\\{A,A^{c}\\}} . Let {\\displaystyle \\textstyle \\lambda (a_{\\diamond }\\mid A)} denote the loss incurred by taking action {\\displaystyle \\textstyle a_{\\diamond }} when an object belongs to {\\displaystyle \\textstyle A} , and let {\\displaystyle \\textstyle \\lambda (a_{\\diamond }\\mid A^{c})} denote the loss incurred by take the same action when the object belongs to {\\displaystyle \\textstyle A^{c}} .",
    "url": "https://en.wikipedia.org/wiki/Decision-theoretic rough sets"
  },
  "{\\displaystyle \\textstyle R(a_{P}\\mid [x])=\\lambda _{PP}P(A\\mid [x])+\\lambda _{PN}P(A^{c}\\mid [x]),}": {
    "before": "Taking individual can be associated with the expected loss {\\displaystyle \\textstyle R(a_{\\diamond }\\mid [x])} actions and can be expressed as:",
    "after": "{\\displaystyle \\textstyle R(a_{N}\\mid [x])=\\lambda _{NP}P(A\\mid [x])+\\lambda _{NN}P(A^{c}\\mid [x]),}",
    "url": "https://en.wikipedia.org/wiki/Decision-theoretic rough sets"
  },
  "{\\displaystyle \\textstyle R(a_{N}\\mid [x])=\\lambda _{NP}P(A\\mid [x])+\\lambda _{NN}P(A^{c}\\mid [x]),}": {
    "before": "{\\displaystyle \\textstyle R(a_{P}\\mid [x])=\\lambda _{PP}P(A\\mid [x])+\\lambda _{PN}P(A^{c}\\mid [x]),}",
    "after": "{\\displaystyle \\textstyle R(a_{B}\\mid [x])=\\lambda _{BP}P(A\\mid [x])+\\lambda _{BN}P(A^{c}\\mid [x]),}",
    "url": "https://en.wikipedia.org/wiki/Decision-theoretic rough sets"
  },
  "{\\displaystyle \\textstyle R(a_{B}\\mid [x])=\\lambda _{BP}P(A\\mid [x])+\\lambda _{BN}P(A^{c}\\mid [x]),}": {
    "before": "{\\displaystyle \\textstyle R(a_{N}\\mid [x])=\\lambda _{NP}P(A\\mid [x])+\\lambda _{NN}P(A^{c}\\mid [x]),}",
    "after": "where {\\displaystyle \\textstyle \\lambda _{\\diamond P}=\\lambda (a_{\\diamond }\\mid A)} , {\\displaystyle \\textstyle \\lambda _{\\diamond N}=\\lambda (a_{\\diamond }\\mid A^{c})} , and {\\displaystyle \\textstyle \\diamond =P} , {\\displaystyle \\textstyle N} , or {\\displaystyle \\textstyle B} .",
    "url": "https://en.wikipedia.org/wiki/Decision-theoretic rough sets"
  },
  "{\\displaystyle \\alpha ={\\frac {\\lambda _{PN}-\\lambda _{BN}}{(\\lambda _{BP}-\\lambda _{BN})-(\\lambda _{PP}-\\lambda _{PN})}},}": {
    "before": "P : If {\\displaystyle \\textstyle P(A\\mid [x])\\geq \\gamma } and {\\displaystyle \\textstyle P(A\\mid [x])\\geq \\alpha } , decide POS( {\\displaystyle \\textstyle A} ); N : If {\\displaystyle \\textstyle P(A\\mid [x])\\leq \\beta } and {\\displaystyle \\textstyle P(A\\mid [x])\\leq \\gamma } , decide NEG( {\\displaystyle \\textstyle A} ); B : If {\\displaystyle \\textstyle \\beta \\leq P(A\\mid [x])\\leq \\alpha } , decide BND( {\\displaystyle \\textstyle A} );where,",
    "after": "{\\displaystyle \\gamma ={\\frac {\\lambda _{PN}-\\lambda _{NN}}{(\\lambda _{NP}-\\lambda _{NN})-(\\lambda _{PP}-\\lambda _{PN})}},}",
    "url": "https://en.wikipedia.org/wiki/Decision-theoretic rough sets"
  },
  "{\\displaystyle \\gamma ={\\frac {\\lambda _{PN}-\\lambda _{NN}}{(\\lambda _{NP}-\\lambda _{NN})-(\\lambda _{PP}-\\lambda _{PN})}},}": {
    "before": "{\\displaystyle \\alpha ={\\frac {\\lambda _{PN}-\\lambda _{BN}}{(\\lambda _{BP}-\\lambda _{BN})-(\\lambda _{PP}-\\lambda _{PN})}},}",
    "after": "{\\displaystyle \\beta ={\\frac {\\lambda _{BN}-\\lambda _{NN}}{(\\lambda _{NP}-\\lambda _{NN})-(\\lambda _{BP}-\\lambda _{BN})}}.}",
    "url": "https://en.wikipedia.org/wiki/Decision-theoretic rough sets"
  },
  "{\\displaystyle \\beta ={\\frac {\\lambda _{BN}-\\lambda _{NN}}{(\\lambda _{NP}-\\lambda _{NN})-(\\lambda _{BP}-\\lambda _{BN})}}.}": {
    "before": "{\\displaystyle \\gamma ={\\frac {\\lambda _{PN}-\\lambda _{NN}}{(\\lambda _{NP}-\\lambda _{NN})-(\\lambda _{PP}-\\lambda _{PN})}},}",
    "after": "The {\\displaystyle \\textstyle \\alpha } , {\\displaystyle \\textstyle \\beta } , and {\\displaystyle \\textstyle \\gamma } values define the three different regions, giving us an associated risk for classifying an object. When {\\displaystyle \\textstyle \\alpha >\\beta } , we get {\\displaystyle \\textstyle \\alpha >\\gamma >\\beta } and can simplify ( P , N , B ) into ( P 1, N 1, B 1):",
    "url": "https://en.wikipedia.org/wiki/Decision-theoretic rough sets"
  },
  "{\\displaystyle {\\mathit {Vs}}(a)={\\mathit {CT}}_{v}(a)-{\\mathit {CT}}_{f}(a)\\,}": {
    "before": "The simplest mathematical formulation that Popper gives of this concept can be found in the tenth chapter of Conjectures and Refutations . Here he defines it as:",
    "after": "where {\\displaystyle {\\mathit {Vs}}(a)} is the verisimilitude of a , {\\displaystyle {\\mathit {CT}}_{v}(a)} is a measure of the content of the truth of a , and {\\displaystyle {\\mathit {CT}}_{f}(a)} is a measure of the content of the falsity of a .",
    "url": "https://en.wikipedia.org/wiki/Karl Popper"
  },
  "{\\displaystyle 1\\,-\\,{\\frac {1}{3}}\\,+\\,{\\frac {1}{5}}\\,-\\,{\\frac {1}{7}}\\,+\\,\\cdots \\,=\\,{\\frac {\\pi }{4}}.}": {
    "before": "Geometry [ edit ]The Leibniz formula for π states that",
    "after": "Leibniz wrote that circles \"can most simply be expressed by this series, that is, the aggregate of fractions alternately added and subtracted\".  However this formula is only accurate with a large number of terms, using 10,000,000 terms to obtain the correct value of π / 4 to 8 decimal places.  Leibniz attempted to create a definition for a straight line while attempting to prove the parallel postulate .  While most mathematicians defined a straight line as the shortest line between two points, Leibniz believed that this was merely a property of a straight line rather than the definition. ",
    "url": "https://en.wikipedia.org/wiki/Gottfried Wilhelm Leibniz"
  },
  "Singapore = Yellow Bilateral Free Trade Agreements = Green Multilateral Free Trade Agreements = Blue": {
    "before": "Singapore[edit]",
    "after": "Singapore has bilateral agreements with the following countries and blocs:",
    "url": "https://en.wikipedia.org/wiki/List of bilateral free-trade agreements"
  },
  "{\\displaystyle {\\begin{aligned}\\theta _{i}\\in {}&\\arg \\max _{\\theta '_{i}\\in \\Theta }\\sum _{\\theta _{-i}}\\ p(\\theta _{-i}\\mid \\theta _{i})\\ u_{i}\\left(y(\\theta '_{i},\\theta _{-i}),\\theta _{i}\\right)\\\\[5pt]&=\\sum _{\\theta _{-i}}\\ p(\\theta _{-i}\\mid \\theta _{i})\\ u_{i}\\left(s_{i}(\\theta ),s_{-i}(\\theta _{-i}),\\theta _{i}\\right)\\end{aligned}}}": {
    "before": "Under such a mechanism the agents of course find it optimal to reveal type since the mechanism plays the strategies they found optimal anyway. Formally, choose {\\displaystyle y(\\theta )} such that",
    "after": "Implementability [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle f(\\theta )=x\\left({\\hat {\\theta }}(\\theta )\\right)}": {
    "before": "To implement a social choice function {\\displaystyle f(\\theta )} is to find some {\\displaystyle t(\\theta )} transfer function that motivates agents to pick {\\displaystyle f(\\theta )} . Formally, if the equilibrium strategy profile under the mechanism maps to the same goods allocation as a social choice function,",
    "after": "we say the mechanism implements the social choice function.",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle {\\hat {\\theta }}(\\theta )=\\theta }": {
    "before": "Thanks to the revelation principle, the designer can usually find a transfer function {\\displaystyle t(\\theta )} to implement a social choice by solving an associated truthtelling game. If agents find it optimal to truthfully report type,",
    "after": "we say such a mechanism is truthfully implementable (or just \"implementable\"). The task is then to solve for a truthfully implementable {\\displaystyle t(\\theta )} and impute this transfer function to the original game. An allocation {\\displaystyle x(\\theta )} is truthfully implementable if there exists a transfer function {\\displaystyle t(\\theta )} such that",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle \\sum _{k=1}^{n}{\\frac {\\partial }{\\partial \\theta }}\\left({\\frac {\\partial u/\\partial x_{k}}{\\left|\\partial u/\\partial t\\right|}}\\right){\\frac {\\partial x}{\\partial \\theta }}\\geq 0}": {
    "before": "The function {\\displaystyle x(\\theta )} is implementable only if",
    "after": "whenever {\\displaystyle x=x(\\theta )} and {\\displaystyle t=t(\\theta )} and x is continuous at {\\displaystyle \\theta } . This is a necessary condition and is derived from the first- and second-order conditions of the agent's optimization problem assuming truth-telling.",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle {\\frac {\\partial }{\\partial \\theta }}\\left({\\frac {\\partial u/\\partial x_{k}}{\\left|\\partial u/\\partial t\\right|}}\\right)={\\frac {\\partial }{\\partial \\theta }}\\mathrm {MRS} _{x,t}}": {
    "before": "Its meaning can be understood in two pieces. The first piece says the agent's marginal rate of substitution (MRS) increases as a function of the type,",
    "after": "In short, agents will not tell the truth if the mechanism does not offer higher agent types a better deal. Otherwise, higher types facing any mechanism that punishes high types for reporting will lie and declare they are lower types, violating the truthtelling IC constraint. The second piece is a monotonicity condition waiting to happen,",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle t_{i}({\\hat {\\theta }})=\\sum _{j\\in I-i}v_{j}(x_{I-i}^{*}(\\theta _{I-i}),\\theta _{j})-\\sum _{j\\in I-i}v_{j}(x_{I}^{*}({\\hat {\\theta }}_{i},\\theta _{I}),\\theta _{j})}": {
    "before": "The cleverness of the VCG mechanism is the way it motivates truthful revelation. It eliminates incentives to misreport by penalizing any agent by the cost of the distortion he causes. Among the reports the agent may make, the VCG mechanism permits a \"null\" report saying he is indifferent to the public good and cares only about the money transfer. This effectively removes the agent from the game. If an agent does choose to report a type, the VCG mechanism charges the agent a fee if his report is pivotal , that is if his report changes the optimal allocation x so as to harm other agents. The payment is calculated",
    "after": "which sums the distortion in the utilities of the other agents (and not his own) caused by one agent reporting.",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle u(x,t,\\theta )=V(x,\\theta )-t}": {
    "before": "Mirrlees ( 1971 ) introduces a setting in which the transfer function t () is easy to solve for. Due to its relevance and tractability it is a common setting in the literature. Consider a single-good, single-agent setting in which the agent has quasilinear utility with an unknown type parameter {\\displaystyle \\theta }",
    "after": "and in which the principal has a prior CDF over the agent's type {\\displaystyle P(\\theta )} . The principal can produce goods at a convex marginal cost c ( x ) and wants to maximize the expected profit from the transaction",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle {\\text{let }}U(\\theta )=\\max _{\\theta '}u\\left(x(\\theta '),t(\\theta '),\\theta \\right)} {\\displaystyle {\\frac {dU}{d\\theta }}={\\frac {\\partial u}{\\partial \\theta }}={\\frac {\\partial V}{\\partial \\theta }}}": {
    "before": "A trick given by Mirrlees (1971) is to use the envelope theorem to eliminate the transfer function from the expectation to be maximized,",
    "after": "Integrating, {\\displaystyle U(\\theta )={\\underline {u}}(\\theta _{0})+\\int _{\\theta _{0}}^{\\theta }{\\frac {\\partial V}{\\partial {\\tilde {\\theta }}}}d{\\tilde {\\theta }}}",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle U(\\theta )={\\underline {u}}(\\theta _{0})+\\int _{\\theta _{0}}^{\\theta }{\\frac {\\partial V}{\\partial {\\tilde {\\theta }}}}d{\\tilde {\\theta }}}": {
    "before": "{\\displaystyle {\\text{let }}U(\\theta )=\\max _{\\theta '}u\\left(x(\\theta '),t(\\theta '),\\theta \\right)} {\\displaystyle {\\frac {dU}{d\\theta }}={\\frac {\\partial u}{\\partial \\theta }}={\\frac {\\partial V}{\\partial \\theta }}} Integrating,",
    "after": "where {\\displaystyle \\theta _{0}} is some index type. Replacing the incentive-compatible {\\displaystyle t(\\theta )=V(x(\\theta ),\\theta )-U(\\theta )} in the maximand,",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle {\\begin{aligned}&\\mathbb {E} _{\\theta }\\left[V(x(\\theta ),\\theta )-{\\underline {u}}(\\theta _{0})-\\int _{\\theta _{0}}^{\\theta }{\\frac {\\partial V}{\\partial {\\tilde {\\theta }}}}d{\\tilde {\\theta }}-c\\left(x(\\theta )\\right)\\right]\\\\&{}=\\mathbb {E} _{\\theta }\\left[V(x(\\theta ),\\theta )-{\\underline {u}}(\\theta _{0})-{\\frac {1-P(\\theta )}{p(\\theta )}}{\\frac {\\partial V}{\\partial \\theta }}-c\\left(x(\\theta )\\right)\\right]\\end{aligned}}}": {
    "before": "where {\\displaystyle \\theta _{0}} is some index type. Replacing the incentive-compatible {\\displaystyle t(\\theta )=V(x(\\theta ),\\theta )-U(\\theta )} in the maximand,",
    "after": "after an integration by parts. This function can be maximized pointwise.",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle H=\\left(V(x,\\theta )-{\\underline {u}}(\\theta _{0})-{\\frac {1-P(\\theta )}{p(\\theta )}}{\\frac {\\partial V}{\\partial \\theta }}(x,\\theta )-c(x)\\right)p(\\theta )+\\nu (\\theta ){\\frac {\\partial x}{\\partial \\theta }}}": {
    "before": "and use a Hamiltonian to do it, with shadow price {\\displaystyle \\nu (\\theta )}",
    "after": "where {\\displaystyle x} is a state variable and {\\displaystyle \\partial x/\\partial \\theta } the control. As usual in optimal control the costate evolution equation must satisfy",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle {\\frac {\\partial \\nu }{\\partial \\theta }}=-{\\frac {\\partial H}{\\partial x}}=-\\left({\\frac {\\partial V}{\\partial x}}(x,\\theta )-{\\frac {1-P(\\theta )}{p(\\theta )}}{\\frac {\\partial ^{2}V}{\\partial \\theta \\,\\partial x}}(x,\\theta )-{\\frac {\\partial c}{\\partial x}}(x)\\right)p(\\theta )}": {
    "before": "where {\\displaystyle x} is a state variable and {\\displaystyle \\partial x/\\partial \\theta } the control. As usual in optimal control the costate evolution equation must satisfy",
    "after": "Taking advantage of condition 2, note the monotonicity constraint is not binding at the boundaries of the {\\displaystyle \\theta } interval,",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle \\nu ({\\underline {\\theta }})=\\nu ({\\overline {\\theta }})=0}": {
    "before": "Taking advantage of condition 2, note the monotonicity constraint is not binding at the boundaries of the {\\displaystyle \\theta } interval,",
    "after": "meaning the costate variable condition can be integrated and also equals 0",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle f(\\Theta )=X}": {
    "before": "Preferences are rational",
    "after": "Myerson–Satterthwaite theorem [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Mechanism design"
  },
  "{\\displaystyle O{\\bigg (}({H \\over \\epsilon })^{2}(D\\ln({H \\over \\epsilon })+\\ln({1 \\over \\delta })){\\bigg )}}": {
    "before": "",
    "after": "the agents' valuations are bounded in {\\displaystyle [1,H]} , the pseudo- VC dimension of the class of auctions is at most {\\displaystyle D} , the required approximation factor is {\\displaystyle 1-\\epsilon } , the required success probability is {\\displaystyle 1-\\delta } .",
    "url": "https://en.wikipedia.org/wiki/Prior-independent mechanism"
  },
  "{\\displaystyle x_{i,m}-\\mu _{i}=l_{i,1}f_{1,m}+\\dots +l_{i,k}f_{k,m}+\\varepsilon _{i,m}}": {
    "before": "The model attempts to explain a set of {\\displaystyle p} observations in each of {\\displaystyle n} individuals with a set of {\\displaystyle k} common factors ( {\\displaystyle f_{i,j}} ) where there are fewer factors per unit than observations per unit ( {\\displaystyle k<p} ). Each individual has {\\displaystyle k} of their own common factors, and these are related to the observations via factor loading matrix ( {\\displaystyle L\\in \\mathbb {R} ^{p\\times k}} ), for a single observation, according to",
    "after": "whereby {\\displaystyle x_{i,m}} is the value of the {\\displaystyle i} th observation of the {\\displaystyle m} th individual, {\\displaystyle \\mu _{i}} is the observation mean for the {\\displaystyle i} th observation, {\\displaystyle l_{i,j}} is the loading for the {\\displaystyle i} th observation of the {\\displaystyle j} th factor, {\\displaystyle f_{j,m}} is the value of the {\\displaystyle j} th factor of the {\\displaystyle m} th individual, and {\\displaystyle \\varepsilon _{i,m}} is the {\\displaystyle (i,m)} th unobserved stochastic error term with mean zero and finite variance.",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle X-\\mathrm {M} =LF+\\varepsilon }": {
    "before": "{\\displaystyle x_{i,m}} is the value of the {\\displaystyle i} th observation of the {\\displaystyle m} th individual, {\\displaystyle \\mu _{i}} is the observation mean for the {\\displaystyle i} th observation, {\\displaystyle l_{i,j}} is the loading for the {\\displaystyle i} th observation of the {\\displaystyle j} th factor, {\\displaystyle f_{j,m}} is the value of the {\\displaystyle j} th factor of the {\\displaystyle m} th individual, and {\\displaystyle \\varepsilon _{i,m}} is the {\\displaystyle (i,m)} th unobserved stochastic error term with mean zero and finite variance.In matrix notation",
    "after": "where observation matrix {\\displaystyle X\\in \\mathbb {R} ^{p\\times n}} , loading matrix {\\displaystyle L\\in \\mathbb {R} ^{p\\times k}} , factor matrix {\\displaystyle F\\in \\mathbb {R} ^{k\\times n}} , error term matrix {\\displaystyle \\varepsilon \\in \\mathbb {R} ^{p\\times n}} and mean matrix {\\displaystyle \\mathrm {M} \\in \\mathbb {R} ^{p\\times n}} whereby the {\\displaystyle (i,m)} th element is simply {\\displaystyle \\mathrm {M} _{i,m}=\\mu _{i}} .",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle \\Sigma =\\mathrm {Cov} (X-\\mathrm {M} )=\\mathrm {Cov} (LF+\\varepsilon ),\\,}": {
    "before": "Suppose {\\displaystyle \\mathrm {Cov} (X-\\mathrm {M} )=\\Sigma } . Then",
    "after": "and therefore, from the conditions imposed on {\\displaystyle F} above,",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle \\Sigma =L\\mathrm {Cov} (F)L^{T}+\\mathrm {Cov} (\\varepsilon ),\\,}": {
    "before": "and therefore, from the conditions imposed on {\\displaystyle F} above,",
    "after": "or, setting {\\displaystyle \\Psi :=\\mathrm {Cov} (\\varepsilon )} ,",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle \\Sigma =LL^{T}+\\Psi .\\,}": {
    "before": "or, setting {\\displaystyle \\Psi :=\\mathrm {Cov} (\\varepsilon )} ,",
    "after": "Note that for any orthogonal matrix {\\displaystyle Q} , if we set {\\displaystyle L^{\\prime }=\\ LQ} and {\\displaystyle F^{\\prime }=Q^{T}F} , the criteria for being factors and factor loadings still hold. Hence a set of factors and factor loadings is unique only up to an orthogonal transformation .",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle z_{ai}={\\frac {x_{ai}-{\\hat {\\mu }}_{a}}{{\\hat {\\sigma }}_{a}}}}": {
    "before": "In the following, matrices will be indicated by indexed variables. \"Subject\" indices will be indicated using letters {\\displaystyle a} , {\\displaystyle b} and {\\displaystyle c} , with values running from {\\displaystyle 1} to {\\displaystyle p} which is equal to {\\displaystyle 10} in the above example. \"Factor\" indices will be indicated using letters {\\displaystyle p} , {\\displaystyle q} and {\\displaystyle r} , with values running from {\\displaystyle 1} to {\\displaystyle k} which is equal to {\\displaystyle 2} in the above example. \"Instance\" or \"sample\" indices will be indicated using letters {\\displaystyle i} , {\\displaystyle j} and {\\displaystyle k} , with values running from {\\displaystyle 1} to {\\displaystyle N} . In the example above, if a sample of {\\displaystyle N=1000} students participated in the {\\displaystyle p=10} exams, the {\\displaystyle i} th student's score for the {\\displaystyle a} th exam is given by {\\displaystyle x_{ai}} . The purpose of factor analysis is to characterize the correlations between the variables {\\displaystyle x_{a}} of which the {\\displaystyle x_{ai}} are a particular instance, or set of observations. In order for the variables to be on equal footing, they are normalized into standard scores {\\displaystyle z} :",
    "after": "where the sample mean is:",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle {\\hat {\\mu }}_{a}={\\tfrac {1}{N}}\\sum _{i}x_{ai}}": {
    "before": "{\\displaystyle z_{ai}={\\frac {x_{ai}-{\\hat {\\mu }}_{a}}{{\\hat {\\sigma }}_{a}}}} where the sample mean is:",
    "after": "and the sample variance is given by:",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle {\\hat {\\sigma }}_{a}^{2}={\\tfrac {1}{N-1}}\\sum _{i}(x_{ai}-\\mu _{a})^{2}}": {
    "before": "{\\displaystyle {\\hat {\\mu }}_{a}={\\tfrac {1}{N}}\\sum _{i}x_{ai}} and the sample variance is given by:",
    "after": "The factor analysis model for this particular sample is then:",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle {\\begin{matrix}z_{1,i}&=&\\ell _{1,1}F_{1,i}&+&\\ell _{1,2}F_{2,i}&+&\\varepsilon _{1,i}\\\\\\vdots &&\\vdots &&\\vdots &&\\vdots \\\\z_{10,i}&=&\\ell _{10,1}F_{1,i}&+&\\ell _{10,2}F_{2,i}&+&\\varepsilon _{10,i}\\end{matrix}}}": {
    "before": "The factor analysis model for this particular sample is then:",
    "after": "or, more succinctly:",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle z_{ai}=\\sum _{p}\\ell _{ap}F_{pi}+\\varepsilon _{ai}}": {
    "before": "{\\displaystyle {\\begin{matrix}z_{1,i}&=&\\ell _{1,1}F_{1,i}&+&\\ell _{1,2}F_{2,i}&+&\\varepsilon _{1,i}\\\\\\vdots &&\\vdots &&\\vdots &&\\vdots \\\\z_{10,i}&=&\\ell _{10,1}F_{1,i}&+&\\ell _{10,2}F_{2,i}&+&\\varepsilon _{10,i}\\end{matrix}}} or, more succinctly:",
    "after": "where {\\displaystyle F_{1i}} is the {\\displaystyle i} th student's \"verbal intelligence\", {\\displaystyle F_{2i}} is the {\\displaystyle i} th student's \"mathematical intelligence\", {\\displaystyle \\ell _{ap}} are the factor loadings for the {\\displaystyle a} th subject, for {\\displaystyle p=1,2} .",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle Z=LF+\\varepsilon }": {
    "before": "{\\displaystyle F_{1i}} is the {\\displaystyle i} th student's \"verbal intelligence\", {\\displaystyle F_{2i}} is the {\\displaystyle i} th student's \"mathematical intelligence\", {\\displaystyle \\ell _{ap}} are the factor loadings for the {\\displaystyle a} th subject, for {\\displaystyle p=1,2} .In matrix notation, we have",
    "after": "Observe that by doubling the scale on which \"verbal intelligence\"—the first component in each column of {\\displaystyle F} —is measured, and simultaneously halving the factor loadings for verbal intelligence makes no difference to the model. Thus, no generality is lost by assuming that the standard deviation of the factors for verbal intelligence is {\\displaystyle 1} . Likewise for mathematical intelligence. Moreover, for similar reasons, no generality is lost by assuming the two factors are uncorrelated with each other. In other words:",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle \\sum _{i}F_{pi}F_{qi}=\\delta _{pq}}": {
    "before": "Observe that by doubling the scale on which \"verbal intelligence\"—the first component in each column of {\\displaystyle F} —is measured, and simultaneously halving the factor loadings for verbal intelligence makes no difference to the model. Thus, no generality is lost by assuming that the standard deviation of the factors for verbal intelligence is {\\displaystyle 1} . Likewise for mathematical intelligence. Moreover, for similar reasons, no generality is lost by assuming the two factors are uncorrelated with each other. In other words:",
    "after": "where {\\displaystyle \\delta _{pq}} is the Kronecker delta ( {\\displaystyle 0} when {\\displaystyle p\\neq q} and {\\displaystyle 1} when {\\displaystyle p=q} ).The errors are assumed to be independent of the factors:",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle \\sum _{i}z_{ai}z_{bi}=\\sum _{j}\\ell _{aj}\\ell _{bj}+\\sum _{i}\\varepsilon _{ai}\\varepsilon _{bi}}": {
    "before": "The values of the loadings {\\displaystyle L} , the averages {\\displaystyle \\mu } , and the variances of the \"errors\" {\\displaystyle \\varepsilon } must be estimated given the observed data {\\displaystyle X} and {\\displaystyle F} (the assumption about the levels of the factors is fixed for a given {\\displaystyle F} ). The \"fundamental theorem\" may be derived from the above conditions:",
    "after": "The term on the left is the {\\displaystyle (a,b)} -term of the correlation matrix (a {\\displaystyle p\\times p} matrix derived as the product of the {\\displaystyle p\\times N} matrix of standardized observations with its transpose) of the observed data, and its {\\displaystyle p} diagonal elements will be {\\displaystyle 1} s. The second term on the right will be a diagonal matrix with terms less than unity. The first term on the right is the \"reduced correlation matrix\" and will be equal to the correlation matrix except for its diagonal values which will be less than unity. These diagonal elements of the reduced correlation matrix are called \"communalities\" (which represent the fraction of the variance in the observed variable that is accounted for by the factors):",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle h_{a}^{2}=1-\\psi _{a}=\\sum _{j}\\ell _{aj}\\ell _{aj}}": {
    "before": "The term on the left is the {\\displaystyle (a,b)} -term of the correlation matrix (a {\\displaystyle p\\times p} matrix derived as the product of the {\\displaystyle p\\times N} matrix of standardized observations with its transpose) of the observed data, and its {\\displaystyle p} diagonal elements will be {\\displaystyle 1} s. The second term on the right will be a diagonal matrix with terms less than unity. The first term on the right is the \"reduced correlation matrix\" and will be equal to the correlation matrix except for its diagonal values which will be less than unity. These diagonal elements of the reduced correlation matrix are called \"communalities\" (which represent the fraction of the variance in the observed variable that is accounted for by the factors):",
    "after": "The sample data {\\displaystyle z_{ai}} will not exactly obey the fundamental equation given above due to sampling errors, inadequacy of the model, etc. The goal of any analysis of the above model is to find the factors {\\displaystyle F_{pi}} and loadings {\\displaystyle \\ell _{ap}} which give a \"best fit\" to the data. In factor analysis, the best fit is defined as the minimum of the mean square error in the off-diagonal residuals of the correlation matrix: ",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle \\varepsilon ^{2}=\\sum _{a\\neq b}\\left[\\sum _{i}z_{ai}z_{bi}-\\sum _{j}\\ell _{aj}\\ell _{bj}\\right]^{2}}": {
    "before": "The sample data {\\displaystyle z_{ai}} will not exactly obey the fundamental equation given above due to sampling errors, inadequacy of the model, etc. The goal of any analysis of the above model is to find the factors {\\displaystyle F_{pi}} and loadings {\\displaystyle \\ell _{ap}} which give a \"best fit\" to the data. In factor analysis, the best fit is defined as the minimum of the mean square error in the off-diagonal residuals of the correlation matrix: ",
    "after": "This is equivalent to minimizing the off-diagonal components of the error covariance which, in the model equations have expected values of zero. This is to be contrasted with principal component analysis which seeks to minimize the mean square error of all residuals.  Before the advent of high-speed computers, considerable effort was devoted to finding approximate solutions to the problem, particularly in estimating the communalities by other means, which then simplifies the problem considerably by yielding a known reduced correlation matrix. This was then used to estimate the factors and the loadings. With the advent of high-speed computers, the minimization problem can be solved iteratively with adequate speed, and the communalities are calculated in the process, rather than being needed beforehand. The MinRes algorithm is particularly suited to this problem, but is hardly the only iterative means of finding a solution.",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle \\mathbf {z} _{a}=\\sum _{p}\\ell _{ap}\\mathbf {F} _{p}+{\\boldsymbol {\\varepsilon }}_{a}}": {
    "before": "The parameters and variables of factor analysis can be given a geometrical interpretation. The data ( {\\displaystyle z_{ai}} ), the factors ( {\\displaystyle F_{pi}} ) and the errors ( {\\displaystyle \\varepsilon _{ai}} ) can be viewed as vectors in an {\\displaystyle N} -dimensional Euclidean space (sample space), represented as {\\displaystyle \\mathbf {z} _{a}} , {\\displaystyle \\mathbf {F} _{p}} and {\\displaystyle {\\boldsymbol {\\varepsilon }}_{a}} respectively. Since the data are standardized, the data vectors are of unit length ( {\\displaystyle ||\\mathbf {z} _{a}||=1} ). The factor vectors define an {\\displaystyle k} -dimensional linear subspace (i.e. a hyperplane) in this space, upon which the data vectors are projected orthogonally. This follows from the model equation",
    "after": "and the independence of the factors and the errors: {\\displaystyle \\mathbf {F} _{p}\\cdot {\\boldsymbol {\\varepsilon }}_{a}=0} . In the above example, the hyperplane is just a 2-dimensional plane defined by the two factor vectors. The projection of the data vectors onto the hyperplane is given by",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle {\\hat {\\mathbf {z} }}_{a}=\\sum _{p}\\ell _{ap}\\mathbf {F} _{p}}": {
    "before": "and the independence of the factors and the errors: {\\displaystyle \\mathbf {F} _{p}\\cdot {\\boldsymbol {\\varepsilon }}_{a}=0} . In the above example, the hyperplane is just a 2-dimensional plane defined by the two factor vectors. The projection of the data vectors onto the hyperplane is given by",
    "after": "and the errors are vectors from that projected point to the data point and are perpendicular to the hyperplane. The goal of factor analysis is to find a hyperplane which is a \"best fit\" to the data in some sense, so it doesn't matter how the factor vectors which define this hyperplane are chosen, as long as they are independent and lie in the hyperplane. We are free to specify them as both orthogonal and normal ( {\\displaystyle \\mathbf {F} _{p}\\cdot \\mathbf {F} _{q}=\\delta _{pq}} ) with no loss of generality. After a suitable set of factors are found, they may also be arbitrarily rotated within the hyperplane, so that any rotation of the factor vectors will define the same hyperplane, and also be a solution. As a result, in the above example, in which the fitting hyperplane is two dimensional, if we do not know beforehand that the two types of intelligence are uncorrelated, then we cannot interpret the two factors as the two different types of intelligence. Even if they are uncorrelated, we cannot tell which factor corresponds to verbal intelligence and which corresponds to mathematical intelligence, or whether the factors are linear combinations of both, without an outside argument.",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle {\\hat {r}}_{ab}={\\hat {\\mathbf {z} }}_{a}\\cdot {\\hat {\\mathbf {z} }}_{b}} .": {
    "before": "The data vectors {\\displaystyle \\mathbf {z} _{a}} have unit length. The entries of the correlation matrix for the data are given by {\\displaystyle r_{ab}=\\mathbf {z} _{a}\\cdot \\mathbf {z} _{b}} . The correlation matrix can be geometrically interpreted as the cosine of the angle between the two data vectors {\\displaystyle \\mathbf {z} _{a}} and {\\displaystyle \\mathbf {z} _{b}} . The diagonal elements will clearly be {\\displaystyle 1} s and the off diagonal elements will have absolute values less than or equal to unity. The \"reduced correlation matrix\" is defined as",
    "after": "The goal of factor analysis is to choose the fitting hyperplane such that the reduced correlation matrix reproduces the correlation matrix as nearly as possible, except for the diagonal elements of the correlation matrix which are known to have unit value. In other words, the goal is to reproduce as accurately as possible the cross-correlations in the data. Specifically, for the fitting hyperplane, the mean square error in the off-diagonal components",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle \\varepsilon ^{2}=\\sum _{a\\neq b}\\left(r_{ab}-{\\hat {r}}_{ab}\\right)^{2}}": {
    "before": "The goal of factor analysis is to choose the fitting hyperplane such that the reduced correlation matrix reproduces the correlation matrix as nearly as possible, except for the diagonal elements of the correlation matrix which are known to have unit value. In other words, the goal is to reproduce as accurately as possible the cross-correlations in the data. Specifically, for the fitting hyperplane, the mean square error in the off-diagonal components",
    "after": "is to be minimized, and this is accomplished by minimizing it with respect to a set of orthonormal factor vectors. It can be seen that",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle r_{ab}-{\\hat {r}}_{ab}={\\boldsymbol {\\varepsilon }}_{a}\\cdot {\\boldsymbol {\\varepsilon }}_{b}}": {
    "before": "is to be minimized, and this is accomplished by minimizing it with respect to a set of orthonormal factor vectors. It can be seen that",
    "after": "The term on the right is just the covariance of the errors. In the model, the error covariance is stated to be a diagonal matrix and so the above minimization problem will in fact yield a \"best fit\" to the model: It will yield a sample estimate of the error covariance which has its off-diagonal components minimized in the mean square sense. It can be seen that since the {\\displaystyle {\\hat {z}}_{a}} are orthogonal projections of the data vectors, their length will be less than or equal to the length of the projected data vector, which is unity. The square of these lengths are just the diagonal elements of the reduced correlation matrix. These diagonal elements of the reduced correlation matrix are known as \"communalities\":",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "{\\displaystyle {h_{a}}^{2}=||{\\hat {\\mathbf {z} }}_{a}||^{2}=\\sum _{p}{\\ell _{ap}}^{2}}": {
    "before": "The term on the right is just the covariance of the errors. In the model, the error covariance is stated to be a diagonal matrix and so the above minimization problem will in fact yield a \"best fit\" to the model: It will yield a sample estimate of the error covariance which has its off-diagonal components minimized in the mean square sense. It can be seen that since the {\\displaystyle {\\hat {z}}_{a}} are orthogonal projections of the data vectors, their length will be less than or equal to the length of the projected data vector, which is unity. The square of these lengths are just the diagonal elements of the reduced correlation matrix. These diagonal elements of the reduced correlation matrix are known as \"communalities\":",
    "after": "Large values of the communalities will indicate that the fitting hyperplane is rather accurately reproducing the correlation matrix. The mean values of the factors must also be constrained to be zero, from which it follows that the mean values of the errors will also be zero.",
    "url": "https://en.wikipedia.org/wiki/Factor analysis"
  },
  "X = ( X 1 , X 2 , ...).": {
    "before": "A number of different notations are in use for time-series analysis. A common notation specifying a time series X that is indexed by the natural numbers is written",
    "after": "Another common notation is",
    "url": "https://en.wikipedia.org/wiki/Time series"
  },
  "Y = ( Y t : t ∈ T ),": {
    "before": "X = ( X 1 , X 2 , ...).Another common notation is",
    "after": "where T is the index set .",
    "url": "https://en.wikipedia.org/wiki/Time series"
  },
  "Quartile map of amount of exports per country. Darker = more exports.": {
    "before": "Exports by country",
    "after": "Map of countries by exports as of 2022, according to World Bank",
    "url": "https://en.wikipedia.org/wiki/List of countries by exports"
  },
  "5th, 12th, 19th26th34th42ndclass=notpageimage| Host venues of G7 summits in Japan": {
    "before": "2nd7th9th14th16th21st23rd28th30th36th38th44thclass=notpageimage| Host venues of G7 summits in North America",
    "after": "The G7 was founded primarily to facilitate shared macroeconomic initiatives in response to contemporary economic problems; the first gathering was centered around the Nixon shock, the 1970s energy crisis, and the ensuing global recession. Since 1975, the group has met annually at summits organized and hosted by whichever country occupies the annually-rotating presidency; since 1987, the G7 Finance Ministers have met at least semi-annually, and up to four times a year at stand-alone meetings.",
    "url": "https://en.wikipedia.org/wiki/G7"
  },
  "{\\displaystyle y=Hx+w}": {
    "before": "According to the assumptions, the observed vector {\\displaystyle y} and the unknown deterministic parameter vector {\\displaystyle x} are tied by the linear model",
    "after": "where {\\displaystyle H} is a known {\\displaystyle n\\times m} matrix with full column rank {\\displaystyle m} , and {\\displaystyle w} is a zero mean random vector with a known covariance matrix {\\displaystyle C_{w}} .",
    "url": "https://en.wikipedia.org/wiki/Regret (decision theory)"
  },
  "{\\displaystyle {\\hat {x}}=Gy}": {
    "before": "where {\\displaystyle H} is a known {\\displaystyle n\\times m} matrix with full column rank {\\displaystyle m} , and {\\displaystyle w} is a zero mean random vector with a known covariance matrix {\\displaystyle C_{w}} .Let",
    "after": "be a linear estimate of {\\displaystyle x} from {\\displaystyle y} , where {\\displaystyle G} is some {\\displaystyle m\\times n} matrix. The MSE of this estimator is given by",
    "url": "https://en.wikipedia.org/wiki/Regret (decision theory)"
  },
  "{\\displaystyle MSE=E\\left(||{\\hat {x}}-x||^{2}\\right)=Tr(GC_{w}G^{*})+x^{*}(I-GH)^{*}(I-GH)x.}": {
    "before": "be a linear estimate of {\\displaystyle x} from {\\displaystyle y} , where {\\displaystyle G} is some {\\displaystyle m\\times n} matrix. The MSE of this estimator is given by",
    "after": "Since the MSE depends explicitly on {\\displaystyle x} it cannot be minimized directly. Instead, the concept of regret can be used in order to define a linear estimator with good MSE performance. To define the regret here, consider a linear estimator that knows the value of the parameter {\\displaystyle x} , i.e., the matrix {\\displaystyle G} can explicitly depend on {\\displaystyle x} :",
    "url": "https://en.wikipedia.org/wiki/Regret (decision theory)"
  },
  "{\\displaystyle {\\hat {x}}^{o}=G(x)y.}": {
    "before": "Since the MSE depends explicitly on {\\displaystyle x} it cannot be minimized directly. Instead, the concept of regret can be used in order to define a linear estimator with good MSE performance. To define the regret here, consider a linear estimator that knows the value of the parameter {\\displaystyle x} , i.e., the matrix {\\displaystyle G} can explicitly depend on {\\displaystyle x} :",
    "after": "The MSE of {\\displaystyle {\\hat {x}}^{o}} is",
    "url": "https://en.wikipedia.org/wiki/Regret (decision theory)"
  },
  "{\\displaystyle MSE^{o}=E\\left(||{\\hat {x}}^{o}-x||^{2}\\right)=Tr(G(x)C_{w}G(x)^{*})+x^{*}(I-G(x)H)^{*}(I-G(x)H)x.}": {
    "before": "{\\displaystyle {\\hat {x}}^{o}=G(x)y.} The MSE of {\\displaystyle {\\hat {x}}^{o}} is",
    "after": "To find the optimal {\\displaystyle G(x)} , {\\displaystyle MSE^{o}} is differentiated with respect to {\\displaystyle G} and the derivative is equated to 0 getting",
    "url": "https://en.wikipedia.org/wiki/Regret (decision theory)"
  },
  "{\\displaystyle G(x)=xx^{*}H^{*}(C_{w}+Hxx^{*}H^{*})^{-1}.}": {
    "before": "To find the optimal {\\displaystyle G(x)} , {\\displaystyle MSE^{o}} is differentiated with respect to {\\displaystyle G} and the derivative is equated to 0 getting",
    "after": "Then, using the Matrix Inversion Lemma",
    "url": "https://en.wikipedia.org/wiki/Regret (decision theory)"
  },
  "{\\displaystyle G(x)={\\frac {1}{1+x^{*}H^{*}C_{w}^{-1}Hx}}xx^{*}H^{*}C_{w}^{-1}.}": {
    "before": "{\\displaystyle G(x)=xx^{*}H^{*}(C_{w}+Hxx^{*}H^{*})^{-1}.} Then, using the Matrix Inversion Lemma",
    "after": "Substituting this {\\displaystyle G(x)} back into {\\displaystyle MSE^{o}} , one gets",
    "url": "https://en.wikipedia.org/wiki/Regret (decision theory)"
  },
  "{\\displaystyle MSE^{o}={\\frac {x^{*}x}{1+x^{*}H^{*}C_{w}^{-1}Hx}}.}": {
    "before": "Substituting this {\\displaystyle G(x)} back into {\\displaystyle MSE^{o}} , one gets",
    "after": "This is the smallest MSE achievable with a linear estimate that knows {\\displaystyle x} . In practice this MSE cannot be achieved, but it serves as a bound on the optimal MSE. The regret of using the linear estimator specified by {\\displaystyle G} is equal to",
    "url": "https://en.wikipedia.org/wiki/Regret (decision theory)"
  },
  "{\\displaystyle R(x,G)=MSE-MSE^{o}=Tr(GC_{w}G^{*})+x^{*}(I-GH)^{*}(I-GH)x-{\\frac {x^{*}x}{1+x^{*}H^{*}C_{w}^{-1}Hx}}.}": {
    "before": "This is the smallest MSE achievable with a linear estimate that knows {\\displaystyle x} . In practice this MSE cannot be achieved, but it serves as a bound on the optimal MSE. The regret of using the linear estimator specified by {\\displaystyle G} is equal to",
    "after": "The minimax regret approach here is to minimize the worst-case regret, i.e., {\\displaystyle \\sup _{x\\in E}R(x,G).} This will allow a performance as close as possible to the best achievable performance in the worst case of the parameter {\\displaystyle x} . Although this problem appears difficult, it is an instance of convex optimization and in particular a numerical solution can be efficiently calculated.  Similar ideas can be used when {\\displaystyle x} is random with uncertainty in the covariance matrix .  ",
    "url": "https://en.wikipedia.org/wiki/Regret (decision theory)"
  },
  "GDP = nominal gross domestic product , a measure of national income M = money supply T = total taxes .": {
    "before": "Typical exercises of qualitative economics include comparative-static changes studied in microeconomics or macroeconomics and comparative equilibrium-growth states in a macroeconomic growth model . A simple example illustrating qualitative change is from macroeconomics. Let:",
    "after": "Monetary theory hypothesizes a positive relationship between GDP the dependent variable and M the independent variable . Equivalent ways to represent such a qualitative relationship between them are as a signed functional relationship and as a signed derivative :",
    "url": "https://en.wikipedia.org/wiki/Qualitative economics"
  },
  "{\\displaystyle GDP=f({\\overset {+}{M}})\\quad \\!} or {\\displaystyle \\quad {\\frac {df(M)}{dM}}>0.}": {
    "before": "Monetary theory hypothesizes a positive relationship between GDP the dependent variable and M the independent variable . Equivalent ways to represent such a qualitative relationship between them are as a signed functional relationship and as a signed derivative :",
    "after": "where the '+' indexes a positive relationship of GDP to M , that is, as M increases, GDP increases as a result.",
    "url": "https://en.wikipedia.org/wiki/Qualitative economics"
  },
  "{\\displaystyle GDP=f({\\overset {-}{T}})\\quad \\!} or {\\displaystyle \\quad {\\frac {df(T)}{dT}}<0.}": {
    "before": "Another model of GDP hypothesizes that GDP has a negative relationship to T . This can be represented similarly to the above, with a theoretically appropriate sign change as indicated:",
    "after": "That is, as T increases, GDP decreases as a result. A combined model uses both M and T as independent variables. The hypothesized relationships can be equivalently represented as signed functional relationships and signed partial derivatives (suitable for more than one independent variable):",
    "url": "https://en.wikipedia.org/wiki/Qualitative economics"
  },
  "{\\displaystyle GDP=f({\\overset {+}{M}},{\\overset {-}{T}})\\,\\!\\quad } or {\\displaystyle \\quad {\\frac {\\partial f(M,T)}{\\partial M}}>0,\\quad } {\\displaystyle {\\frac {\\partial f(M,T)}{\\partial T}}<0.}": {
    "before": "That is, as T increases, GDP decreases as a result. A combined model uses both M and T as independent variables. The hypothesized relationships can be equivalently represented as signed functional relationships and signed partial derivatives (suitable for more than one independent variable):",
    "after": "Qualitative hypotheses occur in earliest history of formal economics but only as to formal economic models from the late 1930s with Hicks's model of general equilibrium in a competitive economy.  A classic exposition of qualitative economics is Samuelson, 1947.  There Samuelson identifies qualitative restrictions and the hypotheses of maximization and stability of equilibrium as the three fundamental sources of meaningful theorems — hypotheses about empirical data that could conceivably be refuted by empirical data. ",
    "url": "https://en.wikipedia.org/wiki/Qualitative economics"
  },
  "{\\displaystyle p_{i}=\\left[\\max _{a\\in A}\\sum _{j\\neq i}b_{j}(a)\\right]-\\sum _{j\\neq i}b_{j}(a^{*})} .": {
    "before": "If we do not know the values, then we instead solicit bids {\\displaystyle {\\tilde {b}}_{ij}} , asking each player {\\displaystyle i} how much they would wish to bid for house {\\displaystyle j} . Define {\\displaystyle b_{i}(a)={\\tilde {b}}_{ik}} if bidder {\\displaystyle i} receives house {\\displaystyle k} in the matching {\\displaystyle a} . Now compute {\\displaystyle a^{*}} , a maximum weight bipartite matching with respect to the bids, and compute",
    "after": "The first term is another max weight bipartite matching, and the second term can be computed easily from {\\displaystyle a^{*}} .",
    "url": "https://en.wikipedia.org/wiki/Vickrey–Clarke–Groves auction"
  },
  "{\\displaystyle {\\begin{aligned}U_{i}&=v_{i}-\\left(V_{N\\setminus \\{b_{i}\\}}^{M}-V_{N\\setminus \\{b_{i}\\}}^{M\\setminus \\{t_{i}\\}}\\right)\\\\&=\\sum _{j}v_{j}-\\sum _{j\\neq i}v_{j}+V_{N\\setminus \\{b_{i}\\}}^{M\\setminus \\{t_{i}\\}}-V_{N\\setminus \\{b_{i}\\}}^{M}\\\\&=\\sum _{j}v_{j}-V_{N\\setminus \\{b_{i}\\}}^{M\\setminus \\{t_{i}\\}}+V_{N\\setminus \\{b_{i}\\}}^{M\\setminus \\{t_{i}\\}}-V_{N\\setminus \\{b_{i}\\}}^{M}\\\\&=\\sum _{j}v_{j}-V_{N\\setminus \\{b_{i}\\}.}^{M}\\end{aligned}}}": {
    "before": "For each bidder {\\displaystyle b_{i}} , let {\\displaystyle v_{i}} be their true valuation of an item {\\displaystyle t_{i}} , and suppose ( without loss of generality ) that {\\displaystyle b_{i}} wins {\\displaystyle t_{i}} upon submitting their true valuations. Then the net utility {\\displaystyle U_{i}} attained by {\\displaystyle b_{i}} is given by their own valuation of the item they've won, minus the price they've paid:",
    "after": "As {\\displaystyle V_{N\\setminus \\{b_{i}\\}}^{M}} is independent of {\\displaystyle v_{i}} , the maximization of net utility is pursued by the mechanism along with the maximization of corporate gross utility {\\displaystyle \\sum _{j}v_{j}} for the declared bid {\\displaystyle v_{i}} .",
    "url": "https://en.wikipedia.org/wiki/Vickrey–Clarke–Groves auction"
  },
  "{\\displaystyle {\\mbox{EMV}}=\\max _{i}\\sum _{j}p_{j}R_{ij}}": {
    "before": "The problem is modeled with a payoff matrix R ij in which the row index i describes a choice that must be made by the player, while the column index j describes a random variable that the player does not yet have knowledge of, that has probability p j of being in state j . If the player is to choose i without knowing the value of j , the best choice is the one that maximizes the expected monetary value :",
    "after": "where {\\displaystyle \\sum _{j}p_{j}R_{ij}}",
    "url": "https://en.wikipedia.org/wiki/Expected value of perfect information"
  },
  "{\\displaystyle {\\mbox{EMV}}=\\max _{i}}": {
    "before": "is the expected payoff for action i i.e. the expectation value, and",
    "after": "is choosing the maximum of these expectations for all available actions. On the other hand, with perfect knowledge of j , the player may choose a value of i that optimizes the expectation for that specific j . Therefore, the expected value given perfect information is",
    "url": "https://en.wikipedia.org/wiki/Expected value of perfect information"
  },
  "{\\displaystyle {\\mbox{EV}}|{\\mbox{PI}}=\\sum _{j}p_{j}(\\max _{i}R_{ij}),}": {
    "before": "is choosing the maximum of these expectations for all available actions. On the other hand, with perfect knowledge of j , the player may choose a value of i that optimizes the expectation for that specific j . Therefore, the expected value given perfect information is",
    "after": "where {\\displaystyle p_{j}} is the probability that the system is in state j , and {\\displaystyle R_{ij}} is the pay-off if one follows action i while the system is in state j . Here, {\\displaystyle (\\max _{i}R_{ij})} indicates the best choice of action i for each state j .",
    "url": "https://en.wikipedia.org/wiki/Expected value of perfect information"
  },
  "{\\displaystyle {\\mbox{EVPI}}={\\mbox{EV}}|{\\mbox{PI}}-{\\mbox{EMV}}.}": {
    "before": "The expected value of perfect information is the difference between these two quantities,",
    "after": "This difference describes, in expectation, how much larger a value the player can hope to obtain by knowing j and picking the best i for that j , as compared to picking a value of i before j is known. Since EV|PI is necessarily greater than or equal to EMV, EVPI is always non-negative.",
    "url": "https://en.wikipedia.org/wiki/Expected value of perfect information"
  },
  "{\\displaystyle R={\\begin{bmatrix}1500&300&-800\\\\900&600&-200\\\\500&500&500\\end{bmatrix}}}": {
    "before": "Solution:Here the payoff matrix is:",
    "after": "The probability vector is:",
    "url": "https://en.wikipedia.org/wiki/Expected value of perfect information"
  },
  "{\\displaystyle p={\\begin{bmatrix}0.5\\\\0.3\\\\0.2\\end{bmatrix}}}": {
    "before": "{\\displaystyle R={\\begin{bmatrix}1500&300&-800\\\\900&600&-200\\\\500&500&500\\end{bmatrix}}} The probability vector is:",
    "after": "Expectation for each vehicle ( {\\displaystyle Rp} ):",
    "url": "https://en.wikipedia.org/wiki/Expected value of perfect information"
  },
  "{\\displaystyle {\\mbox{Exp}}_{\\text{stock}}=0.5\\times 1500+0.3\\times 300+0.2\\times (-800)=680} {\\displaystyle {\\mbox{Exp}}_{\\text{mutual fund}}=0.5\\times 900+0.3\\times 600+0.2\\times (-200)=590} {\\displaystyle {\\mbox{Exp}}_{\\text{certificate of deposit}}=0.5\\times 500+0.3\\times 500+0.2\\times 500=500}": {
    "before": "Expectation for each vehicle ( {\\displaystyle Rp} ):",
    "after": "The maximum of these expectations is the stock vehicle. Not knowing which direction the market will go (only knowing the probability of the directions), we expect to make the most money with the stock vehicle.",
    "url": "https://en.wikipedia.org/wiki/Expected value of perfect information"
  },
  "{\\displaystyle {\\mbox{EV}}|{\\mbox{PI}}=0.5\\times 1500+0.3\\times 600+0.2\\times 500=1030}": {
    "before": "Expectation for maximizing profit given the state of the market:",
    "after": "That is, given each market direction, we choose the investment vehicle that maximizes the profit.",
    "url": "https://en.wikipedia.org/wiki/Expected value of perfect information"
  },
  "{\\displaystyle {\\mbox{EVPI}}={\\mbox{EV}}|{\\mbox{PI}}-{\\mbox{EMV}}=1030-680=350.}": {
    "before": "That is, given each market direction, we choose the investment vehicle that maximizes the profit.Hence,",
    "after": "Conclusion:Knowing the direction the market will go (i.e. having perfect information) is worth $350.",
    "url": "https://en.wikipedia.org/wiki/Expected value of perfect information"
  },
  "{\\displaystyle E_{t}} being the mathematical expectation conditional on all information available in {\\displaystyle t} {\\displaystyle \\delta =1/\\beta -1} being the agent's rate of time preference {\\displaystyle r_{t}=R_{t}-1\\geq \\delta } being the real rate of interest in {\\displaystyle t} {\\displaystyle u} being the strictly concave one-period utility function {\\displaystyle c_{t}} being the consumption in {\\displaystyle t} {\\displaystyle y_{t}=w_{t}} being the earnings in {\\displaystyle t} {\\displaystyle A_{t}} being the assets, apart from human capital, in {\\displaystyle t} .": {
    "before": "Friedman's theory argues that consumption is linked to the permanent income of agents. Thus, when income is affected by transitory shocks, for example, agents' consumption should not change, since they can use savings or borrowing to adjust. This theory assumes that agents are able to finance consumption with earnings that are not yet generated, and thus assumes perfect capital markets. Empirical evidence shows that liquidity constraint is one of the main reasons why it is difficult to observe consumption smoothing in the data. In 1978, Robert Hall formalized Friedman's idea.  By taking into account the diminishing returns to consumption, and therefore, assuming a concave utility function, he showed that agents optimally would choose to keep a stable path of consumption.With (cf. Hall's paper)",
    "after": "agents choose the consumption path that maximizes:",
    "url": "https://en.wikipedia.org/wiki/Consumption smoothing"
  },
  "{\\displaystyle E_{0}\\sum _{t=0}^{\\infty }\\beta ^{t}\\left[u(c_{t})\\right]}": {
    "before": "agents choose the consumption path that maximizes:",
    "after": "Subject to a sequence of budget constraints:",
    "url": "https://en.wikipedia.org/wiki/Consumption smoothing"
  },
  "{\\displaystyle A_{t+1}=R_{t+1}(A_{t}+y_{t}-c_{t})}": {
    "before": "{\\displaystyle E_{0}\\sum _{t=0}^{\\infty }\\beta ^{t}\\left[u(c_{t})\\right]} Subject to a sequence of budget constraints:",
    "after": "The first order necessary condition in this case will be:",
    "url": "https://en.wikipedia.org/wiki/Consumption smoothing"
  },
  "{\\displaystyle E_{t}u^{\\prime }(c_{t+1})=u^{\\prime }(c_{t})}": {
    "before": "By assuming that {\\displaystyle R_{t+1}=R=\\beta ^{-1}} we obtain, for the previous equation:",
    "after": "Which, due to the concavity of the utility function, implies:",
    "url": "https://en.wikipedia.org/wiki/Consumption smoothing"
  },
  "{\\displaystyle E_{t}[c_{t+1}]=c_{t}}": {
    "before": "Which, due to the concavity of the utility function, implies:",
    "after": "Thus, rational agents would expect to achieve the same consumption in every period.",
    "url": "https://en.wikipedia.org/wiki/Consumption smoothing"
  },
  "{\\displaystyle c_{t}=\\left[{\\frac {r}{1+r}}\\right]\\left[E_{t}\\sum _{i=0}^{\\infty }\\left({\\frac {1}{1+r}}\\right)^{i}y_{t+i}+A_{t}\\right]}": {
    "before": "Hall also showed that for a quadratic utility function, the optimal consumption is equal to:",
    "after": "This expression shows that agents choose to consume a fraction of their present discounted value of their human and financial wealth.",
    "url": "https://en.wikipedia.org/wiki/Consumption smoothing"
  },
  "{\\displaystyle EU=q*U(W|badstate)+(1-q)*U(W|goodstate)}": {
    "before": "Expected utility can be modeled as: ",
    "after": "where: {\\displaystyle q} = probability you will lose all your wealth/consumption",
    "url": "https://en.wikipedia.org/wiki/Consumption smoothing"
  },
  "{\\displaystyle EU=(1-q)*U(W-p)+q*U(W-p-d+p/q)}": {
    "before": "Similarly, actuarially fair insurance can also be modeled: ",
    "after": "where: {\\displaystyle q} = probability you will lose all your wealth/consumption",
    "url": "https://en.wikipedia.org/wiki/Consumption smoothing"
  },
  "{\\displaystyle W}= wealth": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Consumption smoothing"
  },
  "{\\displaystyle d}= damages": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Consumption smoothing"
  },
  "{\\displaystyle C\\varphi \\Leftrightarrow \\bigwedge _{i=0}^{\\infty }E^{i}\\varphi }": {
    "before": "By abbreviating the expression {\\displaystyle E_{G}E_{G}^{n-1}\\varphi } with {\\displaystyle E_{G}^{n}\\varphi } and defining {\\displaystyle E_{G}^{0}\\varphi =\\varphi } , common knowledge could then be defined with the axiom",
    "after": "There is, however, a complication. The languages of epistemic logic are usually finitary , whereas the axiom above defines common knowledge as an infinite conjunction of formulas, hence not a well-formed formula of the language. To overcome this difficulty, a fixed-point definition of common knowledge can be given. Intuitively, common knowledge is thought of as the fixed point of the \"equation\" {\\displaystyle C_{G}\\varphi =[\\varphi \\wedge E_{G}(C_{G}\\varphi )]=E_{G}^{\\aleph _{0}}\\varphi } . Here, {\\displaystyle \\aleph _{0}} is the Aleph-naught . In this way, it is possible to find a formula {\\displaystyle \\psi } implying {\\displaystyle E_{G}(\\varphi \\wedge C_{G}\\varphi )} from which, in the limit, we can infer common knowledge of {\\displaystyle \\varphi } .",
    "url": "https://en.wikipedia.org/wiki/Common knowledge (logic)"
  },
  "{\\displaystyle K_{i}(e)=\\{s\\in S\\mid P_{i}(s)\\subset e\\}}": {
    "before": "A knowledge function K can now be defined in the following way:",
    "after": "That is, K i ( e ) is the set of states where the agent will know that event e obtains. It is a subset of e .",
    "url": "https://en.wikipedia.org/wiki/Common knowledge (logic)"
  },
  "{\\displaystyle E(e)=\\bigcap _{i}K_{i}(e)}": {
    "before": "Similar to the modal logic formulation above, an operator for the idea that \"everyone knows can be defined as e \".",
    "after": "As with the modal operator, we will iterate the E function, {\\displaystyle E^{1}(e)=E(e)} and {\\displaystyle E^{n+1}(e)=E(E^{n}(e))} . Using this we can then define a common knowledge function,",
    "url": "https://en.wikipedia.org/wiki/Common knowledge (logic)"
  },
  "{\\displaystyle C(e)=\\bigcap _{n=1}^{\\infty }E^{n}(e).}": {
    "before": "As with the modal operator, we will iterate the E function, {\\displaystyle E^{1}(e)=E(e)} and {\\displaystyle E^{n+1}(e)=E(E^{n}(e))} . Using this we can then define a common knowledge function,",
    "after": "The equivalence with the syntactic approach sketched above can easily be seen: consider an Aumann structure as the one just defined. We can define a correspondent Kripke structure by taking the same space S , accessibility relations {\\displaystyle R_{i}} that define the equivalence classes corresponding to the partitions {\\displaystyle P_{i}} , and a valuation function such that it yields value true to the primitive proposition p in all and only the states s such that {\\displaystyle s\\in E^{p}} , where {\\displaystyle E^{p}} is the event of the Aumann structure corresponding to the primitive proposition p . It is not difficult to see that the common knowledge accessibility function {\\displaystyle R_{G}} defined in the previous section corresponds to the finest common coarsening of the partitions {\\displaystyle P_{i}} for all {\\displaystyle i\\in G} , which is the finitary characterization of common knowledge also given by Aumann in the 1976 article.",
    "url": "https://en.wikipedia.org/wiki/Common knowledge (logic)"
  },
  "For k = 2, it is merely \"first-order\" knowledge (": {
    "before": "For k > 1, the outsider is only telling the island citizens what they already know: that there are blue-eyed people among them. However, before this fact is announced, the fact is not common knowledge, but instead mutual knowledge.",
    "after": "{\\displaystyle E_{G}[\\exists x\\!\\in \\!G(Bl_{x})]}",
    "url": "https://en.wikipedia.org/wiki/Common knowledge (logic)"
  },
  "For k = 3, it is \"second order\" knowledge (": {
    "before": "). Each blue-eyed person knows that there is someone with blue eyes, but each blue eyed person does not know that the other blue-eyed person has this same knowledge.",
    "after": "{\\displaystyle E_{G}E_{G}[\\exists x\\!\\in \\!G(Bl_{x})]=E_{G}^{2}[\\exists x\\!\\in \\!G(Bl_{x})]}",
    "url": "https://en.wikipedia.org/wiki/Common knowledge (logic)"
  },
  " link=/Documents/WorkingDocs/Doc05/EDOC10765.htm]": {
    "before": "[permanent dead link] 3A//assembly.coe.int/Documents/WorkingDocs/Doc03/EDOC9875.htm]",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Council of Europe resolution 1481"
  },
  "x2 = d y2, and": {
    "before": "To derive a sufficient condition for subgame perfect equilibrium, let x = (x1, x2) and y = (y1, y2) be two divisions of the pie with the following property:",
    "after": "y1 = d x1,",
    "url": "https://en.wikipedia.org/wiki/Rubinstein bargaining model"
  },
  "y1 = d x1,": {
    "before": "x2 = d y2, and",
    "after": "i.e.",
    "url": "https://en.wikipedia.org/wiki/Rubinstein bargaining model"
  },
  "x = (x1, x2), and": {
    "before": "i.e.",
    "after": "y = (d x1,",
    "url": "https://en.wikipedia.org/wiki/Rubinstein bargaining model"
  },
  "y = (d x1,": {
    "before": "x = (x1, x2), and",
    "after": "{\\displaystyle {\\frac {1}{d}}x_{2}}",
    "url": "https://en.wikipedia.org/wiki/Rubinstein bargaining model"
  },
  "enable consumers to decide": {
    "before": "",
    "after": "to access content.",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "P2+ = Persons aged 2 or more": {
    "before": "The demographic of a particular show's audience is also measured. This is often notated in an abbreviated form, e.g.:",
    "after": "P12–34 = Persons aged 12 to 34",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "P12–34 = Persons aged 12 to 34": {
    "before": "P2+ = Persons aged 2 or more",
    "after": "P18–49 = Persons aged 18 to 49",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "P18–49 = Persons aged 18 to 49": {
    "before": "P12–34 = Persons aged 12 to 34",
    "after": "A18–34 = Adults aged 18 to 34",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "A18–34 = Adults aged 18 to 34": {
    "before": "P18–49 = Persons aged 18 to 49",
    "after": "Men 18–34",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "Reach = (600,000/1,000,000) x 100": {
    "before": "If out of above 1,000,000 of individuals 600,000 saw at least 1 minute of programme then:",
    "after": "Reach = 60%",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "Hence, gross reach = Week 1 + Week 2 + Week 3 + Week 4": {
    "before": "Week 4: 1,200",
    "after": "Gross reach = 5,700",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "Total time = Total average minutes (universe) x Universe": {
    "before": "The number of individuals within the TG who are exposed to the medium or vehicle over a certain period of time",
    "after": "Total time/reach = Avg minutes viewers",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "Total time/reach = Avg minutes viewers": {
    "before": "Total time = Total average minutes (universe) x Universe",
    "after": "Net reach",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "TVR = Reach x Time spent": {
    "before": "What is a TVR (television rating point):",
    "after": "TVR = (minutes viewed/minutes available) + (minutes viewed / minutes available) /N X100",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "TVR = (minutes viewed/minutes available) + (minutes viewed / minutes available) /N X100": {
    "before": "TVR = Reach x Time spent",
    "after": "N = Number of individuals",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "N = Number of individuals": {
    "before": "TVR = (minutes viewed/minutes available) + (minutes viewed / minutes available) /N X100",
    "after": "Gross rating points (GRPs)",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "CPRP = 2,491 (i.e., Total amt/Total GRPs)": {
    "before": "277",
    "after": "Terminology[edit]",
    "url": "https://en.wikipedia.org/wiki/Audience measurement"
  },
  "{\\textstyle 5\\%={\\frac {40+10}{500+500}}}": {
    "before": "As a result, the company might select a segmented strategy as a result of the A/B test, sending variant B to men and variant A to women in the future. In this example, a segmented strategy would yield an increase in expected response rates from",
    "after": "to",
    "url": "https://en.wikipedia.org/wiki/A/B testing"
  },
  "{\\textstyle 6.5\\%={\\frac {40+25}{500+500}}}": {
    "before": "to",
    "after": "– constituting a 30% increase.",
    "url": "https://en.wikipedia.org/wiki/A/B testing"
  },
  "{\\displaystyle \\mathbf {E} (X_{n+1}\\mid X_{1},\\ldots ,X_{n})=X_{n}.}": {
    "before": "{\\displaystyle \\mathbf {E} (\\vert X_{n}\\vert )<\\infty }",
    "after": "That is, the conditional expected value of the next observation, given all the past observations, is equal to the most recent observation.",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "{\\displaystyle \\mathbf {E} (Y_{n+1}\\mid X_{1},\\ldots ,X_{n})=Y_{n}.}": {
    "before": "{\\displaystyle \\mathbf {E} (\\vert Y_{n}\\vert )<\\infty }",
    "after": "Similarly, a continuous-time martingale with respect to the stochastic process X t is a stochastic process Y t such that for all t",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "{\\displaystyle \\mathbf {E} (Y_{t}\\mid \\{X_{\\tau },\\tau \\leq s\\})=Y_{s}\\quad \\forall s\\leq t.}": {
    "before": "{\\displaystyle \\mathbf {E} (\\vert Y_{t}\\vert )<\\infty }",
    "after": "This expresses the property that the conditional expectation of an observation at time t , given all the observations up to time {\\displaystyle s} , is equal to the observation at time s (of course, provided that s ≤ t ). Note that the second property implies that {\\displaystyle Y_{n}} is measurable with respect to {\\displaystyle X_{1}\\dots X_{n}} .",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "{\\displaystyle \\mathbf {E} _{\\mathbb {P} }\\left([Y_{t}-Y_{s}]\\chi _{F}\\right)=0,} where χ F denotes the indicator function of the event F . In Grimmett and Stirzaker's Probability and Random Processes , this last condition is denoted as {\\displaystyle Y_{s}=\\mathbf {E} _{\\mathbb {P} }(Y_{t}\\mid \\Sigma _{s}),} which is a general form of conditional expectation . ": {
    "before": "{\\displaystyle \\mathbf {E} _{\\mathbb {P} }(\\lVert Y_{t}\\rVert _{S})<+\\infty ;} for all s and t with s < t and all F ∈ Σ s ,",
    "after": "It is important to note that the property of being a martingale involves both the filtration and the probability measure (with respect to which the expectations are taken). It is possible that Y could be a martingale with respect to one measure but not another one; the Girsanov theorem offers a way to find a measure with respect to which an Itō process is a martingale.",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "{\\displaystyle Y_{s}=\\mathbf {E} _{\\mathbb {P} }(Y_{t}\\mid \\Sigma _{s}),}": {
    "before": "Probability and Random Processes, this last condition is denoted as",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "{\\displaystyle X_{n+1}=X_{n}\\pm 1} with \"+\" in case of \"heads\" and \"−\" in case of \"tails\". Let": {
    "before": "An unbiased random walk (in any number of dimensions) is an example of a martingale. A gambler's fortune (capital) is a martingale if all the betting games which the gambler plays are fair. To be more specific: suppose X n is a gambler's fortune after n tosses of a fair coin , where the gambler wins $1 if the coin comes up heads and loses $1 if it comes up tails. The gambler's conditional expected fortune after the next trial, given the history, is equal to their present fortune. This sequence is thus a martingale. Let Y n = X n 2 − n where X n is the gambler's fortune from the preceding example. Then the sequence { Y n : n = 1, 2, 3, ... } is a martingale. This can be used to show that the gambler's total gain or loss varies roughly between plus or minus the square root of the number of steps. ( de Moivre 's martingale) Now suppose the coin is unfair, i.e., biased, with probability p of coming up heads and probability q = 1 − p of tails. Let",
    "after": "{\\displaystyle Y_{n}=(q/p)^{X_{n}}.}",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "{\\displaystyle X_{n+1}=X_{n}\\pm 1}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "{\\displaystyle Y_{n}=(q/p)^{X_{n}}.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "Then { Y n : n = 1, 2, 3, ... } is a martingale with respect to { X n : n = 1, 2, 3, ... }. To show this {\\displaystyle {\\begin{aligned}E[Y_{n+1}\\mid X_{1},\\dots ,X_{n}]&=p(q/p)^{X_{n}+1}+q(q/p)^{X_{n}-1}\\\\[6pt]&=p(q/p)(q/p)^{X_{n}}+q(p/q)(q/p)^{X_{n}}\\\\[6pt]&=q(q/p)^{X_{n}}+p(q/p)^{X_{n}}=(q/p)^{X_{n}}=Y_{n}.\\end{aligned}}}": {
    "before": "{\\displaystyle X_{n+1}=X_{n}\\pm 1} with \"+\" in case of \"heads\" and \"−\" in case of \"tails\". Let {\\displaystyle Y_{n}=(q/p)^{X_{n}}.}",
    "after": "Pólya's urn contains a number of different-coloured marbles; at each iteration a marble is randomly selected from the urn and replaced with several more of that same colour. For any given colour, the fraction of marbles in the urn with that colour is a martingale. For example, if currently 95% of the marbles are red then, though the next iteration is more likely to add red marbles than another color, this bias is exactly balanced out by the fact that adding more red marbles alters the fraction much less significantly than adding the same number of non-red marbles would. ( Likelihood-ratio testing in statistics ) A random variable X is thought to be distributed according either to probability density f or to a different probability density g . A random sample X 1 , ..., X n is taken. Let Y n be the \"likelihood ratio\"",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "{\\displaystyle {\\begin{aligned}E[Y_{n+1}\\mid X_{1},\\dots ,X_{n}]&=p(q/p)^{X_{n}+1}+q(q/p)^{X_{n}-1}\\\\[6pt]&=p(q/p)(q/p)^{X_{n}}+q(p/q)(q/p)^{X_{n}}\\\\[6pt]&=q(q/p)^{X_{n}}+p(q/p)^{X_{n}}=(q/p)^{X_{n}}=Y_{n}.\\end{aligned}}}": {
    "before": "n= 1, 2, 3, ... }. To show this",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "{\\displaystyle Y_{n}=\\prod _{i=1}^{n}{\\frac {g(X_{i})}{f(X_{i})}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "If X is actually distributed according to the density f rather than according to g , then { Y n : n = 1, 2, 3, ... } is a martingale with respect to { X n : n = 1, 2, 3, ... }.": {
    "before": "{\\displaystyle Y_{n}=\\prod _{i=1}^{n}{\\frac {g(X_{i})}{f(X_{i})}}}",
    "after": "Software-created martingale series.",
    "url": "https://en.wikipedia.org/wiki/Martingale (probability theory)"
  },
  "{\\displaystyle R(1)={\\frac {1}{2\\pi }}\\int _{-\\pi }^{\\pi }S(\\omega )e^{i\\,\\omega }d\\omega .}": {
    "before": "The autocorrelation of lag 1 can be expressed using the inverse Fourier transform of the power spectrum {\\displaystyle S(\\omega )} :",
    "after": "If we model the power spectrum as a single frequency {\\displaystyle S(\\omega )\\ {\\stackrel {\\mathrm {def} }{=}}\\ \\delta (\\omega -\\omega _{0})} , this becomes:",
    "url": "https://en.wikipedia.org/wiki/Autocorrelation technique"
  },
  "{\\displaystyle R(1)={\\frac {1}{2\\pi }}\\int _{-\\pi }^{\\pi }\\delta (\\omega -\\omega _{0})e^{i\\,\\omega }d\\omega } {\\displaystyle R(1)={\\frac {1}{2\\pi }}e^{i\\,\\omega _{0}}}": {
    "before": "If we model the power spectrum as a single frequency {\\displaystyle S(\\omega )\\ {\\stackrel {\\mathrm {def} }{=}}\\ \\delta (\\omega -\\omega _{0})} , this becomes:",
    "after": "where it is apparent that the phase of {\\displaystyle R(1)} equals the signal frequency.",
    "url": "https://en.wikipedia.org/wiki/Autocorrelation technique"
  },
  "{\\displaystyle \\omega =\\angle R_{N}(1)=\\tan ^{-1}{\\frac {{\\text{im}}\\{R_{N}(1)\\}}{{\\text{re}}\\{R_{N}(1)\\}}}.}": {
    "before": "The mean frequency is calculated based on the autocorrelation with lag one, evaluated over a signal consisting of N samples:",
    "after": "The spectral variance is calculated as follows:",
    "url": "https://en.wikipedia.org/wiki/Autocorrelation technique"
  },
  "{\\displaystyle {\\text{var}}\\{\\omega \\}={\\frac {2}{N}}\\left(1-{\\frac {|R_{N}(1)|}{R_{N}(0)}}\\right).}": {
    "before": "{\\displaystyle \\omega =\\angle R_{N}(1)=\\tan ^{-1}{\\frac {{\\text{im}}\\{R_{N}(1)\\}}{{\\text{re}}\\{R_{N}(1)\\}}}.} The spectral variance is calculated as follows:",
    "after": "Applications [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autocorrelation technique"
  },
  "{\\displaystyle x(t)=As(t)={\\begin{bmatrix}A^{\\mathfrak {s}}&A^{\\mathfrak {n}}\\end{bmatrix}}{\\begin{bmatrix}s^{\\mathfrak {s}}(t)\\\\s^{\\mathfrak {n}}(t)\\\\\\end{bmatrix}},}": {
    "before": "According to the SSA model,  the observed multivariate time series {\\displaystyle x(t)} is assumed to be generated as a linear superposition of stationary sources {\\displaystyle s^{\\mathfrak {s}}(t)} and non-stationary sources {\\displaystyle s^{\\mathfrak {n}}(t)} ,",
    "after": "where {\\displaystyle A} is an unknown but time-constant mixing matrix; {\\displaystyle A^{\\mathfrak {s}}} and {\\displaystyle A^{\\mathfrak {n}}} are the basis of the stationary and non-stationary subspace respectively.",
    "url": "https://en.wikipedia.org/wiki/Stationary subspace analysis"
  },
  "{\\displaystyle d={\\sum _{t=2}^{T}(e_{t}-e_{t-1})^{2} \\over {\\sum _{t=1}^{T}e_{t}^{2}}},}": {
    "before": "If e t is the residual given by {\\displaystyle e_{t}=\\rho e_{t-1}+\\nu _{t},} the Durbin-Watson test statistic is",
    "after": "where T is the number of observations. For large T , d is approximately equal to 2(1 − {\\displaystyle {\\hat {\\rho }}} ), where {\\displaystyle {\\hat {\\rho }}} is the sample autocorrelation of the residuals,  d = 2 therefore indicates no autocorrelation. The value of d always lies between 0 and 4. If the Durbin–Watson statistic is substantially less than 2, there is evidence of positive serial correlation. As a rough rule of thumb, if Durbin–Watson is less than 1.0, there may be cause for alarm. Small values of d indicate successive error terms are positively correlated. If d > 2, successive error terms are negatively correlated. In regressions, this can imply an underestimation of the level of statistical significance .",
    "url": "https://en.wikipedia.org/wiki/Durbin–Watson statistic"
  },
  "{\\displaystyle {\\frac {\\sum _{i=1}^{n-k}\\nu _{i}\\xi _{i}^{2}}{\\sum _{i=1}^{n-k}\\xi _{i}^{2}}},}": {
    "before": "If the design matrix {\\displaystyle \\mathbf {X} } of the regression is known, exact critical values for the distribution of {\\displaystyle d} under the null hypothesis of no serial correlation can be calculated. Under the null hypothesis {\\displaystyle d} is distributed as",
    "after": "where n are the number of observations and k the number of regression variables; the {\\displaystyle \\xi _{i}} are independent standard normal random variables; and the {\\displaystyle \\nu _{i}} are the nonzero eigenvalues of {\\displaystyle (\\mathbf {I} -\\mathbf {X} (\\mathbf {X} ^{T}\\mathbf {X} )^{-1}\\mathbf {X} ^{T})\\mathbf {A} ,} where {\\displaystyle \\mathbf {A} } is the matrix that transforms the residuals into the {\\displaystyle d} statistic, i.e. {\\displaystyle d=\\mathbf {e} ^{T}\\mathbf {A} \\mathbf {e} .} .  A number of computational algorithms for finding percentiles of this distribution are available. ",
    "url": "https://en.wikipedia.org/wiki/Durbin–Watson statistic"
  },
  "{\\displaystyle h=\\left(1-{\\frac {1}{2}}d\\right){\\sqrt {\\frac {T}{1-T\\cdot {\\widehat {\\operatorname {Var} }}({\\widehat {\\beta }}_{1}\\,)}}},}": {
    "before": "The Durbin–Watson statistic is biased for autoregressive moving average models , so that autocorrelation is underestimated. But for large samples one can easily compute the unbiased normally distributed h-statistic:",
    "after": "using the Durbin–Watson statistic d and the estimated variance",
    "url": "https://en.wikipedia.org/wiki/Durbin–Watson statistic"
  },
  "{\\displaystyle X_{t}=\\sum _{k=1}^{M}\\alpha _{k}X_{t-k}+\\epsilon _{k}}": {
    "before": "Therefore, the maximum entropy method is equivalent to least-squares fitting the available time series data to an autoregressive model",
    "after": "where the {\\displaystyle \\epsilon _{k}} are independent and identically distributed as {\\displaystyle N(0,\\sigma ^{2})} . The unknowns coefficients {\\displaystyle \\alpha _{k}} are found using least-square method. Once the autoregressive coefficients have been determined, the spectrum of the time series data is estimated by evaluating the power spectral density function of the fitted autoregressive model",
    "url": "https://en.wikipedia.org/wiki/Maximum entropy spectral estimation"
  },
  "{\\displaystyle {\\hat {S}}(\\omega )={\\frac {\\sigma ^{2}T_{s}}{\\left|1+\\sum _{k=1}^{M}\\alpha _{k}e^{-ik\\omega T_{s}}\\right|^{2}}},}": {
    "before": "where the {\\displaystyle \\epsilon _{k}} are independent and identically distributed as {\\displaystyle N(0,\\sigma ^{2})} . The unknowns coefficients {\\displaystyle \\alpha _{k}} are found using least-square method. Once the autoregressive coefficients have been determined, the spectrum of the time series data is estimated by evaluating the power spectral density function of the fitted autoregressive model",
    "after": "where {\\displaystyle T_{s}} is the sampling period and {\\displaystyle i={\\sqrt {-1}}} is the imaginary unit.",
    "url": "https://en.wikipedia.org/wiki/Maximum entropy spectral estimation"
  },
  "{\\displaystyle P_{j}=\\left({\\frac {1}{2}}\\right)^{2j}{\\frac {\\left(2j\\right)!}{\\left(j!\\right)^{2}}}.}": {
    "before": "Assuming that all members of the body vote independently (the votes are uncorrelated) and that the probability of each vote 'Yes' is equal to p = 1/2 one can estimate likelihood of such an event using the Bernoulli trial . The probability to obtain j votes 'Yes' out of 2 j votes reads",
    "after": "For large N we may use the Stirling's approximation for the factorial j ! and obtain the probability {\\displaystyle \\psi } that the vote of a given voter is decisive",
    "url": "https://en.wikipedia.org/wiki/Penrose square root law"
  },
  "{\\displaystyle \\psi =P_{j}\\sim 2^{-2j}{\\frac {(2j/e)^{2j}{\\sqrt {4\\pi j}}}{[(j/e)^{j}{\\sqrt {2\\pi j}}]^{2}}}\\ =\\ {\\frac {1}{\\sqrt {\\pi j}}}\\sim {\\sqrt {\\frac {2}{\\pi }}}{\\frac {1}{\\sqrt {N}}}.}": {
    "before": "For large N we may use the Stirling's approximation for the factorial j ! and obtain the probability {\\displaystyle \\psi } that the vote of a given voter is decisive",
    "after": "The same approximation is obtained for an even number N .",
    "url": "https://en.wikipedia.org/wiki/Penrose square root law"
  },
  "\"net\" forced saving ratio = (shortage effect + demand spillover effect)/savings rate": {
    "before": "We can define forced saving ratio which measures how much of household savings is composed by forced savings.",
    "after": "\"gross\" forced saving ratio = shortage effect/savings rate",
    "url": "https://en.wikipedia.org/wiki/Forced saving"
  },
  "\"gross\" forced saving ratio = shortage effect/savings rate": {
    "before": "\"net\" forced saving ratio = (shortage effect + demand spillover effect)/savings rate",
    "after": "Net forced savings ratio considers that informal economy role under shortage conditions.",
    "url": "https://en.wikipedia.org/wiki/Forced saving"
  },
  "{\\displaystyle \\nu (i)=\\sup _{\\tau >0}{\\frac {\\left\\langle \\sum _{t=0}^{\\tau -1}\\beta ^{t}R[Z(t)]\\right\\rangle _{Z(0)=i}}{\\left\\langle \\sum _{t=0}^{\\tau -1}\\beta ^{t}\\right\\rangle _{Z(0)=i}}}}": {
    "before": "Dynamic allocation index [ edit ]The classical definition by Gittins et al. is:",
    "after": "where {\\displaystyle Z(\\cdot )} is a stochastic process, {\\displaystyle R(i)} is the utility (also called reward) associated to the discrete state {\\displaystyle i} , {\\displaystyle \\beta <1} is the probability that the stochastic process does not terminate, and {\\displaystyle \\langle \\cdot \\rangle _{c}} is the conditional expectation operator given c :",
    "url": "https://en.wikipedia.org/wiki/Gittins index"
  },
  "{\\displaystyle \\langle X\\rangle _{c}\\doteq \\sum _{x\\in \\chi }xP\\{X=x|c\\}}": {
    "before": "where {\\displaystyle Z(\\cdot )} is a stochastic process, {\\displaystyle R(i)} is the utility (also called reward) associated to the discrete state {\\displaystyle i} , {\\displaystyle \\beta <1} is the probability that the stochastic process does not terminate, and {\\displaystyle \\langle \\cdot \\rangle _{c}} is the conditional expectation operator given c :",
    "after": "with {\\displaystyle \\chi } being the domain of X .",
    "url": "https://en.wikipedia.org/wiki/Gittins index"
  },
  "{\\displaystyle w(i)=\\inf\\{k:v(i,k)=k\\}}": {
    "before": "The dynamic programming formulation in terms of retirement process, given by Whittle, is:",
    "after": "where {\\displaystyle v(i,k)} is the value function",
    "url": "https://en.wikipedia.org/wiki/Gittins index"
  },
  "{\\displaystyle v(i,k)=\\sup _{\\tau >0}\\left\\langle \\sum _{t=0}^{\\tau -1}\\beta ^{t}R[Z(t)]+\\beta ^{t}k\\right\\rangle _{Z(0)=i}}": {
    "before": "where {\\displaystyle v(i,k)} is the value function",
    "after": "with the same notation as above. It holds that",
    "url": "https://en.wikipedia.org/wiki/Gittins index"
  },
  "{\\displaystyle \\nu (i)=(1-\\beta )w(i).}": {
    "before": "{\\displaystyle v(i,k)=\\sup _{\\tau >0}\\left\\langle \\sum _{t=0}^{\\tau -1}\\beta ^{t}R[Z(t)]+\\beta ^{t}k\\right\\rangle _{Z(0)=i}} with the same notation as above. It holds that",
    "after": "Restart-in-state formulation [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Gittins index"
  },
  "{\\displaystyle h(i)=\\sup _{\\pi }\\left\\langle \\sum _{t=0}^{\\tau -1}\\beta ^{t}R[Z^{\\pi }(t)]\\right\\rangle _{Z(0)=i}}": {
    "before": "The Gittins Index of that state {\\displaystyle i} is the highest total reward which can be achieved on {\\displaystyle M_{i}} if one can always choose to continue or restart from that state {\\displaystyle i} .",
    "after": "where {\\displaystyle \\pi } indicates a policy over {\\displaystyle M_{i}} . It holds that",
    "url": "https://en.wikipedia.org/wiki/Gittins index"
  },
  "{\\displaystyle h(i)=w(i)} .": {
    "before": "where {\\displaystyle \\pi } indicates a policy over {\\displaystyle M_{i}} . It holds that",
    "after": "Generalized index [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Gittins index"
  },
  "{\\displaystyle \\alpha (i)=\\sup _{\\tau >0}{\\frac {R^{\\tau }(i)}{Q^{\\tau }(i)}}}": {
    "before": "If the probability of survival {\\displaystyle \\beta (i)} depends on the state {\\displaystyle i} , a generalization introduced by Sonin (2008) defines the Gittins index {\\displaystyle \\alpha (i)} as the maximum discounted total reward per chance of termination.",
    "after": "where {\\displaystyle R^{\\tau }(i)=\\left\\langle \\sum _{t=0}^{\\tau -1}R[Z(t)]\\right\\rangle _{Z(0)=i}} {\\displaystyle Q^{\\tau }(i)=\\left\\langle 1-\\prod _{t=0}^{\\tau -1}\\beta [Z(t)]\\right\\rangle _{Z(0)=i}}",
    "url": "https://en.wikipedia.org/wiki/Gittins index"
  },
  "{\\displaystyle R^{\\tau }(i)=\\left\\langle \\sum _{t=0}^{\\tau -1}R[Z(t)]\\right\\rangle _{Z(0)=i}} {\\displaystyle Q^{\\tau }(i)=\\left\\langle 1-\\prod _{t=0}^{\\tau -1}\\beta [Z(t)]\\right\\rangle _{Z(0)=i}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Gittins index"
  },
  "{\\displaystyle \\alpha (i)=h(i)=w(i)} {\\displaystyle \\alpha (i)\\neq k\\nu (i),\\forall k}": {
    "before": "If {\\displaystyle \\beta ^{t}} is replaced by {\\displaystyle \\prod _{j=0}^{t-1}\\beta [Z(j)]} in the definitions of {\\displaystyle \\nu (i)} , {\\displaystyle w(i)} and {\\displaystyle h(i)} , then it holds that",
    "after": "this observation leads Sonin to conclude that {\\displaystyle \\alpha (i)} and not {\\displaystyle \\nu (i)} is the \"true meaning\" of the Gittins index.",
    "url": "https://en.wikipedia.org/wiki/Gittins index"
  },
  "Initialize X1 = X2 = ... = Xn = empty.": {
    "before": "The maximum welfare can be approximated by the following polynomial-time greedy algorithm:",
    "after": "For every item j (in an arbitrary order):",
    "url": "https://en.wikipedia.org/wiki/Utilitarian item allocation"
  },
  "Formula: Wicksellian Differential = Natural Rate of Interest - Money Rate of Interest": {
    "before": "The Wicksellian Differential is derived from Knut Wicksell's theory of interest and is an approximation of the extent of disequilibrium in an economy.",
    "after": "Wicksell argued in Interest and Prices that the equilibrium of a credit economy could be ascertained by comparing the money rate of interest to the natural rate of interest. In modern terminology this equates to comparing the cost of capital with the return on capital. In economies where the natural rate is higher than the money rate, credit growth will drive a positive disequilibrium in an economy. When the natural rate of interest is lower than the money rate, the demand for credit dries up leading to a negative disequilibrium and capital destruction.",
    "url": "https://en.wikipedia.org/wiki/Wicksellian Differential"
  },
  "{\\displaystyle \\sup _{\\theta \\in \\Theta }R(\\theta ,\\delta ^{M})=\\inf _{\\delta }\\sup _{\\theta \\in \\Theta }R(\\theta ,\\delta ).\\,}": {
    "before": "Definition : An estimator {\\displaystyle \\delta ^{M}:{\\mathcal {X}}\\rightarrow \\Theta \\,\\!} is called minimax with respect to a risk function {\\displaystyle R(\\theta ,\\delta )\\,\\!} if it achieves the smallest maximum risk among all estimators, meaning it satisfies",
    "after": "Least favorable distribution [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Minimax estimator"
  },
  "{\\displaystyle r_{\\pi }=\\int R(\\theta ,\\delta _{\\pi })\\,d\\pi (\\theta )\\,}": {
    "before": "Logically, an estimator is minimax when it is the best in the worst case. Continuing this logic, a minimax estimator should be a Bayes estimator with respect to a least favorable prior distribution of {\\displaystyle \\theta \\,\\!} . To demonstrate this notion denote the average risk of the Bayes estimator {\\displaystyle \\delta _{\\pi }\\,\\!} with respect to a prior distribution {\\displaystyle \\pi \\,\\!} as",
    "after": "Definition: A prior distribution {\\displaystyle \\pi \\,\\!} is called least favorable if for every other distribution {\\displaystyle \\pi '\\,\\!} the average risk satisfies {\\displaystyle r_{\\pi }\\geq r_{\\pi '}\\,} .",
    "url": "https://en.wikipedia.org/wiki/Minimax estimator"
  },
  "{\\displaystyle \\delta ^{M}={\\frac {x+0.5{\\sqrt {n}}}{n+{\\sqrt {n}}}},\\,}": {
    "before": "Example 1: Unfair coin   : Consider the problem of estimating the \"success\" rate of a binomial variable, {\\displaystyle x\\sim B(n,\\theta )\\,\\!} . This may be viewed as estimating the rate at which an unfair coin falls on \"heads\" or \"tails\". In this case the Bayes estimator with respect to a Beta -distributed prior, {\\displaystyle \\theta \\sim {\\text{Beta}}({\\sqrt {n}}/2,{\\sqrt {n}}/2)\\,} is",
    "after": "with constant Bayes risk",
    "url": "https://en.wikipedia.org/wiki/Minimax estimator"
  },
  "{\\displaystyle r={\\frac {1}{4(1+{\\sqrt {n}})^{2}}}\\,}": {
    "before": "{\\displaystyle \\delta ^{M}={\\frac {x+0.5{\\sqrt {n}}}{n+{\\sqrt {n}}}},\\,} with constant Bayes risk",
    "after": "and, according to the Corollary, is minimax.",
    "url": "https://en.wikipedia.org/wiki/Minimax estimator"
  },
  "{\\displaystyle R(\\theta ,\\delta _{\\text{ML}})=E{\\|\\delta _{ML}-\\theta \\|^{2}}=\\sum _{i=1}^{p}E(x_{i}-\\theta _{i})^{2}=p\\sigma ^{2}.\\,}": {
    "before": "Example 2: Consider the problem of estimating the mean of {\\displaystyle p\\,\\!} dimensional Gaussian random vector, {\\displaystyle x\\sim N(\\theta ,I_{p}\\sigma ^{2})\\,\\!} . The maximum likelihood (ML) estimator for {\\displaystyle \\theta \\,\\!} in this case is simply {\\displaystyle \\delta _{\\text{ML}}=x\\,\\!} , and its risk is",
    "after": "MSE of maximum likelihood estimator versus James–Stein estimator",
    "url": "https://en.wikipedia.org/wiki/Minimax estimator"
  },
  "{\\displaystyle \\delta ^{M}(x)={\\frac {MJ_{n+1}(M\\|x\\|)}{\\|x\\|J_{n}(M\\|x\\|)}}x,\\,}": {
    "before": "Example 3: Bounded normal mean: When estimating the mean of a normal vector {\\displaystyle x\\sim N(\\theta ,I_{n}\\sigma ^{2})\\,\\!} , where it is known that {\\displaystyle \\|\\theta \\|^{2}\\leq M\\,\\!} . The Bayes estimator with respect to a prior which is uniformly distributed on the edge of the bounding sphere is known to be minimax whenever {\\displaystyle M\\leq n\\,\\!} . The analytical expression for this estimator is",
    "after": "where {\\displaystyle J_{n}(t)\\,\\!} , is the modified Bessel function of the first kind of order n .",
    "url": "https://en.wikipedia.org/wiki/Minimax estimator"
  },
  "{\\displaystyle \\rho (x_{1},x_{2})=\\sup _{y\\in {\\mathfrak {Y}}}\\left|H(x_{1},y)-H(x_{2},y)\\right|.}": {
    "before": "The Helly metric {\\displaystyle \\rho (x_{1},x_{2})} is defined as",
    "after": "The metric so defined is symmetric, reflexive, and satisfies the triangle inequality .",
    "url": "https://en.wikipedia.org/wiki/Helly metric"
  },
  "{\\displaystyle \\rho (y_{1},y_{2})=\\sup _{x\\in {\\mathfrak {X}}}\\left|H(x,y_{1})-H(x,y_{2})\\right|.}": {
    "before": "The metric on the space of player II's strategies is analogous:",
    "after": "Note that {\\displaystyle \\Gamma } thus defines two Helly metrics: one for each player's strategy space.",
    "url": "https://en.wikipedia.org/wiki/Helly metric"
  },
  "{\\displaystyle {\\begin{aligned}{\\textit {Y}}_{t}&={T}_{t}+{S}_{t}+{I}_{t}\\end{aligned}}}": {
    "before": "The default method for seasonal adjustment is based on the X-11 algorithm. It is assumed that the observations in a time series, {\\displaystyle Y_{t}} , can be decomposed additively,",
    "after": "or multiplicatively,",
    "url": "https://en.wikipedia.org/wiki/X-13ARIMA-SEATS"
  },
  "{\\displaystyle {\\begin{aligned}{\\textit {Y}}_{t}&={T}_{t}\\times {S}_{t}\\times {I}_{t}.\\end{aligned}}}": {
    "before": "{\\displaystyle {\\begin{aligned}{\\textit {Y}}_{t}&={T}_{t}+{S}_{t}+{I}_{t}\\end{aligned}}} or multiplicatively,",
    "after": "In this decomposition, {\\displaystyle T_{t}} is the trend (or the \"trend cycle\" because it also includes cyclical movements such as business cycles) component, {\\displaystyle S_{t}} is the seasonal component, and {\\displaystyle I_{t}} is the irregular (or random) component. The goal is to estimate each of the three components and then remove the seasonal component from the time series, producing a seasonally adjusted time series. ",
    "url": "https://en.wikipedia.org/wiki/X-13ARIMA-SEATS"
  },
  "{\\displaystyle r_{n}(q,p)=\\mathbb {E} (D(p||q(X))).}": {
    "before": "where {\\displaystyle {\\mathcal {P}}} is the set of all possible probability distribution, and",
    "after": "where {\\displaystyle D(p||q)} is the Kullback–Leibler divergence between {\\displaystyle p} and {\\displaystyle q} .",
    "url": "https://en.wikipedia.org/wiki/Competitive regret"
  },
  "{\\displaystyle r_{n}(P)=\\min _{q}\\max _{p\\in P}r_{n}(q,p).}": {
    "before": "The oracle is restricted to have access to partial information of the true distribution {\\displaystyle p} by knowing the location of {\\displaystyle p} in the parameter space up to a partition.  Given a partition {\\displaystyle \\mathbb {P} } of the parameter space, and suppose the oracle knows the subset {\\displaystyle P} where the true {\\displaystyle p\\in P} . The oracle will have regret as",
    "after": "The competitive regret to the oracle will be",
    "url": "https://en.wikipedia.org/wiki/Competitive regret"
  },
  "{\\displaystyle r_{n}^{\\mathbb {P} }(q,{\\mathcal {P}})=\\max _{P\\in \\mathbb {P} }(r_{n}(q,P)-r_{n}(P)).}": {
    "before": "{\\displaystyle r_{n}(P)=\\min _{q}\\max _{p\\in P}r_{n}(q,p).} The competitive regret to the oracle will be",
    "after": "Oracle with partial information [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Competitive regret"
  },
  "{\\displaystyle r_{n}^{nat}(p)=\\min _{q\\in {\\mathcal {Q}}_{nat}}r_{n}(q,p),}": {
    "before": "The oracle knows exactly {\\displaystyle p} , but can only choose the estimator among natural estimators. A natural estimator assigns equal probability to the symbols which appear the same number of time in the sample.  The regret of the oracle is",
    "after": "and the competitive regret is",
    "url": "https://en.wikipedia.org/wiki/Competitive regret"
  },
  "{\\displaystyle P=1-x-y}": {
    "before": "Let there be two firms, X and Y, with outputs x and y. The market price P is given by the linear demand curve",
    "after": "so that the total revenue of firm X is then",
    "url": "https://en.wikipedia.org/wiki/Conjectural variation"
  },
  "{\\displaystyle xP=x(1-x-y)=x-x^{2}-xy}": {
    "before": "so that the total revenue of firm X is then",
    "after": "For simplicity, let us follow Cournot 's 1838 model and assume that there are no production costs, so that profits equal revenue {\\displaystyle \\Pi =x-x^{2}-xy} .",
    "url": "https://en.wikipedia.org/wiki/Conjectural variation"
  },
  "{\\displaystyle {\\frac {d\\Pi }{dx}}=(1-2x-y)-x{\\frac {dy}{dx}}=0}": {
    "before": "With conjectural variations, the first order condition for the firm becomes:",
    "after": "where {\\displaystyle {\\frac {dy}{dx}}=\\phi } is the firms conjecture about how the other firm will respond, the conjectural variation or CV term. This first order optimization condition defines the reaction function for the firm, which states, for a given CV, the optimal choice of output given the other firm's output.",
    "url": "https://en.wikipedia.org/wiki/Conjectural variation"
  },
  "{\\displaystyle x=R(y,\\phi )={\\frac {1-y}{2+\\phi }}}": {
    "before": "where {\\displaystyle {\\frac {dy}{dx}}=\\phi } is the firms conjecture about how the other firm will respond, the conjectural variation or CV term. This first order optimization condition defines the reaction function for the firm, which states, for a given CV, the optimal choice of output given the other firm's output.",
    "after": "Note that the Cournot-Nash Conjecture is {\\displaystyle \\phi =0} , in which case we have the standard Cournot Reaction function . The CV term serves to shift the reaction function and most importantly later its slope. To solve for a symmetric equilibrium, where both firms have the same CV, we simply note that the reaction function will pass through the x=y line so that:",
    "url": "https://en.wikipedia.org/wiki/Conjectural variation"
  },
  "{\\displaystyle \\Pi =(x-x^{2}-xy)-{\\frac {a.x^{2}}{2}}}": {
    "before": "Take the previous example. Now let the cost of production take the form: cost = a.x 2 . In this case, the profit function (revenue minus cost) becomes (for firm X and analogously for firm Y):",
    "after": "The first-order condition then becomes:",
    "url": "https://en.wikipedia.org/wiki/Conjectural variation"
  },
  "{\\displaystyle {\\frac {d\\Pi }{dx}}=(1-2x-y)-x{\\frac {dy}{dx}}-ax=0}": {
    "before": "The first-order condition then becomes:",
    "after": "which defines the reaction function for firm X as:",
    "url": "https://en.wikipedia.org/wiki/Conjectural variation"
  },
  "{\\displaystyle x=R(y,\\phi )={\\frac {1-y}{2+a+\\phi }}}": {
    "before": "which defines the reaction function for firm X as:",
    "after": "This has slope (in output space)",
    "url": "https://en.wikipedia.org/wiki/Conjectural variation"
  },
  "{\\displaystyle R_{y}=-{\\frac {1}{2+a+\\phi }}}": {
    "before": "This has slope (in output space)",
    "after": "and analogously for firm Y which (we assume) has the same conjecture. To see what consistency means, consider the simple Cournot conjecture {\\displaystyle \\phi =0} with constant marginal cost a=0 . In this case the slope of the reaction functions is −1/2 which is \"inconsistent\" with the conjecture. The Bresnehan consistency condition is that the conjectured slope {\\displaystyle \\phi } equals the actual slope {\\displaystyle R_{y}} which means that",
    "url": "https://en.wikipedia.org/wiki/Conjectural variation"
  },
  "{\\displaystyle \\phi =-{\\frac {1}{2+a+\\phi }}}": {
    "before": "and analogously for firm Y which (we assume) has the same conjecture. To see what consistency means, consider the simple Cournot conjecture {\\displaystyle \\phi =0} with constant marginal cost a=0 . In this case the slope of the reaction functions is −1/2 which is \"inconsistent\" with the conjecture. The Bresnehan consistency condition is that the conjectured slope {\\displaystyle \\phi } equals the actual slope {\\displaystyle R_{y}} which means that",
    "after": "This is a quadratic equation which gives us the unique consistent conjecture",
    "url": "https://en.wikipedia.org/wiki/Conjectural variation"
  },
  "{\\displaystyle \\phi ^{*}=-(1+{\\frac {a}{2}})+{\\sqrt {\\frac {4a+a^{2}}{4}}}}": {
    "before": "This is a quadratic equation which gives us the unique consistent conjecture",
    "after": "This is the positive root of the quadratic: the negative solution would be a conjecture more negative than −1 which would violate the second order conditions. As we can see from this example, when a=0 (marginal cost is horizontal), the Bertrand conjecture is consistent {\\displaystyle \\phi ^{*}=-1} . As the steepness of marginal cost increases ( a goes up), the consistent conjecture increases. Note that the consistent conjecture will always be less than 0 for any finite a .",
    "url": "https://en.wikipedia.org/wiki/Conjectural variation"
  },
  "{\\displaystyle {\\dot {x_{i}}}=x_{i}\\left(\\left(Ax\\right)_{i}-x^{T}Ax\\right),}": {
    "before": "For the purpose of predicting evolutionary outcomes, the replicator equation is also a frequently utilized tool.   Evolutionarily stable states are often taken as solutions to the replicator equation , here in linear payoff form:",
    "after": "The state {\\displaystyle {\\hat {x}}} is said to be evolutionarily stable if for all {\\displaystyle x\\neq {\\hat {x}}} in some neighborhood of {\\displaystyle {\\hat {x}}} .",
    "url": "https://en.wikipedia.org/wiki/Evolutionarily stable state"
  },
  "Wealth = cash balances + government bonds + housing equity + stocks + other assets - debt": {
    "before": "This is analogous to the definition of the income effect from the income elasticity of demand , or the substitution effect from the price elasticity. The measure of \"wealth\" is mostly taken to be total personal realizable wealth at market prices, liquid or not:",
    "after": "Some economists say that bonds are simply a loan to the government and that they are not considered (on the aggregate) to be part of net wealth. Generally, the wealth change is measured in real terms.",
    "url": "https://en.wikipedia.org/wiki/Wealth elasticity of demand"
  },
  "Income elasticity = Wealth elasticity × rate of investment return.": {
    "before": "A naïve assumption (or first approximation) linking the wealth and income elasticities of demand is:",
    "after": "However, this approach overlooks the fact that people typically treat income and capital differently. (Behavioural economics hypothesises different \"mental accounts\" for income and assets, and points to empirical studies showing that the marginal propensity to consume extra income is one, but is lower for windfall asset increases.)",
    "url": "https://en.wikipedia.org/wiki/Wealth elasticity of demand"
  },
  "{\\displaystyle p(x|\\mu ,\\sigma ^{2})={\\frac {1}{\\sqrt {2\\pi \\sigma ^{2}}}}e^{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}}}}": {
    "before": "An example is the normal distribution . Its probability density function is",
    "after": "and the associated kernel is",
    "url": "https://en.wikipedia.org/wiki/Kernel (statistics)"
  },
  "{\\displaystyle K(-u)=K(u){\\mbox{ for all values of }}u\\,.}": {
    "before": "{\\displaystyle \\int _{-\\infty }^{+\\infty }K(u)\\,du=1\\,;} Symmetry:",
    "after": "The first requirement ensures that the method of kernel density estimation results in a probability density function . The second requirement ensures that the average of the corresponding distribution is equal to that of the sample used.",
    "url": "https://en.wikipedia.org/wiki/Kernel (statistics)"
  },
  "{\\displaystyle K(u)={\\frac {1}{\\sqrt {2\\pi }}}e^{-{\\frac {1}{2}}u^{2}}}": {
    "before": "Gaussian",
    "after": "{\\displaystyle 1\\,}",
    "url": "https://en.wikipedia.org/wiki/Kernel (statistics)"
  },
  "{\\displaystyle K(u)={\\frac {1}{e^{u}+2+e^{-u}}}}": {
    "before": "Logistic",
    "after": "{\\displaystyle {\\frac {\\pi ^{2}}{3}}}",
    "url": "https://en.wikipedia.org/wiki/Kernel (statistics)"
  },
  "{\\displaystyle K(u)={\\frac {2}{\\pi }}{\\frac {1}{e^{u}+e^{-u}}}}": {
    "before": "Sigmoid function",
    "after": "{\\displaystyle {\\frac {\\pi ^{2}}{4}}}",
    "url": "https://en.wikipedia.org/wiki/Kernel (statistics)"
  },
  "{\\displaystyle K(u)={\\frac {1}{2}}e^{-{\\frac {|u|}{\\sqrt {2}}}}\\cdot \\sin \\left({\\frac {|u|}{\\sqrt {2}}}+{\\frac {\\pi }{4}}\\right)}": {
    "before": "Silverman kernel ",
    "after": "{\\displaystyle 0}",
    "url": "https://en.wikipedia.org/wiki/Kernel (statistics)"
  },
  "{\\displaystyle I_{S}(s):={\\begin{cases}{\\begin{array}{ccc}1&,&s\\in S\\\\0&,&s\\notin S\\end{array}}\\end{cases}}\\ ,\\ s\\in X}": {
    "before": "where I s denotes the Indicator function of S , that is",
    "after": "A solution s ∈ X to this optimization problem is optimal if, and only if, it is a satisficing option (an element of S ). Thus, from a decision theory point of view, the distinction between \"optimizing\" and \"satisficing\" is essentially a stylistic issue (that can nevertheless be very important in certain applications) rather than a substantive issue. What is important to determine is what should be optimized and what should be satisficed. The following quote from Jan Odhnoff's 1965 paper is appropriate: ",
    "url": "https://en.wikipedia.org/wiki/Satisficing"
  },
  "{\\displaystyle \\left.{\\frac {\\partial x_{j}}{\\partial p_{i}}}\\right|_{u=const}>0}": {
    "before": "Goods {\\displaystyle x_{i}} and {\\displaystyle x_{j}} are said to be net substitutes if",
    "after": "That is, goods are net substitutes if they are substitutes for each other under a constant utility function. Net substitutability has the desirable property that, unlike gross substitutability, it is symmetric:",
    "url": "https://en.wikipedia.org/wiki/Substitute good"
  },
  "{\\displaystyle \\left.{\\frac {\\partial x_{j}}{\\partial p_{i}}}\\right|_{u=const}=\\left.{\\frac {\\partial x_{i}}{\\partial p_{j}}}\\right|_{u=const}}": {
    "before": "That is, goods are net substitutes if they are substitutes for each other under a constant utility function. Net substitutability has the desirable property that, unlike gross substitutability, it is symmetric:",
    "after": "That is, if good {\\displaystyle x_{j}} is a net substitute for good {\\displaystyle x_{i}} , then good {\\displaystyle x_{i}} is also a net substitute for good {\\displaystyle x_{j}} . The symmetry of net substitution is both intuitively appealing and theoretically useful. ",
    "url": "https://en.wikipedia.org/wiki/Substitute good"
  },
  "Ex,y = Percentage Change in Quantity Demanded for Good X / Percentage Change in Price of Good Y": {
    "before": "Cross-Price Elasticity of Demand (Ex,y) is calculated with the following formula:",
    "after": "The cross-price elasticity may be positive or negative, depending on whether the goods are complements or substitutes. A substitute good is a good with a positive cross elasticity of demand. This means that, if good",
    "url": "https://en.wikipedia.org/wiki/Substitute good"
  },
  "{\\displaystyle {\\mu _{1}-d_{1} \\over \\mu _{2}-d_{2}}={Best_{1}(F)-d_{1} \\over Best_{2}(F)-d_{2}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Kalai–Smorodinsky bargaining solution"
  },
  "{\\displaystyle \\max {30x+20y \\over 30}={30y+70z \\over 70}}": {
    "before": "The KS bargaining solution equalizes the relative gains - the gain of each player relative to its maximum possible gain - and maximizes this equal value:",
    "after": "Here, the maximum is attained when {\\displaystyle x=0} and {\\displaystyle y=21/26} and {\\displaystyle z=5/26} . The utility-gain of Alice is $16.1 and of George $37.7.",
    "url": "https://en.wikipedia.org/wiki/Kalai–Smorodinsky bargaining solution"
  },
  "{\\displaystyle Best_{1}(F)=Best_{1}(F')}": {
    "before": "The monotonicity requirement says that, if {\\displaystyle (F,d)} and {\\displaystyle (F',d)} are two bargaining problems such that:",
    "after": "For every u , {\\displaystyle Best_{2}(F,u)\\leq Best_{2}(F',u)}",
    "url": "https://en.wikipedia.org/wiki/Kalai–Smorodinsky bargaining solution"
  },
  "{\\displaystyle \\sum _{i=1}^{n}{V_{i}(X_{i})}}": {
    "before": "A division {\\displaystyle X} is called utilitarian or utilitarian-maximal or maxsum if it maximizes the following expression:",
    "after": "The concept is often generalized by assigning a different weight to each partner. A division {\\displaystyle X} is called weighted-utilitarian-maximal (WUM) if it maximizes the following expression:",
    "url": "https://en.wikipedia.org/wiki/Utilitarian cake-cutting"
  },
  "{\\displaystyle \\sum _{i=1}^{n}{\\frac {V_{i}(X_{i})}{w_{i}}}}": {
    "before": "The concept is often generalized by assigning a different weight to each partner. A division {\\displaystyle X} is called weighted-utilitarian-maximal (WUM) if it maximizes the following expression:",
    "after": "where the {\\displaystyle w_{i}} are given positive constants.",
    "url": "https://en.wikipedia.org/wiki/Utilitarian cake-cutting"
  },
  "{\\displaystyle {\\bar {\\mathbf {S} }}={\\frac {1}{n}}\\sum _{i}\\mathbf {S} (F_{i},y_{i})}": {
    "before": "Given a sample {\\displaystyle y_{i},i=1\\ldots n} and corresponding forecasts {\\displaystyle F_{i}} or {\\displaystyle x_{i}} (e.g. forecasts from a single model), one calculates the average score as",
    "after": "or {\\displaystyle {\\bar {S}}={\\frac {1}{n}}\\sum _{i}S(x_{i},y_{i})}",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle {\\bar {S}}={\\frac {1}{n}}\\sum _{i}S(x_{i},y_{i})}": {
    "before": "{\\displaystyle {\\bar {\\mathbf {S} }}={\\frac {1}{n}}\\sum _{i}\\mathbf {S} (F_{i},y_{i})} or",
    "after": "Average scores are used to compare and rank different forecast(er)s or models.",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle \\mathbf {S} (F,Q)=\\int \\mathbf {S} (F,\\omega )\\mathrm {d} Q(\\omega )}": {
    "before": "We write for the expected score under {\\displaystyle Q\\in {\\mathcal {F}}}",
    "after": "A scoring rule {\\displaystyle \\mathbf {S} } is proper relative to {\\displaystyle {\\mathcal {F}}} if (assuming negative orientation)",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle L(\\mathbf {r} ,i)=\\ln(r_{i})}": {
    "before": "The logarithmic scoring rule is a local strictly proper scoring rule. This is also the negative of surprisal , which is commonly used as a scoring criterion in Bayesian inference ; the goal is to minimize expected surprise. This scoring rule has strong foundations in information theory .",
    "after": "Here, the score is calculated as the logarithm of the probability estimate for the actual outcome. That is, a prediction of 80% that correctly proved true would receive a score of ln(0.8) = −0.22 . This same prediction also assigns 20% likelihood to the opposite case, and so if the prediction proves false, it would receive a score based on the 20%: ln(0.2) = −1.6 . The goal of a forecaster is to maximize the score and for the score to be as large as possible, and −0.22 is indeed larger than −1.6.",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle L(\\mathbf {r} ,i)=\\log _{b}(r_{i})}": {
    "before": "If one treats the truth or falsity of the prediction as a variable x with value 1 or 0 respectively, and the expressed probability as p , then one can write the logarithmic scoring rule as x ln( p ) + (1 − x ) ln(1 − p ) . Note that any logarithmic base may be used, since strictly proper scoring rules remain strictly proper under linear transformation. That is:",
    "after": "is strictly proper for all {\\displaystyle b>1} .",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle Q(\\mathbf {r} ,i)=2r_{i}-\\mathbf {r} \\cdot \\mathbf {r} =2r_{i}-\\sum _{j=1}^{C}r_{j}^{2}}": {
    "before": "The quadratic scoring rule is a strictly proper scoring rule",
    "after": "where {\\displaystyle r_{i}} is the probability assigned to the correct answer and {\\displaystyle C} is the number of classes.",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle B(\\mathbf {r} ,i)=\\sum _{j=1}^{C}(y_{j}-r_{j})^{2}}": {
    "before": "The Brier score , originally proposed by Glenn W. Brier in 1950,  can be obtained by an affine transform from the quadratic scoring rule.",
    "after": "Where {\\displaystyle y_{j}=1} when the {\\displaystyle j} th event is correct and {\\displaystyle y_{j}=0} otherwise and {\\displaystyle C} is the number of classes.",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle s(p)=2\\Delta _{y}\\log p(y)+\\|\\nabla _{y}\\log p(y)\\|_{2}^{2}}": {
    "before": "The Hyvärinen scoring function (of a density p) is defined by ",
    "after": "Where {\\displaystyle \\Delta } denotes the Hessian trace and {\\displaystyle \\nabla } denotes the gradient . This scoring rule can be used to computationally simplify parameter inference and address Bayesian model comparison with arbitrarily-vague priors.   It was also used to introduce new information-theoretic quantities beyond the existing information theory . ",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle S(\\mathbf {r} ,i)={\\frac {r_{i}}{\\lVert \\mathbf {r} \\rVert }}={\\frac {r_{i}}{\\sqrt {r_{1}^{2}+\\cdots +r_{c}^{2}}}}}": {
    "before": "The spherical scoring rule is also a strictly proper scoring rule",
    "after": "Continuous variables [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle E(S)=\\mathrm {UNC} +\\mathrm {REL} -\\mathrm {RES} .}": {
    "before": "The expectation value of a proper scoring rule {\\displaystyle S} can be decomposed into the sum of three components, called uncertainty , reliability , and resolution ,   which characterize different attributes of probabilistic forecasts:",
    "after": "If a score is proper and negatively oriented (such as the Brier Score), all three terms are positive definite. The uncertainty component is equal to the expected score of the forecast which constantly predicts the average event frequency. The reliability component penalizes poorly calibrated forecasts, in which the predicted probabilities do not coincide with the event frequencies.",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle \\mathrm {UNC} ={\\bar {x}}(1-{\\bar {x}})} {\\displaystyle \\mathrm {REL} =E(p-\\pi (p))^{2}} {\\displaystyle \\mathrm {RES} =E(\\pi (p)-{\\bar {x}})^{2}}": {
    "before": "The equations for the individual components depend on the particular scoring rule. For the Brier Score, they are given by",
    "after": "where {\\displaystyle {\\bar {x}}} is the average probability of occurrence of the binary event {\\displaystyle x} , and {\\displaystyle \\pi (p)} is the conditional event probability, given {\\displaystyle p} , i.e. {\\displaystyle \\pi (p)=P(x=1\\mid p)}",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle CRPS(F,y)=\\int _{\\mathbb {R} }(F(x)-\\mathbb {1} (x\\geq y))^{2}dx}": {
    "before": "The continuous ranked probability score (CRPS)  is a strictly proper scoring rule much used in Meteorology. It is defined as",
    "after": "where F is the forecast cumulative distribution function and {\\displaystyle y\\in \\mathbb {R} } is the observation.",
    "url": "https://en.wikipedia.org/wiki/Scoring rule"
  },
  "{\\displaystyle E[B_{H}(t)B_{H}(s)]={\\tfrac {1}{2}}(|t|^{2H}+|s|^{2H}-|t-s|^{2H}),}": {
    "before": "In probability theory , fractional Brownian motion ( fBm ), also called a fractal Brownian motion , is a generalization of Brownian motion . Unlike classical Brownian motion, the increments of fBm need not be independent. fBm is a continuous-time Gaussian process B H ( t ) on [0, T ], that starts at zero, has expectation zero for all t in [0, T ], and has the following covariance function :",
    "after": "where H is a real number in (0, 1), called the Hurst index or Hurst parameter associated with the fractional Brownian motion. The Hurst exponent describes the raggedness of the resultant motion, with a higher value leading to a smoother motion. It was introduced by Mandelbrot & van Ness (1968) .",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "{\\displaystyle B_{H}(t)={\\frac {1}{\\Gamma (H+1/2)}}\\int _{0}^{t}(t-s)^{H-1/2}\\,dB(s)}": {
    "before": "Prior to the introduction of the fractional Brownian motion, Lévy (1953) used the Riemann–Liouville fractional integral to define the process",
    "after": "where integration is with respect to the white noise measure dB ( s ). This integral turns out to be ill-suited to applications of fractional Brownian motion because of its over-emphasis of the origin ( Mandelbrot & van Ness 1968 , p. 424).",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "{\\displaystyle B_{H}(t)=B_{H}(0)+{\\frac {1}{\\Gamma (H+1/2)}}\\left\\{\\int _{-\\infty }^{0}\\left[(t-s)^{H-1/2}-(-s)^{H-1/2}\\right]\\,dB(s)+\\int _{0}^{t}(t-s)^{H-1/2}\\,dB(s)\\right\\}}": {
    "before": "The idea instead is to use a different fractional integral of white noise to define the process: the Weyl integral",
    "after": "for t > 0 (and similarly for t < 0).",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "{\\displaystyle \\sum _{n=1}^{\\infty }E[B_{H}(1)(B_{H}(n+1)-B_{H}(n))]=\\infty .}": {
    "before": "For H > ½ the process exhibits long-range dependence ,",
    "after": "Regularity [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "{\\displaystyle B_{H}(t)=\\int _{0}^{t}K_{H}(t,s)\\,dB(s)}": {
    "before": "Method 2 of simulation [ edit ]It is also known that ",
    "after": "where B is a standard Brownian motion and",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "{\\displaystyle K_{H}(t,s)={\\frac {(t-s)^{H-{\\frac {1}{2}}}}{\\Gamma (H+{\\frac {1}{2}})}}\\;_{2}F_{1}\\left(H-{\\frac {1}{2}};\\,{\\frac {1}{2}}-H;\\;H+{\\frac {1}{2}};\\,1-{\\frac {t}{s}}\\right).}": {
    "before": "{\\displaystyle B_{H}(t)=\\int _{0}^{t}K_{H}(t,s)\\,dB(s)} where B is a standard Brownian motion and",
    "after": "Where {\\displaystyle _{2}F_{1}} is the Euler hypergeometric integral .",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "{\\displaystyle B_{H}(t_{j})={\\frac {n}{T}}\\sum _{i=0}^{j-1}\\int _{t_{i}}^{t_{i+1}}K_{H}(t_{j},\\,s)\\,ds\\ \\delta B_{i}.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "if H = 1/2 then the process is in fact a Brownian motion or Wiener process;": {
    "before": "The value of H determines what kind of process the fBm is:",
    "after": "if H > 1/2 then the increments of the process are positively correlated;",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "The increment process, X(t) = BH(t+1) − BH(t), is known as fractional Gaussian noise.": {
    "before": "if H < 1/2 then the increments of the process are negatively correlated.",
    "after": "There is also a generalization of fractional Brownian motion: n-th order fractional Brownian motion, abbreviated as n-fBm. n-fBm is a Gaussian, self-similar, non-stationary process whose increments of order n are stationary. For n = 1, n-fBm is classical fBm.",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "\"H\" = 0.75 realisation 1": {
    "before": "Practical computer realisations of an fBm can be generated, although they are only a finite approximation. The sample paths chosen can be thought of as showing discrete sampled points on an fBm process. Three realizations are shown below, each with 1000 points of an fBm with Hurst parameter 0.75.",
    "after": "\"H\" = 0.75 realisation 2",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "\"H\" = 0.75 realisation 2": {
    "before": "\"H\" = 0.75 realisation 1",
    "after": "\"H\" = 0.75 realisation 3",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "\"H\" = 0.75 realisation 3": {
    "before": "\"H\" = 0.75 realisation 2",
    "after": "Realizations of three different types of fBm are shown below, each showing 1000 points, the first with Hurst parameter 0.15, the second with Hurst parameter 0.55, and the third with Hurst parameter 0.95. The higher the Hurst parameter is, the smoother the curve will be.",
    "url": "https://en.wikipedia.org/wiki/Fractional Brownian motion"
  },
  "{\\displaystyle x(t)=x_{c}(t)\\cos(2\\pi f_{0}t)-x_{s}(t)\\sin(2\\pi f_{0}t)=\\Re \\left\\{{\\underline {x}}(t)e^{j2\\pi f_{0}t}\\right\\},}": {
    "before": "The random modulation procedure starts with two stochastic baseband signals , {\\displaystyle x_{c}(t)} and {\\displaystyle x_{s}(t)} , whose frequency spectrum is non-zero only for {\\displaystyle f\\in [-B/2,B/2]} . It applies quadrature modulation to combine these with a carrier frequency {\\displaystyle f_{0}} (with {\\displaystyle f_{0}>B/2} ) to form the signal {\\displaystyle x(t)} given by",
    "after": "where {\\displaystyle {\\underline {x}}(t)} is the equivalent baseband representation of the modulated signal {\\displaystyle x(t)}",
    "url": "https://en.wikipedia.org/wiki/Random modulation"
  },
  "{\\displaystyle {\\underline {x}}(t)=x_{c}(t)+jx_{s}(t).}": {
    "before": "where {\\displaystyle {\\underline {x}}(t)} is the equivalent baseband representation of the modulated signal {\\displaystyle x(t)}",
    "after": "In the following it is assumed that {\\displaystyle x_{c}(t)} and {\\displaystyle x_{s}(t)} are two real jointly wide sense stationary processes. It can be shown [ citation needed ] that the new signal {\\displaystyle x(t)} is wide sense stationary if and only if {\\displaystyle {\\underline {x}}(t)} is circular complex, i.e. if and only if {\\displaystyle x_{c}(t)} and {\\displaystyle x_{s}(t)} are such that",
    "url": "https://en.wikipedia.org/wiki/Random modulation"
  },
  "{\\displaystyle R_{x_{c}x_{c}}(\\tau )=R_{x_{s}x_{s}}(\\tau )\\qquad {\\text{and }}\\qquad R_{x_{c}x_{s}}(\\tau )=-R_{x_{s}x_{c}}(\\tau ).}": {
    "before": "In the following it is assumed that {\\displaystyle x_{c}(t)} and {\\displaystyle x_{s}(t)} are two real jointly wide sense stationary processes. It can be shown [ citation needed ] that the new signal {\\displaystyle x(t)} is wide sense stationary if and only if {\\displaystyle {\\underline {x}}(t)} is circular complex, i.e. if and only if {\\displaystyle x_{c}(t)} and {\\displaystyle x_{s}(t)} are such that",
    "after": "This article includes a list of general references , but it lacks sufficient corresponding inline citations . Please help to improve this article by introducing more precise citations. ( August 2011 ) ( Learn how and when to remove this template message )",
    "url": "https://en.wikipedia.org/wiki/Random modulation"
  },
  "time covered = (#CDPs stored) × (#PDPs per CDP) × (step time length)": {
    "before": "After the data has been consolidated, the resulting CDP is stored in a round-robin archive ( RRA ). A round-robin archive stores a fixed number of CDPs and specifies how many PDPs should be consolidated into one CDP and which CF to use. The total time covered by an RRA can be calculated as follows:",
    "after": "After this time the archive will \"wrap around\": the next insertion will overwrite the oldest entry. This behavior in this context is referred to as \"round-robin\" and is the reason for the program's name. However this is different from the common computer science definition, which is a method of distributing resources among multiple consumers or processes.",
    "url": "https://en.wikipedia.org/wiki/RRDtool"
  },
  "for Journal i . The authority distribution for π = πP would quantify the long-term influence of": {
    "before": "measures the direct impact between any two journals and P(i, i) is the self-citation rate",
    "after": "each journal in the group of journals and can be used to rank these journals.",
    "url": "https://en.wikipedia.org/wiki/Authority distribution"
  },
  "distribution π satisfying π = πP will measure the relative traffic intensity on each Fi and": {
    "before": "let P(i,j) be the (estimated) proportion of the traffic flowing into Fj. Then the authority",
    "after": "can be used in the investment allocation.",
    "url": "https://en.wikipedia.org/wiki/Authority distribution"
  },
  "{\\displaystyle C_{t}=\\alpha +\\lambda Y_{t}}": {
    "before": "Model [ edit ]The model is",
    "after": "where: {\\displaystyle C_{t}} is consumption at time t, {\\displaystyle \\alpha } is autonomous consumption , a constant, {\\displaystyle \\lambda } is the marginal propensity to consume ( {\\displaystyle 0<\\lambda <1} ), {\\displaystyle Y_{t}} is disposable income at time t.",
    "url": "https://en.wikipedia.org/wiki/Absolute income hypothesis"
  },
  "{\\displaystyle n!=n\\cdot (n-1)\\cdot \\ldots \\cdot 2\\cdot 1}": {
    "before": "Arithmetic [ edit ]Suppose we take the factorial of n :",
    "after": "Then 1! = 1, 2! = 2, 3! = 6, and 4! = 24. However, we quickly get to extremely large numbers, even for relatively small n . For example, 100! ≈ 9.332 621 54 × 10 157 , a number so large that it cannot be displayed on most calculators, and vastly larger than the estimated number of fundamental particles in the observable universe. ",
    "url": "https://en.wikipedia.org/wiki/Combinatorial explosion"
  },
  "(n = 9 is the commonly played 9 × 9 Sudoku. The puzzle does not include grids where √n is irrational.)": {
    "before": "5,524,751,496,156,892,842,531,225,600",
    "after": "Games[edit]",
    "url": "https://en.wikipedia.org/wiki/Combinatorial explosion"
  },
  "{\\displaystyle A_{i}^{\\text{WSM-score}}=\\sum _{j=1}^{n}w_{j}a_{ij},{\\text{ for }}i=1,2,3,\\dots ,m.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Weighted sum model"
  },
  "{\\displaystyle A_{1}^{\\text{WSM-score}}=25\\times 0.20+20\\times 0.15+15\\times 0.40+30\\times 0.25=21.50.}": {
    "before": "When the previous formula is applied on these numerical data the WSM scores for the three alternatives are:",
    "after": "Similarly, one gets:",
    "url": "https://en.wikipedia.org/wiki/Weighted sum model"
  },
  "{\\displaystyle A_{2}^{\\text{WSM-score}}=22.00,{\\text{ and }}A_{3}^{\\text{WSM-score}}=22.00.}": {
    "before": "{\\displaystyle A_{1}^{\\text{WSM-score}}=25\\times 0.20+20\\times 0.15+15\\times 0.40+30\\times 0.25=21.50.} Similarly, one gets:",
    "after": "Thus, the best choice (in the maximization case) is either alternative A 2 or A 3 (because they both have the maximum WSM score which is equal to 22.00). These numerical results imply the following ranking of these three alternatives: A 2 = A 3 > A 1 (where the symbol \">\" stands for \"greater than\").",
    "url": "https://en.wikipedia.org/wiki/Weighted sum model"
  },
  "{\\displaystyle X=ABC+\\Sigma ^{1/2}E}": {
    "before": "Growth curve model :  Let X be a p × n random matrix corresponding to the observations, A a p × q within design matrix with q ≤ p , B a q × k parameter matrix, C a k × n between individual design matrix with rank( C ) + p ≤ n and let Σ be a positive-definite p × p matrix. Then",
    "after": "defines the growth curve model, where A and C are known, B and Σ are unknown, and E is a random matrix distributed as N p , n (0, I p , n ).",
    "url": "https://en.wikipedia.org/wiki/Growth curve (statistics)"
  },
  "{\\displaystyle U_{S}(v_{S},v'_{S})=\\int _{u_{B}={\\underline {B}}}^{\\overline {B}}p(v'_{S},u_{B})f_{B}(u_{B})\\,du_{B}-v_{S}\\int _{u_{B}={\\underline {B}}}^{\\overline {B}}t(v'_{S},u_{B})f_{B}(u_{B})\\,du_{B}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Myerson–Satterthwaite theorem"
  },
  "{\\displaystyle U_{B}(v_{B},v'_{B})=v_{B}\\int _{u_{S}={\\underline {S}}}^{\\overline {S}}t(u_{S},v'_{B})f_{S}(u_{S})\\,du_{S}-\\int _{u_{S}={\\underline {S}}}^{\\overline {S}}p(u_{S},v'_{B})f_{S}(u_{S})\\,du_{S}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Myerson–Satterthwaite theorem"
  },
  "Δ%A = Δ%Y − Δ%X": {
    "before": "Former Chief Economist and Senior Vice President of the World Bank Paul Romer [note 6] has criticized the \"mathiness\" of DSGE models  and dismisses the inclusion of \"imaginary shocks\" in DSGE models that ignore \"actions that people take.\"  Romer submits a simplified [note 7] presentation of real business cycle (RBC) modelling, which, as he states, essentially involves two mathematical expressions: The well known formula of the quantity theory of money , and an identity that defines the growth accounting residual A as the difference between growth of output Y and growth of an index X of inputs in production.",
    "after": "Romer assigned to residual A the label \" phlogiston \" [note 8] while he criticized the lack of consideration given to monetary policy in DSGE analysis.  [note 9]",
    "url": "https://en.wikipedia.org/wiki/Dynamic stochastic general equilibrium"
  },
  "{\\displaystyle \\min _{\\tau }\\left(\\sum _{t=1}^{T}{(y_{t}-\\tau _{t})^{2}}+\\lambda \\sum _{t=2}^{T-1}{[(\\tau _{t+1}-\\tau _{t})-(\\tau _{t}-\\tau _{t-1})]^{2}}\\right).\\,}": {
    "before": "The reasoning for the methodology uses ideas related to the decomposition of time series . Let {\\displaystyle y_{t}\\,} for {\\displaystyle t=1,2,...,T\\,} denote the logarithms of a time series variable. The series {\\displaystyle y_{t}\\,} is made up of a trend component {\\displaystyle \\tau _{t}} , a cyclical component {\\displaystyle c_{t}} , and an error component {\\displaystyle \\epsilon _{t}} such that {\\displaystyle y_{t}\\ =\\tau _{t}\\ +c_{t}\\ +\\epsilon _{t}\\,} .  Given an adequately chosen, positive value of {\\displaystyle \\lambda } , there is a trend component that will solve",
    "after": "The first term of the equation is the sum of the squared deviations {\\displaystyle d_{t}=y_{t}-\\tau _{t}} , which penalizes the cyclical component. The second term is a multiple {\\displaystyle \\lambda } of the sum of the squares of the trend component's second differences. This second term penalizes variations in the growth rate of the trend component. The larger the value of {\\displaystyle \\lambda } , the higher is the penalty. Hodrick and Prescott suggest 1600 as a value for {\\displaystyle \\lambda } for quarterly data. Ravn and Uhlig (2002) state that {\\displaystyle \\lambda } should vary by the fourth power of the frequency observation ratio; thus, {\\displaystyle \\lambda } should equal 6.25 (1600/4^4) for annual data and 129,600 (1600*3^4) for monthly data;  in practice, {\\displaystyle \\lambda =100} for yearly data and {\\displaystyle \\lambda =14,400} for monthly data are commonly used, however.",
    "url": "https://en.wikipedia.org/wiki/Hodrick–Prescott filter"
  },
  "{\\displaystyle {\\mathit {HP}}=\\left[\\lambda L^{2}-4\\lambda L+(1+6\\lambda )-4\\lambda L^{-1}+\\lambda L^{-2}\\right]^{-1}}": {
    "before": "The Hodrick–Prescott filter is explicitly given by",
    "after": "where {\\displaystyle L} denotes the lag operator , as can seen from the first-order condition for the minimization problem.",
    "url": "https://en.wikipedia.org/wiki/Hodrick–Prescott filter"
  },
  "Problem 1 (N = 152): Imagine that the U.S. is preparing for the outbreak of an unusual disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. Assume that the exact scientific estimates of the consequences of the programs are as follows:If Program A is adopted, 200 people will be saved. (72%)If Program B is adopted, there is a one-third probability that 600 people will be saved and a two-thirds probability that no people will be saved. (28%)Which of the two programs would you favor?.": {
    "before": "The total number of respondents in each problem is denoted by N, and the percentage who chose each option is indicated in parentheses.",
    "after": "The formulation of Problem 1 implicitly adopts as a reference point a state of affairs in which the disease is allowed to take its toll of 600 lives. The outcomes of the programs include the reference state and two possible gains, measured by the number of lives saved. As expected, preferences are risk averse: a clear majority of respondents prefer saving 200 lives for sure over a gamble that offers a one-third chance of saving 600 lives.",
    "url": "https://en.wikipedia.org/wiki/Risk aversion (psychology)"
  },
  "Problem 2 (N = 155): Imagine that the U.S. is preparing for the outbreak of an unusual disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. Assume that the exact scientific estimates of the consequences of the programs are as follows:If Program C is adopted, 400 people will die. (22%)If Program D is adopted, there is a one-third probability that nobody will die and a two-thirds probability that 600 people will die. (78%)": {
    "before": "Now consider another problem in which the same cover story is followed by a different description of the prospects associated with the two programs:",
    "after": "It is easy to verify that options C and D in Problem 2 are indistinguishable in real terms from options A and B in Problem 1, respectively. The second version, however, assumes a reference state in which no one dies of the disease. The best outcome is the maintenance of this state and the alternatives are losses measured by the number of people that will die of the disease. People who evaluate options in these terms are expected to show a risk-seeking preference for the gamble (option D) over the sure loss of 400 lives. Of course, the “sure loss” of 400 lives that participants found so unattractive is exactly the same outcome as the “sure gain” of 200 subjects found so attractive in the Problem 1. The public health problem illustrates a formulation effect in which a change of wording from \"lives saved\" to \"lives lost\" induced a marked shift of preference from risk aversion to risk seeking.",
    "url": "https://en.wikipedia.org/wiki/Risk aversion (psychology)"
  },
  "{\\displaystyle y_{t}=\\beta _{0}+\\beta _{1}B(L^{1/m};\\theta )x_{t}^{(m)}+\\varepsilon _{t}^{(m)},}": {
    "before": "A simple regression example has the independent variable appearing at a higher frequency than the dependent variable :",
    "after": "where y is the dependent variable, x is the regressor, m denotes the frequency – for instance if y is yearly {\\displaystyle x_{t}^{(4)}} is quarterly – {\\displaystyle \\varepsilon } is the disturbance and {\\displaystyle B(L^{1/m};\\theta )} is a lag distribution, for instance the Beta function or the Almon Lag . For example {\\displaystyle B(L^{1/m};\\theta )=\\sum _{k=0}^{K}B(k;\\theta )L^{k/m}} .",
    "url": "https://en.wikipedia.org/wiki/Mixed-data sampling"
  },
  "A = 5/12, B = 3/12, C = 3/12, D = 1/12": {
    "before": "There are 12 total swing votes, so by the Banzhaf index, power is divided thus:",
    "after": "U.S. Electoral College[edit]",
    "url": "https://en.wikipedia.org/wiki/Banzhaf power index"
  },
  "{\\displaystyle P(A_{K}/A_{L})=\\prod _{j=1}^{n}(a_{Kj}/a_{Lj})^{w_{j}},{\\text{ for }}K,L=1,2,3,\\dots ,m.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Weighted product model"
  },
  "{\\displaystyle P(A_{1}/A_{2})=(25/10)^{0.20}\\times (20/30)^{0.15}\\times (15/20)^{0.40}\\times (30/30)^{0.25}=1.007>1.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Weighted product model"
  },
  "{\\displaystyle P(A_{1}/A_{3})=1.067>1,{\\text{ and }}P(A_{2}/A_{3})=1.059>1.\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Weighted product model"
  },
  "{\\displaystyle P(A_{K})=\\prod _{j=1}^{n}(a_{Kj})^{w_{j}},{\\text{ for }}K=1,2,3,\\dots ,m.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Weighted product model"
  },
  "{\\displaystyle U_{-t}=\\pi \\,U_{t}\\,\\pi }": {
    "before": "In mathematics , a dynamical system is time-reversible if the forward evolution is one-to-one , so that for every state there exists a transformation (an involution ) π which gives a one-to-one mapping between the time-reversed evolution of any one state and the forward-time evolution of another corresponding state, given by the operator equation:",
    "after": "Any time-independent structures (e.g. critical points or attractors ) which the dynamics give rise to must therefore either be self-symmetrical or have symmetrical images under the involution π.",
    "url": "https://en.wikipedia.org/wiki/Time reversibility"
  },
  "{\\displaystyle p(x_{t},x_{t+\\tau _{1}},x_{t+\\tau _{2}},\\ldots ,x_{t+\\tau _{k}})=p(x_{t'},x_{t'-\\tau _{1}},x_{t'-\\tau _{2}},\\ldots ,x_{t'-\\tau _{k}})}": {
    "before": "A stochastic process is time-reversible if the joint probabilities of the forward and reverse state sequences are the same for all sets of time increments { τ s }, for s = 1, ..., k for any k : ",
    "after": "A univariate stationary Gaussian process is time-reversible. Markov processes can only be reversible if their stationary distributions have the property of detailed balance :",
    "url": "https://en.wikipedia.org/wiki/Time reversibility"
  },
  "{\\displaystyle p(x_{t}=i,x_{t+1}=j)=\\,p(x_{t}=j,x_{t+1}=i)}": {
    "before": "A univariate stationary Gaussian process is time-reversible. Markov processes can only be reversible if their stationary distributions have the property of detailed balance :",
    "after": "Kolmogorov's criterion defines the condition for a Markov chain or continuous-time Markov chain to be time-reversible.",
    "url": "https://en.wikipedia.org/wiki/Time reversibility"
  },
  "{\\displaystyle y_{it}=x_{it}\\beta +c_{i}+u_{it}}": {
    "before": "In the standard random effects (RE) and fixed effects (FE) models, independent variables are assumed to be uncorrelated with error terms. Provided the availability of valid instruments, RE and FE methods extend to the case where some of the explanatory variables are allowed to be endogenous. As in the exogenous setting, RE model with Instrumental Variables (REIV) requires more stringent assumptions than FE model with Instrumental Variables (FEIV) but it tends to be more efficient under appropriate conditions.  To fix ideas, consider the following model:",
    "after": "where {\\displaystyle c_{i}} is unobserved unit-specific time-invariant effect (call it unobserved effect) and {\\displaystyle x_{it}} can be correlated with {\\displaystyle u_{is}} for s possibly different from t . Suppose there exists a set of valid instruments {\\displaystyle z_{i}=(z_{i1},\\ldots ,z_{it})} .",
    "url": "https://en.wikipedia.org/wiki/Panel analysis"
  },
  "{\\displaystyle y_{it}=a+bx_{it}+\\rho y_{it-1}+\\varepsilon _{it}}": {
    "before": "In contrast to the standard panel data model, a dynamic panel model also includes lagged values of the dependent variable as regressors. For example, including one lag of the dependent variable generates:",
    "after": "The assumptions of the fixed effect and random effect models are violated in this setting. Instead, practitioners use a technique like the Arellano–Bond estimator .",
    "url": "https://en.wikipedia.org/wiki/Panel analysis"
  },
  "{\\displaystyle \\sum _{t=1}^{\\infty }\\delta ^{t}35={\\frac {\\delta }{1-\\delta }}35} .": {
    "before": "To be more precise, suppose that firms have a discount factor {\\displaystyle \\delta } . The discounted value of the cost to cheating and being punished indefinitely are",
    "after": "The firms therefore prefer not to cheat (so that collusion is an equilibrium) if",
    "url": "https://en.wikipedia.org/wiki/Tacit collusion"
  },
  "{\\displaystyle y_{t}=\\alpha +X_{t}\\beta +\\varepsilon _{t},\\,}": {
    "before": "Theory [ edit ]Consider the model",
    "after": "where {\\displaystyle y_{t}} is the time series of interest at time t , {\\displaystyle \\beta } is a vector of coefficients, {\\displaystyle X_{t}} is a matrix of explanatory variables , and {\\displaystyle \\varepsilon _{t}} is the error term . The error term can be serially correlated over time: {\\displaystyle \\varepsilon _{t}=\\rho \\varepsilon _{t-1}+e_{t},\\ |\\rho |<1} and {\\displaystyle e_{t}} is white noise. In addition to the Cochrane–Orcutt transformation, which is",
    "url": "https://en.wikipedia.org/wiki/Prais–Winsten estimation"
  },
  "{\\displaystyle y_{t}-\\rho y_{t-1}=\\alpha (1-\\rho )+(X_{t}-\\rho X_{t-1})\\beta +e_{t}.\\,}": {
    "before": "If it is found, for instance via the Durbin–Watson statistic , that the error term is serially correlated over time, then standard statistical inference as normally applied to regressions is invalid because standard errors are estimated with bias . To avoid this problem, the residuals must be modeled. If the process generating the residuals is found to be a stationary first-order autoregressive structure ,  {\\displaystyle \\varepsilon _{t}=\\rho \\varepsilon _{t-1}+e_{t},\\ |\\rho |<1} , with the errors { {\\displaystyle e_{t}} } being white noise , then the Cochrane–Orcutt procedure can be used to transform the model by taking a quasi-difference:",
    "after": "In this specification the error terms are white noise, so statistical inference is valid. Then the sum of squared residuals (the sum of squared estimates of {\\displaystyle e_{t}^{2}} ) is minimized with respect to {\\displaystyle (\\alpha ,\\beta )} , conditional on {\\displaystyle \\rho } .",
    "url": "https://en.wikipedia.org/wiki/Cochrane–Orcutt estimation"
  },
  "Group + Complementary Group = Overall Economy": {
    "before": "Thereby a group also can be a single economic entity. Each group has a complementary group, so that the sum of group plus complementary group gives the overall economy.",
    "after": "Examples for groups are all private households of a national economy or all companies of a national economy. The group of private economic entities (private sector) is the sum of all companies and all private households.",
    "url": "https://en.wikipedia.org/wiki/Balances Mechanics"
  },
  "Revenues – Expenses = ΔNet money assets": {
    "before": "For a single economic entity and groups of economic entities the partial sentence is valid, that the entities can rise their net-money assets by surplus of revenues (partial sentence):",
    "after": "Furthermore, it is valid that the expense of an economic entity A is the revenue of an economic entity B:",
    "url": "https://en.wikipedia.org/wiki/Balances Mechanics"
  },
  "Expense A = Revenue B": {
    "before": "Furthermore, it is valid that the expense of an economic entity A is the revenue of an economic entity B:",
    "after": "A purchase of a good by a customer leads to a revenue to the seller, the wage payment of an employer leads to the revenue of a worker and so on. Because every expense faces a revenue (and every revenue faces an expense) the sum of all expenses must be the sum of all revenues:",
    "url": "https://en.wikipedia.org/wiki/Balances Mechanics"
  },
  "Sum revenues = Sum expenses": {
    "before": "A purchase of a good by a customer leads to a revenue to the seller, the wage payment of an employer leads to the revenue of a worker and so on. Because every expense faces a revenue (and every revenue faces an expense) the sum of all expenses must be the sum of all revenues:",
    "after": "From that the global sentence derives that the aggregate expense-revenue-balance of a closed aggregate economy equals zero (current account/performance record). This is valid for the global economy and closed national economies. Open national economies are groups because they can have a current account balance value. For them the partial sentence is valid that their net money assets can differ from zero. In addition, it is valid that every debt claim of an economic entity corresponds to a liability of an other economic entity, so that the sum of all claims necessarily corresponds to the sum of all liabilities:",
    "url": "https://en.wikipedia.org/wiki/Balances Mechanics"
  },
  "Sum claims = Sum liabilities": {
    "before": "From that the global sentence derives that the aggregate expense-revenue-balance of a closed aggregate economy equals zero (current account/performance record). This is valid for the global economy and closed national economies. Open national economies are groups because they can have a current account balance value. For them the partial sentence is valid that their net money assets can differ from zero. In addition, it is valid that every debt claim of an economic entity corresponds to a liability of an other economic entity, so that the sum of all claims necessarily corresponds to the sum of all liabilities:",
    "after": "From that comes the global sentence that the aggregate net financial assets of a closed economy (all claims minus all liabilities) necessarily is Zero. The same is valid for changes of claims and liabilities:",
    "url": "https://en.wikipedia.org/wiki/Balances Mechanics"
  },
  "Sum Δclaims = Sum Δliabilities": {
    "before": "From that comes the global sentence that the aggregate net financial assets of a closed economy (all claims minus all liabilities) necessarily is Zero. The same is valid for changes of claims and liabilities:",
    "after": "Here the Global Sentence is:",
    "url": "https://en.wikipedia.org/wiki/Balances Mechanics"
  },
  "net worth = tangible assets + claims – liabilities": {
    "before": "So it is valid for each economic entity:",
    "after": "Claims minus liabilities equals net money assets:",
    "url": "https://en.wikipedia.org/wiki/Balances Mechanics"
  },
  "net money assets = claims – liabilities": {
    "before": "Claims minus liabilities equals net money assets:",
    "after": "The claims can be divided into medium of exchange and other claims:",
    "url": "https://en.wikipedia.org/wiki/Balances Mechanics"
  },
  "claims = medium of exchange + other claims": {
    "before": "The claims can be divided into medium of exchange and other claims:",
    "after": "Generally all \"other claims\" can be converted into a medium of exchange by monetization. Debt claims against business banks are monetized claims because they commonly are accepted as fiat money as medium of exchange.",
    "url": "https://en.wikipedia.org/wiki/Balances Mechanics"
  },
  "Revenue surplus of one group = Expense surplus of the complementary group": {
    "before": "Revenue surpluses of a group are only possible if the complementary group enables an expense surplus. Economic relationships always are two-sided, because every expense comes up to a revenue and every debt to a claim. If an economic entity gains more than it spends, the complementary group must spend more than it gains:",
    "after": "If individual economic entities cut their expenses, so that their expenses are lower than their revenues the global sentence is as follows:",
    "url": "https://en.wikipedia.org/wiki/Balances Mechanics"
  },
  "{\\displaystyle \\Delta y_{1}^{s}=y_{1}(p_{1}',m')-y_{1}(p_{1},m)=Y_{s}-Y_{1}.}": {
    "before": "The substitution effect, {\\displaystyle \\Delta y_{1}^{s}} , is the change in the amount demanded for {\\displaystyle \\ Y} when the price of good {\\displaystyle \\ Y} falls from {\\displaystyle \\ p_{1}} to {\\displaystyle \\ p_{1}'} (represented by the budget constraint shifting from {\\displaystyle BC1} to {\\displaystyle BC2} and thus increasing purchasing power) and, at the same time, the money income falls from {\\displaystyle m} to {\\displaystyle m'} to keep the consumer at the same level of utility on {\\displaystyle \\ I1} :",
    "after": "The substitution effect increases the amount demanded of good {\\displaystyle \\ Y} from {\\displaystyle \\ Y_{1}} to {\\displaystyle \\ Y_{s}} in the diagram. In the example shown, the income effect of the fall in {\\displaystyle \\ p_{1}} partly offsets the substitution effect as the amount demanded of {\\displaystyle \\ Y} in the absence of an offsetting income change ends up at {\\displaystyle \\ Y_{2}} thus the income effect from the rise in purchasing power due to the price drop is that the quantity demanded of {\\displaystyle \\ Y} goes from {\\displaystyle \\ Y_{s}} to {\\displaystyle \\ Y_{2}} . The total effect of the price drop on quantity demanded is the sum of the substitution effect and the income effect.",
    "url": "https://en.wikipedia.org/wiki/Consumer choice"
  },
  "{\\displaystyle \\ell +L=T.}": {
    "before": "The previous model of consumer choice theory is applicable with only slight modifications. First, the total amount of time that an individual has to allocate is known as his \"time endowment\", and is often denoted as T . The amount an individual allocates to labor (denoted L ) and leisure ( ℓ ) is constrained by T such that",
    "after": "A person's consumption is the amount of labor they choose multiplied by the amount they are paid per hour of labor (their wage, often denoted w ). Thus, the amount that a person consumes is:",
    "url": "https://en.wikipedia.org/wiki/Consumer choice"
  },
  "{\\displaystyle C=w(T-\\ell ).}": {
    "before": "A person's consumption is the amount of labor they choose multiplied by the amount they are paid per hour of labor (their wage, often denoted w ). Thus, the amount that a person consumes is:",
    "after": "When a consumer chooses no leisure {\\displaystyle (\\ell =0)} then {\\displaystyle T-\\ell =T} and {\\displaystyle C=wT} .",
    "url": "https://en.wikipedia.org/wiki/Consumer choice"
  },
  "{\\displaystyle \\Delta y_{1}^{n}=y_{1}(p_{1}',m)-y_{1}(p_{1}',m').}": {
    "before": "{\\displaystyle \\Delta y_{1}^{n}} is the change in the demand for good 1 when we change income from {\\displaystyle m'} to {\\displaystyle m} , holding the price of good 1 fixed at {\\displaystyle p_{1}'} :",
    "after": "Price effect as sum of substitution and income effects [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Consumer choice"
  },
  "U=√BZ": {
    "before": "Utility function - the relationship between utility values and every possible bundle of goods: U(Z, B),",
    "after": "Caution: Utility ≠ Happiness",
    "url": "https://en.wikipedia.org/wiki/Consumer choice"
  },
  "MUz=△U/△Z": {
    "before": "The marginal utility function of good Z is:",
    "after": "Assumptions[edit]",
    "url": "https://en.wikipedia.org/wiki/Consumer choice"
  },
  "{\\displaystyle (1-B)^{2}=1-2B+B^{2}\\,,}": {
    "before": "In an ARIMA model, the integrated part of the model includes the differencing operator (1 − B ) (where B is the backshift operator ) raised to an integer power. For example,",
    "after": "where {\\displaystyle B^{2}X_{t}=X_{t-2}\\,,}",
    "url": "https://en.wikipedia.org/wiki/Autoregressive fractionally integrated moving average"
  },
  "{\\displaystyle B^{2}X_{t}=X_{t-2}\\,,}": {
    "before": "{\\displaystyle (1-B)^{2}=1-2B+B^{2}\\,,} where",
    "after": "so that {\\displaystyle (1-B)^{2}X_{t}=X_{t}-2X_{t-1}+X_{t-2}.}",
    "url": "https://en.wikipedia.org/wiki/Autoregressive fractionally integrated moving average"
  },
  "{\\displaystyle (1-B)^{2}X_{t}=X_{t}-2X_{t-1}+X_{t-2}.}": {
    "before": "{\\displaystyle B^{2}X_{t}=X_{t-2}\\,,} so that",
    "after": "In a fractional model, the power is allowed to be fractional, with the meaning of the term identified using the following formal binomial series expansion",
    "url": "https://en.wikipedia.org/wiki/Autoregressive fractionally integrated moving average"
  },
  "{\\displaystyle {\\begin{aligned}(1-B)^{d}&=\\sum _{k=0}^{\\infty }\\;{d \\choose k}\\;(-B)^{k}\\\\&=\\sum _{k=0}^{\\infty }\\;{\\frac {\\prod _{a=0}^{k-1}(d-a)\\ (-B)^{k}}{k!}}\\\\&=1-dB+{\\frac {d(d-1)}{2!}}B^{2}-\\cdots \\,.\\end{aligned}}}": {
    "before": "In a fractional model, the power is allowed to be fractional, with the meaning of the term identified using the following formal binomial series expansion",
    "after": "ARFIMA(0, d , 0) [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autoregressive fractionally integrated moving average"
  },
  "{\\displaystyle (1-B)^{d}X_{t}=\\varepsilon _{t},}": {
    "before": "The simplest autoregressive fractionally integrated model, ARFIMA(0, d , 0), is, in standard notation,",
    "after": "where this has the interpretation",
    "url": "https://en.wikipedia.org/wiki/Autoregressive fractionally integrated moving average"
  },
  "{\\displaystyle X_{t}-dX_{t-1}+{\\frac {d(d-1)}{2!}}X_{t-2}-\\cdots =\\varepsilon _{t}.}": {
    "before": "{\\displaystyle (1-B)^{d}X_{t}=\\varepsilon _{t},} where this has the interpretation",
    "after": "ARFIMA(0, d , 0) is similar to fractional Gaussian noise (fGn): with d = H − 1 ⁄ 2 , their covariances have the same power-law decay. The advantage of fGn over ARFIMA(0, d ,0) is that many asymptotic relations hold for finite samples.  The advantage of ARFIMA(0, d ,0) over fGn is that it has an especially simple spectral density —",
    "url": "https://en.wikipedia.org/wiki/Autoregressive fractionally integrated moving average"
  },
  "{\\displaystyle \\left(1-\\sum _{i=1}^{p}\\phi _{i}B^{i}\\right)\\left(1-B\\right)^{d}X_{t}=\\left(1+\\sum _{i=1}^{q}\\theta _{i}B^{i}\\right)\\varepsilon _{t}\\,.}": {
    "before": "An ARFIMA model shares the same form of representation as the ARIMA ( p , d , q ) process, specifically:",
    "after": "In contrast to the ordinary ARIMA process, the \"difference parameter\", d , is allowed to take non-integer values.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive fractionally integrated moving average"
  },
  "{\\displaystyle \\mathbb {E} \\left[{\\frac {R(n)}{S(n)}}\\right]=Cn^{H}{\\text{ as }}n\\to \\infty \\,,}": {
    "before": "The Hurst exponent, H , is defined in terms of the asymptotic behaviour of the rescaled range as a function of the time span of a time series as follows;  ",
    "after": "where; {\\displaystyle R(n)} is the range of the first {\\displaystyle n} cumulative deviations from the mean {\\displaystyle S(n)} is the series (sum) of the first n standard deviations {\\displaystyle \\mathbb {E} \\left[x\\right]\\,} is the expected value {\\displaystyle n} is the time span of the observation (number of data points in a time series) {\\displaystyle C} is a constant.",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle m={\\frac {1}{n}}\\sum _{i=1}^{n}X_{i}\\,.}": {
    "before": "For a (partial) time series of length {\\displaystyle n} , {\\displaystyle X=X_{1},X_{2},\\dots ,X_{n}\\,} , the rescaled range is calculated as follows:   1. Calculate the mean ;",
    "after": "2. Create a mean-adjusted series;",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle Y_{t}=X_{t}-m\\quad {\\text{ for }}t=1,2,\\dots ,n\\,.}": {
    "before": "{\\displaystyle m={\\frac {1}{n}}\\sum _{i=1}^{n}X_{i}\\,.} 2. Create a mean-adjusted series;",
    "after": "3. Calculate the cumulative deviate series {\\displaystyle Z} ;",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle Z_{t}=\\sum _{i=1}^{t}Y_{i}\\quad {\\text{ for }}t=1,2,\\dots ,n\\,.}": {
    "before": "3. Calculate the cumulative deviate series {\\displaystyle Z} ;",
    "after": "4. Compute the range {\\displaystyle R} ;",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle R(n)=\\operatorname {max} \\left(Z_{1},Z_{2},\\dots ,Z_{n}\\right)-\\operatorname {min} \\left(Z_{1},Z_{2},\\dots ,Z_{n}\\right).}": {
    "before": "{\\displaystyle Z_{t}=\\sum _{i=1}^{t}Y_{i}\\quad {\\text{ for }}t=1,2,\\dots ,n\\,.} 4. Compute the range {\\displaystyle R} ;",
    "after": "5. Compute the standard deviation {\\displaystyle S} ;",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle S(n)={\\sqrt {{\\frac {1}{n}}\\sum _{i=1}^{n}\\left(X_{i}-m\\right)^{2}}}.}": {
    "before": "5. Compute the standard deviation {\\displaystyle S} ;",
    "after": "6. Calculate the rescaled range {\\displaystyle R(n)/S(n)} and average over all the partial time series of length {\\displaystyle n.}",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle H_{q}=H(q),}": {
    "before": "There are a variety of techniques that exist for estimating H , however assessing the accuracy of the estimation can be a complicated issue. Mathematically, in one technique, the Hurst exponent can be estimated such that:  ",
    "after": "for a time series",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle S_{q}=\\langle |g(t+\\tau )-g(t)|^{q}\\rangle _{t}\\sim \\tau ^{qH(q)},\\,}": {
    "before": "may be defined by the scaling properties of its structure functions {\\displaystyle S_{q}} ( {\\displaystyle \\tau } ):",
    "after": "where {\\displaystyle q>0} , {\\displaystyle \\tau } is the time lag and averaging is over the time window",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle H_{q}={\\frac {1}{2}}} ,": {
    "before": "For the BRW ( brown noise , {\\displaystyle 1/f^{2}} ) one gets",
    "after": "and for pink noise ( {\\displaystyle 1/f} )",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle H_{q}^{1D}={\\frac {1}{2}},\\quad H_{q}^{2D}=-1} .": {
    "before": "The Hurst exponent for white noise is dimension dependent,  and for 1D and 2D it is",
    "after": "For the popular Lévy stable processes and truncated Lévy processes with parameter α it has been found that",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle H_{q}=q/\\alpha } , for {\\displaystyle q<\\alpha } , and {\\displaystyle H_{q}=1} for {\\displaystyle q\\geq \\alpha } .": {
    "before": "For the popular Lévy stable processes and truncated Lévy processes with parameter α it has been found that",
    "after": "Multifractal detrended fluctuation analysis  is one method to estimate {\\displaystyle H(q)} from non-stationary time series. When {\\displaystyle H(q)} is a non-linear function of q the time series is a multifractal system .",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle \\mathbb {E} [R(n)/S(n)]={\\begin{cases}{\\frac {\\Gamma ({\\frac {n-1}{2}})}{{\\sqrt {\\pi }}\\Gamma ({\\frac {n}{2}})}}\\sum \\limits _{i=1}^{n-1}{\\sqrt {\\frac {n-i}{i}}},&{\\text{for }}n\\leq 340\\\\{\\frac {1}{\\sqrt {n{\\frac {\\pi }{2}}}}}\\sum \\limits _{i=1}^{n-1}{\\sqrt {\\frac {n-i}{i}}},&{\\text{for }}n>340\\end{cases}}}": {
    "before": "The Hurst exponent is estimated by fitting the power law {\\displaystyle \\mathbb {E} [R(n)/S(n)]=Cn^{H}} to the data. This can be done by plotting {\\displaystyle \\log[R(n)/S(n)]} as a function of {\\displaystyle \\log n} , and fitting a straight line; the slope of the line gives {\\displaystyle H} (a more principled approach fits the power law in a maximum-likelihood fashion  ). Such a graph is called a box plot. However, this approach is known to produce biased estimates of the power-law exponent. For small {\\displaystyle n} there is a significant deviation from the 0.5 slope. Anis and Lloyd  estimated the theoretical (i.e., for white noise) values of the R/S statistic to be:",
    "after": "where {\\displaystyle \\Gamma } is the Euler gamma function . The Anis-Lloyd corrected R/S Hurst exponent is calculated as 0.5 plus the slope of {\\displaystyle R(n)/S(n)-\\mathbb {E} [R(n)/S(n)]} .",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "(only q = 1, 2 are used to define the volatility). In particular, the H1 exponent indicates persistent (H1 > ½) or antipersistent (H1 < ½) behavior of the trend.": {
    "before": "{\\displaystyle \\tau }",
    "after": "For the BRW (brown noise,",
    "url": "https://en.wikipedia.org/wiki/Hurst exponent"
  },
  "{\\displaystyle X_{it},\\quad i=1,\\dots ,N,\\quad t=1,\\dots ,T,}": {
    "before": "Main article: Panel analysisA panel has the form",
    "after": "where {\\displaystyle i} is the individual dimension and {\\displaystyle t} is the time dimension. A general panel data regression model is written as {\\displaystyle y_{it}=\\alpha +\\beta 'X_{it}+u_{it}.} Different assumptions can be made on the precise structure of this general model. Two important models are the fixed effects model and the random effects model .",
    "url": "https://en.wikipedia.org/wiki/Panel data"
  },
  "{\\displaystyle y_{it}=\\alpha +\\beta 'X_{it}+u_{it},}": {
    "before": "where {\\displaystyle i} is the individual dimension and {\\displaystyle t} is the time dimension. A general panel data regression model is written as {\\displaystyle y_{it}=\\alpha +\\beta 'X_{it}+u_{it}.} Different assumptions can be made on the precise structure of this general model. Two important models are the fixed effects model and the random effects model .Consider a generic panel data model:",
    "after": "{\\displaystyle u_{it}=\\mu _{i}+v_{it}.}",
    "url": "https://en.wikipedia.org/wiki/Panel data"
  },
  "{\\displaystyle u_{it}=\\mu _{i}+v_{it}.}": {
    "before": "{\\displaystyle y_{it}=\\alpha +\\beta 'X_{it}+u_{it},}",
    "after": "{\\displaystyle \\mu _{i}} are individual-specific, time-invariant effects (for example in a panel of countries this could include geography, climate etc.) which are fixed over time., whereas {\\displaystyle v_{it}} is a time-varying random component.",
    "url": "https://en.wikipedia.org/wiki/Panel data"
  },
  "{\\displaystyle y_{it}=\\alpha +\\beta 'X_{it}+\\gamma y_{it-1}+u_{it},}": {
    "before": "Dynamic panel data describes the case where a lag of the dependent variable is used as regressor:",
    "after": "The presence of the lagged dependent variable violates strict exogeneity , that is, endogeneity may occur. The fixed effect estimator and the first differences estimator both rely on the assumption of strict exogeneity. Hence, if {\\displaystyle u_{i}} is believed to be correlated with one of the independent variables, an alternative estimation technique must be used. Instrumental variables or GMM techniques are commonly used in this situation, such as the Arellano–Bond estimator .",
    "url": "https://en.wikipedia.org/wiki/Panel data"
  },
  "{\\displaystyle y_{t}=a_{1}y_{t-1}+a_{2}y_{t-2}+\\cdots +a_{p}y_{t-p}+\\varepsilon _{t}.}": {
    "before": "Consider a discrete-time stochastic process {\\displaystyle (y_{t},t=1,2,3,\\ldots )} , and suppose that it can be written as an autoregressive process of order p :",
    "after": "Here, {\\displaystyle (\\varepsilon _{t},t=0,1,2,\\ldots ,)} is a serially uncorrelated, zero-mean stochastic process with constant variance {\\displaystyle \\sigma ^{2}} . For convenience, assume {\\displaystyle y_{0}=0} . If {\\displaystyle m=1} is a root of the characteristic equation , of multiplicity 1:",
    "url": "https://en.wikipedia.org/wiki/Unit root"
  },
  "{\\displaystyle y_{t}=y_{t-1}+\\varepsilon _{t}.}": {
    "before": "If the process has a unit root, then it is a non-stationary time series. That is, the moments of the stochastic process depend on {\\displaystyle t} . To illustrate the effect of a unit root, we can consider the first order case, starting from y 0 = 0:",
    "after": "By repeated substitution, we can write {\\displaystyle y_{t}=y_{0}+\\sum _{j=1}^{t}\\varepsilon _{j}} . Then the variance of {\\displaystyle y_{t}} is given by:",
    "url": "https://en.wikipedia.org/wiki/Unit root"
  },
  "{\\displaystyle \\operatorname {Var} (y_{t})=\\sum _{j=1}^{t}\\sigma ^{2}=t\\sigma ^{2}.}": {
    "before": "By repeated substitution, we can write {\\displaystyle y_{t}=y_{0}+\\sum _{j=1}^{t}\\varepsilon _{j}} . Then the variance of {\\displaystyle y_{t}} is given by:",
    "after": "The variance depends on t since {\\displaystyle \\operatorname {Var} (y_{1})=\\sigma ^{2}} , while {\\displaystyle \\operatorname {Var} (y_{2})=2\\sigma ^{2}} . Note that the variance of the series is diverging to infinity with t .",
    "url": "https://en.wikipedia.org/wiki/Unit root"
  },
  "{\\displaystyle z_{t}=\\lambda _{1}z_{t-1}+\\varepsilon _{t}}": {
    "before": "In the AR(2) case, {\\displaystyle y_{t}=a_{1}y_{t-1}+a_{2}y_{t-2}+\\varepsilon _{t}} can be written as {\\displaystyle (1-\\lambda _{1}L)(1-\\lambda _{2}L)y_{t}=\\varepsilon _{t}} where L is a lag operator that decreases the time index of a variable by one period: {\\displaystyle Ly_{t}=y_{t-1}} . If {\\displaystyle \\lambda _{2}=1} , the model has a unit root and we can define {\\displaystyle z_{t}=\\Delta y_{t}} ; then",
    "after": "is stationary if {\\displaystyle |\\lambda _{1}|<1} . OLS can be used to estimate the slope coefficient, {\\displaystyle \\lambda _{1}} .",
    "url": "https://en.wikipedia.org/wiki/Unit root"
  },
  "{\\displaystyle y_{t}=y_{t-1}+c+e_{t}}": {
    "before": "Economists debate whether various economic statistics, especially output , have a unit root or are trend-stationary .  A unit root process with drift is given in the first-order case by",
    "after": "where c is a constant term referred to as the \"drift\" term, and {\\displaystyle e_{t}} is white noise. Any non-zero value of the noise term, occurring for only one period, will permanently affect the value of {\\displaystyle y_{t}} as shown in the graph, so deviations from the line {\\displaystyle y_{t}=a+ct} are non-stationary; there is no reversion to any trend line. In contrast, a trend-stationary process is given by",
    "url": "https://en.wikipedia.org/wiki/Unit root"
  },
  "{\\displaystyle y_{t}=k\\cdot t+u_{t}}": {
    "before": "where c is a constant term referred to as the \"drift\" term, and {\\displaystyle e_{t}} is white noise. Any non-zero value of the noise term, occurring for only one period, will permanently affect the value of {\\displaystyle y_{t}} as shown in the graph, so deviations from the line {\\displaystyle y_{t}=a+ct} are non-stationary; there is no reversion to any trend line. In contrast, a trend-stationary process is given by",
    "after": "where k is the slope of the trend and {\\displaystyle u_{t}} is noise (white noise in the simplest case; more generally, noise following its own stationary autoregressive process). Here any transient noise will not alter the long-run tendency for {\\displaystyle y_{t}} to be on the trend line, as also shown in the graph. This process is said to be trend-stationary because deviations from the trend line are stationary.",
    "url": "https://en.wikipedia.org/wiki/Unit root"
  },
  "{\\displaystyle W(y)={\\begin{cases}1,&y<y*\\\\2,&y>y*\\end{cases}}}": {
    "before": "Suppose that the employer believes that there is a level of education y* below which productivity is 1 and above which productivity is 2. Their offered wage schedule W(y) will be:",
    "after": "Working with these hypotheses Spence shows that:",
    "url": "https://en.wikipedia.org/wiki/Signalling (economics)"
  },
  "Person (credential) = E ( Productivity | Cost (credential) ≤ Person (credential) - Person (no credential) )": {
    "before": "Edit: For there to be a separating equilibrium the high type 'h' must also check their outside option; do they want to choose the net pay in the separating equilibrium (calculated above) over the net pay in the pooling equilibrium. Thus we also need to test that: {\\displaystyle W^{*}-C'(h)>W^{*}q_{1}+W_{o}(1-q_{1})} Otherwise high type 'h' will choose Do not obtain credential of the pooling equilibrium.For the employers:",
    "after": "Person (no credential) = E ( Productivity | Cost (credential) > Person (credential) - Person (no credential) )",
    "url": "https://en.wikipedia.org/wiki/Signalling (economics)"
  },
  "Person (no credential) = E ( Productivity | Cost (credential) > Person (credential) - Person (no credential) )": {
    "before": "Person (credential) = E ( Productivity | Cost (credential) ≤ Person (credential) - Person (no credential) )",
    "after": "In equilibrium, in order for the signalling model to hold, the employer must recognize the signal and pay the corresponding wage and this will result in the workers self-sorting into the two groups. One can see that the cost/benefit structure for a signal to be effective must fall within certain bounds or else the system will fail. ",
    "url": "https://en.wikipedia.org/wiki/Signalling (economics)"
  },
  "Group I sets y=0 if 1>2-y*, that is if the return for not investing in education is higher than investing in education.": {
    "before": "There is no rational reason for someone choosing a different level of education from 0 or y*.",
    "after": "Group II sets y=y* if 2-y*/2>1, that is the return for investing in education is higher than not investing in education.",
    "url": "https://en.wikipedia.org/wiki/Signalling (economics)"
  },
  "Group II sets y=y* if 2-y*/2>1, that is the return for investing in education is higher than not investing in education.": {
    "before": "Group I sets y=0 if 1>2-y*, that is if the return for not investing in education is higher than investing in education.",
    "after": "Therefore, putting the previous two inequalities together, if 1<y*<2, then the employer's initial beliefs are confirmed.",
    "url": "https://en.wikipedia.org/wiki/Signalling (economics)"
  },
  "{\\displaystyle U=\\sum _{t=0}^{T}\\beta ^{t}u(c_{t})}": {
    "before": "Discrete time [ edit ]Total lifetime utility is given by",
    "after": "In this setting, the gross real interest rate {\\displaystyle R} will be given by the following condition:",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle Qu'(c_{t})=Q\\beta Ru'(c_{t+1})}": {
    "before": "In this setting, the gross real interest rate {\\displaystyle R} will be given by the following condition:",
    "after": "A quantity of money {\\displaystyle Q} invested today costs {\\displaystyle Qu'(c_{t})} units of utility, and so must yield exactly that number of units of utility in the future when saved at the prevailing gross interest rate {\\displaystyle R=1+r} , where {\\displaystyle r} is the net interest rate (if it yielded more, then the agent could make himself better off by saving more).",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle R={\\frac {u'(c_{t})}{\\beta u'(c_{t+1})}}}": {
    "before": "A quantity of money {\\displaystyle Q} invested today costs {\\displaystyle Qu'(c_{t})} units of utility, and so must yield exactly that number of units of utility in the future when saved at the prevailing gross interest rate {\\displaystyle R=1+r} , where {\\displaystyle r} is the net interest rate (if it yielded more, then the agent could make himself better off by saving more).Solving for the gross interest rate, we see that",
    "after": "In logs, we have",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle \\ln(R)=\\ln(1+r)=-\\ln {\\left[{\\frac {u'(c_{t+1})}{u'(c_{t})}}\\right]}-\\ln {\\beta }}": {
    "before": "{\\displaystyle R={\\frac {u'(c_{t})}{\\beta u'(c_{t+1})}}} In logs, we have",
    "after": "Since {\\displaystyle \\ln(1+r)\\approx r} for small {\\displaystyle r} (logs are very close to percentage changes) we have",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle u(c_{t})={\\frac {c_{t}^{1-\\sigma }}{1-\\sigma }}.}": {
    "before": "Let utility of consumption in period {\\displaystyle t} be given by",
    "after": "Since this utility function belongs to the family of CRRA utility functions we have {\\displaystyle u'(c_{t})=c_{t}^{-\\sigma }.} Thus,",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle \\ln \\left[{\\frac {u'(c_{t+1})}{u'(c_{t})}}\\right]=-\\sigma \\ln \\left[{\\frac {c_{t+1}}{c_{t}}}\\right].}": {
    "before": "Since this utility function belongs to the family of CRRA utility functions we have {\\displaystyle u'(c_{t})=c_{t}^{-\\sigma }.} Thus,",
    "after": "This can be rewritten as",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle \\ln \\left[{\\frac {c_{t+1}}{c_{t}}}\\right]=-{\\frac {1}{\\sigma }}\\ln \\left[{\\frac {u'(c_{t+1})}{u'(c_{t})}}\\right]}": {
    "before": "{\\displaystyle \\ln \\left[{\\frac {u'(c_{t+1})}{u'(c_{t})}}\\right]=-\\sigma \\ln \\left[{\\frac {c_{t+1}}{c_{t}}}\\right].} This can be rewritten as",
    "after": "Hence, applying the above derived formula",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle -{\\frac {\\partial \\ln(c_{t+1}/c_{t})}{\\partial \\ln(u'(c_{t+1})/u'(c_{t}))}}=-\\left[-{\\frac {1}{\\sigma }}\\right]={\\frac {1}{\\sigma }}.}": {
    "before": "{\\displaystyle \\ln \\left[{\\frac {c_{t+1}}{c_{t}}}\\right]=-{\\frac {1}{\\sigma }}\\ln \\left[{\\frac {u'(c_{t+1})}{u'(c_{t})}}\\right]} Hence, applying the above derived formula",
    "after": "Continuous time [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle RRA=-{\\frac {d(u'(c_{t}))}{d(c_{t})}}{\\frac {c_{t}}{u'(c_{t})}}=-u''(c_{t}){\\frac {c_{t}}{u'(c_{t})}}}": {
    "before": "where {\\displaystyle c_{t}} is shorthand for {\\displaystyle c(t)} , {\\displaystyle u(c(t))} is the utility of consumption in (instant) time t, and {\\displaystyle \\rho } is the time discount rate. First define the measure of relative risk aversion (this is useful even if the model has no uncertainty or risk) as,",
    "after": "then the elasticity of intertemporal substitution is defined as",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle U=\\int _{0}^{T}e^{-\\rho t}u(c_{t})dt}": {
    "before": "Let total lifetime utility be given by",
    "after": "where {\\displaystyle c_{t}} is shorthand for {\\displaystyle c(t)} , {\\displaystyle u(c(t))} is the utility of consumption in (instant) time t, and {\\displaystyle \\rho } is the time discount rate. First define the measure of relative risk aversion (this is useful even if the model has no uncertainty or risk) as,",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle EIS=-{\\frac {\\partial ({\\dot {c}}_{t}/c_{t})}{\\partial ({\\dot {u}}'(c_{t})/u'(c_{t}))}}=-{\\frac {\\partial ({\\dot {c}}_{t}/c_{t})}{\\partial (u''(c_{t}){\\dot {c}}_{t}/u'(c_{t}))}}={\\frac {\\partial ({\\dot {c}}_{t}/c_{t})}{\\partial (RRA\\cdot ({\\dot {c}}_{t}/c_{t}))}}={\\frac {1}{RRA}}=-{\\frac {u'(c_{t})}{u''(c_{t})\\cdot c_{t}}}}": {
    "before": "then the elasticity of intertemporal substitution is defined as",
    "after": "If the utility function {\\displaystyle u(c)} is of the CRRA type:",
    "url": "https://en.wikipedia.org/wiki/Elasticity of intertemporal substitution"
  },
  "{\\displaystyle a_{t}:=\\arg \\max _{a_{t}}\\sum _{o_{t}r_{t}}\\ldots \\max _{a_{m}}\\sum _{o_{m}r_{m}}[r_{t}+\\ldots +r_{m}]\\sum _{q:\\;U(q,a_{1}\\ldots a_{m})=o_{1}r_{1}\\ldots o_{m}r_{m}}2^{-{\\textrm {length}}(q)}}": {
    "before": "In general, at time step {\\displaystyle t} (which ranges from 1 to m), AIXI, having previously executed actions {\\displaystyle a_{1}\\dots a_{t-1}} (which is often abbreviated in the literature as {\\displaystyle a_{<t}} ) and having observed the history of percepts {\\displaystyle o_{1}r_{1}...o_{t-1}r_{t-1}} (which can be abbreviated as {\\displaystyle e_{<t}} ), chooses and executes in the environment the action, {\\displaystyle a_{t}} , defined as follows ",
    "after": "or, using parentheses, to disambiguate the precedences",
    "url": "https://en.wikipedia.org/wiki/AIXI"
  },
  "{\\displaystyle a_{t}:=\\arg \\max _{a_{t}}\\left(\\sum _{o_{t}r_{t}}\\ldots \\left(\\max _{a_{m}}\\sum _{o_{m}r_{m}}[r_{t}+\\ldots +r_{m}]\\left(\\sum _{q:\\;U(q,a_{1}\\ldots a_{m})=o_{1}r_{1}\\ldots o_{m}r_{m}}2^{-{\\textrm {length}}(q)}\\right)\\right)\\right)}": {
    "before": "or, using parentheses, to disambiguate the precedences",
    "after": "Intuitively, in the definition above, AIXI considers the sum of the total reward over all possible \"futures\" up to {\\displaystyle m-t} time steps ahead (that is, from {\\displaystyle t} to {\\displaystyle m} ), weighs each of them by the complexity of programs {\\displaystyle q} (that is, by {\\displaystyle 2^{-{\\textrm {length}}(q)}} ) consistent with the agent's past (that is, the previously executed actions, {\\displaystyle a_{<t}} , and received percepts, {\\displaystyle e_{<t}} ) that can generate that future, and then picks the action that maximises expected future rewards. ",
    "url": "https://en.wikipedia.org/wiki/AIXI"
  },
  "{\\displaystyle \\left|\\varphi \\right\\rangle ={\\frac {1}{\\sqrt {2}}}{\\bigg (}\\left|+\\right\\rangle _{a}\\otimes \\left|+\\right\\rangle _{b}+\\left|-\\right\\rangle _{a}\\otimes \\left|-\\right\\rangle _{b}{\\bigg )}\\otimes {\\frac {1}{\\sqrt {2}}}{\\bigg (}\\left|+\\right\\rangle _{c}\\otimes \\left|+\\right\\rangle _{d}+\\left|-\\right\\rangle _{c}\\otimes \\left|-\\right\\rangle _{d}{\\bigg )}}": {
    "before": "The trick is for Alice and Bob to share an entangled quantum state and to use specific measurements on their components of the entangled state to derive the table entries. A suitable correlated state consists of a pair of entangled Bell states :",
    "after": "here {\\displaystyle \\left|+\\right\\rangle } and {\\displaystyle \\left|-\\right\\rangle } are eigenstates of the Pauli operator S x with eigenvalues +1 and −1, respectively, whilst the subscripts a, b, c, and d identify the components of each Bell state, with a and c going to Alice, and b and d going to Bob. The symbol {\\displaystyle \\otimes } represents a tensor product .",
    "url": "https://en.wikipedia.org/wiki/Quantum pseudo-telepathy"
  },
  "{\\displaystyle S_{x}={\\begin{bmatrix}0&1\\\\1&0\\end{bmatrix}},S_{y}={\\begin{bmatrix}0&-i\\\\i&0\\end{bmatrix}},S_{z}={\\begin{bmatrix}1&0\\\\0&-1\\end{bmatrix}}}": {
    "before": "Observables for these components can be written as products of the Pauli spin matrices :",
    "after": "Products of these Pauli spin operators can be used to fill the 3×3 table such that each row and each column contains a mutually commuting set of observables with eigenvalues +1 and −1, and with the product of the observables in each row being the identity operator, and the product of observables in each column equating to minus the identity operator. This is a so-called Mermin – Peres magic square. It is shown in below table.",
    "url": "https://en.wikipedia.org/wiki/Quantum pseudo-telepathy"
  },
  "{\\textstyle |{\\psi }\\rangle ={\\frac {1}{\\sqrt {2}}}(|000\\rangle +|111\\rangle )}": {
    "before": "Now we have come to the interesting part where Alice, Bob, and Carol decided to adopt a quantum strategy. The three of them now share a tripartite entangled state",
    "after": ", known as the GHZ state.",
    "url": "https://en.wikipedia.org/wiki/Quantum pseudo-telepathy"
  },
  "{\\displaystyle U_{i}(x_{i},x_{-i})=\\max _{x_{i}'\\in A_{i}(x)}U_{i}(x_{i}',x_{-i})}": {
    "before": "An equilibrium in an abstract economy is a vector of choices, {\\displaystyle x=(x_{1},\\ldots ,x_{N})=(x_{i},x_{-i})} , such that, for each agent {\\displaystyle i} , the action {\\displaystyle x_{i}} maximizes the function {\\displaystyle U_{i}(\\cdot ,x_{-i})} subject to the constraint {\\displaystyle x_{i}\\in A_{i}(x)} :",
    "after": "Equivalently, for each agent {\\displaystyle i} , there is no action {\\displaystyle x_{i}'\\in A_{i}(x)} such that:",
    "url": "https://en.wikipedia.org/wiki/Abstract economy"
  },
  "{\\displaystyle \\sum _{i\\in J}y'_{i}=\\sum _{i\\in J}y_{i}.}": {
    "before": "A Pareto-optimal allocation is, as usual, an allocation without a Pareto-improvement. A Pareto-improvement of an allocation {\\displaystyle \\mathbf {y} } is defined as another allocation {\\displaystyle \\mathbf {y'} } that is strictly better for a subset {\\displaystyle J} of the agents, and remains the same allocation for all other agents. That is:",
    "after": "{\\displaystyle y'_{i}\\in P_{i}(y_{i})} for all {\\displaystyle i\\in J} .",
    "url": "https://en.wikipedia.org/wiki/Abstract economy"
  },
  "is convex and does not contain x (= irreflexivity). Mas-Collel added the condition that the set": {
    "before": "{\\displaystyle P_{i}(x)}",
    "after": "{\\displaystyle P_{i}(x)}",
    "url": "https://en.wikipedia.org/wiki/Abstract economy"
  },
  "is non-empty (= non-saturation).": {
    "before": "{\\displaystyle P_{i}(x)}",
    "after": "For every i:",
    "url": "https://en.wikipedia.org/wiki/Abstract economy"
  },
  "{\\displaystyle {\\text{d}}x=-B^{-1}C{\\text{d}}a.}": {
    "before": "Here {\\displaystyle {\\text{d}}x} and {\\displaystyle {\\text{d}}a} represent the changes in {\\displaystyle x} and {\\displaystyle a} , respectively, while {\\displaystyle B} and {\\displaystyle C} are the partial derivatives of {\\displaystyle f} with respect to {\\displaystyle x} and {\\displaystyle a} (evaluated at the initial values of {\\displaystyle x} and {\\displaystyle a} ), respectively. Equivalently, we can write the change in {\\displaystyle x} as:",
    "after": "Dividing through the last equation by d a gives the comparative static derivative of x with respect to a , also called the multiplier of a on x :",
    "url": "https://en.wikipedia.org/wiki/Comparative statics"
  },
  "{\\displaystyle {\\frac {{\\text{d}}x}{{\\text{d}}a}}=-B^{-1}C.}": {
    "before": "Dividing through the last equation by d a gives the comparative static derivative of x with respect to a , also called the multiplier of a on x :",
    "after": "Many equations and unknowns [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Comparative statics"
  },
  "{\\displaystyle Q^{d}(P)=a+bP}": {
    "before": "Suppose that the quantities demanded and supplied of a product are determined by the following equations:",
    "after": "{\\displaystyle Q^{s}(P)=c+gP}",
    "url": "https://en.wikipedia.org/wiki/Comparative statics"
  },
  "{\\displaystyle Q^{s}(P)=c+gP}": {
    "before": "Suppose that the quantities demanded and supplied of a product are determined by the following equations: {\\displaystyle Q^{d}(P)=a+bP}",
    "after": "where {\\displaystyle Q^{d}} is the quantity demanded, {\\displaystyle Q^{s}} is the quantity supplied, P is the price, a and c are intercept parameters determined by exogenous influences on demand and supply respectively, b < 0 is the reciprocal of the slope of the demand curve , and g is the reciprocal of the slope of the supply curve; g > 0 if the supply curve is upward sloped, g = 0 if the supply curve is vertical, and g < 0 if the supply curve is backward-bending. If we equate quantity supplied with quantity demanded to find the equilibrium price {\\displaystyle P^{eqb}} , we find that",
    "url": "https://en.wikipedia.org/wiki/Comparative statics"
  },
  "{\\displaystyle P^{eqb}={\\frac {a-c}{g-b}}.}": {
    "before": "where {\\displaystyle Q^{d}} is the quantity demanded, {\\displaystyle Q^{s}} is the quantity supplied, P is the price, a and c are intercept parameters determined by exogenous influences on demand and supply respectively, b < 0 is the reciprocal of the slope of the demand curve , and g is the reciprocal of the slope of the supply curve; g > 0 if the supply curve is upward sloped, g = 0 if the supply curve is vertical, and g < 0 if the supply curve is backward-bending. If we equate quantity supplied with quantity demanded to find the equilibrium price {\\displaystyle P^{eqb}} , we find that",
    "after": "This means that the equilibrium price depends positively on the demand intercept if g – b > 0, but depends negatively on it if g – b < 0. Which of these possibilities is relevant? In fact, starting from an initial static equilibrium and then changing a , the new equilibrium is relevant only if the market actually goes to that new equilibrium. Suppose that price adjustments in the market occur according to",
    "url": "https://en.wikipedia.org/wiki/Comparative statics"
  },
  "{\\displaystyle {\\frac {dP}{dt}}=\\lambda (Q^{d}(P)-Q^{s}(P))}": {
    "before": "This means that the equilibrium price depends positively on the demand intercept if g – b > 0, but depends negatively on it if g – b < 0. Which of these possibilities is relevant? In fact, starting from an initial static equilibrium and then changing a , the new equilibrium is relevant only if the market actually goes to that new equilibrium. Suppose that price adjustments in the market occur according to",
    "after": "where {\\displaystyle \\lambda } > 0 is the speed of adjustment parameter and {\\displaystyle {\\frac {dP}{dt}}} is the time derivative of the price — that is, it denotes how fast and in what direction the price changes. By stability theory , P will converge to its equilibrium value if and only if the derivative {\\displaystyle {\\frac {d(dP/dt)}{dP}}} is negative. This derivative is given by",
    "url": "https://en.wikipedia.org/wiki/Comparative statics"
  },
  "{\\displaystyle {\\frac {d(dP/dt)}{dP}}=-\\lambda (-b+g).}": {
    "before": "where {\\displaystyle \\lambda } > 0 is the speed of adjustment parameter and {\\displaystyle {\\frac {dP}{dt}}} is the time derivative of the price — that is, it denotes how fast and in what direction the price changes. By stability theory , P will converge to its equilibrium value if and only if the derivative {\\displaystyle {\\frac {d(dP/dt)}{dP}}} is negative. This derivative is given by",
    "after": "This is negative if and only if g – b > 0, in which case the demand intercept parameter a positively influences the price. So we can say that while the direction of effect of the demand intercept on the equilibrium price is ambiguous when all we know is that the reciprocal of the supply curve's slope, g , is negative, in the only relevant case (in which the price actually goes to its new equilibrium value) an increase in the demand intercept increases the price. Note that this case, with g – b > 0, is the case in which the supply curve, if negatively sloped, is steeper than the demand curve.",
    "url": "https://en.wikipedia.org/wiki/Comparative statics"
  },
  "{\\displaystyle D_{q}x^{*}(q)=-[D_{x}f(x^{*}(q);q)]^{-1}D_{q}f(x^{*}(q);q).}": {
    "before": "The strict concavity of the objective function implies that the Jacobian of f , which is exactly the matrix of second partial derivatives of p with respect to the endogenous variables, is nonsingular (has an inverse). By the implicit function theorem , then, {\\displaystyle x^{*}(q)} may be viewed locally as a continuously differentiable function, and the local response of {\\displaystyle x^{*}(q)} to small changes in q is given by",
    "after": "Applying the chain rule and first order condition,",
    "url": "https://en.wikipedia.org/wiki/Comparative statics"
  },
  "{\\displaystyle D_{q}p(x^{*}(q),q)=D_{q}p(x;q)|_{x=x^{*}(q)}.}": {
    "before": "Applying the chain rule and first order condition,",
    "after": "(See Envelope theorem ).",
    "url": "https://en.wikipedia.org/wiki/Comparative statics"
  },
  "{\\displaystyle X_{t}=\\sum _{i=1}^{p}\\varphi _{i}X_{t-i}+\\varepsilon _{t}}": {
    "before": "The notation {\\displaystyle AR(p)} indicates an autoregressive model of order p . The AR( p ) model is defined as",
    "after": "where {\\displaystyle \\varphi _{1},\\ldots ,\\varphi _{p}} are the parameters of the model, and {\\displaystyle \\varepsilon _{t}} is white noise .   This can be equivalently written using the backshift operator B as",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle X_{t}=\\mu +\\varepsilon _{t}+\\sum _{i=1}^{q}\\theta _{i}\\varepsilon _{t-i}\\,}": {
    "before": "The notation MA( q ) refers to the moving average model of order q :",
    "after": "where the {\\displaystyle \\theta _{1},...,\\theta _{q}} are the parameters of the model, {\\displaystyle \\mu } is the expectation of {\\displaystyle X_{t}} (often assumed to equal 0), and the {\\displaystyle \\varepsilon _{t}} , {\\displaystyle \\varepsilon _{t-1}} ,... are again i.i.d. white noise error terms that are commonly normal random variables. ",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle X_{t}=\\varepsilon _{t}+\\sum _{i=1}^{p}\\varphi _{i}X_{t-i}+\\sum _{i=1}^{q}\\theta _{i}\\varepsilon _{t-i}.\\,}": {
    "before": "The notation ARMA( p , q ) refers to the model with p autoregressive terms and q moving-average terms. This model contains the AR( p ) and MA( q ) models, ",
    "after": "The general ARMA model was described in the 1951 thesis of Peter Whittle , who used mathematical analysis ( Laurent series and Fourier analysis ) and statistical inference.   ARMA models were popularized by a 1970 book by George E. P. Box and Jenkins, who expounded an iterative ( Box–Jenkins ) method for choosing and estimating them. This method was useful for low-order polynomials (of degree three or less). ",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle \\varepsilon _{t}=\\left(1-\\sum _{i=1}^{p}\\varphi _{i}L^{i}\\right)X_{t}=\\varphi (L)X_{t}\\,}": {
    "before": "In some texts the models will be specified in terms of the lag operator L . In these terms then the AR( p ) model is given by",
    "after": "where {\\displaystyle \\varphi } represents the polynomial",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle \\varphi (L)=1-\\sum _{i=1}^{p}\\varphi _{i}L^{i}.\\,}": {
    "before": "where {\\displaystyle \\varphi } represents the polynomial",
    "after": "The MA( q ) model is given by",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle X_{t}=\\left(1+\\sum _{i=1}^{q}\\theta _{i}L^{i}\\right)\\varepsilon _{t}=\\theta (L)\\varepsilon _{t},\\,}": {
    "before": "{\\displaystyle \\varphi (L)=1-\\sum _{i=1}^{p}\\varphi _{i}L^{i}.\\,} The MA( q ) model is given by",
    "after": "where {\\displaystyle \\theta } represents the polynomial",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle \\left(1-\\sum _{i=1}^{p}\\varphi _{i}L^{i}\\right)X_{t}=\\left(1+\\sum _{i=1}^{q}\\theta _{i}L^{i}\\right)\\varepsilon _{t}\\,,}": {
    "before": "Finally, the combined ARMA( p , q ) model is given by",
    "after": "or more concisely,",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle \\varphi (L)X_{t}=\\theta (L)\\varepsilon _{t}\\,}": {
    "before": "{\\displaystyle \\left(1-\\sum _{i=1}^{p}\\varphi _{i}L^{i}\\right)X_{t}=\\left(1+\\sum _{i=1}^{q}\\theta _{i}L^{i}\\right)\\varepsilon _{t}\\,,} or more concisely,",
    "after": "or {\\displaystyle {\\frac {\\varphi (L)}{\\theta (L)}}X_{t}=\\varepsilon _{t}\\,.}",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle {\\frac {\\varphi (L)}{\\theta (L)}}X_{t}=\\varepsilon _{t}\\,.}": {
    "before": "{\\displaystyle \\varphi (L)X_{t}=\\theta (L)\\varepsilon _{t}\\,} or",
    "after": "Alternative notation [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle \\left(1-\\sum _{i=1}^{p}\\phi _{i}L^{i}\\right)X_{t}=\\left(1+\\sum _{i=1}^{q}\\theta _{i}L^{i}\\right)\\varepsilon _{t}\\,.}": {
    "before": "Some authors, including Box , Jenkins & Reinsel use a different convention for the autoregression coefficients.  This allows all the polynomials involving the lag operator to appear in a similar form throughout. Thus the ARMA model would be written as",
    "after": "Moreover, starting summations from {\\displaystyle i=0} and setting {\\displaystyle \\phi _{0}=-1} and {\\displaystyle \\theta _{0}=1} , then we get an even more elegant formulation: {\\displaystyle -\\sum _{i=0}^{p}\\phi _{i}L^{i}\\;X_{t}=\\sum _{i=0}^{q}\\theta _{i}L^{i}\\;\\varepsilon _{t}\\,.}",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle X_{t}=\\varepsilon _{t}+\\sum _{i=1}^{p}\\varphi _{i}X_{t-i}+\\sum _{i=1}^{q}\\theta _{i}\\varepsilon _{t-i}+\\sum _{i=1}^{b}\\eta _{i}d_{t-i}.\\,}": {
    "before": "The notation ARMAX( p , q , b ) refers to the model with p autoregressive terms, q moving average terms and b exogenous inputs terms. This model contains the AR( p ) and MA( q ) models and a linear combination of the last b terms of a known and external time series {\\displaystyle d_{t}} . It is given by:",
    "after": "where {\\displaystyle \\eta _{1},\\ldots ,\\eta _{b}} are the parameters of the exogenous input {\\displaystyle d_{t}} .",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle X_{t}-m_{t}=\\varepsilon _{t}+\\sum _{i=1}^{p}\\varphi _{i}(X_{t-i}-m_{t-i})+\\sum _{i=1}^{q}\\theta _{i}\\varepsilon _{t-i}.\\,}": {
    "before": "Statistical packages implement the ARMAX model through the use of \"exogenous\" (that is, independent,) variables. Care must be taken when interpreting the output of those packages, because the estimated parameters usually (for example, in R  and gretl ) refer to the regression:",
    "after": "where {\\displaystyle m_{t}} incorporates all exogenous (or independent) variables:",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle m_{t}=c+\\sum _{i=0}^{b}\\eta _{i}d_{t-i}.\\,}": {
    "before": "where {\\displaystyle m_{t}} incorporates all exogenous (or independent) variables:",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autoregressive–moving-average model"
  },
  "{\\displaystyle L=\\ln \\left({\\sum _{i}{\\frac {c_{i}}{a_{i}y_{i}}}}\\right)+1}": {
    "before": "L -index combines the number of citations, the number of coauthors, the age of publications into a single value, which is independent of the number of publications and conveniently ranges from 0.0 to 9.9.  With c as number of citations, a as number of authors and y as number of years, L -index is defined by the formula:",
    "after": "L -index is automatically calculated by the Exaly database. ",
    "url": "https://en.wikipedia.org/wiki/Author-level metrics"
  },
  "[–10×(number of members)]=10×(number of members)), which may fulfill the private sector's desired savings quota.": {
    "before": "{\\displaystyle S_{m}=-S_{g}=-}",
    "after": "The emphasis on the net scrip of co-op members, which equal the amount injected into the co-op by the administration, is the distinguishing feature of the Chartalist view. From this perspective, the function of introducing lending, as Krugman suggests, is that interest on this lending creates or destroys net member savings. For example, if the administration lends ten hours' worth of scrip at 10% interest for one year (thus collecting eleven hours' worth of scrip in one year's time), then it has created ten hours' worth of scrip but will withdraw eleven hours in the future, thus reducing net private sector assets by one hour.",
    "url": "https://en.wikipedia.org/wiki/Capitol Hill Babysitting Co-op"
  },
  "{\\displaystyle a_{i}={\\bar {a}}(t_{i-1},t_{i})=\\mathrm {arg} \\max _{a}\\int _{t_{i-1}}^{t_{i}}U^{R}(a,t)dt}": {
    "before": "The action function is now indirectly characterized by the fact that each value a i optimizes return for the R , knowing that t is between t 1 and t 2 . Mathematically (assuming that t is uniformly distributed over [0, 1]),",
    "after": "→ Quadratic utilities:",
    "url": "https://en.wikipedia.org/wiki/Cheap talk"
  },
  "where 0 = t0(N) < t1(N) < . . . < tN(N) = 1. This partition is shown on the top right segment of Figure 1.": {
    "before": "Thus an equilibrium may be characterized by a partition (t0(N), t1(N). . . tN(N)) of the set of types [0, 1],",
    "after": "The ti(N)’s are the bounds of intervals where the messages are constant: for ti-1(N) < t < ti(N), µ(t) = mi.",
    "url": "https://en.wikipedia.org/wiki/Cheap talk"
  },
  "for ti-1(N) < t < ti(N), α(t) = α(mi) = ai.": {
    "before": "Since actions are functions of messages, actions are also constant over these intervals:",
    "after": "The action function is now indirectly characterized by the fact that each value ai optimizes return for the R, knowing that t is between t1 and t2. Mathematically (assuming that t is uniformly distributed over [0, 1]),",
    "url": "https://en.wikipedia.org/wiki/Cheap talk"
  },
  "What happens at t = ti? The sender has to be indifferent between sending either message mi-1 or mi.": {
    "before": "Indifference condition[edit]",
    "after": "{\\displaystyle U^{S}(a_{i},t_{i})=U^{S}(a_{i+1},t_{i})}",
    "url": "https://en.wikipedia.org/wiki/Cheap talk"
  },
  "Example: We assume that b = 1/20. Then N* = 3. We now describe all the equilibria for N=1, 2, or 3 (see Figure 2).": {
    "before": ".",
    "after": "Figure 2: Message and utilities for conflict of interest b = 1/20, for N=1, 2, and 3",
    "url": "https://en.wikipedia.org/wiki/Cheap talk"
  },
  "Figure 2: Message and utilities for conflict of interest b = 1/20, for N=1, 2, and 3": {
    "before": "Example: We assume that b = 1/20. Then N* = 3. We now describe all the equilibria for N=1, 2, or 3 (see Figure 2).",
    "after": "N = 1: This is the babbling equilibrium. t0 = 0, t1 = 1; a1 = 1/2 = 0.5.",
    "url": "https://en.wikipedia.org/wiki/Cheap talk"
  },
  "N = 1: This is the babbling equilibrium. t0 = 0, t1 = 1; a1 = 1/2 = 0.5.": {
    "before": "Figure 2: Message and utilities for conflict of interest b = 1/20, for N=1, 2, and 3",
    "after": "N = 2: t0 = 0, t1 = 2/5 = 0.4, t2 = 1; a1 = 1/5 = 0.2, a2 = 7/10 = 0.7.",
    "url": "https://en.wikipedia.org/wiki/Cheap talk"
  },
  "N = 2: t0 = 0, t1 = 2/5 = 0.4, t2 = 1; a1 = 1/5 = 0.2, a2 = 7/10 = 0.7.": {
    "before": "N = 1: This is the babbling equilibrium. t0 = 0, t1 = 1; a1 = 1/2 = 0.5.",
    "after": "N = N* = 3: t0 = 0, t1 = 2/15, t2 = 7/15, t3 = 1; a1 = 1/15, a2 = 3/10 = 0.3, a3 = 11/15.",
    "url": "https://en.wikipedia.org/wiki/Cheap talk"
  },
  "N = N* = 3: t0 = 0, t1 = 2/15, t2 = 7/15, t3 = 1; a1 = 1/15, a2 = 3/10 = 0.3, a3 = 11/15.": {
    "before": "N = 2: t0 = 0, t1 = 2/5 = 0.4, t2 = 1; a1 = 1/5 = 0.2, a2 = 7/10 = 0.7.",
    "after": "With N = 1, we get the coarsest possible message, which does not give any information. So everything is red on the top left panel. With N = 3, the message is finer. However, it remains quite coarse compared to full revelation, which would be the 45° line, but which is not a Nash equilibrium.",
    "url": "https://en.wikipedia.org/wiki/Cheap talk"
  },
  "With N = 1, we get the coarsest possible message, which does not give any information. So everything is red on the top left panel. With N = 3, the message is finer. However, it remains quite coarse compared to full revelation, which would be the 45° line, but which is not a Nash equilibrium.": {
    "before": "N = N* = 3: t0 = 0, t1 = 2/15, t2 = 7/15, t3 = 1; a1 = 1/15, a2 = 3/10 = 0.3, a3 = 11/15.",
    "after": "With a higher N, and a finer message, the blue area is more important. This implies higher utility. Disclosing more information benefits both parties.",
    "url": "https://en.wikipedia.org/wiki/Cheap talk"
  },
  "{\\textstyle p_{s}^{*}={\\frac {T-S}{T-S+R-P}}}": {
    "before": ". Defining",
    "after": ", we obtain a simple decision rule: cooperate whenever",
    "url": "https://en.wikipedia.org/wiki/Subjective expected relative similarity"
  },
  "{\\displaystyle RI={\\frac {|{\\text{yes}}-{\\text{no}}|}{{\\text{yes}}+{\\text{no}}}}}": {
    "before": "A result of 0 indicates a stalemate, while a 1 indicates a perfect consensus.  The formula is often used in the social sciences, and is the ratio of the difference between majority and minority to the sum of majority and minority. ",
    "after": "Yes = Number of yes votes, No = Number of votes against.",
    "url": "https://en.wikipedia.org/wiki/Rice index"
  },
  "α := min(α, expectiminimax(child, depth-1))": {
    "before": "foreach child of node",
    "after": "else if we are to play at node",
    "url": "https://en.wikipedia.org/wiki/Expectiminimax"
  },
  "α := max(α, expectiminimax(child, depth-1))": {
    "before": "foreach child of node",
    "after": "else if random event at node",
    "url": "https://en.wikipedia.org/wiki/Expectiminimax"
  },
  "α := α + (Probability[child] × expectiminimax(child, depth-1))": {
    "before": "foreach child of node",
    "after": "return α",
    "url": "https://en.wikipedia.org/wiki/Expectiminimax"
  },
  "measurement(,tag_key=tag_val)* field_key=field_val(,field_key_n=field_value_n)* (nanoseconds-timestamp)?": {
    "before": "InfluxDB accepts data via HTTP, TCP, and UDP. It defines a line protocol backwards compatible with Graphite and takes the form:",
    "after": "Licensing [ edit ]",
    "url": "https://en.wikipedia.org/wiki/InfluxDB"
  },
  "{\\displaystyle X_{isth},\\;i=1,\\dots ,N,\\;s=1,\\dots ,S,\\;t=1,\\dots ,T,\\;h=1,\\dots ,H,\\,}": {
    "before": "A multidimensional panel with four dimensions can have the form",
    "after": "where i is the individual dimension, s is the series dimension, t is the time dimension, and h is the horizon dimension. A general multidimensional panel data regression model is written as",
    "url": "https://en.wikipedia.org/wiki/Multidimensional panel data"
  },
  "{\\displaystyle y_{isth}=\\alpha +X_{sith}\\beta +u_{sith}.\\,}": {
    "before": "where i is the individual dimension, s is the series dimension, t is the time dimension, and h is the horizon dimension. A general multidimensional panel data regression model is written as",
    "after": "Complex assumptions can be made on the precise structure of the correlations among errors in this model. For example, serial correlation (error terms correlated across time) has multiple distinct meanings. Error terms can be correlated across time for the same series, individual, and horizon. They can be correlated across time and across series for the same individual and horizon, etc. Similarly, heteroskedasticity can be defined across individuals for the same series, time, and horizon, across individuals and different series for the same time and horizon, etc.",
    "url": "https://en.wikipedia.org/wiki/Multidimensional panel data"
  },
  "To set this template's initial visibility, the |state= parameter may be used:": {
    "before": "Initial visibility: currently defaults to autocollapse",
    "after": "|state=collapsed: {{Anarchist revolution|state=collapsed}} to show the template collapsed, i.e., hidden apart from its title bar",
    "url": "https://en.wikipedia.org/wiki/Template:Anarchist revolution"
  },
  "|state=collapsed: {{Nobel Memorial Prize in Economic Sciences laureates|state=collapsed}} to show the template collapsed, i.e., hidden apart from its title bar": {
    "before": "To set this template's initial visibility, the |state= parameter may be used:",
    "after": "|state=expanded: {{Nobel Memorial Prize in Economic Sciences laureates|state=expanded}} to show the template expanded, i.e., fully visible",
    "url": "https://en.wikipedia.org/wiki/Template:Nobel Memorial Prize in Economic Sciences laureates"
  },
  "|state=expanded: {{Nobel Memorial Prize in Economic Sciences laureates|state=expanded}} to show the template expanded, i.e., fully visible": {
    "before": "|state=collapsed: {{Nobel Memorial Prize in Economic Sciences laureates|state=collapsed}} to show the template collapsed, i.e., hidden apart from its title bar",
    "after": "|state=autocollapse: {{Nobel Memorial Prize in Economic Sciences laureates|state=autocollapse}}",
    "url": "https://en.wikipedia.org/wiki/Template:Nobel Memorial Prize in Economic Sciences laureates"
  },
  "|state=autocollapse: {{Nobel Memorial Prize in Economic Sciences laureates|state=autocollapse}}": {
    "before": "|state=expanded: {{Nobel Memorial Prize in Economic Sciences laureates|state=expanded}} to show the template expanded, i.e., fully visible",
    "after": "shows the template collapsed to the title bar if there is a {{navbox}}, a {{sidebar}}, or some other table on the page with the collapsible attribute",
    "url": "https://en.wikipedia.org/wiki/Template:Nobel Memorial Prize in Economic Sciences laureates"
  },
  "If the |state= parameter in the template on this page is not set, the template's initial visibility is taken from the |default= parameter in the Collapsible option template. For the template on this page, that currently evaluates to autocollapse.": {
    "before": "shows the template in its expanded state if there are no other collapsible items on the page",
    "after": "Retrieved from \"https://en.wikipedia.org/w/index.php?title=Template:Anarchist_revolution&oldid=1100360916\"",
    "url": "https://en.wikipedia.org/wiki/Template:Anarchist revolution"
  },
  "{\\displaystyle Y=g(X)+U} ( 1 )": {
    "before": "Assume we start from a standard endogenous variable setup with additive errors, where X is an endogenous variable, and Z is an exogenous variable that can serve as an instrument.",
    "after": "{\\displaystyle X=\\pi (Z)+V} ( 2 )",
    "url": "https://en.wikipedia.org/wiki/Endogeneity with an exponential regression function"
  },
  "{\\displaystyle X=\\pi (Z)+V} ( 2 )": {
    "before": "{\\displaystyle Y=g(X)+U} ( 1 )",
    "after": "{\\displaystyle E[U\\mid Z,V]=E[U\\mid V]} ( 3 )",
    "url": "https://en.wikipedia.org/wiki/Endogeneity with an exponential regression function"
  },
  "{\\displaystyle E[U\\mid Z,V]=E[U\\mid V]} ( 3 )": {
    "before": "{\\displaystyle X=\\pi (Z)+V} ( 2 )",
    "after": "{\\displaystyle E[V\\mid Z]=0} ( 4 )",
    "url": "https://en.wikipedia.org/wiki/Endogeneity with an exponential regression function"
  },
  "{\\displaystyle E[Y\\mid Z,V]=g(X)+E[U\\mid Z,V]=g(X)+E[U\\mid V]=g(X)+h(V)} ( 5 )": {
    "before": "A popular instrumental variable approach is to use a two-step procedure and estimate equation ( 2 ) first and then use the estimates of this first step to estimate equation ( 1 ) in a second step. The control function, however, uses that this model implies",
    "after": "The function h ( V ) is effectively the control function that models the endogeneity and where this econometric approach lends its name from. ",
    "url": "https://en.wikipedia.org/wiki/Endogeneity with an exponential regression function"
  },
  "{\\displaystyle E[Y_{1}\\mid X,Z,D=1]=\\mu _{1}(X)+E[U\\mid D=1]} ( 6 )": {
    "before": "In a Rubin causal model potential outcomes framework, where Y 1 is the outcome variable of people for who the participation indicator D equals 1, the control function approach leads to the following model",
    "after": "as long as the potential outcomes Y 0 and Y 1 are independent of D conditional on X and Z . ",
    "url": "https://en.wikipedia.org/wiki/Endogeneity with an exponential regression function"
  },
  "{\\displaystyle \\operatorname {E} [y_{i}\\mid x_{i},z_{i},a_{i}]=\\exp(x_{i}b_{0}+z_{i}c_{0}+a_{i})}": {
    "before": "Assume the following exponential regression model, where {\\displaystyle a_{i}} is an unobserved term in the latent variable. We allow for correlation between {\\displaystyle a_{i}} and {\\displaystyle x_{i}} (implying {\\displaystyle x_{i}} is possibly endogenous), but allow for no such correlation between {\\displaystyle a_{i}} and {\\displaystyle z_{i}} .",
    "after": "The variables {\\displaystyle z_{i}} serve as instrumental variables for the potentially endogenous {\\displaystyle x_{i}} . One can assume a linear relationship between these two variables or alternatively project the endogenous variable {\\displaystyle x_{i}} onto the instruments to get the following reduced form equation:",
    "url": "https://en.wikipedia.org/wiki/Endogeneity with an exponential regression function"
  },
  "{\\displaystyle x_{i}=z_{i}\\Pi +v_{i}} ( 1 )": {
    "before": "The variables {\\displaystyle z_{i}} serve as instrumental variables for the potentially endogenous {\\displaystyle x_{i}} . One can assume a linear relationship between these two variables or alternatively project the endogenous variable {\\displaystyle x_{i}} onto the instruments to get the following reduced form equation:",
    "after": "The usual rank condition is needed to ensure identification. The endogeneity is then modeled in the following way, where {\\displaystyle \\rho } determines the severity of endogeneity and {\\displaystyle v_{i}} is assumed to be independent of {\\displaystyle e_{i}} .",
    "url": "https://en.wikipedia.org/wiki/Endogeneity with an exponential regression function"
  },
  "{\\displaystyle a_{i}=v_{i}\\rho +e_{i}}": {
    "before": "The usual rank condition is needed to ensure identification. The endogeneity is then modeled in the following way, where {\\displaystyle \\rho } determines the severity of endogeneity and {\\displaystyle v_{i}} is assumed to be independent of {\\displaystyle e_{i}} .",
    "after": "Imposing these assumptions, assuming the models are correctly specified, and normalizing {\\displaystyle \\operatorname {E} [\\exp(e_{i})]=1} , we can rewrite the conditional mean as follows:",
    "url": "https://en.wikipedia.org/wiki/Endogeneity with an exponential regression function"
  },
  "{\\displaystyle \\operatorname {E} [y_{i}\\mid x_{i},z_{i},v_{i}]=\\exp(x_{i}b_{0}+z_{i}c_{0}+v_{i}\\rho )} ( 2 )": {
    "before": "Imposing these assumptions, assuming the models are correctly specified, and normalizing {\\displaystyle \\operatorname {E} [\\exp(e_{i})]=1} , we can rewrite the conditional mean as follows:",
    "after": "If {\\displaystyle v_{i}} were known at this point, it would be possible to estimate the relevant parameters by quasi-maximum likelihood estimation (QMLE). Following the two step procedure strategies, Wooldridge and Terza propose estimating equation ( 1 ) by ordinary least squares . The fitted residuals from this regression can then be plugged into the estimating equation ( 2 ) and QMLE methods will lead to consistent estimators of the parameters of interest. Significance tests on {\\displaystyle {\\hat {\\rho }}} can then be used to test for endogeneity within the model.",
    "url": "https://en.wikipedia.org/wiki/Endogeneity with an exponential regression function"
  },
  "{\\displaystyle z={\\frac {T-{\\frac {2n-4}{3}}}{\\sqrt {\\frac {16n-29}{90}}}}}": {
    "before": "Letting T be the number of turning points then for large n , T is approximately normally distributed with mean (2 n − 4)/3 and variance (16 n − 29)/90. The test statistic ",
    "after": "is approximately standard normal for large values of n.",
    "url": "https://en.wikipedia.org/wiki/Turning point test"
  },
  "summarize mpg if foreign == 1 // Summary information about mpg if the car is foreign (the \"==\" sign tests for equality)": {
    "before": "tabulate rep78 foreign, row // Two-way frequency table for variables rep78 and foreign",
    "after": "by foreign, sort: summarize mpg // As above, but using the \"by\" prefix.",
    "url": "https://en.wikipedia.org/wiki/Stata"
  },
  "generate wtsq = weight^2 // Create a new variable for weight squared": {
    "before": "Linear regression:",
    "after": "regress mpg weight wtsq foreign, vce(robust) // Linear regression of mpg on weight, wtsq, and foreign",
    "url": "https://en.wikipedia.org/wiki/Stata"
  },
  "{\\displaystyle {\\text{PoS}}={\\frac {\\text{value of best Nash equilibrium}}{\\text{value of optimal solution}}},\\ {\\text{PoS}}\\geq 0.}": {
    "before": "Examples [ edit ]Another way of expressing PoS is:",
    "after": "In particular, if the optimal solution is a Nash equilibrium, then the PoS is 1.",
    "url": "https://en.wikipedia.org/wiki/Price of stability"
  },
  "{\\displaystyle \\Phi (S)=\\sum _{e\\in S}\\sum _{i=1}^{n_{e}}{\\frac {c_{e}}{i}}=\\sum _{e\\in S}c_{e}H_{n_{e}}\\leq \\sum _{e\\in S}c_{e}H_{n}=H_{n}\\cdot SC(S).}": {
    "before": "Now recall that the social cost was defined as the sum of costs over edges, so",
    "after": "We trivially have {\\displaystyle A=1} , and the computation above gives {\\displaystyle B=H_{n}} , so we may invoke the theorem for an upper bound on the price of stability.",
    "url": "https://en.wikipedia.org/wiki/Price of stability"
  },
  "we have PoS = PoA = 1/2.": {
    "before": "{\\displaystyle (B,R)}",
    "after": "Prisoner's Dilemma",
    "url": "https://en.wikipedia.org/wiki/Price of stability"
  },
  ", with values 3 and 15, respectively. The optimal value is 15. Thus, PoS = 1 while PoA = 1/5.": {
    "before": "{\\displaystyle (B,R)}",
    "after": "Left",
    "url": "https://en.wikipedia.org/wiki/Price of stability"
  },
  "{\\displaystyle U_{x}(x_{1},x_{2};y_{2})=p_{1}x_{1}+(1-x_{2}-y_{2})x_{2}-(x_{1}+x_{2})^{2}/2-F}": {
    "before": "In their original paper, Bulow et al. use a simple model of competition between two firms to illustrate their ideas. The revenue for firm x with production rates {\\displaystyle (x_{1},x_{2})} is given by",
    "after": "while the revenue for firm y with production rate {\\displaystyle y_{2}} in market 2 is given by",
    "url": "https://en.wikipedia.org/wiki/Strategic complements"
  },
  "{\\displaystyle U_{y}(y_{2};x_{1},x_{2})=(1-x_{2}-y_{2})y_{2}-y_{2}^{2}/2-F}": {
    "before": "while the revenue for firm y with production rate {\\displaystyle y_{2}} in market 2 is given by",
    "after": "At any interior equilibrium, {\\displaystyle (x_{1}^{*},x_{2}^{*},y_{2}^{*})} , we must have",
    "url": "https://en.wikipedia.org/wiki/Strategic complements"
  },
  "{\\displaystyle {\\dfrac {\\partial U_{x}}{\\partial x_{1}}}=0,{\\dfrac {\\partial U_{x}}{\\partial x_{2}}}=0,{\\dfrac {\\partial U_{y}}{\\partial y_{2}}}=0.}": {
    "before": "At any interior equilibrium, {\\displaystyle (x_{1}^{*},x_{2}^{*},y_{2}^{*})} , we must have",
    "after": "Using vector calculus, geometric algebra, or differential geometry, Bulow et al. showed that the sensitivity of the Cournot equilibrium to changes in {\\displaystyle p_{1}} can be calculated in terms of second partial derivatives of the payoff functions:",
    "url": "https://en.wikipedia.org/wiki/Strategic complements"
  },
  "{\\displaystyle {\\begin{bmatrix}{\\dfrac {dx_{1}^{*}}{dp_{1}}}\\\\[2.2ex]{\\dfrac {dx_{2}^{*}}{dp_{1}}}\\\\[2.2ex]{\\dfrac {dy_{2}^{*}}{dp_{1}}}\\end{bmatrix}}={\\begin{bmatrix}{\\dfrac {\\partial ^{2}U_{x}}{\\partial x_{1}\\partial x_{1}}}&{\\dfrac {\\partial ^{2}U_{x}}{\\partial x_{1}\\partial x_{2}}}&{\\dfrac {\\partial ^{2}U_{x}}{\\partial x_{1}\\partial y_{2}}}\\\\[2.2ex]{\\dfrac {\\partial ^{2}U_{x}}{\\partial x_{1}\\partial x_{2}}}&{\\dfrac {\\partial ^{2}U_{x}}{\\partial x_{2}\\partial x_{2}}}&{\\dfrac {\\partial ^{2}U_{x}}{\\partial y_{2}\\partial x_{2}}}\\\\[2.2ex]{\\dfrac {\\partial ^{2}U_{y}}{\\partial x_{1}\\partial y_{2}}}&{\\dfrac {\\partial ^{2}U_{y}}{\\partial x_{2}\\partial y_{2}}}&{\\dfrac {\\partial ^{2}U_{y}}{\\partial y_{2}\\partial y_{2}}}\\end{bmatrix}}^{-1}{\\begin{bmatrix}-{\\dfrac {\\partial ^{2}U_{x}}{\\partial p_{1}\\partial x_{1}}}\\\\[2.2ex]-{\\dfrac {\\partial ^{2}U_{x}}{\\partial p_{1}\\partial x_{2}}}\\\\[2.2ex]-{\\dfrac {\\partial ^{2}U_{y}}{\\partial p_{1}\\partial y_{2}}}\\end{bmatrix}}}": {
    "before": "Using vector calculus, geometric algebra, or differential geometry, Bulow et al. showed that the sensitivity of the Cournot equilibrium to changes in {\\displaystyle p_{1}} can be calculated in terms of second partial derivatives of the payoff functions:",
    "after": "When {\\displaystyle 1/4\\leq p_{1}\\leq 2/3} ,",
    "url": "https://en.wikipedia.org/wiki/Strategic complements"
  },
  "{\\displaystyle {\\begin{bmatrix}{\\dfrac {dx_{1}^{*}}{dp_{1}}}\\\\[2.2ex]{\\dfrac {dx_{2}^{*}}{dp_{1}}}\\\\[2.2ex]{\\dfrac {dy_{2}^{*}}{dp_{1}}}\\end{bmatrix}}={\\begin{bmatrix}-1&-1&0\\\\-1&-3&-1\\\\0&-1&-3\\end{bmatrix}}^{-1}{\\begin{bmatrix}-1\\\\0\\\\0\\end{bmatrix}}={\\frac {1}{5}}{\\begin{bmatrix}8\\\\-3\\\\1\\end{bmatrix}}}": {
    "before": "{\\displaystyle {\\begin{bmatrix}{\\dfrac {dx_{1}^{*}}{dp_{1}}}\\\\[2.2ex]{\\dfrac {dx_{2}^{*}}{dp_{1}}}\\\\[2.2ex]{\\dfrac {dy_{2}^{*}}{dp_{1}}}\\end{bmatrix}}={\\begin{bmatrix}{\\dfrac {\\partial ^{2}U_{x}}{\\partial x_{1}\\partial x_{1}}}&{\\dfrac {\\partial ^{2}U_{x}}{\\partial x_{1}\\partial x_{2}}}&{\\dfrac {\\partial ^{2}U_{x}}{\\partial x_{1}\\partial y_{2}}}\\\\[2.2ex]{\\dfrac {\\partial ^{2}U_{x}}{\\partial x_{1}\\partial x_{2}}}&{\\dfrac {\\partial ^{2}U_{x}}{\\partial x_{2}\\partial x_{2}}}&{\\dfrac {\\partial ^{2}U_{x}}{\\partial y_{2}\\partial x_{2}}}\\\\[2.2ex]{\\dfrac {\\partial ^{2}U_{y}}{\\partial x_{1}\\partial y_{2}}}&{\\dfrac {\\partial ^{2}U_{y}}{\\partial x_{2}\\partial y_{2}}}&{\\dfrac {\\partial ^{2}U_{y}}{\\partial y_{2}\\partial y_{2}}}\\end{bmatrix}}^{-1}{\\begin{bmatrix}-{\\dfrac {\\partial ^{2}U_{x}}{\\partial p_{1}\\partial x_{1}}}\\\\[2.2ex]-{\\dfrac {\\partial ^{2}U_{x}}{\\partial p_{1}\\partial x_{2}}}\\\\[2.2ex]-{\\dfrac {\\partial ^{2}U_{y}}{\\partial p_{1}\\partial y_{2}}}\\end{bmatrix}}} When {\\displaystyle 1/4\\leq p_{1}\\leq 2/3} ,",
    "after": "This, as price is increased in market 1, Firm x sells more in market 1 and less in market 2, while firm y sells more in market 2. If the Cournot equilibrium of this model is calculated explicitly, we find",
    "url": "https://en.wikipedia.org/wiki/Strategic complements"
  },
  "{\\displaystyle x_{1}^{*}=\\max \\left\\{0,{\\frac {8p_{1}-2}{5}}\\right\\},x_{2}^{*}=\\max \\left\\{0,{\\frac {2-3p_{1}}{5}}\\right\\},y_{2}^{*}={\\frac {p_{1}+1}{5}}.}": {
    "before": "This, as price is increased in market 1, Firm x sells more in market 1 and less in market 2, while firm y sells more in market 2. If the Cournot equilibrium of this model is calculated explicitly, we find",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Strategic complements"
  },
  "PED mi = nPED m - (n - 1) PES": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Demand"
  },
  "PED mi = (80 x (-1)) - (79 x 3) = -80 - 237 = -317": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Demand"
  },
  "Dr(p) = D(p) - So(p)": {
    "before": "The demand curve facing a particular firm is called the residual demand curve. The residual demand curve is the market demand that is not met by other firms in the industry at a given price. The residual demand curve is the market demand curve D(p), minus the supply of other organizations, So(p):",
    "after": "Demand function and total revenue[edit]",
    "url": "https://en.wikipedia.org/wiki/Demand"
  },
  "{\\displaystyle {\\dot {x_{i}}}=x_{i}\\left(\\left(Ax\\right)_{i}-x^{T}Ax\\right)}": {
    "before": "To simplify analysis, fitness is often assumed to depend linearly upon the population distribution, which allows the replicator equation to be written in the form:",
    "after": "where the payoff matrix {\\displaystyle A} holds all the fitness information for the population: the expected payoff can be written as {\\displaystyle \\left(Ax\\right)_{i}} and the mean fitness of the population as a whole can be written as {\\displaystyle x^{T}Ax} . It can be shown that the change in the ratio of two proportions {\\displaystyle x_{i}/x_{j}} with respect to time is:",
    "url": "https://en.wikipedia.org/wiki/Replicator equation"
  },
  "{\\displaystyle x_{i}={\\frac {y_{i}}{1+\\sum _{j=1}^{n-1}{y_{j}}}}\\quad i=1,\\ldots ,n-1} {\\displaystyle x_{n}={\\frac {1}{1+\\sum _{j=1}^{n-1}{y_{j}}}},}": {
    "before": "The continuous replicator equation on {\\displaystyle n} types is equivalent to the Generalized Lotka–Volterra equation in {\\displaystyle n-1} dimensions.   The transformation is made by the change of variables:",
    "after": "where {\\displaystyle y_{i}} is the Lotka–Volterra variable. The continuous replicator dynamic is also equivalent to the Price equation . ",
    "url": "https://en.wikipedia.org/wiki/Replicator equation"
  },
  "{\\displaystyle x'_{i}=x_{i}+x_{i}\\left[\\left(Ax\\right)_{i}-x^{T}Ax\\right]\\,({\\rm {type~I),}}} {\\displaystyle x'_{i}=x_{i}\\left[{\\frac {\\left(Ax\\right)_{i}}{x^{T}Ax}}\\right]\\,({\\rm {type~II),}}}": {
    "before": "When one considers an unstructured infinite population with non-overlapping generations, one should work with the discrete forms of the replicator equation. Mathematically, two simple phenomenological versions---",
    "after": "---are consistent with the Darwinian tenet of natural selection or any analogous evolutionary phenomena. Here, prime stands for the next time step. However, the discrete nature of the equations puts bounds on the payoff-matrix elements.  Interestingly, for the simple case of two-player-two-strategy games, the type I replicator map is capable of showing period doubling bifurcation leading to chaos and it also gives a hint on how to generalize  the concept of the evolutionary stable state to accommodate the periodic solutions of the map.",
    "url": "https://en.wikipedia.org/wiki/Replicator equation"
  },
  "{\\displaystyle {\\dot {x_{i}}}=\\sum _{j=1}^{n}{x_{j}f_{j}(x)Q_{ji}}-\\phi (x)x_{i},}": {
    "before": "A generalization of the replicator equation which incorporates mutation is given by the replicator-mutator equation, which takes the following form in the continuous version: ",
    "after": "where the matrix {\\displaystyle Q} gives the transition probabilities for the mutation of type {\\displaystyle j} to type {\\displaystyle i} , {\\displaystyle f_{i}} is the fitness of the {\\displaystyle i^{th}} and {\\displaystyle \\phi } is the mean fitness of the population. This equation is a simultaneous generalization of the replicator equation and the quasispecies equation, and is used in the mathematical analysis of language.",
    "url": "https://en.wikipedia.org/wiki/Replicator equation"
  },
  "{\\displaystyle x'_{i}=x_{i}+\\sum _{j=1}^{n}{x_{j}f_{j}(x)Q_{ji}}-\\phi (x)x_{i},}": {
    "before": "The discrete version of the replicator-mutator equation may have two simple types in line with the two replicator maps written above:",
    "after": "and {\\displaystyle x'_{i}=x_{i}+{\\frac {\\sum _{j=1}^{n}{x_{j}f_{j}(x)Q_{ji}}}{\\phi (x)}},}",
    "url": "https://en.wikipedia.org/wiki/Replicator equation"
  },
  "{\\displaystyle x'_{i}=x_{i}+{\\frac {\\sum _{j=1}^{n}{x_{j}f_{j}(x)Q_{ji}}}{\\phi (x)}},}": {
    "before": "{\\displaystyle x'_{i}=x_{i}+\\sum _{j=1}^{n}{x_{j}f_{j}(x)Q_{ji}}-\\phi (x)x_{i},} and",
    "after": "respectively.The replicator equation or the replicator-mutator equation can be extended  to include the effect of delay that either corresponds to the delayed information about the population state or in realizing the effect of interaction among players. The replicator equation can also easily be generalized to asymmetric games . A recent generalization that incorporates population structure is used in evolutionary graph theory . ",
    "url": "https://en.wikipedia.org/wiki/Replicator equation"
  },
  "{\\displaystyle {\\dot {x_{i}}}=x_{i}[f_{i}(x)-\\phi (x)],\\quad \\phi (x)=\\sum _{j=1}^{n}{x_{j}f_{j}(x)}}": {
    "before": "{\\displaystyle {\\dot {x_{i}}}=x_{i}[f_{i}(x)-\\phi (x)],\\quad \\phi (x)=\\sum _{j=1}^{n}{x_{j}f_{j}(x)}}",
    "after": "{\\displaystyle {\\dot {x_{i}}}=x_{i}[f_{i}(x)-\\phi (x)],\\quad \\phi (x)=\\sum _{j=1}^{n}{x_{j}f_{j}(x)}}",
    "url": "https://en.wikipedia.org/wiki/Replicator equation"
  },
  "{\\displaystyle E_{21}={\\frac {d\\ln(c_{2}/c_{1})}{d\\ln(MRS_{12})}}={\\frac {d\\ln(c_{2}/c_{1})}{d\\ln(U_{c_{1}}/U_{c_{2}})}}={\\frac {\\frac {d(c_{2}/c_{1})}{c_{2}/c_{1}}}{\\frac {d(U_{c_{1}}/U_{c_{2}})}{U_{c_{1}}/U_{c_{2}}}}}={\\frac {\\frac {d(c_{2}/c_{1})}{c_{2}/c_{1}}}{\\frac {d(p_{1}/p_{2})}{p_{1}/p_{2}}}}}": {
    "before": "Let the utility over consumption be given by {\\displaystyle U(c_{1},c_{2})} and let {\\displaystyle U_{c_{i}}=\\partial U(c_{1},c_{2})/\\partial {c_{i}}} . Then the elasticity of substitution is:",
    "after": "where {\\displaystyle MRS} is the marginal rate of substitution . (These differentials are taken along the isoquant that passes through the base point. That is, the inputs {\\displaystyle c_{1}} and {\\displaystyle c_{2}} are not varied independently, but instead one input is varied freely while the other input is constrained to lie on the isoquant that passes through the base point. Because of this constraint, the MRS and the ratio of inputs are one-to-one functions of each other under suitable convexity assumptions.) The last equality presents {\\displaystyle MRS_{12}=p_{1}/p_{2}} , where {\\displaystyle p_{1},p_{2}} are the prices of goods 1 and 2. This is a relationship from the first order condition for a consumer utility maximization problem in Arrow–Debreu interior equilibrium, where the marginal utilities of two goods are proportional to prices. Intuitively we are looking at how a consumer's choices over consumption items change as their relative prices change.",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle E_{21}={\\frac {d\\ln(c_{2}/c_{1})}{d\\ln(U_{c_{1}}/U_{c_{2}})}}={\\frac {d\\left(-\\ln(c_{2}/c_{1})\\right)}{d\\left(-\\ln(U_{c_{1}}/U_{c_{2}})\\right)}}={\\frac {d\\ln(c_{1}/c_{2})}{d\\ln(U_{c_{2}}/U_{c_{1}})}}=E_{12}}": {
    "before": "Note also that {\\displaystyle E_{21}=E_{12}} :",
    "after": "An equivalent characterization of the elasticity of substitution is: ",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle E_{21}={\\frac {d\\ln(c_{2}/c_{1})}{d\\ln(MRS_{12})}}=-{\\frac {d\\ln(c_{2}/c_{1})}{d\\ln(MRS_{21})}}=-{\\frac {d\\ln(c_{2}/c_{1})}{d\\ln(U_{c_{2}}/U_{c_{1}})}}=-{\\frac {\\frac {d(c_{2}/c_{1})}{c_{2}/c_{1}}}{\\frac {d(U_{c_{2}}/U_{c_{1}})}{U_{c_{2}}/U_{c_{1}}}}}=-{\\frac {\\frac {d(c_{2}/c_{1})}{c_{2}/c_{1}}}{\\frac {d(p_{2}/p_{1})}{p_{2}/p_{1}}}}}": {
    "before": "An equivalent characterization of the elasticity of substitution is: ",
    "after": "In discrete-time models, the elasticity of substitution of consumption in periods {\\displaystyle t} and {\\displaystyle t+1} is known as elasticity of intertemporal substitution .",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle \\sigma _{21}={\\frac {d\\ln(x_{2}/x_{1})}{d\\ln MRTS_{12}}}={\\frac {d\\ln(x_{2}/x_{1})}{d\\ln({\\frac {df}{dx_{1}}}/{\\frac {df}{dx_{2}}})}}={\\frac {\\frac {d(x_{2}/x_{1})}{x_{2}/x_{1}}}{\\frac {d({\\frac {df}{dx_{1}}}/{\\frac {df}{dx_{2}}})}{{\\frac {df}{dx_{1}}}/{\\frac {df}{dx_{2}}}}}}=-{\\frac {\\frac {d(x_{2}/x_{1})}{x_{2}/x_{1}}}{\\frac {d({\\frac {df}{dx_{2}}}/{\\frac {df}{dx_{1}}})}{{\\frac {df}{dx_{2}}}/{\\frac {df}{dx_{1}}}}}}}": {
    "before": "Similarly, if the production function is {\\displaystyle f(x_{1},x_{2})} then the elasticity of substitution is:",
    "after": "where {\\displaystyle MRTS} is the marginal rate of technical substitution .",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle MRTS_{21}={\\frac {1-a}{a}}{\\frac {x_{1}}{x_{2}}}}": {
    "before": "Consider Cobb–Douglas production function {\\displaystyle f(x_{1},x_{2})=x_{1}^{a}x_{2}^{1-a}} .The marginal rate of technical substitution is",
    "after": "It is convenient to change the notations. Denote",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle {\\frac {1-a}{a}}{\\frac {x_{1}}{x_{2}}}=\\theta }": {
    "before": "{\\displaystyle MRTS_{21}={\\frac {1-a}{a}}{\\frac {x_{1}}{x_{2}}}} It is convenient to change the notations. Denote",
    "after": "Rewriting this we have",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle {\\frac {x_{1}}{x_{2}}}={\\frac {a}{1-a}}\\theta }": {
    "before": "{\\displaystyle {\\frac {1-a}{a}}{\\frac {x_{1}}{x_{2}}}=\\theta } Rewriting this we have",
    "after": "Then the elasticity of substitution is ",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle \\sigma _{21}={\\frac {d\\ln({\\frac {x_{1}}{x_{2}}})}{d\\ln(MRTS_{21})}}={\\frac {d\\ln({\\frac {x_{1}}{x_{2}}})}{d\\ln(\\theta )}}={\\frac {d{\\frac {x_{1}}{x_{2}}}}{\\frac {x_{1}}{x_{2}}}}{\\frac {\\theta }{d\\theta }}={\\frac {d{\\frac {x_{1}}{x_{2}}}}{d\\theta }}{\\frac {\\theta }{\\frac {x_{1}}{x_{2}}}}={\\frac {a}{1-a}}{\\frac {1-a}{a}}{\\frac {x_{1}}{x_{2}}}{\\frac {x_{2}}{x_{1}}}=1}": {
    "before": "{\\displaystyle {\\frac {x_{1}}{x_{2}}}={\\frac {a}{1-a}}\\theta } Then the elasticity of substitution is ",
    "after": "Economic interpretation [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle {\\frac {dS_{21}}{d\\left(p_{2}/p_{1}\\right)}}={\\frac {c_{2}}{c_{1}}}+{\\frac {p_{2}}{p_{1}}}\\cdot {\\frac {d\\left(c_{2}/c_{1}\\right)}{d\\left(p_{2}/p_{1}\\right)}}={\\frac {c_{2}}{c_{1}}}\\left[1+{\\frac {d\\left(c_{2}/c_{1}\\right)}{d\\left(p_{2}/p_{1}\\right)}}\\cdot {\\frac {p_{2}/p_{1}}{c_{2}/c_{1}}}\\right]={\\frac {c_{2}}{c_{1}}}\\left(1-E_{21}\\right)}": {
    "before": "As the relative price {\\displaystyle p_{2}/p_{1}} changes, relative expenditure changes according to:",
    "after": "Thus, whether or not an increase in the relative price of {\\displaystyle c_{2}} leads to an increase or decrease in the relative expenditure on {\\displaystyle c_{2}} depends on whether the elasticity of substitution is less than or greater than one.",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle \\ {\\frac {d(x_{2}/x_{1})}{x_{2}/x_{1}}}=d\\log(x_{2}/x_{1})=d\\log x_{2}-d\\log x_{1}=-(d\\log x_{1}-d\\log x_{2})=-d\\log(x_{1}/x_{2})=-{\\frac {d(x_{1}/x_{2})}{x_{1}/x_{2}}}}": {
    "before": "Given that:",
    "after": "an equivalent way to define the elasticity of substitution is:",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle \\ \\sigma =-{\\frac {d(c_{1}/c_{2})}{dMRS}}{\\frac {MRS}{c_{1}/c_{2}}}=-{\\frac {d\\log(c_{1}/c_{2})}{d\\log MRS}}} .": {
    "before": "an equivalent way to define the elasticity of substitution is:",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Elasticity of substitution"
  },
  "{\\displaystyle X_{t}-\\alpha _{1}X_{t-1}-\\dots -\\alpha _{p'}X_{t-p'}=\\varepsilon _{t}+\\theta _{1}\\varepsilon _{t-1}+\\cdots +\\theta _{q}\\varepsilon _{t-q},}": {
    "before": "Given time series data X t where t is an integer index and the X t are real numbers, an {\\displaystyle {\\text{ARIMA}}(p',q)} model is given by",
    "after": "or equivalently by",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle \\left(1-\\sum _{i=1}^{p'}\\alpha _{i}L^{i}\\right)X_{t}=\\left(1+\\sum _{i=1}^{q}\\theta _{i}L^{i}\\right)\\varepsilon _{t}\\,}": {
    "before": "{\\displaystyle X_{t}-\\alpha _{1}X_{t-1}-\\dots -\\alpha _{p'}X_{t-p'}=\\varepsilon _{t}+\\theta _{1}\\varepsilon _{t-1}+\\cdots +\\theta _{q}\\varepsilon _{t-q},} or equivalently by",
    "after": "where {\\displaystyle L} is the lag operator , the {\\displaystyle \\alpha _{i}} are the parameters of the autoregressive part of the model, the {\\displaystyle \\theta _{i}} are the parameters of the moving average part and the {\\displaystyle \\varepsilon _{t}} are error terms. The error terms {\\displaystyle \\varepsilon _{t}} are generally assumed to be independent, identically distributed variables sampled from a normal distribution with zero mean.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle \\left(1-\\sum _{i=1}^{p'}\\alpha _{i}L^{i}\\right)=\\left(1-\\sum _{i=1}^{p'-d}\\varphi _{i}L^{i}\\right)\\left(1-L\\right)^{d}.}": {
    "before": "Assume now that the polynomial {\\displaystyle \\textstyle \\left(1-\\sum _{i=1}^{p'}\\alpha _{i}L^{i}\\right)} has a unit root (a factor {\\displaystyle (1-L)} ) of multiplicity d . Then it can be rewritten as:",
    "after": "An ARIMA( p , d , q ) process expresses this polynomial factorisation property with p = p'−d , and is given by:",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle \\left(1-\\sum _{i=1}^{p}\\varphi _{i}L^{i}\\right)(1-L)^{d}X_{t}=\\left(1+\\sum _{i=1}^{q}\\theta _{i}L^{i}\\right)\\varepsilon _{t}\\,}": {
    "before": "An ARIMA( p , d , q ) process expresses this polynomial factorisation property with p = p'−d , and is given by:",
    "after": "and thus can be thought as a particular case of an ARMA( p+d , q ) process having the autoregressive polynomial with d unit roots. (For this reason, no process that is accurately described by an ARIMA model with d > 0 is wide-sense stationary .)",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle \\left(1-\\sum _{i=1}^{p}\\varphi _{i}L^{i}\\right)(1-L)^{d}X_{t}=\\delta +\\left(1+\\sum _{i=1}^{q}\\theta _{i}L^{i}\\right)\\varepsilon _{t}.\\,}": {
    "before": "and thus can be thought as a particular case of an ARMA( p+d , q ) process having the autoregressive polynomial with d unit roots. (For this reason, no process that is accurately described by an ARIMA model with d > 0 is wide-sense stationary .)The above can be generalized as follows.",
    "after": "This defines an ARIMA( p , d , q ) process with drift {\\displaystyle {\\frac {\\delta }{1-\\sum \\varphi _{i}}}} .",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle y_{t}'=y_{t}-y_{t-1}\\,}": {
    "before": "To difference the data, the difference between consecutive observations is computed. Mathematically, this is shown as",
    "after": "Differencing removes the changes in the level of a time series, eliminating trend and seasonality and consequently stabilizing the mean of the time series. ",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle {\\begin{aligned}y_{t}^{*}&=y_{t}'-y_{t-1}'\\\\&=(y_{t}-y_{t-1})-(y_{t-1}-y_{t-2})\\\\&=y_{t}-2y_{t-1}+y_{t-2}\\end{aligned}}}": {
    "before": "Sometimes it may be necessary to difference the data a second time to obtain a stationary time series, which is referred to as second-order differencing :",
    "after": "Another method of differencing data is seasonal differencing, which involves computing the difference between an observation and the corresponding observation in the previous season e.g a year. This is shown as:",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle y_{t}'=y_{t}-y_{t-m}\\quad {\\text{where }}m={\\text{duration of season}}.}": {
    "before": "Another method of differencing data is seasonal differencing, which involves computing the difference between an observation and the corresponding observation in the previous season e.g a year. This is shown as:",
    "after": "The differenced data are then used for the estimation of an ARMA model.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle {\\text{AIC}}=-2\\log(L)+2(p+q+k),}": {
    "before": "Other alternative methods include AIC, BIC, etc.  To determine the order of a non-seasonal ARIMA model, a useful criterion is the Akaike information criterion (AIC) . It is written as",
    "after": "where L is the likelihood of the data, p is the order of the autoregressive part and q is the order of the moving average part. The k represents the intercept of the ARIMA model. For AIC, if k = 1 then there is an intercept in the ARIMA model ( c ≠ 0) and if k = 0 then there is no intercept in the ARIMA model ( c = 0).",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle {\\text{AICc}}={\\text{AIC}}+{\\frac {2(p+q+k)(p+q+k+1)}{T-p-q-k-1}}.}": {
    "before": "The corrected AIC for ARIMA models can be written as",
    "after": "The Bayesian Information Criterion (BIC) can be written as",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle {\\text{BIC}}={\\text{AIC}}+((\\log T)-2)(p+q+k).}": {
    "before": "The Bayesian Information Criterion (BIC) can be written as",
    "after": "The objective is to minimize the AIC, AICc or BIC values for a good model. The lower the value of one of these criteria for a range of models being investigated, the better the model will suit the data. The AIC and the BIC are used for two completely different purposes. While the AIC tries to approximate models towards the reality of the situation, the BIC attempts to find the perfect fit. The BIC approach is often criticized as there never is a perfect fit to real-life complex data; however, it is still a useful method for selection as it penalizes models more heavily for having more parameters than the AIC would.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle Y_{t}=(1-L)^{d}X_{t}}": {
    "before": "The ARIMA model can be viewed as a \"cascade\" of two models. The first is non-stationary:",
    "after": "while the second is wide-sense stationary :",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle \\left(1-\\sum _{i=1}^{p}\\varphi _{i}L^{i}\\right)Y_{t}=\\left(1+\\sum _{i=1}^{q}\\theta _{i}L^{i}\\right)\\varepsilon _{t}\\,.}": {
    "before": "{\\displaystyle Y_{t}=(1-L)^{d}X_{t}} while the second is wide-sense stationary :",
    "after": "Now forecasts can be made for the process {\\displaystyle Y_{t}} , using a generalization of the method of autoregressive forecasting .",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "{\\displaystyle v_{T+h\\,\\mid \\,T}={\\hat {\\sigma }}^{2}\\left[1+\\sum _{i=1}^{h-1}\\theta _{i}e_{t-i}\\right],{\\text{ for }}h=2,3,\\ldots } [ citation needed ]": {
    "before": "For ARIMA(0,0,q), {\\displaystyle y_{t}=e_{t}+\\sum _{i=1}^{q}\\theta _{i}e_{t-i}.}",
    "after": "In general, forecast intervals from ARIMA models will increase as the forecast horizon increases.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive integrated moving average"
  },
  "Observed test score = true score + errors of measurement": {
    "before": "This conceptual breakdown is typically represented by the simple equation:",
    "after": "Classical test theory [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Reliability (statistics)"
  },
  "{\\displaystyle \\sigma _{X}^{2}=\\sigma _{T}^{2}+\\sigma _{E}^{2}}": {
    "before": "Reliability theory shows that the variance of obtained scores is simply the sum of the variance of true scores plus the variance of errors of measurement . ",
    "after": "This equation suggests that test scores vary as the result of two factors:",
    "url": "https://en.wikipedia.org/wiki/Reliability (statistics)"
  },
  "{\\displaystyle \\rho _{xx'}={\\frac {\\sigma _{T}^{2}}{\\sigma _{X}^{2}}}=1-{\\frac {\\sigma _{E}^{2}}{\\sigma _{X}^{2}}}}": {
    "before": "The reliability coefficient {\\displaystyle \\rho _{xx'}} provides an index of the relative influence of true and error scores on attained test scores. In its general form, the reliability coefficient is defined as the ratio of true score variance to the total variance of test scores. Or, equivalently, one minus the ratio of the variation of the error score and the variation of the observed score :",
    "after": "Unfortunately, there is no way to directly observe or calculate the true score , so a variety of methods are used to estimate the reliability of a test.",
    "url": "https://en.wikipedia.org/wiki/Reliability (statistics)"
  },
  "{\\displaystyle R(t)=1-F(t).}": {
    "before": "Reliability may be improved by clarity of expression (for written assessments), lengthening the measure,  and other informal means. However, formal psychometric analysis, called item analysis, is considered the most effective way to increase reliability. This analysis consists of computation of item difficulties and item discrimination indices, the latter index involving computation of correlations between the items and sum of the item scores of the entire test. If items that are too difficult, too easy, and/or have near-zero or negative discrimination are replaced with better items, the reliability of the measure will increase.",
    "after": "{\\displaystyle R(t)=\\exp(-\\lambda t).} (where {\\displaystyle \\lambda } is the failure rate)",
    "url": "https://en.wikipedia.org/wiki/Reliability (statistics)"
  },
  "{\\displaystyle y_{t}-\\rho y_{t-1}=\\alpha (1-\\rho )+(X_{t}-\\rho X_{t-1})\\beta +e_{t},\\,}": {
    "before": "where {\\displaystyle y_{t}} is the time series of interest at time t , {\\displaystyle \\beta } is a vector of coefficients, {\\displaystyle X_{t}} is a matrix of explanatory variables , and {\\displaystyle \\varepsilon _{t}} is the error term . The error term can be serially correlated over time: {\\displaystyle \\varepsilon _{t}=\\rho \\varepsilon _{t-1}+e_{t},\\ |\\rho |<1} and {\\displaystyle e_{t}} is white noise. In addition to the Cochrane–Orcutt transformation, which is",
    "after": "for t = 2,3,..., T , the Prais-Winsten procedure makes a reasonable transformation for t = 1 in the following form:",
    "url": "https://en.wikipedia.org/wiki/Prais–Winsten estimation"
  },
  "{\\displaystyle {\\sqrt {1-\\rho ^{2}}}y_{1}=\\alpha {\\sqrt {1-\\rho ^{2}}}+\\left({\\sqrt {1-\\rho ^{2}}}X_{1}\\right)\\beta +{\\sqrt {1-\\rho ^{2}}}\\varepsilon _{1}.\\,}": {
    "before": "for t = 2,3,..., T , the Prais-Winsten procedure makes a reasonable transformation for t = 1 in the following form:",
    "after": "Then the usual least squares estimation is done.",
    "url": "https://en.wikipedia.org/wiki/Prais–Winsten estimation"
  },
  "{\\displaystyle \\mathrm {cov} (\\varepsilon _{t},\\varepsilon _{t+h})=\\rho ^{h}\\mathrm {var} (\\varepsilon _{t})={\\frac {\\rho ^{h}}{1-\\rho ^{2}}},{\\text{ for }}h=0,\\pm 1,\\pm 2,\\dots \\,.}": {
    "before": "Without loss of generality suppose the variance of the white noise is 1. To do the estimation in a compact way one must look at the autocovariance function of the error term considered in the model blow:",
    "after": "It is easy to see that the variance–covariance matrix , {\\displaystyle \\mathbf {\\Omega } } , of the model is",
    "url": "https://en.wikipedia.org/wiki/Prais–Winsten estimation"
  },
  "{\\displaystyle \\mathbf {\\Omega } ={\\begin{bmatrix}{\\frac {1}{1-\\rho ^{2}}}&{\\frac {\\rho }{1-\\rho ^{2}}}&{\\frac {\\rho ^{2}}{1-\\rho ^{2}}}&\\cdots &{\\frac {\\rho ^{T-1}}{1-\\rho ^{2}}}\\\\[8pt]{\\frac {\\rho }{1-\\rho ^{2}}}&{\\frac {1}{1-\\rho ^{2}}}&{\\frac {\\rho }{1-\\rho ^{2}}}&\\cdots &{\\frac {\\rho ^{T-2}}{1-\\rho ^{2}}}\\\\[8pt]{\\frac {\\rho ^{2}}{1-\\rho ^{2}}}&{\\frac {\\rho }{1-\\rho ^{2}}}&{\\frac {1}{1-\\rho ^{2}}}&\\cdots &{\\frac {\\rho ^{T-3}}{1-\\rho ^{2}}}\\\\[8pt]\\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\[8pt]{\\frac {\\rho ^{T-1}}{1-\\rho ^{2}}}&{\\frac {\\rho ^{T-2}}{1-\\rho ^{2}}}&{\\frac {\\rho ^{T-3}}{1-\\rho ^{2}}}&\\cdots &{\\frac {1}{1-\\rho ^{2}}}\\end{bmatrix}}.}": {
    "before": "It is easy to see that the variance–covariance matrix , {\\displaystyle \\mathbf {\\Omega } } , of the model is",
    "after": "Having {\\displaystyle \\rho } (or an estimate of it), we see that,",
    "url": "https://en.wikipedia.org/wiki/Prais–Winsten estimation"
  },
  "{\\displaystyle {\\hat {\\Theta }}=(\\mathbf {Z} ^{\\mathsf {T}}\\mathbf {\\Omega } ^{-1}\\mathbf {Z} )^{-1}(\\mathbf {Z} ^{\\mathsf {T}}\\mathbf {\\Omega } ^{-1}\\mathbf {Y} ),\\,}": {
    "before": "Having {\\displaystyle \\rho } (or an estimate of it), we see that,",
    "after": "where {\\displaystyle \\mathbf {Z} } is a matrix of observations on the independent variable ( X t , t = 1, 2, ..., T ) including a vector of ones, {\\displaystyle \\mathbf {Y} } is a vector stacking the observations on the dependent variable ( y t , t = 1, 2, ..., T ) and {\\displaystyle {\\hat {\\Theta }}} includes the model parameters.",
    "url": "https://en.wikipedia.org/wiki/Prais–Winsten estimation"
  },
  "{\\displaystyle \\mathbf {G} ={\\begin{bmatrix}{\\sqrt {1-\\rho ^{2}}}&0&0&\\cdots &0\\\\-\\rho &1&0&\\cdots &0\\\\0&-\\rho &1&\\cdots &0\\\\\\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\0&0&0&\\cdots &1\\end{bmatrix}}.}": {
    "before": "To see why the initial observation assumption stated by Prais–Winsten (1954) is reasonable, considering the mechanics of generalized least square estimation procedure sketched above is helpful. The inverse of {\\displaystyle \\mathbf {\\Omega } } can be decomposed as {\\displaystyle \\mathbf {\\Omega } ^{-1}=\\mathbf {G} ^{\\mathsf {T}}\\mathbf {G} } with ",
    "after": "A pre-multiplication of model in a matrix notation with this matrix gives the transformed model of Prais–Winsten.",
    "url": "https://en.wikipedia.org/wiki/Prais–Winsten estimation"
  },
  "{\\displaystyle \\mathrm {var} (\\varepsilon _{t})=\\mathrm {var} (\\rho \\varepsilon _{t-1}+e_{it})=\\rho ^{2}\\mathrm {var} (\\varepsilon _{t-1})+\\mathrm {var} (e_{it})}": {
    "before": "First notice that",
    "after": "Noting that for a stationary process, variance is constant over time,",
    "url": "https://en.wikipedia.org/wiki/Prais–Winsten estimation"
  },
  "{\\displaystyle (1-\\rho ^{2})\\mathrm {var} (\\varepsilon _{t})=\\mathrm {var} (e_{it})}": {
    "before": "Noting that for a stationary process, variance is constant over time,",
    "after": "and thus, {\\displaystyle \\mathrm {var} (\\varepsilon _{t})={\\frac {\\mathrm {var} (e_{it})}{(1-\\rho ^{2})}}}",
    "url": "https://en.wikipedia.org/wiki/Prais–Winsten estimation"
  },
  "{\\displaystyle \\mathrm {var} (\\varepsilon _{t})={\\frac {\\mathrm {var} (e_{it})}{(1-\\rho ^{2})}}}": {
    "before": "and thus,",
    "after": "Without loss of generality suppose the variance of the white noise is 1. To do the estimation in a compact way one must look at the autocovariance function of the error term considered in the model blow:",
    "url": "https://en.wikipedia.org/wiki/Prais–Winsten estimation"
  },
  "{\\displaystyle U(A)=\\sum \\limits _{j}P(A>O_{j})D(O_{j}),}": {
    "before": "In a 1981 article, Allan Gibbard and William Harper explained causal decision theory as maximization of the expected utility {\\displaystyle U} of an action {\\displaystyle A} \"calculated from probabilities of counterfactuals \": ",
    "after": "where {\\displaystyle D(O_{j})} is the desirability of outcome {\\displaystyle O_{j}} and {\\displaystyle P(A>O_{j})} is the counterfactual probability that, if {\\displaystyle A} were done, then {\\displaystyle O_{j}} would hold.",
    "url": "https://en.wikipedia.org/wiki/Causal decision theory"
  },
  "L ( x j ) = Max(Min(seq −1 ), Min(seq 0 ), Min(seq +1 ))": {
    "before": "Firstly we create ( n + 1) mini-sequences of length ( n + 1) each. Each of these mini-sequences contains the element x j . For example, for width 1, we create 2 mini-sequences of length 2 each. For width 1 these mini sequences are ( x j −1 , x j ) and ( x j , x j +1 ). For width 2, the mini-sequences are ( x j −2 , x j −1 , x j ), ( x j −1 , x j , x j +1 ) and ( x j , x j +1 , x j +2 ). For width 2, we refer to these mini-sequences as seq −1 , seq 0 and seq +1 Then we take the minimum of each of the mini sequences. Again for width 2 this gives: (Min(seq −1 ), Min(seq 0 ), Min(seq +1 )). This gives us ( n + 1) numbers for each point. Lastly we take the maximum of (the minimums of the mini sequences), or Max(Min(seq −1 ), Min(seq 0 ), Min(seq +1 )) and this becomes L ( x j )Thus for width 2, the L operator is:",
    "after": "U Operator [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Lulu smoothing"
  },
  "U ( x j ) = Min(Max(seq −1 ), Max(seq 0 ), Max(seq +1 ))": {
    "before": "This is identical to the L operator, except that the order of Min and Max is reversed, i.e. for width 2:",
    "after": "Examples [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Lulu smoothing"
  },
  "{\\displaystyle {\\begin{aligned}P(r)&=\\sum _{i=1}^{n}P\\left({\\text{applicant }}i{\\text{ is selected}}\\cap {\\text{applicant }}i{\\text{ is the best}}\\right)\\\\&=\\sum _{i=1}^{n}P\\left({\\text{applicant }}i{\\text{ is selected}}|{\\text{applicant }}i{\\text{ is the best}}\\right)\\cdot P\\left({\\text{applicant }}i{\\text{ is the best}}\\right)\\\\&=\\left[\\sum _{i=1}^{r-1}0+\\sum _{i=r}^{n}P\\left(\\left.{\\begin{array}{l}{\\text{the best of the first }}i-1{\\text{ applicants}}\\\\{\\text{is in the first }}r-1{\\text{ applicants}}\\end{array}}\\right|{\\text{applicant }}i{\\text{ is the best}}\\right)\\right]\\cdot {\\frac {1}{n}}\\\\&=\\left[\\sum _{i=r}^{n}{\\frac {r-1}{i-1}}\\right]\\cdot {\\frac {1}{n}}\\\\&={\\frac {r-1}{n}}\\sum _{i=r}^{n}{\\frac {1}{i-1}}.\\end{aligned}}}": {
    "before": "The optimal policy for the problem is a stopping rule . Under it, the interviewer rejects the first r − 1 applicants (let applicant M be the best applicant among these r − 1 applicants), and then selects the first subsequent applicant that is better than applicant M . It can be shown that the optimal strategy lies in this class of strategies. [ citation needed ] (Note that we should never choose an applicant who is not the best we have seen so far, since they cannot be the best overall applicant.) For an arbitrary cutoff r , the probability that the best applicant is selected is",
    "after": "The sum is not defined for r = 1, but in this case the only feasible policy is to select the first applicant, and hence P (1) = 1/ n . This sum is obtained by noting that if applicant i is the best applicant, then it is selected if and only if the best applicant among the first i − 1 applicants is among the first r − 1 applicants that were rejected. Letting n tend to infinity, writing {\\displaystyle x} as the limit of (r−1) / n , using t for (i−1) / n and dt for 1/ n , the sum can be approximated by the integral",
    "url": "https://en.wikipedia.org/wiki/Secretary problem"
  },
  "{\\displaystyle P(x)=x\\int _{x}^{1}{\\frac {1}{t}}\\,dt=-x\\ln(x)\\;.}": {
    "before": "The sum is not defined for r = 1, but in this case the only feasible policy is to select the first applicant, and hence P (1) = 1/ n . This sum is obtained by noting that if applicant i is the best applicant, then it is selected if and only if the best applicant among the first i − 1 applicants is among the first r − 1 applicants that were rejected. Letting n tend to infinity, writing {\\displaystyle x} as the limit of (r−1) / n , using t for (i−1) / n and dt for 1/ n , the sum can be approximated by the integral",
    "after": "Taking the derivative of P ( x ) with respect to {\\displaystyle x} , setting it to 0, and solving for x , we find that the optimal x is equal to 1/ e . Thus, the optimal cutoff tends to n / e as n increases, and the best applicant is selected with probability 1/ e .",
    "url": "https://en.wikipedia.org/wiki/Secretary problem"
  },
  "{\\displaystyle F(t)=\\int _{0}^{t}f(s)ds} , {\\displaystyle \\,0\\leq t\\leq T} .": {
    "before": "The model is defined as follows: An applicant must be selected on some time interval {\\displaystyle [0,T]} from an unknown number {\\displaystyle N} of rankable applicants. The goal is to maximize the probability of selecting only the best under the hypothesis that all arrival orders of different ranks are equally likely. Suppose that all applicants have the same, but independent to each other, arrival time density {\\displaystyle f} on {\\displaystyle [0,T]} and let {\\displaystyle F} denote the corresponding arrival time distribution function, that is",
    "after": "Let {\\displaystyle \\tau } be such that {\\displaystyle F(\\tau )=1/e.} Consider the strategy to wait and observe all applicants up to time {\\displaystyle \\tau } and then to select, if possible, the first candidate after time {\\displaystyle \\tau } which is better than all preceding ones. Then this strategy, called 1/e-strategy , has the following properties:",
    "url": "https://en.wikipedia.org/wiki/Secretary problem"
  },
  "{\\displaystyle E_{t}=E\\left(X_{t}|I_{t}=1\\right)={\\frac {t}{t+1}}.}": {
    "before": "Since the applicant's values are i.i.d. draws from a uniform distribution on [0, 1], the expected value of the t th applicant given that {\\displaystyle x_{t}=\\max \\left\\{x_{1},x_{2},\\ldots ,x_{t}\\right\\}} is given by",
    "after": "As in the classical problem, the optimal policy is given by a threshold, which for this problem we will denote by {\\displaystyle c} , at which the interviewer should begin accepting candidates. Bearden showed that c is either {\\displaystyle \\lfloor {\\sqrt {n}}\\rfloor } or {\\displaystyle \\lceil {\\sqrt {n}}\\rceil } .  (In fact, whichever is closest to {\\displaystyle {\\sqrt {n}}} .) This follows from the fact that given a problem with {\\displaystyle n} applicants, the expected payoff for some arbitrary threshold {\\displaystyle 1\\leq c\\leq n} is",
    "url": "https://en.wikipedia.org/wiki/Secretary problem"
  },
  "{\\displaystyle V_{n}(c)=\\sum _{t=c}^{n-1}\\left[\\prod _{s=c}^{t-1}\\left({\\frac {s-1}{s}}\\right)\\right]\\left({\\frac {1}{t+1}}\\right)+\\left[\\prod _{s=c}^{n-1}\\left({\\frac {s-1}{s}}\\right)\\right]{\\frac {1}{2}}={\\frac {2cn-{c}^{2}+c-n}{2cn}}.}": {
    "before": "As in the classical problem, the optimal policy is given by a threshold, which for this problem we will denote by {\\displaystyle c} , at which the interviewer should begin accepting candidates. Bearden showed that c is either {\\displaystyle \\lfloor {\\sqrt {n}}\\rfloor } or {\\displaystyle \\lceil {\\sqrt {n}}\\rceil } .  (In fact, whichever is closest to {\\displaystyle {\\sqrt {n}}} .) This follows from the fact that given a problem with {\\displaystyle n} applicants, the expected payoff for some arbitrary threshold {\\displaystyle 1\\leq c\\leq n} is",
    "after": "Differentiating {\\displaystyle V_{n}(c)} with respect to c , one gets",
    "url": "https://en.wikipedia.org/wiki/Secretary problem"
  },
  "{\\displaystyle {\\frac {\\partial V}{\\partial c}}={\\frac {-{c}^{\\,2}+n}{2{c}^{\\,2}n}}.}": {
    "before": "Differentiating {\\displaystyle V_{n}(c)} with respect to c , one gets",
    "after": "Learning in the partial-information sequential search paradigm. The numbers display the expected values of applicants based on their relative rank (out of m total applicants seen so far) at various points in the search. Expectations are calculated based on the case when their values are uniformly distributed between 0 and 1. Relative rank information allows the interviewer to more finely evaluate applicants as they accumulate more data points to compare them to.",
    "url": "https://en.wikipedia.org/wiki/Secretary problem"
  },
  "{\\displaystyle v(S)={\\begin{cases}|S|/2,&{\\text{if }}|S|{\\text{ is even}};\\\\(|S|-1)/2,&{\\text{if }}|S|{\\text{ is odd}}.\\end{cases}}}": {
    "before": "Consider a group of n miners, who have discovered large bars of gold. If two miners can carry one piece of gold, then the payoff of a coalition S is",
    "after": "If there are more than two miners and there is an even number of miners, then the core consists of the single payoff where each miner gets 1/2. If there is an odd number of miners, then the core is empty.",
    "url": "https://en.wikipedia.org/wiki/Core (game theory)"
  },
  "{\\displaystyle L_{j}(a)={\\frac {\\sum _{i:a_{i}=j}w_{i}}{s_{j}}}.}": {
    "before": "Each machine has a speed {\\displaystyle s_{1},\\ldots ,s_{M}>0.} Each job has a weight {\\displaystyle w_{1},\\ldots ,w_{N}>0.} A player picks a machine to run his or her job on. So, the strategies of each player are {\\displaystyle A_{i}=\\{1,2,\\ldots ,M\\}.} Define the load on machine {\\displaystyle j} to be:",
    "after": "The cost for player {\\displaystyle i} is {\\displaystyle c_{i}(a)=L_{a_{i}}(a),} i.e., the load of the machine they chose. We consider the egalitarian cost function {\\displaystyle {\\mbox{MS}}(a)=\\max _{j}L_{j}(a)} , here called the makespan .",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle \\sum _{p:\\,s_{i}\\rightarrow t_{i}}{f_{p}}=r_{i}\\;\\;\\forall (s_{i},t_{i})\\in \\Gamma .}": {
    "before": "Definition (Generalized flow) . Let {\\displaystyle G=(V,E)} , {\\displaystyle L} and {\\displaystyle w} be as defined above, and suppose that we want to route the quantities {\\displaystyle R=\\{r_{1},r_{2},\\dots ,r_{k},\\;|\\;r_{i}>0\\}} through each distinct pair of nodes in {\\displaystyle \\Gamma =\\{(s_{1},t_{1}),(s_{2},t_{2}),\\dots ,(s_{k},t_{k})\\}\\subseteq (V\\times V)} . A flow {\\displaystyle f_{\\Gamma ,R}} is defined as an assignment {\\displaystyle p\\mapsto \\Re } of a real, nonnegative number to each path {\\displaystyle p} going from {\\displaystyle s_{i}} to {\\displaystyle t_{i}} {\\displaystyle \\in \\Gamma } , with the constraint that",
    "after": "The flow traversing a specific edge of {\\displaystyle G} is defined as",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle f_{e,\\Gamma ,R}=\\sum _{p:\\,e\\in p}{f_{p}}.}": {
    "before": "The flow traversing a specific edge of {\\displaystyle G} is defined as",
    "after": "For succinctness, we write {\\displaystyle f_{e}} when {\\displaystyle \\Gamma ,R} are clear from context.",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle w^{f}(f^{*})=\\sum _{e\\in E}{f_{e}^{*}\\cdot l_{e}(f_{e})}}": {
    "before": "Definition (Conditional welfare of a flow) . Let {\\displaystyle f_{\\Gamma ,R}} and {\\displaystyle f_{\\Gamma ,R}^{*}} be two flows in {\\displaystyle G} associated with the same sets {\\displaystyle \\Gamma } and {\\displaystyle R} . In what follows, we will drop the subscript to make the notation clearer. Assume to fix the latencies induced by {\\displaystyle f} on the graph: the conditional welfare of {\\displaystyle f^{*}} with respect to {\\displaystyle f} is defined as",
    "after": "Fact 1 . Given a Nash-equilibrium flow {\\displaystyle f} and any other flow {\\displaystyle f^{*}} , {\\displaystyle w(f)=w^{f}(f)\\leq w^{f}(f^{*})} .",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle \\sum _{i=1}^{k}\\sum _{p:s_{i}\\rightarrow t_{i}}f_{p}^{*}\\cdot \\sum _{e\\in p}l_{e}(f_{e})<\\sum _{i=1}^{k}\\sum _{p:s_{i}\\rightarrow t_{i}}f_{p}\\cdot \\sum _{e\\in p}l_{e}(f_{e})} .": {
    "before": "Proof (By contradiction) . Assume that {\\displaystyle w^{f}(f^{*})<w^{f}(f)} . By definition,",
    "after": "Since {\\displaystyle f} and {\\displaystyle f^{*}} are associated with the same sets {\\displaystyle \\Gamma ,R} , we know that",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle \\sum _{p:s_{i}\\rightarrow t_{i}}f_{p}=\\sum _{p:s_{i}\\rightarrow t_{i}}f_{p}^{*}=r_{i}\\;\\;\\forall i.}": {
    "before": "Since {\\displaystyle f} and {\\displaystyle f^{*}} are associated with the same sets {\\displaystyle \\Gamma ,R} , we know that",
    "after": "Therefore, there must be a pair {\\displaystyle (s_{i},t_{i})} and two paths {\\displaystyle p,q} from {\\displaystyle s_{i}} to {\\displaystyle t_{i}} such that {\\displaystyle f_{p}^{*}>f_{p}} , {\\displaystyle f_{q}^{*}<f_{q}} , and",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle w^{f}(f^{*})=\\sum _{e\\in E}f_{e}^{*}(a_{e}\\cdot f_{e}+b_{e})}": {
    "before": "Proof . Note that this theorem is equivalent to saying that for each Nash-equilibrium flow {\\displaystyle f} , {\\displaystyle w(f)\\leq (4/3)\\cdot \\min _{f^{*}}\\{w(f^{*})\\}} , where {\\displaystyle f^{*}} is any other flow. By definition,",
    "after": "{\\displaystyle =\\sum _{e}(a_{e}f_{e}f_{e}^{*})+\\sum _{e\\in E}f_{e}^{*}b_{e}.}",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle =\\sum _{e}(a_{e}f_{e}f_{e}^{*})+\\sum _{e\\in E}f_{e}^{*}b_{e}.}": {
    "before": "{\\displaystyle w^{f}(f^{*})=\\sum _{e\\in E}f_{e}^{*}(a_{e}\\cdot f_{e}+b_{e})}",
    "after": "By using Fact 2, we have that",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle =\\left(\\sum _{e\\in E}a_{e}(f_{e}^{*})^{2}+f_{e}^{*}b_{e}\\right)+\\sum _{e\\in E}a_{e}(f_{e})^{2}/4}": {
    "before": "{\\displaystyle w^{f}(f^{*})\\leq \\sum _{e\\in E}\\left(a_{e}\\cdot \\left((f_{e}^{*})^{2}+(f_{e})^{2}/4\\right)\\right)+\\sum _{e\\in E}f_{e}^{*}\\cdot b_{e}}",
    "after": "{\\displaystyle \\leq w(f^{*})+{\\frac {w(f)}{4}},}",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle (1/4)\\cdot w(f)=(1/4)\\cdot \\sum _{e\\in E}f_{e}(a_{e}f_{e}+b_{e})}": {
    "before": "{\\displaystyle \\leq w(f^{*})+{\\frac {w(f)}{4}},} since",
    "after": "{\\displaystyle =(1/4)\\cdot \\sum _{e\\in E}(f_{e})^{2}+\\underbrace {(1/4)\\cdot \\sum _{e\\in E}f_{e}b_{e}} _{\\geq 0}.}",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle =(1/4)\\cdot \\sum _{e\\in E}(f_{e})^{2}+\\underbrace {(1/4)\\cdot \\sum _{e\\in E}f_{e}b_{e}} _{\\geq 0}.}": {
    "before": "{\\displaystyle (1/4)\\cdot w(f)=(1/4)\\cdot \\sum _{e\\in E}f_{e}(a_{e}f_{e}+b_{e})}",
    "after": "We can conclude that {\\displaystyle w^{f}(f^{*})\\leq w(f^{*})+w(f)/4} , and prove the thesis using Fact 1. Q.E.D.",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle w=\\left(1-{\\frac {1}{\\sqrt {d+1}}}\\right)^{d}\\cdot \\left(1-{\\frac {1}{\\sqrt {d+1}}}\\right)+1\\cdot {\\frac {1}{\\sqrt {d+1}}}}": {
    "before": "Note that the PoA can grow with {\\displaystyle d} . Consider the example shown in the following figure, where we assume unit flow: the Nash-equilibrium flows have social welfare 1; however, the best welfare is achieved when {\\displaystyle x=1-1/{\\sqrt {d+1}}} , in which case",
    "after": "{\\displaystyle =\\left(\\left(1-{\\frac {1}{\\sqrt {d+1}}}\\right)^{\\sqrt {d+1}}\\right)^{\\sqrt {d+1}}+{\\frac {1}{\\sqrt {d+1}}}}",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle =\\left(\\left(1-{\\frac {1}{\\sqrt {d+1}}}\\right)^{\\sqrt {d+1}}\\right)^{\\sqrt {d+1}}+{\\frac {1}{\\sqrt {d+1}}}}": {
    "before": "{\\displaystyle w=\\left(1-{\\frac {1}{\\sqrt {d+1}}}\\right)^{d}\\cdot \\left(1-{\\frac {1}{\\sqrt {d+1}}}\\right)+1\\cdot {\\frac {1}{\\sqrt {d+1}}}}",
    "after": "{\\displaystyle \\leq e^{-{\\sqrt {d+1}}}+{\\frac {1}{\\sqrt {d+1}}}.}",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle PoA={\\frac {\\max _{s\\in S}\\operatorname {Welf} (s)}{\\min _{s\\in Equil}\\operatorname {Welf} (s)}}}": {
    "before": "We can define a subset {\\displaystyle Equil\\subseteq S} to be the set of strategies in equilibrium (for example, the set of Nash equilibria ). The Price of Anarchy is then defined as the ratio between the 'worst equilibrium' and the optimal 'centralized' solution:",
    "after": "If, instead of a 'welfare' which we want to 'maximize', the function measure efficiency is a 'cost function' {\\displaystyle \\operatorname {Cost} :S\\rightarrow \\mathbb {R} } which we want to 'minimize' (e.g. delay in a network) we use (following the convention in approximation algorithms):",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle PoA={\\frac {\\max _{s\\in Equil}\\operatorname {Cost} (s)}{\\min _{s\\in S}\\operatorname {Cost} (s)}}}": {
    "before": "If, instead of a 'welfare' which we want to 'maximize', the function measure efficiency is a 'cost function' {\\displaystyle \\operatorname {Cost} :S\\rightarrow \\mathbb {R} } which we want to 'minimize' (e.g. delay in a network) we use (following the convention in approximation algorithms):",
    "after": "A related notion is that of the Price of Stability ( PoS ) which measures the ratio between the 'best equilibrium' and the optimal 'centralized' solution:",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle PoS={\\frac {\\max _{s\\in S}\\operatorname {Welf} (s)}{\\max _{s\\in Equil}\\operatorname {Welf} (s)}}}": {
    "before": "A related notion is that of the Price of Stability ( PoS ) which measures the ratio between the 'best equilibrium' and the optimal 'centralized' solution:",
    "after": "or in the case of cost functions:",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "{\\displaystyle PoS={\\frac {\\min _{s\\in Equil}\\operatorname {Cost} (s)}{\\min _{s\\in S}\\operatorname {Cost} (s)}}}": {
    "before": "or in the case of cost functions:",
    "after": "We know that {\\displaystyle 1\\leq PoS\\leq PoA} by the definition. It is expected that the loss in efficiency due to game-theoretical constraints is somewhere between 'PoS' and 'PoA'.",
    "url": "https://en.wikipedia.org/wiki/Price of anarchy"
  },
  "2.3Principle of interaction (SABI: I = ƒ[A, B, S])": {
    "before": "2.2Principle of transformation (what people make of the situation)",
    "after": "2.4Principle of adaptation",
    "url": "https://en.wikipedia.org/wiki/Interdependence theory"
  },
  "Principle of interaction (SABI: I = ƒ[A, B, S])[edit]": {
    "before": "Aggression (MinOther) minimizes positive outcomes for others",
    "after": "The Principle of Interaction (also referred to as the SABI model) is used to assess the variable that affect any given interaction. This model states that Interactions (I) are a function (ƒ) of the situation, Person A's (A) motives, traits, and actions, plus Person B's (B) motives, traits, and actions (I = ƒ[A, B, S]).",
    "url": "https://en.wikipedia.org/wiki/Interdependence theory"
  },
  "{\\displaystyle SampEn=-\\ln {A \\over B}}": {
    "before": "Now assume we have a time-series data set of length {\\displaystyle N={\\{x_{1},x_{2},x_{3},...,x_{N}\\}}} with a constant time interval {\\displaystyle \\tau } . We define a template vector of length {\\displaystyle m} , such that {\\displaystyle X_{m}(i)={\\{x_{i},x_{i+1},x_{i+2},...,x_{i+m-1}\\}}} and the distance function {\\displaystyle d[X_{m}(i),X_{m}(j)]} (i≠j) is to be the Chebyshev distance (but it could be any distance function, including Euclidean distance). We define the sample entropy to be",
    "after": "Where {\\displaystyle A} = number of template vector pairs having {\\displaystyle d[X_{m+1}(i),X_{m+1}(j)]<r}",
    "url": "https://en.wikipedia.org/wiki/Sample entropy"
  },
  "{\\displaystyle B}= number of template vector pairs having": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Sample entropy"
  },
  "N = len(L)": {
    "before": "\"\"\"Sample entropy.\"\"\"",
    "after": "B = 0.0",
    "url": "https://en.wikipedia.org/wiki/Sample entropy"
  },
  "xmi = np.array([L[i : i + m] for i in range(N - m)])": {
    "before": "# Split time series and save all templates of length m",
    "after": "xmj = np.array([L[i : i + m] for i in range(N - m + 1)])",
    "url": "https://en.wikipedia.org/wiki/Sample entropy"
  },
  "xmj = np.array([L[i : i + m] for i in range(N - m + 1)])": {
    "before": "xmi = np.array([L[i : i + m] for i in range(N - m)])",
    "after": "# Save all matches minus the self-match, compute B",
    "url": "https://en.wikipedia.org/wiki/Sample entropy"
  },
  "B = np.sum([np.sum(np.abs(xmii - xmj).max(axis=1) <= r) - 1 for xmii in xmi])": {
    "before": "# Save all matches minus the self-match, compute B",
    "after": "# Similar for computing A",
    "url": "https://en.wikipedia.org/wiki/Sample entropy"
  },
  "xm = np.array([L[i : i + m] for i in range(N - m + 1)])": {
    "before": "m += 1",
    "after": "A = np.sum([np.sum(np.abs(xmi - xm).max(axis=1) <= r) - 1 for xmi in xm])",
    "url": "https://en.wikipedia.org/wiki/Sample entropy"
  },
  "A = np.sum([np.sum(np.abs(xmi - xm).max(axis=1) <= r) - 1 for xmi in xm])": {
    "before": "xm = np.array([L[i : i + m] for i in range(N - m + 1)])",
    "after": "# Return SampEn",
    "url": "https://en.wikipedia.org/wiki/Sample entropy"
  },
  "{\\displaystyle N^{*}=\\left({\\frac {Yi}{2C}}\\right)^{\\frac {1}{2}}}": {
    "before": "Solving this for N we get the optimal number of withdrawals:",
    "after": "Using the fact that average money holdings are equal to Y/2N we obtain a demand for money function:",
    "url": "https://en.wikipedia.org/wiki/Baumol–Tobin model"
  },
  "{\\displaystyle M=\\left({\\frac {CY}{2i}}\\right)^{\\frac {1}{2}}}": {
    "before": "Using the fact that average money holdings are equal to Y/2N we obtain a demand for money function:",
    "after": "The model can be easily modified to incorporate an average price level which turns the money demand function into a demand for liquidity function:",
    "url": "https://en.wikipedia.org/wiki/Baumol–Tobin model"
  },
  "{\\displaystyle L(Y,i)={\\frac {M}{P}}=\\left({\\frac {CQ}{2iP}}\\right)^{\\frac {1}{2}}}": {
    "before": "The model can be easily modified to incorporate an average price level which turns the money demand function into a demand for liquidity function:",
    "after": "where Q is the volume of goods sold at an average price P, so that Y = P*Q.",
    "url": "https://en.wikipedia.org/wiki/Baumol–Tobin model"
  },
  "Real numbers {\\displaystyle \\mathbb {R} } . The set of players {\\displaystyle \\mathrm {N} } . Strategy space {\\displaystyle \\Sigma \\ =\\prod _{i\\in \\mathrm {N} }\\Sigma \\ ^{i}} , where Player i's strategy space {\\displaystyle \\Sigma \\ ^{i}} is the space of all possible ways in which player i can play the game. A strategy for player i": {
    "before": "Definitions of a game [ edit ]Notational conventions [ edit ]",
    "after": "{\\displaystyle \\sigma \\ _{i}} is an element of {\\displaystyle \\Sigma \\ ^{i}} .",
    "url": "https://en.wikipedia.org/wiki/Glossary of game theory"
  },
  "Dictator A player is a strong dictator if he can guarantee any outcome regardless of the other players. {\\displaystyle m\\in \\mathbb {N} } is a weak dictator if he can guarantee any outcome, but his strategies for doing so might depend on the complement strategy vector. Naturally, every strong dictator is a weak dictator. Formally: m is a Strong dictator if: {\\displaystyle \\forall a\\in \\mathrm {A} ,\\;\\exists \\sigma \\ _{n}\\in \\Sigma \\ ^{n}\\;s.t.\\;\\forall \\sigma \\ _{-n}\\in \\Sigma \\ ^{-n}:\\;\\Gamma \\ (\\sigma \\ _{-n},\\sigma \\ _{n})=a} m is a Weak dictator if: {\\displaystyle \\forall a\\in \\mathrm {A} ,\\;\\forall \\sigma \\ _{-n}\\in \\Sigma \\ ^{-n}\\;\\exists \\sigma \\ _{n}\\in \\Sigma \\ ^{n}\\;s.t.\\;\\Gamma \\ (\\sigma \\ _{-n},\\sigma \\ _{n})=a} Another way to put it is: a weak dictator is {\\displaystyle \\alpha } -effective for every possible outcome. A strong dictator is {\\displaystyle \\beta } -effective for every possible outcome. A game can have no more than one strong dictator . Some games have multiple weak dictators (in rock-paper-scissors both players are weak dictators but none is a strong dictator ). Also see Effectiveness . Antonym: dummy .": {
    "before": "Determined game (or Strictly determined game ) In game theory, a strictly determined game is a two-player zero-sum game that has at least one Nash equilibrium with both players using pure strategies .  ",
    "after": "Dominated outcome Given a preference ν on the outcome space , we say that an outcome a is dominated by outcome b (hence, b is the dominant strategy) if it is preferred by all players. If, in addition, some player strictly prefers b over a , then we say that a is strictly dominated . Formally: {\\displaystyle \\forall j\\in \\mathrm {N} \\;\\quad \\nu \\ _{j}(a)\\leq \\ \\nu \\ _{j}(b)} for domination, and {\\displaystyle \\exists i\\in \\mathrm {N} \\;s.t.\\;\\nu \\ _{i}(a)<\\nu \\ _{i}(b)} for strict domination. An outcome a is (strictly) dominated if it is (strictly) dominated by some other outcome . An outcome a is dominated for a coalition S if all players in S prefer some other outcome to a . See also Condorcet winner .",
    "url": "https://en.wikipedia.org/wiki/Glossary of game theory"
  },
  "Pure Nash Equilibrium An element {\\displaystyle \\sigma \\ =(\\sigma \\ _{i})_{i\\in \\mathrm {N} }} of the strategy space of a game is a pure nash equilibrium point if no player i can benefit by deviating from his strategy {\\displaystyle \\sigma \\ _{i}} , given that the other players are playing in {\\displaystyle \\sigma } . Formally: {\\displaystyle \\forall i\\in \\mathrm {N} \\quad \\forall \\tau \\ _{i}\\in \\ \\Sigma \\ ^{i}\\quad \\pi \\ (\\tau \\ ,\\sigma \\ _{-i})\\leq \\pi \\ (\\sigma \\ )} . No equilibrium point is dominated.": {
    "before": "Preference profile is a function {\\displaystyle \\nu \\ :\\Gamma \\ \\to \\mathbb {R} ^{\\mathrm {N} }} . This is the ordinal approach at describing the outcome of the game. The preference describes how 'pleased' the players are with the possible outcomes of the game. See allocation of goods .",
    "after": "Say A player i has a Say if he is not a Dummy , i.e. if there is some tuple of complement strategies s.t. π (σ_i) is not a constant function. Antonym: Dummy .",
    "url": "https://en.wikipedia.org/wiki/Glossary of game theory"
  },
  "Zero sum game is a game in which the allocation is constant over different outcomes . Formally: {\\displaystyle \\forall \\gamma \\ \\in \\Gamma \\ \\sum _{i\\in \\mathrm {N} }\\nu \\ _{i}(\\gamma \\ )=const.} w.l.g. we can assume that constant to be zero. In a zero-sum game, one player's gain is another player's loss. Most classical board games (e.g. chess , checkers ) are zero sum .": {
    "before": "Weakly acceptable game is a game that has pure nash equilibria some of which are pareto efficient .",
    "after": "v t e Topics in game theory Definitions Congestion game Cooperative game Determinacy Escalation of commitment Extensive-form game First-player and second-player win Game complexity Graphical game Hierarchy of beliefs Information set Normal-form game Preference Sequential game Simultaneous game Simultaneous action selection Solved game Succinct game Equilibrium concepts Bayesian Nash equilibrium Berge equilibrium Core Correlated equilibrium Epsilon-equilibrium Evolutionarily stable strategy Gibbs equilibrium Mertens-stable equilibrium Markov perfect equilibrium Nash equilibrium Pareto efficiency Perfect Bayesian equilibrium Proper equilibrium Quantal response equilibrium Quasi-perfect equilibrium Risk dominance Satisfaction equilibrium Self-confirming equilibrium Sequential equilibrium Shapley value Strong Nash equilibrium Subgame perfection Trembling hand Strategies Backward induction Bid shading Collusion Forward induction Grim trigger Markov strategy Dominant strategies Pure strategy Mixed strategy Strategy-stealing argument Tit for tat Classes of games Bargaining problem Cheap talk Global game Intransitive game Mean-field game Mechanism design n -player game Perfect information Large Poisson game Potential game Repeated game Screening game Signaling game Stackelberg competition Strictly determined game Stochastic game Symmetric game Zero-sum game Games Go Chess Infinite chess Checkers Tic-tac-toe Prisoner's dilemma Gift-exchange game Optional prisoner's dilemma Traveler's dilemma Coordination game Chicken Centipede game Lewis signaling game Volunteer's dilemma Dollar auction Battle of the sexes Stag hunt Matching pennies Ultimatum game Rock paper scissors Pirate game Dictator game Public goods game Blotto game War of attrition El Farol Bar problem Fair division Fair cake-cutting Cournot game Deadlock Diner's dilemma Guess 2/3 of the average Kuhn poker Nash bargaining game Induction puzzles Trust game Princess and monster game Rendezvous problem Theorems Arrow's impossibility theorem Aumann's agreement theorem Folk theorem Minimax theorem Nash's theorem Purification theorem Revelation principle Zermelo's theorem Key figures Albert W. Tucker Amos Tversky Antoine Augustin Cournot Ariel Rubinstein Claude Shannon Daniel Kahneman David K. Levine David M. Kreps Donald B. Gillies Drew Fudenberg Eric Maskin Harold W. Kuhn Herbert Simon Hervé Moulin John Conway Jean Tirole Jean-François Mertens Jennifer Tour Chayes John Harsanyi John Maynard Smith John Nash John von Neumann Kenneth Arrow Kenneth Binmore Leonid Hurwicz Lloyd Shapley Melvin Dresher Merrill M. Flood Olga Bondareva Oskar Morgenstern Paul Milgrom Peyton Young Reinhard Selten Robert Axelrod Robert Aumann Robert B. Wilson Roger Myerson Samuel Bowles Suzanne Scotchmer Thomas Schelling William Vickrey Miscellaneous All-pay auction Alpha–beta pruning Bertrand paradox Bounded rationality Combinatorial game theory Confrontation analysis Coopetition Evolutionary game theory First-move advantage in chess Game Description Language Game mechanics Glossary of game theory List of game theorists List of games in game theory No-win situation Solving chess Topological game Tragedy of the commons Tyranny of small decisions",
    "url": "https://en.wikipedia.org/wiki/Glossary of game theory"
  },
  "{\\displaystyle X_{t}=\\sum _{i=1}^{t}(x_{i}-\\langle x\\rangle )}": {
    "before": "Consider a bounded time series {\\displaystyle x_{t}} of length {\\displaystyle N} , where {\\displaystyle t\\in \\mathbb {N} } , and let its mean value be denoted {\\displaystyle \\langle x\\rangle } . Integration or summation converts this into an unbounded process {\\displaystyle X_{t}} :",
    "after": "{\\displaystyle X_{t}} is called cumulative sum or profile. This process converts, for example, an i.i.d. white noise process into a random walk .",
    "url": "https://en.wikipedia.org/wiki/Detrended fluctuation analysis"
  },
  "{\\displaystyle F(n)={\\sqrt {{\\frac {1}{N}}\\sum _{t=1}^{N}\\left(X_{t}-Y_{t}\\right)^{2}}}.}": {
    "before": "Next, {\\displaystyle X_{t}} is divided into time windows of length {\\displaystyle n} samples each, and a local least squares straight-line fit (the local trend) is calculated by minimising the squared errors within each time window. Let {\\displaystyle Y_{t}} indicate the resulting piecewise sequence of straight-line fits. Then, the root-mean-square deviation from the trend, the fluctuation , is calculated:",
    "after": "Finally, this process of detrending followed by fluctuation measurement is repeated over a range of different window sizes {\\displaystyle n} , and a log-log graph of {\\displaystyle F(n)} against {\\displaystyle n} is constructed.  ",
    "url": "https://en.wikipedia.org/wiki/Detrended fluctuation analysis"
  },
  "{\\displaystyle F_{q}(n)=\\left({\\frac {1}{N}}\\sum _{t=1}^{N}\\left(X_{t}-Y_{t}\\right)^{q}\\right)^{1/q},}": {
    "before": "Essentially, the scaling exponents need not be independent of the scale of the system. In the case {\\displaystyle \\alpha } depends on the power {\\displaystyle q} extracted from",
    "after": "where the previous DFA is {\\displaystyle q=2} . Multifractal systems scale as a function {\\displaystyle F_{q}(n)\\propto n^{\\alpha (q)}} . To uncover multifractality, Multifractal Detrended Fluctuation Analysis is one possible method. ",
    "url": "https://en.wikipedia.org/wiki/Detrended fluctuation analysis"
  },
  "{\\displaystyle \\gamma =2-2\\alpha }": {
    "before": "In the case of power-law decaying auto-correlations, the correlation function decays with an exponent {\\displaystyle \\gamma } : {\\displaystyle C(L)\\sim L^{-\\gamma }\\!\\ } . In addition the power spectrum decays as {\\displaystyle P(f)\\sim f^{-\\beta }\\!\\ } . The three exponents are related by: ",
    "after": "{\\displaystyle \\beta =2\\alpha -1} and",
    "url": "https://en.wikipedia.org/wiki/Detrended fluctuation analysis"
  },
  "|state=collapsed: {{Decision theory|state=collapsed}} to show the template collapsed, i.e., hidden apart from its title bar": {
    "before": "To set this template's initial visibility, the |state= parameter may be used:",
    "after": "|state=expanded: {{Decision theory|state=expanded}} to show the template expanded, i.e., fully visible",
    "url": "https://en.wikipedia.org/wiki/Template:Decision theory"
  },
  "|state=expanded: {{Decision theory|state=expanded}} to show the template expanded, i.e., fully visible": {
    "before": "|state=collapsed: {{Decision theory|state=collapsed}} to show the template collapsed, i.e., hidden apart from its title bar",
    "after": "|state=autocollapse: {{Decision theory|state=autocollapse}}",
    "url": "https://en.wikipedia.org/wiki/Template:Decision theory"
  },
  "|state=autocollapse: {{Decision theory|state=autocollapse}}": {
    "before": "|state=expanded: {{Decision theory|state=expanded}} to show the template expanded, i.e., fully visible",
    "after": "shows the template collapsed to the title bar if there is a {{navbox}}, a {{sidebar}}, or some other table on the page with the collapsible attribute",
    "url": "https://en.wikipedia.org/wiki/Template:Decision theory"
  },
  "{\\displaystyle \\varphi (x)={\\begin{cases}3/4&0\\leq x<0.5\\\\\\{3/4,1/4\\}&x=0.5\\\\1/4&0.5<x\\leq 1\\end{cases}}}": {
    "before": "The requirement that φ ( x ) be convex for all x is essential for the theorem to hold.Consider the following function defined on [0,1]:",
    "after": "The function has no fixed point. Though it satisfies all other requirements of Kakutani's theorem, its value fails to be convex at x = 0.5.",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "{\\displaystyle \\varphi (x)={\\begin{cases}3/4&0\\leq x<0.5\\\\1/4&0.5\\leq x\\leq 1\\end{cases}}}": {
    "before": "A function that does not satisfy closed graph [ edit ]Consider the following function defined on [0,1]:",
    "after": "The function has no fixed point. Though it satisfies all other requirements of Kakutani's theorem, its graph is not closed; for example, consider the sequences x n = 0.5 - 1/ n , y n = 3/4.",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "m = ( a k + b k )/2.": {
    "before": "Now suppose we have chosen a k , b k , p k and q k satisfying (1)–(6). Let,",
    "after": "Then m ∈ [0,1] because [0,1] is convex .",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "a k +1 = m b k +1 = b k p k +1 = r q k +1 = q k": {
    "before": "If there is a r ∈ φ( m ) such that r ≥ m , then we take,",
    "after": "Otherwise, since φ( m ) is non-empty, there must be a s ∈ φ( m ) such that s ≤ m . In this case let,",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "a k +1 = a k b k +1 = m p k +1 = p k q k +1 = s .": {
    "before": "Otherwise, since φ( m ) is non-empty, there must be a s ∈ φ( m ) such that s ≤ m . In this case let,",
    "after": "It can be verified that a k +1 , b k +1 , p k +1 and q k +1 satisfy conditions (1)–(6).",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "b * − a * = (lim b n ) − (lim a n ) = lim ( b n − a n ) = 0.": {
    "before": "The cartesian product [0,1]×[0,1]×[0,1]×[0,1] is a compact set by Tychonoff's theorem . Since the sequence ( a n , p n , b n , q n ) lies in this compact set, it must have a convergent subsequence by the Bolzano-Weierstrass theorem . Let's fix attention on such a subsequence and let its limit be ( a *, p *, b *, q *). Since the graph of φ is closed it must be the case that p * ∈ φ( a *) and q * ∈ φ( b *). Moreover, by condition (5), p * ≥ a * and by condition (6), q * ≤ b *.But since ( b i − a i ) ≤ 2 − i by condition (2),",
    "after": "So, b * equals a *. Let x = b * = a *.",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "{\\displaystyle x=\\left({\\frac {x-q^{*}}{p^{*}-q^{*}}}\\right)p^{*}+\\left(1-{\\frac {x-q^{*}}{p^{*}-q^{*}}}\\right)q^{*}}": {
    "before": "Otherwise, we can write the following. Recall that we can parameterize a line between two points a and b by (1-t)a + tb. Using our finding above that q<x<p, we can create such a line between p and q as a function of x (notice the fractions below are on the unit interval). By a convenient writing of x, and since φ( x ) is convex and",
    "after": "it once again follows that x must belong to φ( x ) since p * and q * do and hence x is a fixed point of φ.",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "{\\displaystyle \\varphi (x)={\\begin{cases}3/4&0\\leq x<0.5\\\\{}[0,1]&x=0.5\\\\1/4&0.5<x\\leq 1\\end{cases}}}": {
    "before": "The function:",
    "after": "satisfies all Kakutani's conditions, and indeed it has a fixed point: x = 0.5 is a fixed point, since x is contained in the interval [0,1].",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "Fixed points for φ(x)=[1−x/2, 1−x/4]": {
    "before": "Examples[edit]",
    "after": "A function with infinitely many fixed points[edit]",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "S = [0,1][edit]": {
    "before": "Proof outline[edit]",
    "after": "The proof of Kakutani's theorem is simplest for set-valued functions defined over closed intervals of the real line. However, the proof of this case is instructive since its general strategy can be carried over to the higher-dimensional case as well.",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "Let (ai, bi, pi, qi) for i = 0, 1, … be a sequence with the following properties:": {
    "before": "Create a sequence of subdivisions of [0,1] with adjacent points moving in opposite directions.",
    "after": "1.",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "If p* = q* then p* = x = q*. Since p* ∈ φ(x), x is a fixed point of φ.": {
    "before": "Show that the limiting point is a fixed point.",
    "after": "Otherwise, we can write the following. Recall that we can parameterize a line between two points a and b by (1-t)a + tb. Using our finding above that q<x<p, we can create such a line between p and q as a function of x (notice the fractions below are on the unit interval). By a convenient writing of x, and since φ(x) is convex and",
    "url": "https://en.wikipedia.org/wiki/Kakutani fixed-point theorem"
  },
  "{\\displaystyle y_{t}-\\rho y_{t-1}=\\alpha (1-\\rho )+(X_{t}-\\rho X_{t-1})\\beta +e_{t}\\,}": {
    "before": "The idea is to repeatedly apply ordinary least squares to",
    "after": "for different values of {\\displaystyle \\rho } between −1 and 1. From all these auxiliary regressions, one selects the pair (α, β) that yields the smallest residual sum of squares .",
    "url": "https://en.wikipedia.org/wiki/Hildreth–Lu estimation"
  },
  "{\\displaystyle \\mu _{t_{1}}=\\mu _{t_{2}}\\triangleq \\mu } for all {\\displaystyle t_{1},t_{2}}": {
    "before": "If {\\displaystyle \\left\\{X_{t}\\right\\}} is a weakly stationary (WSS) process , then the following are true:  : p. 163",
    "after": "and {\\displaystyle \\operatorname {E} [|X_{t}|^{2}]<\\infty } for all {\\displaystyle t}",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle \\operatorname {K} _{XX}(t_{1},t_{2})=\\operatorname {K} _{XX}(t_{2}-t_{1},0)\\triangleq \\operatorname {K} _{XX}(t_{2}-t_{1})=\\operatorname {K} _{XX}(\\tau ),}": {
    "before": "{\\displaystyle \\operatorname {E} [|X_{t}|^{2}]<\\infty } for all {\\displaystyle t} and",
    "after": "where {\\displaystyle \\tau =t_{2}-t_{1}} is the lag time, or the amount of time by which the signal has been shifted.",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle \\operatorname {K} _{XX}(\\tau )=\\operatorname {E} [(X_{t+\\tau }-\\mu _{t+\\tau })(X_{t}-\\mu _{t})]=\\operatorname {E} [X_{t+\\tau }X_{t}]-\\mu ^{2}} .": {
    "before": "{\\displaystyle \\operatorname {K} _{XX}(\\tau )=\\operatorname {E} [(X_{t}-\\mu _{t})(X_{t-\\tau }-\\mu _{t-\\tau })]=\\operatorname {E} [X_{t}X_{t-\\tau }]-\\mu _{t}\\mu _{t-\\tau }} ( Eq.2 ) which is equivalent to",
    "after": "Normalization [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle \\rho _{XX}(t_{1},t_{2})={\\frac {\\operatorname {K} _{XX}(t_{1},t_{2})}{\\sigma _{t_{1}}\\sigma _{t_{2}}}}={\\frac {\\operatorname {E} [(X_{t_{1}}-\\mu _{t_{1}})(X_{t_{2}}-\\mu _{t_{2}})]}{\\sigma _{t_{1}}\\sigma _{t_{2}}}}} .": {
    "before": "The definition of the normalized auto-correlation of a stochastic process is",
    "after": "If the function {\\displaystyle \\rho _{XX}} is well-defined, its value must lie in the range {\\displaystyle [-1,1]} , with 1 indicating perfect correlation and −1 indicating perfect anti-correlation .",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle \\rho _{XX}(\\tau )={\\frac {\\operatorname {K} _{XX}(\\tau )}{\\sigma ^{2}}}={\\frac {\\operatorname {E} [(X_{t}-\\mu )(X_{t+\\tau }-\\mu )]}{\\sigma ^{2}}}} .": {
    "before": "If the function {\\displaystyle \\rho _{XX}} is well-defined, its value must lie in the range {\\displaystyle [-1,1]} , with 1 indicating perfect correlation and −1 indicating perfect anti-correlation .For a WSS process, the definition is",
    "after": "where {\\displaystyle \\operatorname {K} _{XX}(0)=\\sigma ^{2}} .",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle \\operatorname {K} _{XX}(0)=\\sigma ^{2}} .": {
    "before": "{\\displaystyle \\rho _{XX}(\\tau )={\\frac {\\operatorname {K} _{XX}(\\tau )}{\\sigma ^{2}}}={\\frac {\\operatorname {E} [(X_{t}-\\mu )(X_{t+\\tau }-\\mu )]}{\\sigma ^{2}}}} .where",
    "after": "Properties [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle \\operatorname {K} _{XX}(t_{1},t_{2})={\\overline {\\operatorname {K} _{XX}(t_{2},t_{1})}}}  : p.169": {
    "before": "Properties [ edit ]Symmetry property [ edit ]",
    "after": "respectively for a WSS process:",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle \\operatorname {K} _{XX}(\\tau )={\\overline {\\operatorname {K} _{XX}(-\\tau )}}}  : p.173": {
    "before": "{\\displaystyle \\operatorname {K} _{XX}(t_{1},t_{2})={\\overline {\\operatorname {K} _{XX}(t_{2},t_{1})}}}  : p.169respectively for a WSS process:",
    "after": "Linear filtering [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle Y_{t}=\\sum _{k=-\\infty }^{\\infty }a_{k}X_{t+k}\\,}": {
    "before": "The autocovariance of a linearly filtered process {\\displaystyle \\left\\{Y_{t}\\right\\}}",
    "after": "is {\\displaystyle K_{YY}(\\tau )=\\sum _{k,l=-\\infty }^{\\infty }a_{k}a_{l}K_{XX}(\\tau +k-l).\\,}",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle K_{YY}(\\tau )=\\sum _{k,l=-\\infty }^{\\infty }a_{k}a_{l}K_{XX}(\\tau +k-l).\\,}": {
    "before": "{\\displaystyle Y_{t}=\\sum _{k=-\\infty }^{\\infty }a_{k}X_{t+k}\\,} is",
    "after": "Calculating turbulent diffusivity [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle U(x,t)=\\langle U(x,t)\\rangle +u'(x,t),}": {
    "before": "Reynolds decomposition is used to define the velocity fluctuations {\\displaystyle u'(x,t)} (assume we are now working with 1D problem and {\\displaystyle U(x,t)} is the velocity along {\\displaystyle x} direction):",
    "after": "where {\\displaystyle U(x,t)} is the true velocity, and {\\displaystyle \\langle U(x,t)\\rangle } is the expected value of velocity . If we choose a correct {\\displaystyle \\langle U(x,t)\\rangle } , all of the stochastic components of the turbulent velocity will be included in {\\displaystyle u'(x,t)} . To determine {\\displaystyle \\langle U(x,t)\\rangle } , a set of velocity measurements that are assembled from points in space, moments in time or repeated experiments is required.",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle J_{{\\text{turbulence}}_{x}}=\\langle u'c'\\rangle \\approx D_{T_{x}}{\\frac {\\partial \\langle c\\rangle }{\\partial x}}.}": {
    "before": "If we assume the turbulent flux {\\displaystyle \\langle u'c'\\rangle } ( {\\displaystyle c'=c-\\langle c\\rangle } , and c is the concentration term) can be caused by a random walk, we can use Fick's laws of diffusion to express the turbulent flux term:",
    "after": "The velocity autocovariance is defined as",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle D_{T_{x}}=\\int _{\\tau }^{\\infty }u'(t_{0})u'(t_{0}+\\tau )\\,d\\tau .}": {
    "before": "Lagrangian trajectory:",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle \\operatorname {K} _{XX}(t_{1},t_{2})=\\operatorname {cov} \\left[X_{t_{1}},X_{t_{2}}\\right]=\\operatorname {E} [(X_{t_{1}}-\\mu _{t_{1}})(X_{t_{2}}-\\mu _{t_{2}})]=\\operatorname {E} [X_{t_{1}}X_{t_{2}}]-\\mu _{t_{1}}\\mu _{t_{2}}}": {
    "before": "{\\displaystyle \\operatorname {K} _{XX}(t_{1},t_{2})=\\operatorname {cov} \\left[X_{t_{1}},X_{t_{2}}\\right]=\\operatorname {E} [(X_{t_{1}}-\\mu _{t_{1}})(X_{t_{2}}-\\mu _{t_{2}})]=\\operatorname {E} [X_{t_{1}}X_{t_{2}}]-\\mu _{t_{1}}\\mu _{t_{2}}} ( Eq.1 )",
    "after": "{\\displaystyle \\operatorname {K} _{XX}(t_{1},t_{2})=\\operatorname {cov} \\left[X_{t_{1}},X_{t_{2}}\\right]=\\operatorname {E} [(X_{t_{1}}-\\mu _{t_{1}})(X_{t_{2}}-\\mu _{t_{2}})]=\\operatorname {E} [X_{t_{1}}X_{t_{2}}]-\\mu _{t_{1}}\\mu _{t_{2}}}",
    "url": "https://en.wikipedia.org/wiki/Autocovariance"
  },
  "{\\displaystyle ~\\epsilon _{t}=\\sigma _{t}z_{t}~}": {
    "before": "To model a time series using an ARCH process, let {\\displaystyle ~\\epsilon _{t}~} denote the error terms (return residuals, with respect to a mean process), i.e. the series terms. These {\\displaystyle ~\\epsilon _{t}~} are split into a stochastic piece {\\displaystyle z_{t}} and a time-dependent standard deviation {\\displaystyle \\sigma _{t}} characterizing the typical size of the terms so that",
    "after": "The random variable {\\displaystyle z_{t}} is a strong white noise process. The series {\\displaystyle \\sigma _{t}^{2}} is modeled by",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle \\sigma _{t}^{2}=\\alpha _{0}+\\alpha _{1}\\epsilon _{t-1}^{2}+\\cdots +\\alpha _{q}\\epsilon _{t-q}^{2}=\\alpha _{0}+\\sum _{i=1}^{q}\\alpha _{i}\\epsilon _{t-i}^{2}} , where {\\displaystyle ~\\alpha _{0}>0~} and {\\displaystyle \\alpha _{i}\\geq 0,~i>0} .": {
    "before": "The random variable {\\displaystyle z_{t}} is a strong white noise process. The series {\\displaystyle \\sigma _{t}^{2}} is modeled by",
    "after": "An ARCH( q ) model can be estimated using ordinary least squares . A method for testing whether the residuals {\\displaystyle \\epsilon _{t}} exhibit time-varying heteroskedasticity using the Lagrange multiplier test was proposed by Engle (1982). This procedure is as follows:",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle {\\hat {\\epsilon }}_{t}^{2}={\\hat {\\alpha }}_{0}+\\sum _{i=1}^{q}{\\hat {\\alpha }}_{i}{\\hat {\\epsilon }}_{t-i}^{2}} where q is the length of ARCH lags.": {
    "before": "qlagged values:",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle y_{t}=a_{0}+a_{1}y_{t-1}+\\cdots +a_{q}y_{t-q}+\\epsilon _{t}=a_{0}+\\sum _{i=1}^{q}a_{i}y_{t-i}+\\epsilon _{t}} .": {
    "before": "q) model",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle \\rho ={{\\sum _{t=i+1}^{T}({\\hat {\\epsilon }}_{t}^{2}-{\\hat {\\sigma }}_{t}^{2})({\\hat {\\epsilon }}_{t-1}^{2}-{\\hat {\\sigma }}_{t-1}^{2})} \\over {\\sum _{t=1}^{T}({\\hat {\\epsilon }}_{t}^{2}-{\\hat {\\sigma }}_{t}^{2})^{2}}}}": {
    "before": "{\\displaystyle \\epsilon ^{2}} by",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle ~\\sigma _{t}^{2}=~\\omega +~\\alpha (~\\epsilon _{t-1}-~\\theta ~\\sigma _{t-1})^{2}+~\\beta ~\\sigma _{t-1}^{2}} , where {\\displaystyle ~\\alpha \\geq 0,~\\beta \\geq 0,~\\omega >0} and {\\displaystyle ~\\alpha (1+~\\theta ^{2})+~\\beta <1} , which ensures the non-negativity and stationarity of the variance process.": {
    "before": "Nonlinear Asymmetric GARCH(1,1) ( NAGARCH ) is a model with the specification:  ",
    "after": "For stock returns, parameter {\\displaystyle ~\\theta } is usually estimated to be positive; in this case, it reflects a phenomenon commonly referred to as the \"leverage effect\", signifying that negative returns increase future volatility by a larger amount than positive returns of the same magnitude.  ",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle \\epsilon _{t}=\\sigma _{t}z_{t},} {\\displaystyle \\sigma _{t}^{2}=\\alpha _{0}+\\alpha _{1}\\epsilon _{t-1}^{2}+\\beta _{1}\\sigma _{t-1}^{2}=\\alpha _{0}+\\alpha _{1}\\sigma _{t-1}^{2}z_{t-1}^{2}+\\beta _{1}\\sigma _{t-1}^{2},}": {
    "before": "In 2004, Claudia Klüppelberg , Alexander Lindner and Ross Maller proposed a continuous-time generalization of the discrete-time GARCH(1,1) process. The idea is to start with the GARCH(1,1) model equations",
    "after": "and then to replace the strong white noise process {\\displaystyle z_{t}} by the infinitesimal increments {\\displaystyle \\mathrm {d} L_{t}} of a Lévy process {\\displaystyle (L_{t})_{t\\geq 0}} , and the squared noise process {\\displaystyle z_{t}^{2}} by the increments {\\displaystyle \\mathrm {d} [L,L]_{t}^{\\mathrm {d} }} , where",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle [L,L]_{t}^{\\mathrm {d} }=\\sum _{s\\in [0,t]}(\\Delta L_{t})^{2},\\quad t\\geq 0,}": {
    "before": "and then to replace the strong white noise process {\\displaystyle z_{t}} by the infinitesimal increments {\\displaystyle \\mathrm {d} L_{t}} of a Lévy process {\\displaystyle (L_{t})_{t\\geq 0}} , and the squared noise process {\\displaystyle z_{t}^{2}} by the increments {\\displaystyle \\mathrm {d} [L,L]_{t}^{\\mathrm {d} }} , where",
    "after": "is the purely discontinuous part of the quadratic variation process of {\\displaystyle L} . The result is the following system of stochastic differential equations :",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle \\mathrm {d} G_{t}=\\sigma _{t-}\\,\\mathrm {d} L_{t},} {\\displaystyle \\mathrm {d} \\sigma _{t}^{2}=(\\beta -\\eta \\sigma _{t}^{2})\\,\\mathrm {d} t+\\varphi \\sigma _{t-}^{2}\\,\\mathrm {d} [L,L]_{t}^{\\mathrm {d} },}": {
    "before": "is the purely discontinuous part of the quadratic variation process of {\\displaystyle L} . The result is the following system of stochastic differential equations :",
    "after": "where the positive parameters {\\displaystyle \\beta } , {\\displaystyle \\eta } and {\\displaystyle \\varphi } are determined by {\\displaystyle \\alpha _{0}} , {\\displaystyle \\alpha _{1}} and {\\displaystyle \\beta _{1}} . Now given some initial condition {\\displaystyle (G_{0},\\sigma _{0}^{2})} , the system above has a pathwise unique solution {\\displaystyle (G_{t},\\sigma _{t}^{2})_{t\\geq 0}} which is then called the continuous-time GARCH ( COGARCH ) model. ",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle ~\\sigma (s_{i})^{2}=~\\alpha _{i}+\\sum _{v=1}^{n}\\rho w_{iv}\\epsilon (s_{v})^{2},}": {
    "before": "Spatial GARCH processes by Otto, Schmid and Garthoff (2018)  are considered as the spatial equivalent to the temporal generalized autoregressive conditional heteroscedasticity (GARCH) models. In contrast to the temporal ARCH model, in which the distribution is known given the full information set for the prior periods, the distribution is not straightforward in the spatial and spatiotemporal setting due to the interdependence between neighboring spatial locations. The spatial model is given by {\\displaystyle ~\\epsilon (s_{i})=~\\sigma (s_{i})z(s_{i})} and",
    "after": "where {\\displaystyle ~s_{i}} denotes the {\\displaystyle i} -th spatial location and {\\displaystyle ~w_{iv}} refers to the {\\displaystyle iv} -th entry of a spatial weight matrix and {\\displaystyle w_{ii}=0} for {\\displaystyle ~i=1,...,n} . The spatial weight matrix defines which locations are considered to be adjacent.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle y_{t}=x'_{t}b+\\epsilon _{t}}": {
    "before": "In that case, the GARCH ( p , q ) model (where p is the order of the GARCH terms {\\displaystyle ~\\sigma ^{2}} and q is the order of the ARCH terms {\\displaystyle ~\\epsilon ^{2}} ), following the notation of the original paper, is given by",
    "after": "{\\displaystyle \\epsilon _{t}|\\psi _{t-1}\\sim {\\mathcal {N}}(0,\\sigma _{t}^{2})}",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle \\sigma _{t}^{2}=\\omega +\\alpha _{1}\\epsilon _{t-1}^{2}+\\cdots +\\alpha _{q}\\epsilon _{t-q}^{2}+\\beta _{1}\\sigma _{t-1}^{2}+\\cdots +\\beta _{p}\\sigma _{t-p}^{2}=\\omega +\\sum _{i=1}^{q}\\alpha _{i}\\epsilon _{t-i}^{2}+\\sum _{i=1}^{p}\\beta _{i}\\sigma _{t-i}^{2}}": {
    "before": "{\\displaystyle \\epsilon _{t}|\\psi _{t-1}\\sim {\\mathcal {N}}(0,\\sigma _{t}^{2})}",
    "after": "Generally, when testing for heteroskedasticity in econometric models, the best test is the White test . However, when dealing with time series data, this means to test for ARCH and GARCH errors.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle \\log \\sigma _{t}^{2}=\\omega +\\sum _{k=1}^{q}\\beta _{k}g(Z_{t-k})+\\sum _{k=1}^{p}\\alpha _{k}\\log \\sigma _{t-k}^{2}}": {
    "before": "The exponential generalized autoregressive conditional heteroskedastic (EGARCH) model by Nelson & Cao (1991) is another form of the GARCH model. Formally, an EGARCH(p,q):",
    "after": "where {\\displaystyle g(Z_{t})=\\theta Z_{t}+\\lambda (|Z_{t}|-E(|Z_{t}|))} , {\\displaystyle \\sigma _{t}^{2}} is the conditional variance , {\\displaystyle \\omega } , {\\displaystyle \\beta } , {\\displaystyle \\alpha } , {\\displaystyle \\theta } and {\\displaystyle \\lambda } are coefficients. {\\displaystyle Z_{t}} may be a standard normal variable or come from a generalized error distribution . The formulation for {\\displaystyle g(Z_{t})} allows the sign and the magnitude of {\\displaystyle Z_{t}} to have separate effects on the volatility. This is particularly useful in an asset pricing context.  ",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle y_{t}=~\\beta x_{t}+~\\lambda ~\\sigma _{t}+~\\epsilon _{t}}": {
    "before": "The GARCH-in-mean (GARCH-M) model adds a heteroskedasticity term into the mean equation. It has the specification:",
    "after": "The residual {\\displaystyle ~\\epsilon _{t}} is defined as:",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle ~\\epsilon _{t}=~\\sigma _{t}~\\times z_{t}}": {
    "before": "The residual {\\displaystyle ~\\epsilon _{t}} is defined as:",
    "after": "QGARCH [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle ~\\epsilon _{t}=~\\sigma _{t}z_{t}}": {
    "before": "In the example of a GARCH(1,1) model, the residual process {\\displaystyle ~\\sigma _{t}} is",
    "after": "where {\\displaystyle z_{t}} is i.i.d. and",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle ~\\sigma _{t}^{2}=K+~\\alpha ~\\epsilon _{t-1}^{2}+~\\beta ~\\sigma _{t-1}^{2}+~\\phi ~\\epsilon _{t-1}}": {
    "before": "where {\\displaystyle z_{t}} is i.i.d. and",
    "after": "GJR-GARCH [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle ~\\sigma _{t}^{2}=K+~\\delta ~\\sigma _{t-1}^{2}+~\\alpha ~\\epsilon _{t-1}^{2}+~\\phi ~\\epsilon _{t-1}^{2}I_{t-1}}": {
    "before": "Similar to QGARCH, the Glosten-Jagannathan-Runkle GARCH (GJR-GARCH) model by Glosten, Jagannathan and Runkle (1993) also models asymmetry in the ARCH process. The suggestion is to model {\\displaystyle ~\\epsilon _{t}=~\\sigma _{t}z_{t}} where {\\displaystyle z_{t}} is i.i.d., and",
    "after": "where {\\displaystyle I_{t-1}=0} if {\\displaystyle ~\\epsilon _{t-1}\\geq 0} , and {\\displaystyle I_{t-1}=1} if {\\displaystyle ~\\epsilon _{t-1}<0} .",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle ~\\sigma _{t}=K+~\\delta ~\\sigma _{t-1}+~\\alpha _{1}^{+}~\\epsilon _{t-1}^{+}+~\\alpha _{1}^{-}~\\epsilon _{t-1}^{-}}": {
    "before": "The Threshold GARCH (TGARCH) model by Zakoian (1994) is similar to GJR GARCH. The specification is one on conditional standard deviation instead of conditional variance :",
    "after": "where {\\displaystyle ~\\epsilon _{t-1}^{+}=~\\epsilon _{t-1}} if {\\displaystyle ~\\epsilon _{t-1}>0} , and {\\displaystyle ~\\epsilon _{t-1}^{+}=0} if {\\displaystyle ~\\epsilon _{t-1}\\leq 0} . Likewise, {\\displaystyle ~\\epsilon _{t-1}^{-}=~\\epsilon _{t-1}} if {\\displaystyle ~\\epsilon _{t-1}\\leq 0} , and {\\displaystyle ~\\epsilon _{t-1}^{-}=0} if {\\displaystyle ~\\epsilon _{t-1}>0} .",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle ~\\sigma _{t}^{2}=~\\alpha _{1}~\\epsilon _{t-1}^{2}+~\\beta _{1}~\\sigma _{t-1}^{2}.}": {
    "before": "Unlike GARCH model, the Zero-Drift GARCH (ZD-GARCH) model by Li, Zhang, Zhu and Ling (2018)  lets the drift term {\\displaystyle ~\\omega =0} in the first order GARCH model. The ZD-GARCH model is to model {\\displaystyle ~\\epsilon _{t}=~\\sigma _{t}z_{t}} , where {\\displaystyle z_{t}} is i.i.d., and",
    "after": "The ZD-GARCH model does not require {\\displaystyle ~\\alpha _{1}+~\\beta _{1}=1} , and hence it nests the Exponentially weighted moving average (EWMA) model in \" RiskMetrics \". Since the drift term {\\displaystyle ~\\omega =0} , the ZD-GARCH model is always non-stationary, and its statistical inference methods are quite different from those for the classical GARCH model. Based on the historical data, the parameters {\\displaystyle ~\\alpha _{1}} and {\\displaystyle ~\\beta _{1}} can be estimated by the generalized QMLE method.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive conditional heteroskedasticity"
  },
  "{\\displaystyle \\Delta y_{t}=\\alpha +\\beta t+\\gamma y_{t-1}+\\delta _{1}\\Delta y_{t-1}+\\cdots +\\delta _{p-1}\\Delta y_{t-p+1}+\\varepsilon _{t},}": {
    "before": "The testing procedure for the ADF test is the same as for the Dickey–Fuller test but it is applied to the model",
    "after": "where {\\displaystyle \\alpha } is a constant, {\\displaystyle \\beta } the coefficient on a time trend and {\\displaystyle p} the lag order of the autoregressive process. Imposing the constraints {\\displaystyle \\alpha =0} and {\\displaystyle \\beta =0} corresponds to modelling a random walk and using the constraint {\\displaystyle \\beta =0} corresponds to modeling a random walk with a drift. Consequently, there are three main versions of the test, analogous to the ones discussed on Dickey–Fuller test (see that page for a discussion on dealing with uncertainty about including the intercept and deterministic time trend terms in the test equation.)",
    "url": "https://en.wikipedia.org/wiki/Augmented Dickey–Fuller test"
  },
  "{\\displaystyle \\mathrm {DF} _{\\tau }={\\frac {\\hat {\\gamma }}{\\operatorname {SE} ({\\hat {\\gamma }})}}}": {
    "before": "The unit root test is then carried out under the null hypothesis {\\displaystyle \\gamma =0} against the alternative hypothesis of {\\displaystyle \\gamma <0.} Once a value for the test statistic",
    "after": "is computed it can be compared to the relevant critical value for the Dickey–Fuller test. As this test is asymmetrical, we are only concerned with negative values of our test statistic {\\displaystyle \\mathrm {DF} _{\\tau }} . If the calculated test statistic is less (more negative) than the critical value, then the null hypothesis of {\\displaystyle \\gamma =0} is rejected and no unit root is present.",
    "url": "https://en.wikipedia.org/wiki/Augmented Dickey–Fuller test"
  },
  "SPSS Community?ref=wikipedia – Support for developers of applications using SPSS products, including materials and examples of the Python and R programmability features": {
    "before": "UCLA ATS Technical Reports Archived 2006-02-07 at the Wayback Machine – Report 1 compares Stata, SAS, and SPSS against R (R is a language and environment for statistical computing and graphics).",
    "after": "Biomedical Statistics - An educational website dedicated to statistical evaluation of biomedical data using SPSS software",
    "url": "https://en.wikipedia.org/wiki/SPSS"
  },
  "Mass–energy equivalence (E=mc2)": {
    "before": "General relativity",
    "after": "Brownian motion",
    "url": "https://en.wikipedia.org/wiki/Political views of Albert Einstein"
  },
  "AD = C + I + G + (X – M)": {
    "before": "Since prices in open and competitive capitalist markets are dictated by relative volumes of supply and demand, changes to the amount of goods consumed or produced will induce fluctuations in overall prices. In Keynesian theory the individual factors of aggregate demand can exert inflationary pressure on the prices in the overall economy, rapid increases in consumption by firms, spending by government, exports relative to imports, typically abbreviated and expressed in the following equation:",
    "after": "Where 'AD' is aggregate demand, 'C' is consumption, 'I' is investment, 'G' is government expenditures, 'X' is exports, and 'M' is imports.",
    "url": "https://en.wikipedia.org/wiki/Demand-led growth"
  },
  "{\\displaystyle y_{t}=\\rho y_{t-1}+u_{t}\\,}": {
    "before": "Explanation [ edit ]A simple AR model is",
    "after": "where {\\displaystyle y_{t}} is the variable of interest, {\\displaystyle t} is the time index, {\\displaystyle \\rho } is a coefficient, and {\\displaystyle u_{t}} is the error term (assumed to be white noise ). A unit root is present if {\\displaystyle \\rho =1} . The model would be non-stationary in this case.",
    "url": "https://en.wikipedia.org/wiki/Dickey–Fuller test"
  },
  "{\\displaystyle \\Delta y_{t}=(\\rho -1)y_{t-1}+u_{t}=\\delta y_{t-1}+u_{t}\\,}": {
    "before": "where {\\displaystyle y_{t}} is the variable of interest, {\\displaystyle t} is the time index, {\\displaystyle \\rho } is a coefficient, and {\\displaystyle u_{t}} is the error term (assumed to be white noise ). A unit root is present if {\\displaystyle \\rho =1} . The model would be non-stationary in this case.The regression model can be written as",
    "after": "where {\\displaystyle \\Delta } is the first difference operator and {\\displaystyle \\delta \\equiv \\rho -1} . This model can be estimated and testing for a unit root is equivalent to testing {\\displaystyle \\delta =0} . Since the test is done over the residual term rather than raw data, it is not possible to use standard t-distribution to provide critical values. Therefore, this statistic {\\displaystyle t} has a specific distribution simply known as the Dickey–Fuller table .",
    "url": "https://en.wikipedia.org/wiki/Dickey–Fuller test"
  },
  "{\\displaystyle \\Delta y_{t}=\\delta y_{t-1}+u_{t}\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Dickey–Fuller test"
  },
  "{\\displaystyle \\Delta y_{t}=a_{0}+\\delta y_{t-1}+u_{t}\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Dickey–Fuller test"
  },
  "{\\displaystyle \\Delta y_{t}=a_{0}+a_{1}t+\\delta y_{t-1}+u_{t}\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Dickey–Fuller test"
  },
  "{\\displaystyle \\Delta y_{t}=a_{0}+u_{t}\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Dickey–Fuller test"
  },
  "{\\displaystyle y_{t}=y_{0}+\\sum _{i=1}^{t}u_{i}+a_{0}t}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Dickey–Fuller test"
  },
  "T = Phase 1 table;": {
    "before": "Phase 2 of the algorithm can now be summarized as follows:",
    "after": "while (true) {",
    "url": "https://en.wikipedia.org/wiki/Stable roommates problem"
  },
  "return the matching M = {{x, y} | x and y are on each other's lists in T}; (this is a stable matching)": {
    "before": "else if (each reduced list in T has size 1)",
    "after": "}",
    "url": "https://en.wikipedia.org/wiki/Stable roommates problem"
  },
  "In Phase 2, the rotation r1 = (1,4), (3,2) is first identified. This is because 2 is 1's second favorite, and 4 is the second favorite of 3. Eliminating r1 gives:": {
    "before": "6 : 5 1 3 4 2",
    "after": "1 : 3 4 2 6 5",
    "url": "https://en.wikipedia.org/wiki/Stable roommates problem"
  },
  "Next, the rotation r2 = (1,2), (2,6), (4,5) is identified, and its elimination yields:": {
    "before": "6 : 5 1 3 4 2",
    "after": "1 : 3 4 2 6 5",
    "url": "https://en.wikipedia.org/wiki/Stable roommates problem"
  },
  "{\\displaystyle {\\frac {\\partial \\Pi _{2}}{\\partial q_{2}}}={\\frac {\\partial P(q_{1}+q_{2})}{\\partial q_{2}}}\\cdot q_{2}+P(q_{1}+q_{2})-{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}.}": {
    "before": "The profit of firm {\\displaystyle 2} (the follower) is revenue minus cost. Revenue is the product of price and quantity and cost is given by the firm's cost structure, so profit is: {\\displaystyle \\Pi _{2}=P(q_{1}+q_{2})\\cdot q_{2}-C_{2}(q_{2})} . The best response is to find the value of {\\displaystyle q_{2}} that maximises {\\displaystyle \\Pi _{2}} given {\\displaystyle q_{1}} , i.e. given the output of the leader (firm {\\displaystyle 1} ), the output that maximises the follower's profit is found. Hence, the maximum of {\\displaystyle \\Pi _{2}} with respect to {\\displaystyle q_{2}} is to be found. First differentiate {\\displaystyle \\Pi _{2}} with respect to {\\displaystyle q_{2}} :",
    "after": "Setting this to zero for maximisation:",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle {\\frac {\\partial \\Pi _{2}}{\\partial q_{2}}}={\\frac {\\partial P(q_{1}+q_{2})}{\\partial q_{2}}}\\cdot q_{2}+P(q_{1}+q_{2})-{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}=0.}": {
    "before": "{\\displaystyle {\\frac {\\partial \\Pi _{2}}{\\partial q_{2}}}={\\frac {\\partial P(q_{1}+q_{2})}{\\partial q_{2}}}\\cdot q_{2}+P(q_{1}+q_{2})-{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}.} Setting this to zero for maximisation:",
    "after": "The values of {\\displaystyle q_{2}} that satisfy this equation are the best responses. Now the best response function of the leader is considered. This function is calculated by considering the follower's output as a function of the leader's output, as just computed.",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle {\\frac {\\partial \\Pi _{1}}{\\partial q_{1}}}={\\frac {\\partial P(q_{1}+q_{2})}{\\partial q_{2}}}\\cdot {\\frac {\\partial q_{2}(q_{1})}{\\partial q_{1}}}\\cdot q_{1}+{\\frac {\\partial P(q_{1}+q_{2})}{\\partial q_{1}}}\\cdot q_{1}+P(q_{1}+q_{2}(q_{1}))-{\\frac {\\partial C_{1}(q_{1})}{\\partial q_{1}}}.}": {
    "before": "The profit of firm {\\displaystyle 1} (the leader) is {\\displaystyle \\Pi _{1}=P(q_{1}+q_{2}(q_{1})).q_{1}-C_{1}(q_{1})} , where {\\displaystyle q_{2}(q_{1})} is the follower's quantity as a function of the leader's quantity, namely the function calculated above. The best response is to find the value of {\\displaystyle q_{1}} that maximises {\\displaystyle \\Pi _{1}} given {\\displaystyle q_{2}(q_{1})} , i.e. given the best response function of the follower (firm {\\displaystyle 2} ), the output that maximises the leader's profit is found. Hence, the maximum of {\\displaystyle \\Pi _{1}} with respect to {\\displaystyle q_{1}} is to be found. First, differentiate {\\displaystyle \\Pi _{1}} with respect to {\\displaystyle q_{1}} :",
    "after": "Setting this to zero for maximisation:",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle {\\frac {\\partial \\Pi _{1}}{\\partial q_{1}}}={\\frac {\\partial P(q_{1}+q_{2})}{\\partial q_{2}}}\\cdot {\\frac {\\partial q_{2}(q_{1})}{\\partial q_{1}}}\\cdot q_{1}+{\\frac {\\partial P(q_{1}+q_{2})}{\\partial q_{1}}}\\cdot q_{1}+P(q_{1}+q_{2}(q_{1}))-{\\frac {\\partial C_{1}(q_{1})}{\\partial q_{1}}}=0.}": {
    "before": "{\\displaystyle {\\frac {\\partial \\Pi _{1}}{\\partial q_{1}}}={\\frac {\\partial P(q_{1}+q_{2})}{\\partial q_{2}}}\\cdot {\\frac {\\partial q_{2}(q_{1})}{\\partial q_{1}}}\\cdot q_{1}+{\\frac {\\partial P(q_{1}+q_{2})}{\\partial q_{1}}}\\cdot q_{1}+P(q_{1}+q_{2}(q_{1}))-{\\frac {\\partial C_{1}(q_{1})}{\\partial q_{1}}}.} Setting this to zero for maximisation:",
    "after": "Examples [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle p(q_{1}+q_{2})={\\bigg (}a-b(q_{1}+q_{2}){\\bigg )}}": {
    "before": "The following example is very general. It assumes a generalised linear demand structure",
    "after": "and imposes some restrictions on cost structures for simplicity's sake so the problem can be resolved.",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle {\\frac {\\partial ^{2}C_{i}(q_{i})}{\\partial q_{i}\\cdot \\partial q_{j}}}=0,\\forall j} and {\\displaystyle {\\frac {\\partial C_{i}(q_{i})}{\\partial q_{j}}}=0,j\\neq \\ i}": {
    "before": "and imposes some restrictions on cost structures for simplicity's sake so the problem can be resolved.",
    "after": "for ease of computation.",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle \\pi _{2}={\\bigg (}a-b(q_{1}+q_{2}){\\bigg )}\\cdot q_{2}-C_{2}(q_{2}).}": {
    "before": "for ease of computation.The follower's profit is:",
    "after": "The maximisation problem resolves to (from the general case):",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle \\Rightarrow \\ q_{2}={\\frac {a-bq_{1}-{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}}{2b}}.}": {
    "before": "{\\displaystyle \\Rightarrow \\ -bq_{2}+a-b(q_{1}+q_{2})-{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}=0,}",
    "after": "Consider the leader's problem:",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle \\Pi _{1}={\\bigg (}a-b(q_{1}+q_{2}(q_{1})){\\bigg )}\\cdot q_{1}-C_{1}(q_{1}).}": {
    "before": "{\\displaystyle \\Rightarrow \\ q_{2}={\\frac {a-bq_{1}-{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}}{2b}}.} Consider the leader's problem:",
    "after": "Substituting for {\\displaystyle q_{2}(q_{1})} from the follower's problem:",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle \\Pi _{1}={\\bigg (}a-b{\\bigg (}q_{1}+{\\frac {a-bq_{1}-{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}}{2b}}{\\bigg )}{\\bigg )}\\cdot q_{1}-C_{1}(q_{1}),}": {
    "before": "Substituting for {\\displaystyle q_{2}(q_{1})} from the follower's problem:",
    "after": "{\\displaystyle \\Rightarrow \\Pi _{1}={\\bigg (}{\\frac {a-b.q_{1}+{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}}{2}}){\\bigg )}\\cdot q_{1}-C_{1}(q_{1}).}",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle \\Rightarrow \\Pi _{1}={\\bigg (}{\\frac {a-b.q_{1}+{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}}{2}}){\\bigg )}\\cdot q_{1}-C_{1}(q_{1}).}": {
    "before": "{\\displaystyle \\Pi _{1}={\\bigg (}a-b{\\bigg (}q_{1}+{\\frac {a-bq_{1}-{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}}{2b}}{\\bigg )}{\\bigg )}\\cdot q_{1}-C_{1}(q_{1}),}",
    "after": "The maximisation problem resolves to (from the general case):",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle {\\frac {\\partial \\pi _{1}}{\\partial q_{1}}}={\\bigg (}{\\frac {a-2bq_{1}+{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}}{2}}{\\bigg )}-{\\frac {\\partial C_{1}(q_{1})}{\\partial q_{1}}}=0.}": {
    "before": "The maximisation problem resolves to (from the general case):",
    "after": "Now solving for {\\displaystyle q_{1}} yields {\\displaystyle q_{1}^{*}} , the leader's optimal action:",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle q_{1}^{*}={\\frac {a+{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}-2\\cdot {\\frac {\\partial C_{1}(q_{1})}{\\partial q_{1}}}}{2b}}.}": {
    "before": "Now solving for {\\displaystyle q_{1}} yields {\\displaystyle q_{1}^{*}} , the leader's optimal action:",
    "after": "This is the leader's best response to the reaction of the follower in equilibrium. The follower's actual can now be found by feeding this into its reaction function calculated earlier:",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle q_{2}^{*}={\\frac {a-b\\cdot {\\frac {a+{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}-2\\cdot {\\frac {\\partial C_{1}(q_{1})}{\\partial q_{1}}}}{2b}}-{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}}{2b}},}": {
    "before": "This is the leader's best response to the reaction of the follower in equilibrium. The follower's actual can now be found by feeding this into its reaction function calculated earlier:",
    "after": "{\\displaystyle \\Rightarrow q_{2}^{*}={\\frac {a-3\\cdot {\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}+2\\cdot {\\frac {\\partial C_{1}(q_{1})}{\\partial q_{1}}}}{4b}}.}",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle \\Rightarrow q_{2}^{*}={\\frac {a-3\\cdot {\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}+2\\cdot {\\frac {\\partial C_{1}(q_{1})}{\\partial q_{1}}}}{4b}}.}": {
    "before": "{\\displaystyle q_{2}^{*}={\\frac {a-b\\cdot {\\frac {a+{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}-2\\cdot {\\frac {\\partial C_{1}(q_{1})}{\\partial q_{1}}}}{2b}}-{\\frac {\\partial C_{2}(q_{2})}{\\partial q_{2}}}}{2b}},}",
    "after": "The Nash equilibria are all {\\displaystyle (q_{1}^{*},q_{2}^{*})} . It is clear (if marginal costs are assumed to be zero - i.e. cost is essentially ignored) that the leader has a significant advantage. Intuitively, if the leader was no better off than the follower, it would simply adopt a Cournot competition strategy.",
    "url": "https://en.wikipedia.org/wiki/Stackelberg competition"
  },
  "{\\displaystyle U_{i}(\\{x_{i},x_{j}\\})=x_{i}-{\\frac {\\alpha _{i}}{n-1}}\\times \\sum {\\max(x_{j}-x_{i},0)}-{\\frac {\\beta _{i}}{n-1}}\\times \\sum {\\max(x_{i}-x_{j},0)},}": {
    "before": "A more recent definition of inequity aversion (resistance to inequitable outcomes) was developed in 1999 by Fehr and Schmidt.  They postulated that people make decisions so as to minimize inequity in outcomes. Specifically, consider a setting with individuals {1,2,..., n } who receive pecuniary outcomes x i . Then the utility to person i would be given by",
    "after": "where α parametrizes the distaste of person i for disadvantageous inequality in the first nonstandard term, and β parametrizes the distaste of person i for advantageous inequality in the final term.",
    "url": "https://en.wikipedia.org/wiki/Inequity aversion"
  },
  "{\\displaystyle Y={\\text{constant}}+{\\text{error}}} valid and sufficient?": {
    "before": "Are the data random? Is an observation related to an adjacent observation? Is an observation related to an observation twice-removed? (etc.) Is the observed time series white noise ? Is the observed time series sinusoidal? Is the observed time series autoregressive? What is an appropriate model for the observed time series? Is the model",
    "after": "Is the formula {\\displaystyle s_{\\bar {Y}}=s/{\\sqrt {N}}} valid?",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "{\\displaystyle Y={\\text{constant}}+{\\text{error}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "{\\displaystyle s_{\\bar {Y}}=s/{\\sqrt {N}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "{\\displaystyle r_{h}=c_{h}/c_{0}\\,}": {
    "before": "The autocorrelation coefficient at lag h is given by",
    "after": "where c h is the autocovariance function",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "{\\displaystyle c_{h}={\\frac {1}{N}}\\sum _{t=1}^{N-h}\\left(Y_{t}-{\\bar {Y}}\\right)\\left(Y_{t+h}-{\\bar {Y}}\\right)}": {
    "before": "{\\displaystyle r_{h}=c_{h}/c_{0}\\,} where c h is the autocovariance function",
    "after": "and c 0 is the variance function",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "{\\displaystyle c_{0}={\\frac {1}{N}}\\sum _{t=1}^{N}\\left(Y_{t}-{\\bar {Y}}\\right)^{2}}": {
    "before": "{\\displaystyle c_{h}={\\frac {1}{N}}\\sum _{t=1}^{N-h}\\left(Y_{t}-{\\bar {Y}}\\right)\\left(Y_{t+h}-{\\bar {Y}}\\right)} and c 0 is the variance function",
    "after": "The resulting value of r h will range between −1 and +1.",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "{\\displaystyle c_{h}={\\frac {1}{N-h}}\\sum _{t=1}^{N-h}\\left(Y_{t}-{\\bar {Y}}\\right)\\left(Y_{t+h}-{\\bar {Y}}\\right)}": {
    "before": "Some sources may use the following formula for the autocovariance function:",
    "after": "Although this definition has less bias , the (1/ N ) formulation has some desirable statistical properties and is the form most commonly used in the statistics literature. See pages 20 and 49–50 in Chatfield for details.",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "{\\displaystyle X={\\begin{bmatrix}Y_{1}-{\\bar {Y}}&\\cdots &Y_{N}-{\\bar {Y}}\\end{bmatrix}}\\in \\mathbb {R} ^{n\\times N}}": {
    "before": "In contrast to the definition above, this definition allows us to compute {\\displaystyle c_{h}} in a slightly more intuitive way. Consider the sample {\\displaystyle Y_{1},\\dots ,Y_{N}} , where {\\displaystyle Y_{i}\\in \\mathbb {R} ^{n}} for {\\displaystyle i=1,\\dots ,N} . Then, let",
    "after": "We then compute the Gram matrix {\\displaystyle Q=X^{\\top }X} . Finally, {\\displaystyle c_{h}} is computed as the sample mean of the {\\displaystyle h} th diagonal of {\\displaystyle Q} . For example, the {\\displaystyle 0} th diagonal (the main diagonal) of {\\displaystyle Q} has {\\displaystyle N} elements, and its sample mean corresponds to {\\displaystyle c_{0}} . The {\\displaystyle 1} st diagonal (to the right of the main diagonal) of {\\displaystyle Q} has {\\displaystyle N-1} elements, and its sample mean corresponds to {\\displaystyle c_{1}} , and so on.",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "{\\displaystyle B=\\pm z_{1-\\alpha /2}SE(r_{h})\\,} with {\\displaystyle r_{h}\\,} as the estimated autocorrelation at lag {\\displaystyle h\\,} .": {
    "before": "In the same graph one can draw upper and lower bounds for autocorrelation with significance level {\\displaystyle \\alpha \\,} :",
    "after": "If the autocorrelation is higher (lower) than this upper (lower) bound, the null hypothesis that there is no autocorrelation at and beyond a given lag is rejected at a significance level of {\\displaystyle \\alpha \\,} . This test is an approximate one and assumes that the time-series is Gaussian .",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "{\\displaystyle SE(r_{1})={\\frac {1}{\\sqrt {N}}}} {\\displaystyle SE(r_{h})={\\sqrt {\\frac {1+2\\sum _{i=1}^{h-1}r_{i}^{2}}{N}}}} for {\\displaystyle h>1.\\,}": {
    "before": "In the above, z 1− α /2 is the quantile of the normal distribution ; SE is the standard error, which can be computed by Bartlett 's formula for MA( ℓ ) processes:",
    "after": "In the example plotted, we can reject the null hypothesis that there is no autocorrelation between time-points which are separated by lags up to 4. For most longer periods one cannot reject the null hypothesis of no autocorrelation.",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "{\\displaystyle \\pm z_{1-\\alpha /2}{\\sqrt {{\\frac {1}{N}}\\left(1+2\\sum _{i=1}^{k}r_{i}^{2}\\right)}}}": {
    "before": "2. Correlograms are also used in the model identification stage for fitting ARIMA models. In this case, a moving average model is assumed for the data and the following confidence bands should be generated:",
    "after": "where k is the lag. In this case, the confidence bands increase as the lag increases.",
    "url": "https://en.wikipedia.org/wiki/Correlogram"
  },
  "HRV triangular index = Number of all NN intervals / maximum number. Dependent on the length of the bin -> quote the bin size+ relative insensitive to the analytic quality of the series of NN intervals – need of reasonable number of NN intervals to generate the geometric pattern (in practice 20 min to 24 h) – not appropriate to assess short-term changes in HRV": {
    "before": "Geometric Measures HRV triangular index: integral of density distribution / maximum of density distribution maximum",
    "after": "the sample density distribution of NN interval durations;",
    "url": "https://en.wikipedia.org/wiki/Heart rate variability"
  },
  "{\\displaystyle \\Pr(a_{i}\\leq a^{*})={\\frac {{\\frac {1}{2+3/A}}+A}{2A}}={\\frac {A}{4A^{2}+6A}}+{\\frac {1}{2}}.}": {
    "before": "Suppose that each player i bears an extra cost a i from playing Cooperate, which is uniformly distributed on [− A , A ]. Players only know their own value of this cost. So this is a game of incomplete information which we can solve using Bayesian Nash equilibrium . The probability that a i ≤ a* is ( a* + A )/2 A . If player 2 Cooperates when a 2 ≤ a* , then player 1's expected utility from Cooperating is − a 1 + 3( a* + A )/2 A + 2(1 − ( a* + A )/2 A ) ; his expected utility from Defecting is 4( a* + A )/2 A . He should therefore himself Cooperate when a 1 ≤ 2 - 3( a* + A )/2 A . Seeking a symmetric equilibrium where both players cooperate if a i ≤ a* , we solve this for a* = 1/(2 + 3/ A ). Now we have worked out a* , we can calculate the probability of each player playing Cooperate as",
    "after": "As A → 0, this approaches 2/3 – the same probability as in the mixed strategy in the complete information game.",
    "url": "https://en.wikipedia.org/wiki/Purification theorem"
  },
  "{\\displaystyle V(A)=\\sum \\limits _{j}P(O_{j}|A)D(O_{j}),}": {
    "before": "In a 1976 paper, Allan Gibbard and William Harper distinguished between two kinds of expected utility maximization. EDT proposes to maximize the expected utility of actions computed using conditional probabilities , namely",
    "after": "where {\\displaystyle D(O_{j})} is the desirability of outcome {\\displaystyle O_{j}} and {\\displaystyle P(O_{j}|A)} is the conditional probability of {\\displaystyle O_{j}} given that action {\\displaystyle A} occurs.  This is in contrast to the counterfactual formulation of expected utility used by causal decision theory",
    "url": "https://en.wikipedia.org/wiki/Evidential decision theory"
  },
  "{\\displaystyle U(A)=\\sum \\limits _{j}P(A\\mathrel {\\Box {\\rightarrow }} O_{j})D(O_{j}),}": {
    "before": "where {\\displaystyle D(O_{j})} is the desirability of outcome {\\displaystyle O_{j}} and {\\displaystyle P(O_{j}|A)} is the conditional probability of {\\displaystyle O_{j}} given that action {\\displaystyle A} occurs.  This is in contrast to the counterfactual formulation of expected utility used by causal decision theory",
    "after": "where the expression {\\displaystyle P(A\\mathrel {\\Box {\\rightarrow }} O_{j})} indicates the probability of outcome {\\displaystyle O_{j}} in the counterfactual situation in which action {\\displaystyle A} is performed. Since {\\displaystyle P(A\\mathrel {\\Box {\\rightarrow }} O_{j})} and {\\displaystyle P(O_{j}|A)} are not always equal, these formulations of expected utility are not equivalent,  leading to differences in actions prescribed by EDT and CDT.",
    "url": "https://en.wikipedia.org/wiki/Evidential decision theory"
  },
  "{\\displaystyle {\\begin{aligned}V({\\text{take only B}})&=P({\\text{1M in box B}}|{\\text{take only B}})\\times \\$1,000,000+P({\\text{nothing in box B}}|{\\text{take only B}})\\times \\$0\\\\&=0.99\\times \\$1,000,000+0.01\\times \\$0=\\$990,000\\\\V({\\text{take both boxes}})&=P({\\text{1M in box B}}|{\\text{take both boxes}})\\times \\$1,001,000+P({\\text{nothing in box B}}|{\\text{take both boxes}})\\times \\$1,000\\\\&=0.01\\times \\$1,001,000+0.99\\times \\$1,000=\\$11,000\\end{aligned}}}": {
    "before": "Evidential decision theory recommends taking only box B in this scenario, because taking only box B is strong evidence that the predictor anticipated that the player would only take box B, and therefore it is very likely that box B contains $1,000,000. Conversely, choosing to take both boxes is strong evidence that the predictor knew that the player would take both boxes; therefore we should expect that box B contains nothing.  : 22 Formally, the expected utilities are",
    "after": "Since {\\displaystyle V({\\text{take only B}})>V({\\text{take both boxes}})} , EDT recommends taking only box B.",
    "url": "https://en.wikipedia.org/wiki/Evidential decision theory"
  },
  "{\\displaystyle {\\begin{aligned}V({\\text{Aomame cooperates}})&=P({\\text{twin cooperates}}|{\\text{Aomame cooperates}})\\times \\$5+P({\\text{twin defects}}|{\\text{Aomame cooperates}})\\times \\$0\\\\&=1\\times \\$5+0\\times \\$0=\\$5\\\\V({\\text{Aomame defects}})&=P({\\text{twin cooperates}}|{\\text{Aomame defects}})\\times \\$10+P({\\text{twin defects}}|{\\text{Aomame defects}})\\times \\$1\\\\&=0\\times \\$10+1\\times \\$1=\\$1.\\end{aligned}}}": {
    "before": "Evidential decision theory recommends cooperating in this situation, because Aomame's decision to cooperate is strong evidence that her psychological twin will also cooperate, meaning that her expected payoff is $5. On the other hand, if Aomame defects, this would be strong evidence that her twin will also defect, resulting in an expected payoff of $1. Formally, the expected utilities are",
    "after": "Since {\\displaystyle V({\\text{Aomame cooperates}})>V({\\text{Aomame defects}})} , EDT recommends cooperating.",
    "url": "https://en.wikipedia.org/wiki/Evidential decision theory"
  },
  "{\\displaystyle Q=n(n+2)\\sum _{k=1}^{h}{\\frac {{\\hat {\\rho }}_{k}^{2}}{n-k}}}": {
    "before": "H 0 : The data are independently distributed (i.e. the correlations in the population from which the sample is taken are 0, so that any observed correlations in the data result from randomness of the sampling process). H a : The data are not independently distributed; they exhibit serial correlation.The test statistic is: ",
    "after": "where n is the sample size, {\\displaystyle {\\hat {\\rho }}_{k}} is the sample autocorrelation at lag k , and h is the number of lags being tested. Under {\\displaystyle H_{0}} the statistic Q asymptotically follows a {\\displaystyle \\chi _{(h)}^{2}} . For significance level α, the critical region for rejection of the hypothesis of randomness is:",
    "url": "https://en.wikipedia.org/wiki/Ljung–Box test"
  },
  "{\\displaystyle Q_{\\text{BP}}=n\\sum _{k=1}^{h}{\\hat {\\rho }}_{k}^{2},}": {
    "before": "The Box–Pierce test uses the test statistic, in the notation outlined above, given by ",
    "after": "and it uses the same critical region as defined above.",
    "url": "https://en.wikipedia.org/wiki/Ljung–Box test"
  },
  "{\\displaystyle W_{[a,a+r]}=\\int _{a}^{a+r}w(t)\\,dt}": {
    "before": "Some authors require each value {\\displaystyle w(t)} to be a real-valued random variable with expectation {\\displaystyle \\mu } and some finite variance {\\displaystyle \\sigma ^{2}} . Then the covariance {\\displaystyle \\mathrm {E} (w(t_{1})\\cdot w(t_{2}))} between the values at two times {\\displaystyle t_{1}} and {\\displaystyle t_{2}} is well-defined: it is zero if the times are distinct, and {\\displaystyle \\sigma ^{2}} if they are equal. However, by this definition, the integral",
    "after": "over any interval with positive width {\\displaystyle r} would be simply the width times the expectation: {\\displaystyle r\\mu } . This property would render the concept inadequate as a model of physical \"white noise\" signals.",
    "url": "https://en.wikipedia.org/wiki/White noise"
  },
  "{\\displaystyle \\forall k\\in \\mathbb {R} ^{n}:\\quad \\mathrm {E} (\\mathrm {e} ^{\\mathrm {i} \\langle k,X\\rangle })=\\mathrm {e} ^{\\mathrm {i} \\langle k,\\mu \\rangle -{\\frac {1}{2}}\\langle k,\\Sigma k\\rangle },}": {
    "before": "In the mathematical field known as white noise analysis , a Gaussian white noise {\\displaystyle w} is defined as a stochastic tempered distribution, i.e. a random variable with values in the space {\\displaystyle {\\mathcal {S}}'(\\mathbb {R} )} of tempered distributions . Analogous to the case for finite-dimensional random vectors, a probability law on the infinite-dimensional space {\\displaystyle {\\mathcal {S}}'(\\mathbb {R} )} can be defined via its characteristic function (existence and uniqueness are guaranteed by an extension of the Bochner–Minlos theorem, which goes under the name Bochner–Minlos–Sazanov theorem); analogously to the case of the multivariate normal distribution {\\displaystyle X\\sim {\\mathcal {N}}_{n}(\\mu ,\\Sigma )} , which has characteristic function",
    "after": "the white noise {\\displaystyle w:\\Omega \\to {\\mathcal {S}}'(\\mathbb {R} )} must satisfy",
    "url": "https://en.wikipedia.org/wiki/White noise"
  },
  "{\\displaystyle \\forall \\varphi \\in {\\mathcal {S}}(\\mathbb {R} ):\\quad \\mathrm {E} (\\mathrm {e} ^{\\mathrm {i} \\langle w,\\varphi \\rangle })=\\mathrm {e} ^{-{\\frac {1}{2}}\\|\\varphi \\|_{2}^{2}},}": {
    "before": "the white noise {\\displaystyle w:\\Omega \\to {\\mathcal {S}}'(\\mathbb {R} )} must satisfy",
    "after": "where {\\displaystyle \\langle w,\\varphi \\rangle } is the natural pairing of the tempered distribution {\\displaystyle w(\\omega )} with the Schwartz function {\\displaystyle \\varphi } , taken scenariowise for {\\displaystyle \\omega \\in \\Omega } , and {\\displaystyle \\|\\varphi \\|_{2}^{2}=\\int _{\\mathbb {R} }\\vert \\varphi (x)\\vert ^{2}\\,\\mathrm {d} x} .",
    "url": "https://en.wikipedia.org/wiki/White noise"
  },
  "{\\displaystyle \\mathbf {w} _{X}^{*}=\\arg \\min _{\\mathbf {w} }\\left\\{\\sum _{i=1}^{N}(x_{i}-\\langle \\mathbf {w} ,\\mathbf {z} _{i}\\rangle )^{2}\\right\\}} {\\displaystyle \\mathbf {w} _{Y}^{*}=\\arg \\min _{\\mathbf {w} }\\left\\{\\sum _{i=1}^{N}(y_{i}-\\langle \\mathbf {w} ,\\mathbf {z} _{i}\\rangle )^{2}\\right\\}}": {
    "before": "A simple way to compute the sample partial correlation for some data is to solve the two associated linear regression problems and calculate the correlation between the residuals. Let X and Y be random variables taking real values, and let Z be the n -dimensional vector-valued random variable. Let x i , y i and z i denote the i th of {\\displaystyle N} i.i.d. observations from some joint probability distribution over real random variables X , Y , and Z , with z i having been augmented with a 1 to allow for a constant term in the regression. Solving the linear regression problem amounts to finding ( n +1)-dimensional regression coefficient vectors {\\displaystyle \\mathbf {w} _{X}^{*}} and {\\displaystyle \\mathbf {w} _{Y}^{*}} such that",
    "after": "where {\\displaystyle N} is the number of observations, and {\\displaystyle \\langle \\mathbf {w} ,\\mathbf {z} _{i}\\rangle } is the scalar product between the vectors {\\displaystyle \\mathbf {w} } and {\\displaystyle \\mathbf {z} _{i}} .",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle e_{X,i}=x_{i}-\\langle \\mathbf {w} _{X}^{*},\\mathbf {z} _{i}\\rangle } {\\displaystyle e_{Y,i}=y_{i}-\\langle \\mathbf {w} _{Y}^{*},\\mathbf {z} _{i}\\rangle }": {
    "before": "where {\\displaystyle N} is the number of observations, and {\\displaystyle \\langle \\mathbf {w} ,\\mathbf {z} _{i}\\rangle } is the scalar product between the vectors {\\displaystyle \\mathbf {w} } and {\\displaystyle \\mathbf {z} _{i}} .The residuals are then",
    "after": "and the sample partial correlation is then given by the usual formula for sample correlation , but between these new derived values:",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle {\\begin{aligned}{\\hat {\\rho }}_{XY\\cdot \\mathbf {Z} }&={\\frac {N\\sum _{i=1}^{N}e_{X,i}e_{Y,i}-\\sum _{i=1}^{N}e_{X,i}\\sum _{i=1}^{N}e_{Y,i}}{{\\sqrt {N\\sum _{i=1}^{N}e_{X,i}^{2}-\\left(\\sum _{i=1}^{N}e_{X,i}\\right)^{2}}}~{\\sqrt {N\\sum _{i=1}^{N}e_{Y,i}^{2}-\\left(\\sum _{i=1}^{N}e_{Y,i}\\right)^{2}}}}}\\\\&={\\frac {N\\sum _{i=1}^{N}e_{X,i}e_{Y,i}}{{\\sqrt {N\\sum _{i=1}^{N}e_{X,i}^{2}}}~{\\sqrt {N\\sum _{i=1}^{N}e_{Y,i}^{2}}}}}.\\end{aligned}}}": {
    "before": "and the sample partial correlation is then given by the usual formula for sample correlation , but between these new derived values:",
    "after": "In the first expression the three terms after minus signs all equal 0 since each contains the sum of residuals from an ordinary least squares regression.",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle \\rho _{XY\\cdot \\mathbf {Z} }={\\frac {\\rho _{XY\\cdot \\mathbf {Z} \\setminus \\{Z_{0}\\}}-\\rho _{XZ_{0}\\cdot \\mathbf {Z} \\setminus \\{Z_{0}\\}}\\rho _{Z_{0}Y\\cdot \\mathbf {Z} \\setminus \\{Z_{0}\\}}}{{\\sqrt {1-\\rho _{XZ_{0}\\cdot \\mathbf {Z} \\setminus \\{Z_{0}\\}}^{2}}}{\\sqrt {1-\\rho _{Z_{0}Y\\cdot \\mathbf {Z} \\setminus \\{Z_{0}\\}}^{2}}}}}}": {
    "before": "It holds, for any {\\displaystyle Z_{0}\\in \\mathbf {Z} ,} that [ citation needed ]",
    "after": "Naïvely implementing this computation as a recursive algorithm yields an exponential time complexity . However, this computation has the overlapping subproblems property, such that using dynamic programming or simply caching the results of the recursive calls yields a complexity of {\\displaystyle {\\mathcal {O}}(n^{3})} .",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle \\rho _{XY\\cdot Z}={\\frac {\\rho _{XY}-\\rho _{XZ}\\rho _{ZY}}{{\\sqrt {1-\\rho _{XZ}^{2}}}{\\sqrt {1-\\rho _{ZY}^{2}}}}}}": {
    "before": "Note in the case where Z is a single variable, this reduces to: [ citation needed ]",
    "after": "Using matrix inversion [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle \\rho _{X_{i}X_{j}\\cdot \\mathbf {V} \\setminus \\{X_{i},X_{j}\\}}=-{\\frac {p_{ij}}{\\sqrt {p_{ii}p_{jj}}}}} ( 1 )": {
    "before": "The partial correlation can also be written in terms of the joint precision matrix. Consider a set of random variables, {\\displaystyle \\mathbf {V} ={X_{1},\\dots ,X_{n}}} of cardinality n . We want the partial correlation between two variables {\\displaystyle X_{i}} and {\\displaystyle X_{j}} given all others, i.e., {\\displaystyle \\mathbf {V} \\setminus \\{X_{i},X_{j}\\}} . Suppose the (joint/full) covariance matrix {\\displaystyle \\Sigma =(\\sigma _{ij})} is positive definite and therefore invertible . If the precision matrix is defined as {\\displaystyle \\Omega =(p_{ij})=\\Sigma ^{-1}} , then",
    "after": "Computing this requires {\\displaystyle \\Sigma ^{-1}} , the inverse of the covariance matrix {\\displaystyle \\Sigma } which runs in {\\displaystyle {\\mathcal {O}}(n^{3})} time (using the sample covariance matrix to obtain a sample partial correlation). Note that only a single matrix inversion is required to give all the partial correlations between pairs of variables in {\\displaystyle \\mathbf {V} } .",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle \\beta =\\operatorname {argmin} _{\\beta }\\mathbb {E} \\|X-\\beta ^{T}Z\\|^{2}} {\\displaystyle \\gamma =\\operatorname {argmin} _{\\gamma }\\mathbb {E} \\|Y-\\gamma ^{T}Z\\|^{2}}": {
    "before": "First, suppose {\\displaystyle \\beta ,\\gamma } are the coefficients for linear regression fit; that is,",
    "after": "Write the joint covariance matrix for the vector {\\displaystyle (X,Y,Z^{T})^{T}} as",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle \\Sigma ={\\begin{bmatrix}\\Sigma _{XX}&\\Sigma _{XY}&\\Sigma _{XZ}\\\\\\Sigma _{YX}&\\Sigma _{YY}&\\Sigma _{YZ}\\\\\\Sigma _{ZX}&\\Sigma _{ZY}&\\Sigma _{ZZ}\\end{bmatrix}}={\\begin{bmatrix}C_{11}&C_{12}\\\\C_{21}&C_{22}\\\\\\end{bmatrix}}}": {
    "before": "Write the joint covariance matrix for the vector {\\displaystyle (X,Y,Z^{T})^{T}} as",
    "after": "where {\\displaystyle C_{11}={\\begin{bmatrix}\\Sigma _{XX}&\\Sigma _{XY}\\\\\\Sigma _{YX}&\\Sigma _{YY}\\end{bmatrix}},\\qquad C_{12}={\\begin{bmatrix}\\Sigma _{XZ}\\\\\\Sigma _{YZ}\\end{bmatrix}},\\qquad C_{21}={\\begin{bmatrix}\\Sigma _{ZX}&\\Sigma _{ZY}\\end{bmatrix}},\\qquad C_{22}=\\Sigma _{ZZ}}",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle \\beta =\\left(\\Sigma _{ZZ}\\right)^{-1}\\Sigma _{ZX}}": {
    "before": "Then the standard formula for linear regression gives",
    "after": "Hence, the residuals can be written as",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle R_{X}=X-\\beta ^{T}Z=X-\\Sigma _{XZ}\\left(\\Sigma _{ZZ}\\right)^{-1}Z}": {
    "before": "{\\displaystyle \\beta =\\left(\\Sigma _{ZZ}\\right)^{-1}\\Sigma _{ZX}} Hence, the residuals can be written as",
    "after": "Note that {\\displaystyle R_{X}} has expectation zero because of the inclusion of an intercept term in {\\displaystyle Z} . Computing the covariance now gives",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle \\operatorname {Cov} (R_{X},R_{Y})=\\mathbb {E} (R_{X},R_{Y})=\\dots =\\Sigma _{XY}-\\Sigma _{XZ}\\left(\\Sigma _{ZZ}\\right)^{-1}\\Sigma _{ZY}} ( 2 )": {
    "before": "Note that {\\displaystyle R_{X}} has expectation zero because of the inclusion of an intercept term in {\\displaystyle Z} . Computing the covariance now gives",
    "after": "Next, write the precision matrix {\\displaystyle \\Omega =\\Sigma ^{-1}} in a similar block form:",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle \\Omega ={\\begin{bmatrix}\\Omega _{XX}&\\Omega _{XY}&\\Omega _{XZ}\\\\\\Omega _{YX}&\\Omega _{YY}&\\Omega _{YZ}\\\\\\Omega _{ZX}&\\Omega _{ZY}&\\Omega _{ZZ}\\end{bmatrix}}={\\begin{bmatrix}P_{11}&P_{12}\\\\P_{21}&P_{22}\\\\\\end{bmatrix}}}": {
    "before": "Next, write the precision matrix {\\displaystyle \\Omega =\\Sigma ^{-1}} in a similar block form:",
    "after": "Then, by Schur's formula for block-matrix inversion ,",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle P_{11}^{-1}=C_{11}-C_{12}C_{22}^{-1}C_{21}}": {
    "before": "Then, by Schur's formula for block-matrix inversion ,",
    "after": "The entries of the right-hand-side matrix are precisely the covariances previously computed in ( 2 ), giving",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle P_{11}^{-1}={\\begin{bmatrix}\\operatorname {Cov} (R_{X},R_{X})&\\operatorname {Cov} (R_{X},R_{Y})\\\\\\operatorname {Cov} (R_{Y},R_{X})&\\operatorname {Cov} (R_{Y},R_{Y})\\\\\\end{bmatrix}}}": {
    "before": "The entries of the right-hand-side matrix are precisely the covariances previously computed in ( 2 ), giving",
    "after": "Using the formula for the inverse of a 2×2 matrix gives",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle {\\begin{aligned}P_{11}^{-1}&={\\frac {1}{{\\text{det}}P_{11}}}{\\begin{pmatrix}[P_{11}]_{22}&-[P_{11}]_{12}\\\\-[P_{11}]_{21}&[P_{11}]_{11}\\\\\\end{pmatrix}}\\\\&={\\frac {1}{{\\text{det}}P_{11}}}{\\begin{pmatrix}p_{YY}&-p_{XY}\\\\-p_{YX}&p_{XX}\\\\\\end{pmatrix}}\\end{aligned}}}": {
    "before": "Using the formula for the inverse of a 2×2 matrix gives",
    "after": "So indeed, the partial correlation is",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle \\rho _{XY\\cdot Z}={\\frac {\\operatorname {Cov} (R_{X},R_{Y})}{\\sqrt {\\operatorname {Cov} (R_{X},R_{X})\\operatorname {Cov} (R_{Y},R_{Y})}}}={\\frac {-{\\tfrac {1}{{\\text{det}}P_{11}}}p_{XY}}{\\sqrt {{\\tfrac {1}{{\\text{det}}P_{11}}}p_{XX}{\\tfrac {1}{{\\text{det}}P_{11}}}p_{YY}}}}=-{\\frac {p_{XY}}{\\sqrt {p_{XX}p_{YY}}}}}": {
    "before": "{\\displaystyle {\\begin{aligned}P_{11}^{-1}&={\\frac {1}{{\\text{det}}P_{11}}}{\\begin{pmatrix}[P_{11}]_{22}&-[P_{11}]_{12}\\\\-[P_{11}]_{21}&[P_{11}]_{11}\\\\\\end{pmatrix}}\\\\&={\\frac {1}{{\\text{det}}P_{11}}}{\\begin{pmatrix}p_{YY}&-p_{XY}\\\\-p_{YX}&p_{XX}\\\\\\end{pmatrix}}\\end{aligned}}} So indeed, the partial correlation is",
    "after": "as claimed in ( 1 ).",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle z({\\hat {\\rho }}_{XY\\cdot \\mathbf {Z} })={\\frac {1}{2}}\\ln \\left({\\frac {1+{\\hat {\\rho }}_{XY\\cdot \\mathbf {Z} }}{1-{\\hat {\\rho }}_{XY\\cdot \\mathbf {Z} }}}\\right)}": {
    "before": "To test if a sample partial correlation {\\displaystyle {\\hat {\\rho }}_{XY\\cdot \\mathbf {Z} }} implies that the true population partial correlation differs from 0, Fisher's z-transform of the partial correlation can be used:",
    "after": "The null hypothesis is {\\displaystyle H_{0}:\\rho _{XY\\cdot \\mathbf {Z} }=0} , to be tested against the two-tail alternative {\\displaystyle H_{A}:\\rho _{XY\\cdot \\mathbf {Z} }\\neq 0} . {\\displaystyle H_{0}} can be rejected if",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "{\\displaystyle \\varphi (h)=\\rho _{X_{0}X_{h}\\,\\cdot \\,\\{X_{1},\\,\\dots \\,,X_{h-1}\\}}}": {
    "before": "In time series analysis , the partial autocorrelation function (sometimes \"partial correlation function\") of a time series is defined, for lag {\\displaystyle h} , as",
    "after": "This function is used to determine the appropriate lag length for an autoregression .",
    "url": "https://en.wikipedia.org/wiki/Partial correlation"
  },
  "y'(N) = W/p": {
    "before": "Keynesian",
    "after": "The 'first postulate'",
    "url": "https://en.wikipedia.org/wiki/The General Theory of Employment, Interest and Money"
  },
  "d(W·Y/p)/dN = W/p": {
    "before": "The 'first postulate'",
    "after": "i (r) = s(y(N),r)",
    "url": "https://en.wikipedia.org/wiki/The General Theory of Employment, Interest and Money"
  },
  "i (r) = s(y(N),r)": {
    "before": "d(W·Y/p)/dN = W/p",
    "after": "Determination of the interest rate",
    "url": "https://en.wikipedia.org/wiki/The General Theory of Employment, Interest and Money"
  },
  "I (r) = S(Y)": {
    "before": "Determination of the interest rate",
    "after": "Determination of income",
    "url": "https://en.wikipedia.org/wiki/The General Theory of Employment, Interest and Money"
  },
  "M̂ = p·y(N) /V(r)": {
    "before": "Determination of income",
    "after": "Quantity theory of money",
    "url": "https://en.wikipedia.org/wiki/The General Theory of Employment, Interest and Money"
  },
  "M̂ = L(Y,r)": {
    "before": "Quantity theory of money",
    "after": "Liquidity preference",
    "url": "https://en.wikipedia.org/wiki/The General Theory of Employment, Interest and Money"
  },
  "Y = C(Y) + S(Y) = C(Y) + I (r); and this equation determines a unique value of Y given r.": {
    "before": "The meaning of this is that in equilibrium the total demand for goods must equal total income. Total demand for goods is the sum of demand for consumption goods and demand for investment goods. Hence",
    "after": "Samuelson's Keynesian cross is a graphical representation of the Chapter 3 argument.",
    "url": "https://en.wikipedia.org/wiki/The General Theory of Employment, Interest and Money"
  },
  "{\\displaystyle f:={\\frac {2k^{2}}{\\cosh ^{2}\\left(xk-4k^{3}t\\right)}}}": {
    "before": "Animation of functions [ edit ]Animation of function of two variables",
    "after": "plots :- animate ( subs ( k = 0.5 , f ) , x =- 30. . 30 , t =- 10. . 10 , numpoints = 200 , frames = 50 , color = red , thickness = 3 ) ;",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "{\\displaystyle f(x)-3\\int _{-1}^{1}(xy+x^{2}y^{2})f(y)dy=h(x)} .": {
    "before": "Find functions {\\displaystyle f} that satisfy the integral equation",
    "after": "eqn := f ( x ) - 3 * Int (( x * y + x ^ 2 * y ^ 2 ) * f ( y ) , y =- 1. . 1 ) = h ( x ) : intsolve ( eqn , f ( x )) ;",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "{\\displaystyle f\\left(x\\right)=\\int _{-1}^{1}\\!\\left(-15\\,{x}^{2}{y}^{2}-3\\,xy\\right)h\\left(y\\right){dy}+h\\left(x\\right)}": {
    "before": "eqn := f ( x ) - 3 * Int (( x * y + x ^ 2 * y ^ 2 ) * f ( y ) , y =- 1. . 1 ) = h ( x ) : intsolve ( eqn , f ( x )) ;",
    "after": "Use of the Maple engine [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "myfac := proc(n::nonnegint)": {
    "before": "The following code, which computes the factorial of a nonnegative integer, is an example of an imperative programming construct within Maple:",
    "after": "local out, i;",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "out := out * i": {
    "before": "for i from 2 to n do",
    "after": "end do;",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "myfac := n -> product(i, i = 1..n);": {
    "before": "Simple functions can also be defined using the \"maps to\" arrow notation:",
    "after": "Integration[edit]",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "M := Matrix([[1,2,3], [a,b,c], [x,y,z]]); # example Matrix": {
    "before": "Compute the determinant of a matrix.",
    "after": "{\\displaystyle {\\begin{bmatrix}1&2&3\\\\a&b&c\\\\x&y&z\\end{bmatrix}}}",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "f := x^53-88*x^5-3*x-5 = 0": {
    "before": "The following code numerically calculates the roots of a high-order polynomial:",
    "after": "fsolve(f)",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "f := (cos(x+y))^2 + exp(x)*y+cot(x-y)+cosh(z+x) = 0:": {
    "before": "The same command can also solve systems of equations:",
    "after": "g := x^5 - 8*y = 2:",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "g := x^5 - 8*y = 2:": {
    "before": "f := (cos(x+y))^2 + exp(x)*y+cot(x-y)+cosh(z+x) = 0:",
    "after": "h := x+3*y-77*z=55;",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "h := x+3*y-77*z=55;": {
    "before": "g := x^5 - 8*y = 2:",
    "after": "fsolve( {f,g,h} );",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "{x = -2.080507182, y = -5.122547821, z = -0.9408850733}": {
    "before": "fsolve( {f,g,h} );",
    "after": "Plotting of function of single variable[edit]",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "plot3d(x^2+y^2, x = -1..1, y = -1..1);": {
    "before": "ranging from -1 to 1:",
    "after": "Animation of functions[edit]",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "plots:-animate3d(cos(t*x)*sin(3*t*y), x=-Pi..Pi, y=-Pi..Pi, t=1..2);": {
    "before": "Animation of functions of three variables",
    "after": "3D animation of function",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "M := Matrix([[400,400,200], [100,100,-400], [1,1,1]], datatype=float):": {
    "before": "Fly-through animation of 3-D plots.",
    "after": "plot3d(1, x=0..2*Pi, y=0..Pi, axes=none, coords=spherical, viewpoint=[path=M]);",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "plot3d(1, x=0..2*Pi, y=0..Pi, axes=none, coords=spherical, viewpoint=[path=M]);": {
    "before": "M := Matrix([[400,400,200], [100,100,-400], [1,1,1]], datatype=float):",
    "after": "Maple plot3D fly-through",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "f := (1+A*t+B*t^2)*exp(c*t);": {
    "before": "Laplace transform",
    "after": "{\\displaystyle \\left(1+A\\,t+B\\,t^{2}\\right)e^{ct}}",
    "url": "https://en.wikipedia.org/wiki/Maple (software)"
  },
  "{\\displaystyle Z_{i}\\sim {\\mathcal {N}}(0,N)\\,\\!} {\\displaystyle Y_{i}=X_{i}+Z_{i}.\\,\\!}": {
    "before": "The AWGN channel is represented by a series of outputs {\\displaystyle Y_{i}} at discrete time event index {\\displaystyle i} . {\\displaystyle Y_{i}} is the sum of the input {\\displaystyle X_{i}} and noise, {\\displaystyle Z_{i}} , where {\\displaystyle Z_{i}} is independent and identically distributed and drawn from a zero-mean normal distribution with variance {\\displaystyle N} (the noise). The {\\displaystyle Z_{i}} are further assumed to not be correlated with the {\\displaystyle X_{i}} .",
    "after": "The capacity of the channel is infinite unless the noise {\\displaystyle N} is nonzero, and the {\\displaystyle X_{i}} are sufficiently constrained. The most common constraint on the input is the so-called \"power\" constraint, requiring that for a codeword {\\displaystyle (x_{1},x_{2},\\dots ,x_{k})} transmitted through the channel, we have:",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle {\\frac {1}{k}}\\sum _{i=1}^{k}x_{i}^{2}\\leq P,}": {
    "before": "The capacity of the channel is infinite unless the noise {\\displaystyle N} is nonzero, and the {\\displaystyle X_{i}} are sufficiently constrained. The most common constraint on the input is the so-called \"power\" constraint, requiring that for a codeword {\\displaystyle (x_{1},x_{2},\\dots ,x_{k})} transmitted through the channel, we have:",
    "after": "where {\\displaystyle P} represents the maximum channel power. Therefore, the channel capacity for the power-constrained channel is given by:",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle C=\\max _{f(x){\\text{ s.t. }}E\\left(X^{2}\\right)\\leq P}I(X;Y)\\,\\!}": {
    "before": "where {\\displaystyle P} represents the maximum channel power. Therefore, the channel capacity for the power-constrained channel is given by:",
    "after": "Where {\\displaystyle f(x)} is the distribution of {\\displaystyle X} . Expand {\\displaystyle I(X;Y)} , writing it in terms of the differential entropy :",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle {\\begin{aligned}I(X;Y)=h(Y)-h(Y|X)&=h(Y)-h(X+Z|X)&=h(Y)-h(Z|X)\\end{aligned}}\\,\\!}": {
    "before": "Where {\\displaystyle f(x)} is the distribution of {\\displaystyle X} . Expand {\\displaystyle I(X;Y)} , writing it in terms of the differential entropy :",
    "after": "But {\\displaystyle X} and {\\displaystyle Z} are independent, therefore:",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle I(X;Y)=h(Y)-h(Z)\\,\\!}": {
    "before": "But {\\displaystyle X} and {\\displaystyle Z} are independent, therefore:",
    "after": "Evaluating the differential entropy of a Gaussian gives:",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle h(Z)={\\frac {1}{2}}\\log(2\\pi eN)\\,\\!}": {
    "before": "Evaluating the differential entropy of a Gaussian gives:",
    "after": "Because {\\displaystyle X} and {\\displaystyle Z} are independent and their sum gives {\\displaystyle Y} :",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle E(Y^{2})=E((X+Z)^{2})=E(X^{2})+2E(X)E(Z)+E(Z^{2})\\leq P+N\\,\\!}": {
    "before": "Because {\\displaystyle X} and {\\displaystyle Z} are independent and their sum gives {\\displaystyle Y} :",
    "after": "From this bound, we infer from a property of the differential entropy that",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle C={\\frac {1}{2}}\\log \\left(1+{\\frac {P}{N}}\\right)\\,\\!}": {
    "before": "Thus the channel capacity {\\displaystyle C} for the AWGN channel is given by:",
    "after": "Channel capacity and sphere packing [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle R={\\frac {\\log M}{n}}\\,\\!}": {
    "before": "Suppose that we are sending messages through the channel with index ranging from {\\displaystyle 1} to {\\displaystyle M} , the number of distinct possible messages. If we encode the {\\displaystyle M} messages to {\\displaystyle n} bits, then we define the rate {\\displaystyle R} as:",
    "after": "A rate is said to be achievable if there is a sequence of codes so that the maximum probability of error tends to zero as {\\displaystyle n} approaches infinity. The capacity {\\displaystyle C} is the highest achievable rate.",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle {\\frac {(n(P+N))^{\\frac {n}{2}}}{(nN)^{\\frac {n}{2}}}}=2^{{\\frac {n}{2}}\\log(1+P/N)}\\,\\!}": {
    "before": "Each codeword vector has an associated sphere of received codeword vectors which are decoded to it and each such sphere must map uniquely onto a codeword. Because these spheres therefore must not intersect, we are faced with the problem of sphere packing . How many distinct codewords can we pack into our {\\displaystyle n} -bit codeword vector? The received vectors have a maximum energy of {\\displaystyle n(P+N)} and therefore must occupy a sphere of radius {\\displaystyle {\\sqrt {n(P+N)}}} . Each codeword sphere has radius {\\displaystyle {\\sqrt {nN}}} . The volume of an n -dimensional sphere is directly proportional to {\\displaystyle r^{n}} , so the maximum number of uniquely decodeable spheres that can be packed into our sphere with transmission power P is:",
    "after": "By this argument, the rate R can be no more than {\\displaystyle {\\frac {1}{2}}\\log(1+P/N)} .",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle {\\begin{aligned}nR&=H(W)\\\\&=I(W;{\\hat {W}})+H(W|{\\hat {W}})\\\\&\\leq I(W;{\\hat {W}})+n\\epsilon _{n}\\\\&\\leq I(X^{(n)};Y^{(n)})+n\\epsilon _{n}\\\\&=h(Y^{(n)})-h(Y^{(n)}|X^{(n)})+n\\epsilon _{n}\\\\&=h(Y^{(n)})-h(Z^{(n)})+n\\epsilon _{n}\\\\&\\leq \\sum _{i=1}^{n}h(Y_{i})-h(Z^{(n)})+n\\epsilon _{n}\\\\&\\leq \\sum _{i=1}^{n}I(X_{i};Y_{i})+n\\epsilon _{n}\\end{aligned}}}": {
    "before": "Let {\\displaystyle X_{i}} be the encoded message of codeword index i. Then:",
    "after": "Let {\\displaystyle P_{i}} be the average power of the codeword of index i:",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle P_{i}={\\frac {1}{2^{nR}}}\\sum _{w}x_{i}^{2}(w)\\,\\!}": {
    "before": "Let {\\displaystyle P_{i}} be the average power of the codeword of index i:",
    "after": "Where the sum is over all input messages {\\displaystyle w} . {\\displaystyle X_{i}} and {\\displaystyle Z_{i}} are independent, thus the expectation of the power of {\\displaystyle Y_{i}} is, for noise level {\\displaystyle N} :",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle E(Y_{i}^{2})=P_{i}+N\\,\\!}": {
    "before": "Where the sum is over all input messages {\\displaystyle w} . {\\displaystyle X_{i}} and {\\displaystyle Z_{i}} are independent, thus the expectation of the power of {\\displaystyle Y_{i}} is, for noise level {\\displaystyle N} :",
    "after": "And, if {\\displaystyle Y_{i}} is normally distributed, we have that",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle {\\begin{aligned}nR&\\leq \\sum (h(Y_{i})-h(Z_{i}))+n\\epsilon _{n}\\\\&\\leq \\sum \\left({\\frac {1}{2}}\\log(2\\pi e(P_{i}+N))-{\\frac {1}{2}}\\log(2\\pi eN)\\right)+n\\epsilon _{n}\\\\&=\\sum {\\frac {1}{2}}\\log(1+{\\frac {P_{i}}{N}})+n\\epsilon _{n}\\end{aligned}}}": {
    "before": "{\\displaystyle h(Y_{i})\\leq {\\frac {1}{2}}\\log {2\\pi e}(P_{i}+N)\\,\\!} Therefore,",
    "after": "We may apply Jensen's equality to {\\displaystyle \\log(1+x)} , a concave (downward) function of x , to get:",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle {\\frac {1}{n}}\\sum _{i=1}^{n}{\\frac {1}{2}}\\log \\left(1+{\\frac {P_{i}}{N}}\\right)\\leq {\\frac {1}{2}}\\log \\left(1+{\\frac {1}{n}}\\sum _{i=1}^{n}{\\frac {P_{i}}{N}}\\right)\\,\\!}": {
    "before": "We may apply Jensen's equality to {\\displaystyle \\log(1+x)} , a concave (downward) function of x , to get:",
    "after": "Because each codeword individually satisfies the power constraint, the average also satisfies the power constraint. Therefore,",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle {\\frac {1}{n}}\\sum _{i=1}^{n}{\\frac {P_{i}}{N}}\\,\\!}": {
    "before": "Because each codeword individually satisfies the power constraint, the average also satisfies the power constraint. Therefore,",
    "after": "Which we may apply to simplify the inequality above and get:",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle {\\frac {1}{2}}\\log \\left(1+{\\frac {1}{n}}\\sum _{i=1}^{n}{\\frac {P_{i}}{N}}\\right)\\leq {\\frac {1}{2}}\\log \\left(1+{\\frac {P}{N}}\\right)\\,\\!}": {
    "before": "Which we may apply to simplify the inequality above and get:",
    "after": "Therefore, it must be that {\\displaystyle R\\leq {\\frac {1}{2}}\\log \\left(1+{\\frac {P}{N}}\\right)+\\epsilon _{n}} . Therefore, R must be less than a value arbitrarily close to the capacity derived earlier, as {\\displaystyle \\epsilon _{n}\\rightarrow 0} .",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle {\\frac {\\text{positive zero crossings}}{\\text{second}}}={\\frac {\\text{negative zero crossings}}{\\text{second}}}} {\\displaystyle \\quad =f_{0}{\\sqrt {\\frac {{\\text{SNR}}+1+{\\frac {B^{2}}{12f_{0}^{2}}}}{{\\text{SNR}}+1}}},}": {
    "before": "When affected by AWGN, the average number of either positive-going or negative-going zero crossings per second at the output of a narrow bandpass filter when the input is a sine wave is",
    "after": "wheref 0 = the center frequency of the filter, B = the filter bandwidth, SNR = the signal-to-noise power ratio in linear terms.",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "f 0 = the center frequency of the filter, B = the filter bandwidth, SNR = the signal-to-noise power ratio in linear terms.": {
    "before": "{\\displaystyle {\\frac {\\text{positive zero crossings}}{\\text{second}}}={\\frac {\\text{negative zero crossings}}{\\text{second}}}} {\\displaystyle \\quad =f_{0}{\\sqrt {\\frac {{\\text{SNR}}+1+{\\frac {B^{2}}{12f_{0}^{2}}}}{{\\text{SNR}}+1}}},} where",
    "after": "Effects in phasor domain [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Additive white Gaussian noise"
  },
  "{\\displaystyle y_{i}={\\frac {e^{x_{i}}}{\\sum _{j=1}^{c}e^{x_{j}}}}}": {
    "before": "By assigning a softmax activation function , a generalization of the logistic function , on the output layer of the neural network (or a softmax component in a component-based network) for categorical target variables, the outputs can be interpreted as posterior probabilities. This is useful in classification as it gives a certainty measure on classifications.The softmax activation function is:",
    "after": "Criticism [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Artificial neural network"
  },
  "Update crossbar memory w'(a,s) = w(a,s) + v(s').": {
    "before": "Compute emotion of being in consequence situation v(s');",
    "after": "The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is behavioral environment where it behaves, and the other is genetic environment, where from it initially and only once receives initial emotions about to be encountered situations in the behavioral environment. Having received the genome vector (species vector) from the genetic environment, the CAA will learn a goal-seeking behavior, in the behavioral environment that contains both desirable and undesirable situations.",
    "url": "https://en.wikipedia.org/wiki/Artificial neural network"
  },
  "DG = Directorate-General": {
    "before": "Table of European Commission Directorates-General and Services",
    "after": "Civil Service",
    "url": "https://en.wikipedia.org/wiki/European Civil Service"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {A} (t)\\mathbf {x} (t)+\\mathbf {B} (t)\\mathbf {u} (t)} {\\displaystyle \\mathbf {y} (t)=\\mathbf {C} (t)\\mathbf {x} (t)+\\mathbf {D} (t)\\mathbf {u} (t)}": {
    "before": "The most general state-space representation of a linear system with {\\displaystyle p} inputs, {\\displaystyle q} outputs and {\\displaystyle n} state variables is written in the following form: ",
    "after": "where: {\\displaystyle \\mathbf {x} (\\cdot )} is called the \"state vector\", {\\displaystyle \\mathbf {x} (t)\\in \\mathbb {R} ^{n}} ; {\\displaystyle \\mathbf {y} (\\cdot )} is called the \"output vector\", {\\displaystyle \\mathbf {y} (t)\\in \\mathbb {R} ^{q}} ; {\\displaystyle \\mathbf {u} (\\cdot )} is called the \"input (or control) vector\", {\\displaystyle \\mathbf {u} (t)\\in \\mathbb {R} ^{p}} ; {\\displaystyle \\mathbf {A} (\\cdot )} is the \"state (or system) matrix\", {\\displaystyle \\dim[\\mathbf {A} (\\cdot )]=n\\times n} , {\\displaystyle \\mathbf {B} (\\cdot )} is the \"input matrix\", {\\displaystyle \\dim[\\mathbf {B} (\\cdot )]=n\\times p} , {\\displaystyle \\mathbf {C} (\\cdot )} is the \"output matrix\", {\\displaystyle \\dim[\\mathbf {C} (\\cdot )]=q\\times n} , {\\displaystyle \\mathbf {D} (\\cdot )} is the \"feedthrough (or feedforward) matrix\" (in cases where the system model does not have a direct feedthrough, {\\displaystyle \\mathbf {D} (\\cdot )} is the zero matrix), {\\displaystyle \\dim[\\mathbf {D} (\\cdot )]=q\\times p} , {\\displaystyle {\\dot {\\mathbf {x} }}(t):={\\frac {d}{dt}}\\mathbf {x} (t)} .",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\mathbf {x} (\\cdot )} is called the \"state vector\", {\\displaystyle \\mathbf {x} (t)\\in \\mathbb {R} ^{n}} ; {\\displaystyle \\mathbf {y} (\\cdot )} is called the \"output vector\", {\\displaystyle \\mathbf {y} (t)\\in \\mathbb {R} ^{q}} ; {\\displaystyle \\mathbf {u} (\\cdot )} is called the \"input (or control) vector\", {\\displaystyle \\mathbf {u} (t)\\in \\mathbb {R} ^{p}} ; {\\displaystyle \\mathbf {A} (\\cdot )} is the \"state (or system) matrix\", {\\displaystyle \\dim[\\mathbf {A} (\\cdot )]=n\\times n} , {\\displaystyle \\mathbf {B} (\\cdot )} is the \"input matrix\", {\\displaystyle \\dim[\\mathbf {B} (\\cdot )]=n\\times p} , {\\displaystyle \\mathbf {C} (\\cdot )} is the \"output matrix\", {\\displaystyle \\dim[\\mathbf {C} (\\cdot )]=q\\times n} , {\\displaystyle \\mathbf {D} (\\cdot )} is the \"feedthrough (or feedforward) matrix\" (in cases where the system model does not have a direct feedthrough, {\\displaystyle \\mathbf {D} (\\cdot )} is the zero matrix), {\\displaystyle \\dim[\\mathbf {D} (\\cdot )]=q\\times p} , {\\displaystyle {\\dot {\\mathbf {x} }}(t):={\\frac {d}{dt}}\\mathbf {x} (t)} .": {
    "before": "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {A} (t)\\mathbf {x} (t)+\\mathbf {B} (t)\\mathbf {u} (t)} {\\displaystyle \\mathbf {y} (t)=\\mathbf {C} (t)\\mathbf {x} (t)+\\mathbf {D} (t)\\mathbf {u} (t)} where:",
    "after": "In this general formulation, all matrices are allowed to be time-variant (i.e. their elements can depend on time); however, in the common LTI case, matrices will be time invariant. The time variable {\\displaystyle t} can be continuous (e.g. {\\displaystyle t\\in \\mathbb {R} } ) or discrete (e.g. {\\displaystyle t\\in \\mathbb {Z} } ). In the latter case, the time variable {\\displaystyle k} is usually used instead of {\\displaystyle t} . Hybrid systems allow for time domains that have both continuous and discrete parts. Depending on the assumptions made, the state-space model representation can assume the following forms:",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\textbf {G}}(s)=k{\\frac {(s-z_{1})(s-z_{2})(s-z_{3})}{(s-p_{1})(s-p_{2})(s-p_{3})(s-p_{4})}}.}": {
    "before": "Stability and natural response characteristics of a continuous-time LTI system (i.e., linear with matrices that are constant with respect to time) can be studied from the eigenvalues of the matrix {\\displaystyle \\mathbf {A} } . The stability of a time-invariant state-space model can be determined by looking at the system's transfer function in factored form. It will then look something like this:",
    "after": "The denominator of the transfer function is equal to the characteristic polynomial found by taking the determinant of {\\displaystyle s\\mathbf {I} -\\mathbf {A} } ,",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\lambda (s)=|s\\mathbf {I} -\\mathbf {A} |.}": {
    "before": "The denominator of the transfer function is equal to the characteristic polynomial found by taking the determinant of {\\displaystyle s\\mathbf {I} -\\mathbf {A} } ,",
    "after": "The roots of this polynomial (the eigenvalues ) are the system transfer function's poles (i.e., the singularities where the transfer function's magnitude is unbounded). These poles can be used to analyze whether the system is asymptotically stable or marginally stable . An alternative approach to determining stability, which does not involve calculating eigenvalues, is to analyze the system's Lyapunov stability .",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\operatorname {rank} {\\begin{bmatrix}\\mathbf {B} &\\mathbf {A} \\mathbf {B} &\\mathbf {A} ^{2}\\mathbf {B} &\\cdots &\\mathbf {A} ^{n-1}\\mathbf {B} \\end{bmatrix}}=n,}": {
    "before": "The state controllability condition implies that it is possible – by admissible inputs – to steer the states from any initial value to any final value within some finite time window. A continuous time-invariant linear state-space model is controllable if and only if",
    "after": "where rank is the number of linearly independent rows in a matrix, and where n is the number of state variables.",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\operatorname {rank} {\\begin{bmatrix}\\mathbf {C} \\\\\\mathbf {C} \\mathbf {A} \\\\\\vdots \\\\\\mathbf {C} \\mathbf {A} ^{n-1}\\end{bmatrix}}=n.}": {
    "before": "A continuous time-invariant linear state-space model is observable if and only if",
    "after": "Transfer function [ edit ]",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {A} \\mathbf {x} (t)+\\mathbf {B} \\mathbf {u} (t)}": {
    "before": "The \" transfer function \" of a continuous time-invariant linear state-space model can be derived in the following way:First, taking the Laplace transform of",
    "after": "yields {\\displaystyle s\\mathbf {X} (s)-\\mathbf {x} (0)=\\mathbf {A} \\mathbf {X} (s)+\\mathbf {B} \\mathbf {U} (s).}",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle s\\mathbf {X} (s)-\\mathbf {x} (0)=\\mathbf {A} \\mathbf {X} (s)+\\mathbf {B} \\mathbf {U} (s).}": {
    "before": "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\mathbf {A} \\mathbf {x} (t)+\\mathbf {B} \\mathbf {u} (t)} yields",
    "after": "Next, we simplify for {\\displaystyle \\mathbf {X} (s)} , giving",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle (s\\mathbf {I} -\\mathbf {A} )\\mathbf {X} (s)=\\mathbf {x} (0)+\\mathbf {B} \\mathbf {U} (s)}": {
    "before": "Next, we simplify for {\\displaystyle \\mathbf {X} (s)} , giving",
    "after": "and thus {\\displaystyle \\mathbf {X} (s)=(s\\mathbf {I} -\\mathbf {A} )^{-1}\\mathbf {x} (0)+(s\\mathbf {I} -\\mathbf {A} )^{-1}\\mathbf {B} \\mathbf {U} (s).}",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\mathbf {X} (s)=(s\\mathbf {I} -\\mathbf {A} )^{-1}\\mathbf {x} (0)+(s\\mathbf {I} -\\mathbf {A} )^{-1}\\mathbf {B} \\mathbf {U} (s).}": {
    "before": "{\\displaystyle (s\\mathbf {I} -\\mathbf {A} )\\mathbf {X} (s)=\\mathbf {x} (0)+\\mathbf {B} \\mathbf {U} (s)} and thus",
    "after": "Substituting for {\\displaystyle \\mathbf {X} (s)} in the output equation",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\mathbf {Y} (s)=\\mathbf {C} \\mathbf {X} (s)+\\mathbf {D} \\mathbf {U} (s),}": {
    "before": "Substituting for {\\displaystyle \\mathbf {X} (s)} in the output equation",
    "after": "giving {\\displaystyle \\mathbf {Y} (s)=\\mathbf {C} ((s\\mathbf {I} -\\mathbf {A} )^{-1}\\mathbf {x} (0)+(s\\mathbf {I} -\\mathbf {A} )^{-1}\\mathbf {B} \\mathbf {U} (s))+\\mathbf {D} \\mathbf {U} (s).}",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\mathbf {Y} (s)=\\mathbf {C} ((s\\mathbf {I} -\\mathbf {A} )^{-1}\\mathbf {x} (0)+(s\\mathbf {I} -\\mathbf {A} )^{-1}\\mathbf {B} \\mathbf {U} (s))+\\mathbf {D} \\mathbf {U} (s).}": {
    "before": "{\\displaystyle \\mathbf {Y} (s)=\\mathbf {C} \\mathbf {X} (s)+\\mathbf {D} \\mathbf {U} (s),} giving",
    "after": "Assuming zero initial conditions {\\displaystyle \\mathbf {x} (0)=\\mathbf {0} } and a single-input single-output (SISO) system , the transfer function is defined as the ratio of output and input {\\displaystyle G(s)=Y(s)/U(s)} . For a multiple-input multiple-output (MIMO) system , however, this ratio is not defined. Therefore, assuming zero initial conditions, the transfer function matrix is derived from",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\mathbf {Y} (s)=\\mathbf {G} (s)\\mathbf {U} (s)}": {
    "before": "Assuming zero initial conditions {\\displaystyle \\mathbf {x} (0)=\\mathbf {0} } and a single-input single-output (SISO) system , the transfer function is defined as the ratio of output and input {\\displaystyle G(s)=Y(s)/U(s)} . For a multiple-input multiple-output (MIMO) system , however, this ratio is not defined. Therefore, assuming zero initial conditions, the transfer function matrix is derived from",
    "after": "using the method of equating the coefficients which yields",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\mathbf {G} (s)=\\mathbf {C} (s\\mathbf {I} -\\mathbf {A} )^{-1}\\mathbf {B} +\\mathbf {D} } .": {
    "before": "using the method of equating the coefficients which yields",
    "after": "Consequently, {\\displaystyle \\mathbf {G} (s)} is a matrix with the dimension {\\displaystyle q\\times p} which contains transfer functions for each input output combination. Due to the simplicity of this matrix notation, the state-space representation is commonly used for multiple-input, multiple-output systems. The Rosenbrock system matrix provides a bridge between the state-space representation and its transfer function .",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\textbf {G}}(s)={\\frac {n_{1}s^{3}+n_{2}s^{2}+n_{3}s+n_{4}}{s^{4}+d_{1}s^{3}+d_{2}s^{2}+d_{3}s+d_{4}}}.}": {
    "before": "Given a transfer function, expand it to reveal all coefficients in both the numerator and denominator. This should result in the following form:",
    "after": "The coefficients can now be inserted directly into the state-space model by the following approach:",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)={\\begin{bmatrix}0&1&0&0\\\\0&0&1&0\\\\0&0&0&1\\\\-d_{4}&-d_{3}&-d_{2}&-d_{1}\\end{bmatrix}}\\mathbf {x} (t)+{\\begin{bmatrix}0\\\\0\\\\0\\\\1\\end{bmatrix}}\\mathbf {u} (t)}": {
    "before": "The coefficients can now be inserted directly into the state-space model by the following approach:",
    "after": "{\\displaystyle \\mathbf {y} (t)={\\begin{bmatrix}n_{4}&n_{3}&n_{2}&n_{1}\\end{bmatrix}}\\mathbf {x} (t).}",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\mathbf {y} (t)={\\begin{bmatrix}n_{4}&n_{3}&n_{2}&n_{1}\\end{bmatrix}}\\mathbf {x} (t).}": {
    "before": "{\\displaystyle {\\dot {\\mathbf {x} }}(t)={\\begin{bmatrix}0&1&0&0\\\\0&0&1&0\\\\0&0&0&1\\\\-d_{4}&-d_{3}&-d_{2}&-d_{1}\\end{bmatrix}}\\mathbf {x} (t)+{\\begin{bmatrix}0\\\\0\\\\0\\\\1\\end{bmatrix}}\\mathbf {u} (t)}",
    "after": "This state-space realization is called controllable canonical form because the resulting model is guaranteed to be controllable (i.e., because the control enters a chain of integrators, it has the ability to move every state).",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\textbf {x}}}(t)={\\begin{bmatrix}0&0&0&-d_{4}\\\\1&0&0&-d_{3}\\\\0&1&0&-d_{2}\\\\0&0&1&-d_{1}\\end{bmatrix}}{\\textbf {x}}(t)+{\\begin{bmatrix}n_{4}\\\\n_{3}\\\\n_{2}\\\\n_{1}\\end{bmatrix}}{\\textbf {u}}(t)}": {
    "before": "The transfer function coefficients can also be used to construct another type of canonical form",
    "after": "{\\displaystyle {\\textbf {y}}(t)={\\begin{bmatrix}0&0&0&1\\end{bmatrix}}{\\textbf {x}}(t).}",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\textbf {y}}(t)={\\begin{bmatrix}0&0&0&1\\end{bmatrix}}{\\textbf {x}}(t).}": {
    "before": "{\\displaystyle {\\dot {\\textbf {x}}}(t)={\\begin{bmatrix}0&0&0&-d_{4}\\\\1&0&0&-d_{3}\\\\0&1&0&-d_{2}\\\\0&0&1&-d_{1}\\end{bmatrix}}{\\textbf {x}}(t)+{\\begin{bmatrix}n_{4}\\\\n_{3}\\\\n_{2}\\\\n_{1}\\end{bmatrix}}{\\textbf {u}}(t)}",
    "after": "This state-space realization is called observable canonical form because the resulting model is guaranteed to be observable (i.e., because the output exits from a chain of integrators, every state has an effect on the output).",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\textbf {G}}(s)={\\textbf {G}}_{\\mathrm {SP} }(s)+{\\textbf {G}}(\\infty ).}": {
    "before": "Transfer functions which are only proper (and not strictly proper ) can also be realised quite easily. The trick here is to separate the transfer function into two parts: a strictly proper part and a constant.",
    "after": "The strictly proper transfer function can then be transformed into a canonical state-space realization using techniques shown above. The state-space realization of the constant is trivially {\\displaystyle {\\textbf {y}}(t)={\\textbf {G}}(\\infty ){\\textbf {u}}(t)} . Together we then get a state-space realization with matrices A , B and C determined by the strictly proper part, and matrix D determined by the constant.",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\textbf {G}}(s)={\\frac {s^{2}+3s+3}{s^{2}+2s+1}}={\\frac {s+2}{s^{2}+2s+1}}+1}": {
    "before": "The strictly proper transfer function can then be transformed into a canonical state-space realization using techniques shown above. The state-space realization of the constant is trivially {\\displaystyle {\\textbf {y}}(t)={\\textbf {G}}(\\infty ){\\textbf {u}}(t)} . Together we then get a state-space realization with matrices A , B and C determined by the strictly proper part, and matrix D determined by the constant.Here is an example to clear things up a bit:",
    "after": "which yields the following controllable realization",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\textbf {x}}}(t)={\\begin{bmatrix}-2&-1\\\\1&0\\\\\\end{bmatrix}}{\\textbf {x}}(t)+{\\begin{bmatrix}1\\\\0\\end{bmatrix}}{\\textbf {u}}(t)}": {
    "before": "which yields the following controllable realization",
    "after": "{\\displaystyle {\\textbf {y}}(t)={\\begin{bmatrix}1&2\\end{bmatrix}}{\\textbf {x}}(t)+{\\begin{bmatrix}1\\end{bmatrix}}{\\textbf {u}}(t)}",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\textbf {y}}(t)={\\begin{bmatrix}1&2\\end{bmatrix}}{\\textbf {x}}(t)+{\\begin{bmatrix}1\\end{bmatrix}}{\\textbf {u}}(t)}": {
    "before": "{\\displaystyle {\\dot {\\textbf {x}}}(t)={\\begin{bmatrix}-2&-1\\\\1&0\\\\\\end{bmatrix}}{\\textbf {x}}(t)+{\\begin{bmatrix}1\\\\0\\end{bmatrix}}{\\textbf {u}}(t)}",
    "after": "Notice how the output also depends directly on the input. This is due to the {\\displaystyle {\\textbf {G}}(\\infty )} constant in the transfer function.",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=A\\mathbf {x} (t)+B\\mathbf {u} (t)} {\\displaystyle \\mathbf {y} (t)=C\\mathbf {x} (t)+D\\mathbf {u} (t)}": {
    "before": "In addition to feedback, an input, {\\displaystyle r(t)} , can be added such that {\\displaystyle \\mathbf {u} (t)=-K\\mathbf {y} (t)+\\mathbf {r} (t)} .",
    "after": "becomes {\\displaystyle {\\dot {\\mathbf {x} }}(t)=A\\mathbf {x} (t)-BK\\mathbf {y} (t)+B\\mathbf {r} (t)} {\\displaystyle \\mathbf {y} (t)=C\\mathbf {x} (t)-DK\\mathbf {y} (t)+D\\mathbf {r} (t)}",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=A\\mathbf {x} (t)+BK\\mathbf {y} (t)} {\\displaystyle \\mathbf {y} (t)=C\\mathbf {x} (t)+DK\\mathbf {y} (t)}": {
    "before": "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=A\\mathbf {x} (t)+B\\mathbf {u} (t)} {\\displaystyle \\mathbf {y} (t)=C\\mathbf {x} (t)+D\\mathbf {u} (t)} becomes",
    "after": "solving the output equation for {\\displaystyle \\mathbf {y} (t)} and substituting in the state equation results in",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\left(A+BK\\left(I-DK\\right)^{-1}C\\right)\\mathbf {x} (t)} {\\displaystyle \\mathbf {y} (t)=\\left(I-DK\\right)^{-1}C\\mathbf {x} (t)}": {
    "before": "solving the output equation for {\\displaystyle \\mathbf {y} (t)} and substituting in the state equation results in",
    "after": "The advantage of this is that the eigenvalues of A can be controlled by setting K appropriately through eigendecomposition of {\\displaystyle \\left(A+BK\\left(I-DK\\right)^{-1}C\\right)} . This assumes that the closed-loop system is controllable or that the unstable eigenvalues of A can be made stable through appropriate choice of K .",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\left(A+BK\\right)\\mathbf {x} (t)} {\\displaystyle \\mathbf {y} (t)=\\mathbf {x} (t)}": {
    "before": "For a strictly proper system D equals zero. Another fairly common situation is when all states are outputs, i.e. y = x , which yields C = I , the Identity matrix . This would then result in the simpler equations",
    "after": "This reduces the necessary eigendecomposition to just {\\displaystyle A+BK} .",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=A\\mathbf {x} (t)-BK\\mathbf {y} (t)+B\\mathbf {r} (t)} {\\displaystyle \\mathbf {y} (t)=C\\mathbf {x} (t)-DK\\mathbf {y} (t)+D\\mathbf {r} (t)}": {
    "before": "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=A\\mathbf {x} (t)+B\\mathbf {u} (t)} {\\displaystyle \\mathbf {y} (t)=C\\mathbf {x} (t)+D\\mathbf {u} (t)} becomes",
    "after": "solving the output equation for {\\displaystyle \\mathbf {y} (t)} and substituting in the state equation results in",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\left(A-BK\\left(I+DK\\right)^{-1}C\\right)\\mathbf {x} (t)+B\\left(I-K\\left(I+DK\\right)^{-1}D\\right)\\mathbf {r} (t)} {\\displaystyle \\mathbf {y} (t)=\\left(I+DK\\right)^{-1}C\\mathbf {x} (t)+\\left(I+DK\\right)^{-1}D\\mathbf {r} (t)}": {
    "before": "solving the output equation for {\\displaystyle \\mathbf {y} (t)} and substituting in the state equation results in",
    "after": "One fairly common simplification to this system is removing D , which reduces the equations to",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)=\\left(A-BKC\\right)\\mathbf {x} (t)+B\\mathbf {r} (t)} {\\displaystyle \\mathbf {y} (t)=C\\mathbf {x} (t)}": {
    "before": "One fairly common simplification to this system is removing D , which reduces the equations to",
    "after": "Moving object example [ edit ]",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle m{\\ddot {y}}(t)=u(t)-b{\\dot {y}}(t)-ky(t)}": {
    "before": "A classical linear system is that of one-dimensional movement of an object (e.g., a cart). Newton's laws of motion for an object moving horizontally on a plane and attached to a wall with a spring:",
    "after": "where {\\displaystyle y(t)} is position; {\\displaystyle {\\dot {y}}(t)} is velocity; {\\displaystyle {\\ddot {y}}(t)} is acceleration {\\displaystyle u(t)} is an applied force {\\displaystyle b} is the viscous friction coefficient {\\displaystyle k} is the spring constant {\\displaystyle m} is the mass of the object",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\begin{bmatrix}{\\dot {\\mathbf {x} }}_{1}(t)\\\\{\\dot {\\mathbf {x} }}_{2}(t)\\end{bmatrix}}={\\begin{bmatrix}0&1\\\\-{\\frac {k}{m}}&-{\\frac {b}{m}}\\end{bmatrix}}{\\begin{bmatrix}\\mathbf {x} _{1}(t)\\\\\\mathbf {x} _{2}(t)\\end{bmatrix}}+{\\begin{bmatrix}0\\\\{\\frac {1}{m}}\\end{bmatrix}}\\mathbf {u} (t)} {\\displaystyle \\mathbf {y} (t)=\\left[{\\begin{matrix}1&0\\end{matrix}}\\right]\\left[{\\begin{matrix}\\mathbf {x_{1}} (t)\\\\\\mathbf {x_{2}} (t)\\end{matrix}}\\right]}": {
    "before": "{\\displaystyle y(t)} is position; {\\displaystyle {\\dot {y}}(t)} is velocity; {\\displaystyle {\\ddot {y}}(t)} is acceleration {\\displaystyle u(t)} is an applied force {\\displaystyle b} is the viscous friction coefficient {\\displaystyle k} is the spring constant {\\displaystyle m} is the mass of the objectThe state equation would then become",
    "after": "where {\\displaystyle x_{1}(t)} represents the position of the object {\\displaystyle x_{2}(t)={\\dot {x}}_{1}(t)} is the velocity of the object {\\displaystyle {\\dot {x}}_{2}(t)={\\ddot {x}}_{1}(t)} is the acceleration of the object the output {\\displaystyle \\mathbf {y} (t)} is the position of the object",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\begin{bmatrix}B&AB\\end{bmatrix}}={\\begin{bmatrix}{\\begin{bmatrix}0\\\\{\\frac {1}{m}}\\end{bmatrix}}&{\\begin{bmatrix}0&1\\\\-{\\frac {k}{m}}&-{\\frac {b}{m}}\\end{bmatrix}}{\\begin{bmatrix}0\\\\{\\frac {1}{m}}\\end{bmatrix}}\\end{bmatrix}}={\\begin{bmatrix}0&{\\frac {1}{m}}\\\\{\\frac {1}{m}}&-{\\frac {b}{m^{2}}}\\end{bmatrix}}}": {
    "before": "{\\displaystyle x_{1}(t)} represents the position of the object {\\displaystyle x_{2}(t)={\\dot {x}}_{1}(t)} is the velocity of the object {\\displaystyle {\\dot {x}}_{2}(t)={\\ddot {x}}_{1}(t)} is the acceleration of the object the output {\\displaystyle \\mathbf {y} (t)} is the position of the objectThe controllability test is then",
    "after": "which has full rank for all {\\displaystyle b} and {\\displaystyle m} . This means, that if initial state of the system is known ( {\\displaystyle y(t)} , {\\displaystyle {\\dot {y}}(t)} , {\\displaystyle {\\ddot {y}}(t)} ), and if the {\\displaystyle b} and {\\displaystyle m} are constants, then there is a force {\\displaystyle u} that could move the cart into any other position in the system.",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\begin{bmatrix}C\\\\CA\\end{bmatrix}}={\\begin{bmatrix}{\\begin{bmatrix}1&0\\end{bmatrix}}\\\\{\\begin{bmatrix}1&0\\end{bmatrix}}{\\begin{bmatrix}0&1\\\\-{\\frac {k}{m}}&-{\\frac {b}{m}}\\end{bmatrix}}\\end{bmatrix}}={\\begin{bmatrix}1&0\\\\0&1\\end{bmatrix}}}": {
    "before": "which has full rank for all {\\displaystyle b} and {\\displaystyle m} . This means, that if initial state of the system is known ( {\\displaystyle y(t)} , {\\displaystyle {\\dot {y}}(t)} , {\\displaystyle {\\ddot {y}}(t)} ), and if the {\\displaystyle b} and {\\displaystyle m} are constants, then there is a force {\\displaystyle u} that could move the cart into any other position in the system.The observability test is then",
    "after": "which also has full rank. Therefore, this system is both controllable and observable.",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle \\mathbf {\\dot {x}} (t)=\\mathbf {f} (t,x(t),u(t))} {\\displaystyle \\mathbf {y} (t)=\\mathbf {h} (t,x(t),u(t))}": {
    "before": "The more general form of a state-space model can be written as two functions.",
    "after": "The first is the state equation and the latter is the output equation. If the function {\\displaystyle f(\\cdot ,\\cdot ,\\cdot )} is a linear combination of states and inputs then the equations can be written in matrix notation like above. The {\\displaystyle u(t)} argument to the functions can be dropped if the system is unforced (i.e., it has no inputs).",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle m\\ell ^{2}{\\ddot {\\theta }}(t)=-m\\ell g\\sin \\theta (t)-k\\ell {\\dot {\\theta }}(t)}": {
    "before": "A classic nonlinear system is a simple unforced pendulum",
    "after": "where {\\displaystyle \\theta (t)} is the angle of the pendulum with respect to the direction of gravity {\\displaystyle m} is the mass of the pendulum (pendulum rod's mass is assumed to be zero) {\\displaystyle g} is the gravitational acceleration {\\displaystyle k} is coefficient of friction at the pivot point {\\displaystyle \\ell } is the radius of the pendulum (to the center of gravity of the mass {\\displaystyle m} )",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {x}}_{1}(t)=x_{2}(t)} {\\displaystyle {\\dot {x}}_{2}(t)=-{\\frac {g}{\\ell }}\\sin {x_{1}}(t)-{\\frac {k}{m\\ell }}{x_{2}}(t)}": {
    "before": "{\\displaystyle \\theta (t)} is the angle of the pendulum with respect to the direction of gravity {\\displaystyle m} is the mass of the pendulum (pendulum rod's mass is assumed to be zero) {\\displaystyle g} is the gravitational acceleration {\\displaystyle k} is coefficient of friction at the pivot point {\\displaystyle \\ell } is the radius of the pendulum (to the center of gravity of the mass {\\displaystyle m} )The state equations are then",
    "after": "where {\\displaystyle x_{1}(t)=\\theta (t)} is the angle of the pendulum {\\displaystyle x_{2}(t)={\\dot {x}}_{1}(t)} is the rotational velocity of the pendulum {\\displaystyle {\\dot {x}}_{2}={\\ddot {x}}_{1}} is the rotational acceleration of the pendulum",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\dot {\\mathbf {x} }}(t)={\\begin{bmatrix}{\\dot {x}}_{1}(t)\\\\{\\dot {x}}_{2}(t)\\end{bmatrix}}=\\mathbf {f} (t,x(t))={\\begin{bmatrix}x_{2}(t)\\\\-{\\frac {g}{\\ell }}\\sin {x_{1}}(t)-{\\frac {k}{m\\ell }}{x_{2}}(t)\\end{bmatrix}}.}": {
    "before": "Instead, the state equation can be written in the general form",
    "after": "The equilibrium / stationary points of a system are when {\\displaystyle {\\dot {x}}=0} and so the equilibrium points of a pendulum are those that satisfy",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "{\\displaystyle {\\begin{bmatrix}x_{1}\\\\x_{2}\\end{bmatrix}}={\\begin{bmatrix}n\\pi \\\\0\\end{bmatrix}}}": {
    "before": "The equilibrium / stationary points of a system are when {\\displaystyle {\\dot {x}}=0} and so the equilibrium points of a pendulum are those that satisfy",
    "after": "for integers n .",
    "url": "https://en.wikipedia.org/wiki/State-space representation"
  },
  "If {\\displaystyle h:A\\rightarrow B} is a graph isomorphism between two tournaments {\\displaystyle T=(A,\\succ )} and {\\displaystyle {\\widetilde {T}}=(B,{\\widetilde {\\succ }})} , then {\\displaystyle a\\in f(T)\\Leftrightarrow h(a)\\in f({\\widetilde {T}})}": {
    "before": "A tournament solution is a function {\\displaystyle f} that maps each tournament {\\displaystyle T=(A,\\succ )} to a nonempty subset {\\displaystyle f(T)} of the alternatives {\\displaystyle A} (called the choice set  ) and does not distinguish between isomorphic tournaments:",
    "after": "Examples [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Tournament solution"
  },
  "<div style=\"border:solid transparent;background-color: initial;position:absolute;width:100px;line-height:0;": {
    "before": "Religion[edit]",
    "after": "Religion in Bhutan",
    "url": "https://en.wikipedia.org/wiki/Bhutan"
  },
  "matrix B = inv(A)": {
    "before": "matrix A = {1, 2 ; 3, 4}",
    "after": "matrix C = A*B",
    "url": "https://en.wikipedia.org/wiki/Gretl"
  },
  "matrix C = A*B": {
    "before": "matrix B = inv(A)",
    "after": "print A B C",
    "url": "https://en.wikipedia.org/wiki/Gretl"
  },
  "printf \"Phi(%d) = %7.3f\\n\", i, cdf(N, i)": {
    "before": "loop i=-3..3",
    "after": "endloop",
    "url": "https://en.wikipedia.org/wiki/Gretl"
  },
  "{\\displaystyle {\\textsf {fix}}\\ f=f\\ ({\\textsf {fix}}\\ f)\\ ,}": {
    "before": "In combinatory logic for computer science , a fixed-point combinator is a higher-order function {\\displaystyle {\\textsf {fix}}} that returns a fixed point of its argument function, if one exists. Formally, if the function f has one or more fixed points, then",
    "after": "Fixed-point logics [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Fixed point (mathematics)"
  },
  "{\\displaystyle {\\mathcal {U}}(\\alpha ,{\\tilde {u}})=\\left\\{u(x):\\ |u(x)-{\\tilde {u}}(x)|\\leq \\alpha {\\tilde {u}}(x),\\ {\\mbox{for all}}\\ x\\in X\\right\\},\\ \\ \\ \\alpha \\geq 0.}": {
    "before": "For example, the above fraction error model for values becomes the fractional error model for functions by adding a parameter x to the definition:",
    "after": "More generally, if {\\displaystyle U(\\alpha ,y)} is a family of info-gap models of values, then one obtains an info-gap model of functions in the same way:",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\mathcal {U}}(\\alpha ,{\\tilde {u}})=\\left\\{u(x):\\ u(x)\\in U(\\alpha ,{\\tilde {u}}(x)),\\ {\\mbox{for all}}\\ x\\in X\\right\\},\\ \\ \\ \\alpha \\geq 0.}": {
    "before": "More generally, if {\\displaystyle U(\\alpha ,y)} is a family of info-gap models of values, then one obtains an info-gap model of functions in the same way:",
    "after": "Motivation [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\mathcal {U}}(\\alpha ,{\\tilde {u}})=\\left\\{u(x):\\ |u(x)-{\\tilde {u}}(x)|\\leq \\alpha {\\tilde {u}}(x),\\ {\\mbox{for all}}\\ x\\right\\},\\ \\ \\ \\alpha \\geq 0}": {
    "before": "A common example of an info-gap model is the fractional error model. The best estimate of an uncertain function {\\displaystyle u(x)\\!\\,} is {\\displaystyle {\\tilde {u}}(x)} , but the fractional error of this estimate is unknown. The following unbounded family of nested sets of functions is a fractional-error info-gap model:",
    "after": "At any horizon of uncertainty {\\displaystyle \\alpha } , the set {\\displaystyle {\\mathcal {U}}(\\alpha ,{\\tilde {u}})} contains all functions {\\displaystyle u(x)\\!\\,} whose fractional deviation from {\\displaystyle {\\tilde {u}}(x)} is no greater than {\\displaystyle \\alpha } . However, the horizon of uncertainty is unknown, so the info-gap model is an unbounded family of sets, and there is no worst case or greatest deviation.",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\mathcal {U}}(0,{\\tilde {u}})=\\{{\\tilde {u}}\\}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle \\phi (u):=\\min\\{\\alpha \\mid u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}}": {
    "before": "For a fixed point estimate {\\displaystyle {\\tilde {u}},} an info-gap model is often equivalent to a function {\\displaystyle \\phi \\colon {\\mathfrak {U}}\\to [0,+\\infty )} defined as:",
    "after": "meaning \"the uncertainty of a point u is the minimum uncertainty such that u is in the set with that uncertainty\". In this case, the family of sets {\\displaystyle {\\mathcal {U}}(\\alpha ,{\\tilde {u}})} can be recovered as the sublevel sets of {\\displaystyle \\phi } :",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\mathcal {U}}(\\alpha ,{\\tilde {u}}):=\\phi ^{-1}([0,\\alpha ])}": {
    "before": "meaning \"the uncertainty of a point u is the minimum uncertainty such that u is in the set with that uncertainty\". In this case, the family of sets {\\displaystyle {\\mathcal {U}}(\\alpha ,{\\tilde {u}})} can be recovered as the sublevel sets of {\\displaystyle \\phi } :",
    "after": "meaning: \"the nested subset with horizon of uncertainty {\\displaystyle \\alpha } consists of all points with uncertainty less than or equal to {\\displaystyle \\alpha } \".",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\mathcal {U}}(\\alpha ,{\\tilde {u}})=\\{u\\mid d({\\tilde {u}},u)\\leq \\alpha \\}.}": {
    "before": "For instance, if the region of uncertainty is a metric space , then the uncertainty function can simply be the distance, {\\displaystyle \\phi (u):=d({\\tilde {u}},u),} so the nested subsets are simply",
    "after": "This always defines an info-gap model, as distances are always non-negative (axiom of non-negativity), and satisfies {\\displaystyle \\phi ^{-1}(0)=\\{{\\tilde {u}}\\}} (info-gap axiom of contraction) because the distance between two points is zero if and only if they are equal (the identity of indiscernibles); nesting follows by construction of sublevel set.",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\hat {\\alpha }}(q)=\\max\\{\\alpha :\\ {\\mbox{minimal requirements are always satisfied}}\\}} (robustness) (1a) {\\displaystyle {\\hat {\\beta }}(q)=\\min\\{\\alpha :\\ {\\mbox{sweeping success is possible}}\\}} (opportuneness) (2a)": {
    "before": "Let {\\displaystyle q} be a decision vector of parameters such as design variables, time of initiation, model parameters or operational options. We can verbally express the robustness and opportuneness functions as the maximum or minimum of a set of values of the uncertainty parameter {\\displaystyle \\alpha } of an info-gap model:",
    "after": "Formally, {\\displaystyle {\\hat {\\alpha }}(q)=\\max\\{\\alpha :\\ {\\mbox{minimal requirements are satisfied for all }}u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}} (robustness) (1b) {\\displaystyle {\\hat {\\beta }}(q)=\\min\\{\\alpha :\\ {\\mbox{windfall is achieved for at least one }}u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}} (opportuneness) (2b)",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\hat {\\alpha }}(q)=\\max\\{\\alpha :\\ {\\mbox{minimal requirements are satisfied for all }}u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}} (robustness) (1b) {\\displaystyle {\\hat {\\beta }}(q)=\\min\\{\\alpha :\\ {\\mbox{windfall is achieved for at least one }}u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}} (opportuneness) (2b)": {
    "before": "{\\displaystyle {\\hat {\\alpha }}(q)=\\max\\{\\alpha :\\ {\\mbox{minimal requirements are always satisfied}}\\}} (robustness) (1a) {\\displaystyle {\\hat {\\beta }}(q)=\\min\\{\\alpha :\\ {\\mbox{sweeping success is possible}}\\}} (opportuneness) (2a)Formally,",
    "after": "We can \"read\" eq. (1) as follows. The robustness {\\displaystyle {\\hat {\\alpha }}(q)} of decision vector {\\displaystyle q} is the greatest value of the horizon of uncertainty {\\displaystyle \\alpha } for which specified minimal requirements are always satisfied. {\\displaystyle {\\hat {\\alpha }}(q)} expresses robustness — the degree of resistance to uncertainty and immunity against failure — so a large value of {\\displaystyle {\\hat {\\alpha }}(q)} is desirable. Robustness is defined as a worst-case scenario up to the horizon of uncertainty: how large can the horizon of uncertainty be and still, even in the worst case, achieve the critical level of outcome?",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\hat {\\alpha }}(q,{r_{\\rm {c}}})=\\max \\left\\{\\alpha :r_{\\rm {c}}\\leq \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}R(q,u)\\right\\}} (3) {\\displaystyle {\\hat {\\beta }}(q,{r_{\\rm {w}}})=\\min \\left\\{\\alpha :r_{\\rm {w}}\\leq \\max _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}R(q,u)\\right\\}} (4)": {
    "before": "The robustness and opportuneness functions of eqs. (1) and (2) can now be expressed more explicitly:",
    "after": "{\\displaystyle {\\hat {\\alpha }}(q,{r_{\\rm {c}}})} is the greatest level of uncertainty consistent with guaranteed reward no less than the critical reward {\\displaystyle {r_{\\rm {c}}}} , while {\\displaystyle {\\hat {\\beta }}(q,{r_{\\rm {w}}})} is the least level of uncertainty which must be accepted in order to facilitate (but not guarantee) windfall as great as {\\displaystyle {r_{\\rm {w}}}} . The complementary or anti-symmetric structure of the immunity functions is evident from eqs. (3) and (4).",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\begin{aligned}{\\hat {\\alpha }}({r_{\\rm {c}}})&=\\max _{q\\in {\\mathcal {Q}}}{\\hat {\\alpha }}(q,{r_{\\rm {c}}})\\\\{{\\hat {q}}_{\\rm {c}}}({r_{\\rm {c}}})&=\\arg \\max _{q\\in {\\mathcal {Q}}}{\\hat {\\alpha }}(q,{r_{\\rm {c}}})\\end{aligned}}}": {
    "before": "Denote the maximum robustness by {\\displaystyle {\\hat {\\alpha }},} (formally {\\displaystyle {\\hat {\\alpha }}({r_{\\rm {c}}}),} for the maximum robustness for a given critical reward), and the corresponding decision (or decisions) by {\\displaystyle {\\hat {q}}_{\\rm {c}}} (formally, {\\displaystyle {{\\hat {q}}_{\\rm {c}}}({r_{\\rm {c}}}),} the critical optimizing action for a given level of critical reward):",
    "after": "Usually, though not invariably, the robust-satisficing action {\\displaystyle {{\\hat {q}}_{\\rm {c}}}({r_{\\rm {c}}})} depends on the critical reward {\\displaystyle {r_{\\rm {c}}}} .",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\begin{aligned}{\\hat {\\beta }}({r_{\\rm {w}}})&=\\min _{q\\in {\\mathcal {Q}}}{\\hat {\\beta }}(q,{r_{\\rm {w}}})\\\\{{\\hat {q}}_{\\rm {w}}}({r_{\\rm {w}}})&=\\arg \\min _{q\\in {\\mathcal {Q}}}{\\hat {\\beta }}(q,{r_{\\rm {w}}})\\end{aligned}}}": {
    "before": "Denote the minimum opportuneness by {\\displaystyle {\\hat {\\beta }},} (formally {\\displaystyle {\\hat {\\beta }}({r_{\\rm {w}}}),} for the minimum opportuneness for a given windfall reward), and the corresponding decision (or decisions) by {\\displaystyle {\\hat {q}}_{\\rm {w}}} (formally, {\\displaystyle {{\\hat {q}}_{\\rm {w}}}({r_{\\rm {w}}}),} the windfall optimizing action for a given level of windfall reward):",
    "after": "The two preference rankings, as well as the corresponding the optimal decisions {\\displaystyle {{\\hat {q}}_{\\rm {c}}}({r_{\\rm {c}}})} and {\\displaystyle {{\\hat {q}}_{\\rm {w}}}({r_{\\rm {w}}})} , may be different, and may vary depending on the values of {\\displaystyle {r_{\\rm {c}}}} and {\\displaystyle {r_{\\rm {w}}}.}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\hat {\\rho }}({\\tilde {p}}):=\\max \\ \\{\\rho \\geq 0:p\\in P(s),\\forall p\\in B(\\rho ,{\\tilde {p}})\\}}": {
    "before": "Sniedovich  has shown that info-gap's robustness model is a simple stability radius model, namely a local stability model of the generic form",
    "after": "where {\\displaystyle B(\\rho ,{\\tilde {p}})} denotes a ball of radius {\\displaystyle \\rho } centered at {\\displaystyle {\\tilde {p}}} and {\\displaystyle P(s)} denotes the set of values of {\\displaystyle p} that satisfy pre-determined stability conditions.",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle z^{*}={\\underset {d\\in D}{\\overset {\\text{DM}}{\\operatorname {Opt} }}}\\ {\\underset {s\\in S(d)}{\\overset {\\text{Nature}}{\\operatorname {opt} }}}g(d,s)}": {
    "before": "At first sight, the simplicity of this framework may strike one as naive. Yet, as attested by the variety of specific instances that it encompasses it is rich in possibilities, flexible, and versatile. For the purposes of this discussion it suffices to consider the following classical generic setup:",
    "after": "where {\\displaystyle \\ \\displaystyle \\mathop {Opt} \\ } and {\\displaystyle \\displaystyle \\mathop {opt} \\ } represent the DM's and Nature's optimality criteria, respectively, that is, each is equal to either {\\displaystyle \\ \\displaystyle \\max \\ } or {\\displaystyle \\ \\displaystyle \\min \\ } .",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle \\min _{x\\in X}f(x)=\\max _{y\\in Y}\\min _{x\\in X}g(y,x)}": {
    "before": "This objection apparently stems from the fact that any optimization problem can be formulated as a maximin model by a simple employment of dummy variables. That is, clearly",
    "after": "where {\\displaystyle g(y,x)=f(x)\\ ,\\ \\forall x\\in X,y\\in Y}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle g(y,x)=f(x)\\ ,\\ \\forall x\\in X,y\\in Y}": {
    "before": "{\\displaystyle \\min _{x\\in X}f(x)=\\max _{y\\in Y}\\min _{x\\in X}g(y,x)} where",
    "after": "for any arbitrary non-empty set {\\displaystyle Y} .",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\begin{aligned}{\\text{Decision space}}&&D&=(0,\\infty )\\\\{\\text{State spaces}}&&S(d)&={\\mathcal {U}}(d,{\\tilde {u}})\\\\{\\text{Outcomes}}&&g(d,s)&=\\varphi (q,d,s)\\end{aligned}}}": {
    "before": "Specifically, as shown above, info-gap's robustness model is an instance of the generic maximin model specified by the following constructs:",
    "after": "Furthermore, those objecting to the use of the term instance of should note that the Maximin model formulated above has an equivalent so called Mathematical Programming (MP) formulation deriving from the fact that",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\begin{array}{rcl}{\\text{Classical maximin format}}&&{\\text{MP maximin format}}\\\\\\displaystyle \\max _{d\\in D}\\ \\min _{s\\in S(d)}\\ g(d,s)&=&\\displaystyle \\max _{d\\in D,\\alpha \\in \\mathbb {R} }\\{\\alpha :\\alpha \\leq \\min _{s\\in S(d)}g(d,s)\\}\\end{array}}}": {
    "before": "Furthermore, those objecting to the use of the term instance of should note that the Maximin model formulated above has an equivalent so called Mathematical Programming (MP) formulation deriving from the fact that",
    "after": "where {\\displaystyle \\ \\mathbb {R} \\ } denotes the real line.",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\hat {\\beta }}(q,{r_{c}})=\\min \\left\\{\\alpha :\\ {r_{c}}\\leq \\max _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}R(q,u)\\right\\}=\\min _{\\alpha \\geq 0}\\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}\\psi (q,\\alpha ,u)}": {
    "before": "By the same token, info-gap's opportuneness model is a simple instance of the generic Minimin model. That is,",
    "after": "where {\\displaystyle \\psi (q,\\alpha ,u)=\\left\\{{\\begin{matrix}\\alpha &,&{r_{c}}\\leq R(q,u)\\\\\\infty &,&{r_{c}}>R(q,u)\\end{matrix}}\\right.\\ ,\\ \\alpha \\geq 0,u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle r\\leq f(x)\\ \\ \\longleftrightarrow \\ \\ 1\\leq I(x)}": {
    "before": "",
    "after": "{\\displaystyle I(x):={\\begin{cases}1&,\\ \\ r\\leq f(x)\\\\0&,\\ \\ r>f(x)\\end{cases}}\\ ,\\ x\\in X}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle R(q,u)\\in C\\ \\ \\ \\longleftrightarrow \\ \\ \\ \\alpha \\leq I(q,\\alpha ,u)}": {
    "before": "",
    "after": "{\\displaystyle I(q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ R(q,u)\\in C\\\\-\\infty &,\\ \\ R(q,u)\\notin C\\end{cases}}\\ ,\\ q\\in {\\mathcal {Q}},u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle \\max _{\\alpha \\geq 0}\\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}\\vartheta (q,\\alpha ,u)}": {
    "before": "",
    "after": "{\\displaystyle \\vartheta (q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ r_{c}\\geq R(q,\\alpha )\\\\-\\infty &,\\ \\ r_{c}<R(q,\\alpha )\\end{cases}}}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle \\varphi (q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ r_{c}\\leq R(q,u)\\\\-\\infty &,\\ \\ r_{c}>R(q,u)\\end{cases}}\\ ,\\ q\\in {\\mathcal {Q}},\\alpha \\geq 0,u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}": {
    "before": "{\\displaystyle \\varphi (q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ r_{c}\\leq R(q,u)\\\\-\\infty &,\\ \\ r_{c}>R(q,u)\\end{cases}}\\ ,\\ q\\in {\\mathcal {Q}},\\alpha \\geq 0,u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}",
    "after": "{\\displaystyle \\varphi (q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ r_{c}\\leq R(q,u)\\\\-\\infty &,\\ \\ r_{c}>R(q,u)\\end{cases}}\\ ,\\ q\\in {\\mathcal {Q}},\\alpha \\geq 0,u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle \\ \\displaystyle {\\hat {\\alpha }}(q,r_{c}):=\\max _{\\alpha \\geq 0}\\,\\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}\\,\\varphi (q,\\alpha ,u)}": {
    "before": "Info-gap's Maximin Robustness Game for decision {\\displaystyle \\ \\displaystyle q\\ } :",
    "after": "Step 1: The DM selects a horizon of uncertainty {\\displaystyle \\ \\displaystyle \\alpha \\geq 0\\ } with a view to maximize the outcome {\\displaystyle \\ \\displaystyle \\varphi (q,\\alpha ,u)\\ } . Step 2: In response, given {\\displaystyle \\ \\displaystyle \\alpha \\ } , Nature selects a {\\displaystyle \\ \\displaystyle u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\ } that minimizes {\\displaystyle \\ \\displaystyle \\varphi (q,\\alpha ,u)\\ } over {\\displaystyle \\ \\displaystyle {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\ } . Step 3: The outcome {\\displaystyle \\ \\displaystyle \\varphi (q,\\alpha ,u)} is allotted to DM.",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\hat {\\alpha }}(q,{r_{c}})=\\max \\left\\{\\alpha :\\ {r_{\\rm {c}}}\\leq \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}R(q,u)\\right\\}=\\max _{\\alpha \\geq 0}\\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}\\varphi (q,\\alpha ,u)\\quad \\quad \\Box }": {
    "before": "As shown in Sniedovich (2007),  Info-gap's robustness model is a simple instance of Wald's maximin model . Specifically,",
    "after": "Info-gap's opportuneness model [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle \\psi (q,\\alpha ,u)=\\left\\{{\\begin{matrix}\\alpha &,&{r_{c}}\\leq R(q,u)\\\\\\infty &,&{r_{c}}>R(q,u)\\end{matrix}}\\right.\\ ,\\ \\alpha \\geq 0,u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}": {
    "before": "where",
    "after": "observing that, as desired, for any triplet {\\displaystyle \\ \\ (q,\\alpha ,u)\\ } of interest we have",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle I(x):={\\begin{cases}1&,\\ \\ r\\leq f(x)\\\\0&,\\ \\ r>f(x)\\end{cases}}\\ ,\\ x\\in X}": {
    "before": "{\\displaystyle I(x):={\\begin{cases}1&,\\ \\ r\\leq f(x)\\\\0&,\\ \\ r>f(x)\\end{cases}}\\ ,\\ x\\in X}",
    "after": "{\\displaystyle I(x):={\\begin{cases}1&,\\ \\ r\\leq f(x)\\\\0&,\\ \\ r>f(x)\\end{cases}}\\ ,\\ x\\in X}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle x\\in X,r\\leq f(x)\\ \\ \\ \\longleftrightarrow \\ \\ \\ x=\\arg \\,\\max _{x\\in X}I(x)}": {
    "before": "{\\displaystyle x\\in X,r\\leq f(x)\\ \\ \\ \\longleftrightarrow \\ \\ \\ x=\\arg \\,\\max _{x\\in X}I(x)}",
    "after": "{\\displaystyle x\\in X,r\\leq f(x)\\ \\ \\ \\longleftrightarrow \\ \\ \\ x=\\arg \\,\\max _{x\\in X}I(x)}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle z(q):=\\max\\{\\alpha :R(q,u)\\in C,\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}}": {
    "before": "{\\displaystyle z(q):=\\max\\{\\alpha :R(q,u)\\in C,\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}}",
    "after": "{\\displaystyle z(q):=\\max\\{\\alpha :R(q,u)\\in C,\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle I(q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ R(q,u)\\in C\\\\-\\infty &,\\ \\ R(q,u)\\notin C\\end{cases}}\\ ,\\ q\\in {\\mathcal {Q}},u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}": {
    "before": "{\\displaystyle I(q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ R(q,u)\\in C\\\\-\\infty &,\\ \\ R(q,u)\\notin C\\end{cases}}\\ ,\\ q\\in {\\mathcal {Q}},u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}",
    "after": "{\\displaystyle I(q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ R(q,u)\\in C\\\\-\\infty &,\\ \\ R(q,u)\\notin C\\end{cases}}\\ ,\\ q\\in {\\mathcal {Q}},u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\begin{array}{ccl}\\max\\{\\alpha :R(q,u)\\in C,\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}&=&\\max\\{\\alpha :\\alpha \\leq I(q,\\alpha ,u),\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}\\\\&=&\\max\\{\\alpha :\\alpha \\leq \\displaystyle \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}I(q,\\alpha ,u)\\}\\end{array}}}": {
    "before": "{\\displaystyle {\\begin{array}{ccl}\\max\\{\\alpha :R(q,u)\\in C,\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}&=&\\max\\{\\alpha :\\alpha \\leq I(q,\\alpha ,u),\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}\\\\&=&\\max\\{\\alpha :\\alpha \\leq \\displaystyle \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}I(q,\\alpha ,u)\\}\\end{array}}}",
    "after": "{\\displaystyle {\\begin{array}{ccl}\\max\\{\\alpha :R(q,u)\\in C,\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}&=&\\max\\{\\alpha :\\alpha \\leq I(q,\\alpha ,u),\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}\\\\&=&\\max\\{\\alpha :\\alpha \\leq \\displaystyle \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}I(q,\\alpha ,u)\\}\\end{array}}}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle \\max\\{\\alpha :R(q,u)\\in C,\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}=\\max _{\\alpha \\geq 0}\\ \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}I(q,\\alpha ,u)\\}}": {
    "before": "{\\displaystyle \\max\\{\\alpha :R(q,u)\\in C,\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}=\\max _{\\alpha \\geq 0}\\ \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}I(q,\\alpha ,u)\\}}",
    "after": "{\\displaystyle \\max\\{\\alpha :R(q,u)\\in C,\\forall u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})\\}=\\max _{\\alpha \\geq 0}\\ \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}I(q,\\alpha ,u)\\}}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle \\vartheta (q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ r_{c}\\geq R(q,\\alpha )\\\\-\\infty &,\\ \\ r_{c}<R(q,\\alpha )\\end{cases}}}": {
    "before": "{\\displaystyle \\vartheta (q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ r_{c}\\geq R(q,\\alpha )\\\\-\\infty &,\\ \\ r_{c}<R(q,\\alpha )\\end{cases}}}",
    "after": "{\\displaystyle \\vartheta (q,\\alpha ,u):={\\begin{cases}\\quad \\alpha &,\\ \\ r_{c}\\geq R(q,\\alpha )\\\\-\\infty &,\\ \\ r_{c}<R(q,\\alpha )\\end{cases}}}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle g(\\alpha ,u):=\\alpha \\cdot \\left(r_{c}\\preceq R(q,u)\\right)}": {
    "before": "{\\displaystyle g(\\alpha ,u):=\\alpha \\cdot \\left(r_{c}\\preceq R(q,u)\\right)}",
    "after": "{\\displaystyle g(\\alpha ,u):=\\alpha \\cdot \\left(r_{c}\\preceq R(q,u)\\right)}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle a\\preceq b:={\\begin{cases}1&,\\ \\ a\\leq b\\\\0&,\\ \\ a>b\\end{cases}}}": {
    "before": "{\\displaystyle a\\preceq b:={\\begin{cases}1&,\\ \\ a\\leq b\\\\0&,\\ \\ a>b\\end{cases}}}",
    "after": "{\\displaystyle a\\preceq b:={\\begin{cases}1&,\\ \\ a\\leq b\\\\0&,\\ \\ a>b\\end{cases}}}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle \\max\\{\\alpha :\\alpha \\leq \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}\\alpha \\cdot \\left(r_{c}\\preceq R(q,u)\\right)\\}=\\max\\{\\alpha :1\\leq \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}\\left(r_{c}\\preceq R(q,u)\\right)\\}}": {
    "before": "{\\displaystyle \\max\\{\\alpha :\\alpha \\leq \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}\\alpha \\cdot \\left(r_{c}\\preceq R(q,u)\\right)\\}=\\max\\{\\alpha :1\\leq \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}\\left(r_{c}\\preceq R(q,u)\\right)\\}}",
    "after": "{\\displaystyle \\max\\{\\alpha :\\alpha \\leq \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}\\alpha \\cdot \\left(r_{c}\\preceq R(q,u)\\right)\\}=\\max\\{\\alpha :1\\leq \\min _{u\\in {\\mathcal {U}}(\\alpha ,{\\tilde {u}})}\\left(r_{c}\\preceq R(q,u)\\right)\\}}",
    "url": "https://en.wikipedia.org/wiki/Info-gap decision theory"
  },
  "{\\displaystyle {\\mathcal {X}}_{k}={\\mathcal {A}}_{k}\\otimes {\\mathcal {B}}_{k}} and {\\displaystyle {\\mathcal {Y}}_{k}={\\mathcal {C}}_{k}\\otimes {\\mathcal {D}}_{k}}": {
    "before": "Mathematically, an n-turn referee is a measuring co-strategy {\\displaystyle \\{R_{a}:a\\in \\Sigma \\}} whose input spaces {\\displaystyle {\\mathcal {X}}_{1},\\cdots ,{\\mathcal {X}}_{n}} and output spaces {\\displaystyle {\\mathcal {Y}}_{1},\\cdots ,{\\mathcal {Y}}_{n}} are of the form",
    "after": "for complex Euclidean spaces {\\displaystyle {\\mathcal {A}}_{k},{\\mathcal {B}}_{k},{\\mathcal {C}}_{k}} and {\\displaystyle {\\mathcal {D}}_{k},\\ 1\\leq k\\leq n} .",
    "url": "https://en.wikipedia.org/wiki/Quantum refereed game"
  },
  "{\\displaystyle \\max _{A}\\min _{B}\\langle A\\otimes B,R\\rangle =\\min _{B}\\max _{A}\\langle A\\otimes B,R\\rangle } .": {
    "before": "The optimal strategy for Alice then lies in the min-max problem",
    "after": "The above equality holds because {\\displaystyle A,B} are drawn from compact and convex sets {\\displaystyle {\\mathcal {S}}_{n}({\\mathcal {A}}_{1\\cdots n},{\\mathcal {C}}_{1\\cdots n})} and {\\displaystyle {\\mathcal {S}}_{n}({\\mathcal {B}}_{1\\cdots n},{\\mathcal {D}}_{1\\cdots n})} . It is called the min-max theorem for zero-sum quantum games.",
    "url": "https://en.wikipedia.org/wiki/Quantum refereed game"
  },
  "{\\displaystyle \\Omega _{a}(A)=\\operatorname {Tr} _{{\\mathcal {C}}_{1\\cdots n}\\otimes {\\mathcal {A}}_{1\\cdots n}}((A\\otimes I_{{\\mathcal {D}}_{1\\cdots n}\\otimes B_{1\\cdots n}})R_{a})} , and": {
    "before": "Using the same notation as the zero sum quantum refereed game as above, the referee is represented by operators {\\displaystyle \\{R_{a},R_{b}\\}} , Alice may pick a strategy from {\\displaystyle A\\in {\\mathcal {S}}_{n}({\\mathcal {A}}_{1\\cdots n},{\\mathcal {C}}_{1\\cdots n})} , and Bob from {\\displaystyle B\\in {\\mathcal {S}}_{n}({\\mathcal {B}}_{1\\cdots n},{\\mathcal {D}}_{1\\cdots n})} . Define",
    "after": "{\\displaystyle \\Omega _{b}(A)=\\operatorname {Tr} _{{\\mathcal {C}}_{1\\cdots n}\\otimes {\\mathcal {A}}_{1\\cdots n}}((A\\otimes I_{{\\mathcal {D}}_{1\\cdots n}\\otimes B_{1\\cdots n}})R_{b})} ,",
    "url": "https://en.wikipedia.org/wiki/Quantum refereed game"
  },
  "{\\displaystyle \\Omega _{b}(A)=\\operatorname {Tr} _{{\\mathcal {C}}_{1\\cdots n}\\otimes {\\mathcal {A}}_{1\\cdots n}}((A\\otimes I_{{\\mathcal {D}}_{1\\cdots n}\\otimes B_{1\\cdots n}})R_{b})} ,": {
    "before": "{\\displaystyle \\Omega _{a}(A)=\\operatorname {Tr} _{{\\mathcal {C}}_{1\\cdots n}\\otimes {\\mathcal {A}}_{1\\cdots n}}((A\\otimes I_{{\\mathcal {D}}_{1\\cdots n}\\otimes B_{1\\cdots n}})R_{a})} , and",
    "after": "where {\\displaystyle \\operatorname {Tr} _{\\mathcal {X}}(Z)} is the partial trace operator.",
    "url": "https://en.wikipedia.org/wiki/Quantum refereed game"
  },
  "{\\displaystyle {\\begin{array}{rll}\\min &\\operatorname {Tr} (P_{1})\\\\{\\text{subject to}}&\\Omega _{b}(A_{n})\\leq Q,\\\\&\\operatorname {Tr} _{{\\mathcal {C}}_{k}}(A_{k})=A_{k-1}\\otimes I_{{\\mathcal {A}}_{k}}&(2\\leq k\\leq n),\\\\&\\operatorname {Tr} _{{\\mathcal {C}}_{1}}(A_{1})=I_{{\\mathcal {A}}_{1}},\\\\&Q_{k}=P_{k}\\otimes I_{{\\mathcal {D}}_{k}}&(1\\leq k\\leq n),\\\\&\\operatorname {Tr} _{{\\mathcal {B}}_{k}}(P_{k})=Q_{k-1}&(2\\leq k\\leq n),\\\\&A_{k}\\in \\operatorname {Pos} ({\\mathcal {C}}_{1\\cdots k}\\otimes A_{1\\cdots k})&(1\\leq k\\leq n),\\\\&Q_{k}\\in \\operatorname {Pos} ({\\mathcal {D}}_{1\\cdots k}\\otimes B_{1\\cdots k})&(1\\leq k\\leq n),\\\\&P_{k}\\in \\operatorname {Pos} ({\\mathcal {D}}_{1\\cdots k}\\otimes B_{1\\cdots k})&(1\\leq k\\leq n),\\\\\\end{array}}} .": {
    "before": "This minimization problem can be expressed by the following SDP problem: ",
    "after": "The dimension of the input and output space of this SPD is exponential (from the tensor product states) in {\\displaystyle n} , and the SDP has a size polynomial in the dimension of its input and output space. Since there are efficient algorithms that can solve SDP in polynomial-time,    it follows that QRG ⊆ EXP.",
    "url": "https://en.wikipedia.org/wiki/Quantum refereed game"
  },
  "It is known that RG = EXP.": {
    "before": ", there is a strategy for Bob to win with probability ≥ 3/4.",
    "after": "Quantum games[edit]",
    "url": "https://en.wikipedia.org/wiki/Quantum refereed game"
  },
  "It turns out that QRG = EXP — allowing the referee to use quantum circuit and send or receive quantum information does not give the referee any extra power. EXP ⊆ QRG follows from the fact that EXP = RG ⊆ QRG. proved QRG ⊆ EXP by a formulation of QRG using semidefinite programs (SDP).": {
    "before": ", there exists a strategy for Bob to win with probability ≥ 3/4.",
    "after": "Semidefinite program formulation[edit]",
    "url": "https://en.wikipedia.org/wiki/Quantum refereed game"
  },
  "{\\displaystyle {\\frac {dP}{dt}}=k(QD-QS),}": {
    "before": "In the textbook story, favored by the followers of Léon Walras , if the quantity demanded does not equal the quantity supplied in a market, \"price adjustment\" is the rule: if there is a market surplus or glut (excess supply), prices fall, ending the glut, while a shortage (excess demand) causes price to rise. A simple model for price adjustment is the Evans price adjustment model , which proposes the differential equation:",
    "after": "This says that the rate of change of the price (P) is proportional to the difference between the quantity demanded (QD) and the quantity supplied (QS).",
    "url": "https://en.wikipedia.org/wiki/Quantity adjustment"
  },
  "{\\displaystyle {\\frac {dQS}{dt}}=k(DP-SP),}": {
    "before": "Economist Alfred Marshall saw market adjustment in quantity-adjustment terms in the short run. During a given \"market day\", the amount of goods on the market was given -- but it adjusts in the short run, a longer period: if the \"supply price\" (the price suppliers were willing to accept) was below the \"demand price\" (what purchasers were willing to pay), the quantity in the market would rise. If the supply price exceeded the demand price, on the other hand, the quantity on the market would fall. Marshallian quantity adjustment is described as follows:",
    "after": "This says that the rate of change of the quantity supplied is proportional to the difference between the demand price (DP) and the supply price (SP).",
    "url": "https://en.wikipedia.org/wiki/Quantity adjustment"
  },
  "c = y ·λ( y ) C = Y ·λ( Y /( p / W ))": {
    "before": "The propensity to consume is introduced in Chapter 8 as the desired level of expenditure on consumption (for an individual or aggregated over an economy) as a function of income. Let us assume that the proportion λ of income consumed is a function of real income, so",
    "after": "Keynes assumes that λ( y ) varies relatively slowly with y , and that p / W moves only within a narrow compass, and thus concludes that changes in p / W have only a weak effect on C , allowing us to adopt the approximation C = C ( Y ), i.e. to treat the propensity to consume as independent of the price level. Keynes shows that he is conscious that this is an approximation in Point 1 of §II of Chapter 8.",
    "url": "https://en.wikipedia.org/wiki/Wage unit"
  },
  "{\\displaystyle u(c,l)={\\frac {c^{1-\\gamma }}{1-\\gamma }}-\\psi {\\frac {l^{1+\\theta }}{1+\\theta }}}": {
    "before": "Often macroeconomic models assume that agents' utility is additively separable in consumption and labor. I.e., frequently the period utility function is something like",
    "after": "where {\\displaystyle c} is consumption and {\\displaystyle l} is labor (e.g., hours worked). Note that this is separable in that the utility (loss) from working does not directly affect the utility (gain or loss) from consumption, i.e. the cross-derivative of utility with respect to consumption and labor is 0.",
    "url": "https://en.wikipedia.org/wiki/Greenwood–Hercowitz–Huffman preferences"
  },
  "{\\displaystyle u(c,l)={\\frac {1}{1-\\gamma }}\\left(c-\\psi {\\frac {l^{1+\\theta }}{1+\\theta }}\\right)^{1-\\gamma }}": {
    "before": "where {\\displaystyle c} is consumption and {\\displaystyle l} is labor (e.g., hours worked). Note that this is separable in that the utility (loss) from working does not directly affect the utility (gain or loss) from consumption, i.e. the cross-derivative of utility with respect to consumption and labor is 0.GHH preferences might instead have a form like:",
    "after": "where now consumption and labor are not additively separable in the same way. For an agent with this utility function, the amount she/he works will actually affect the amount of utility she/he receives from consumption, i.e. the cross-derivative of utility with respect to consumption and labor is unequal to 0.",
    "url": "https://en.wikipedia.org/wiki/Greenwood–Hercowitz–Huffman preferences"
  },
  "{\\displaystyle u(c,l)=U\\left(c-G(l)\\right),U'>0,U''<0,G'>0,G''>0.}": {
    "before": "where now consumption and labor are not additively separable in the same way. For an agent with this utility function, the amount she/he works will actually affect the amount of utility she/he receives from consumption, i.e. the cross-derivative of utility with respect to consumption and labor is unequal to 0.More generally, the preferences are of the form",
    "after": "The first order condition of {\\displaystyle u(c,l)} with respect {\\displaystyle l} is given by",
    "url": "https://en.wikipedia.org/wiki/Greenwood–Hercowitz–Huffman preferences"
  },
  "{\\displaystyle {\\frac {dc}{dl}}=G'(l).}": {
    "before": "{\\displaystyle U'\\left(c-G(l)\\right)\\left({\\frac {dc}{dl}}-G'(l)\\right)=0} which implies",
    "after": "As {\\displaystyle dc/dl} is typically just a wage {\\displaystyle w} , this means the labor choice {\\displaystyle l} is a function of only the wage and has a closed form with {\\displaystyle l=G'^{-1}(w)} . As a result, the preferences are exceptionally convenient to work with. Moreover, as the marginal rate of substitution is independent of consumption and only depends on the real wage, there is no wealth effect on the labour supply. Using preference without a wealth effect on the labour supply might help to explain the aggregate economic behaviour following news shocks,  and government spending shocks.  Their use is also very common in open macro studies. ",
    "url": "https://en.wikipedia.org/wiki/Greenwood–Hercowitz–Huffman preferences"
  },
  "for (rhs = 1, lhs = 0; lhs < rhs; lhs = rhs, rhs = row + 1) {": {
    "before": "int row, col, lhs, rhs;",
    "after": "for (; rhs < n && s[rhs] == s[rhs - 1]; rhs++); /* this line optional */",
    "url": "https://en.wikipedia.org/wiki/Smith set"
  },
  "for (; rhs < n && s[rhs] == s[rhs - 1]; rhs++); /* this line optional */": {
    "before": "for (rhs = 1, lhs = 0; lhs < rhs; lhs = rhs, rhs = row + 1) {",
    "after": "for (col = rhs, row = n; col == rhs && row >= rhs; row--)",
    "url": "https://en.wikipedia.org/wiki/Smith set"
  },
  "for (col = rhs, row = n; col == rhs && row >= rhs; row--)": {
    "before": "for (; rhs < n && s[rhs] == s[rhs - 1]; rhs++); /* this line optional */",
    "after": "for (col = lhs; col < rhs && r[row - 1][col] == 0; col++);",
    "url": "https://en.wikipedia.org/wiki/Smith set"
  },
  "for (col = lhs; col < rhs && r[row - 1][col] == 0; col++);": {
    "before": "for (col = rhs, row = n; col == rhs && row >= rhs; row--)",
    "after": "}",
    "url": "https://en.wikipedia.org/wiki/Smith set"
  },
  "{\\displaystyle y_{t}=a+w_{0}x_{t}+w_{1}x_{t-1}+w_{2}x_{t-2}+...+{\\text{error term}}}": {
    "before": "The starting point for a distributed lag model is an assumed structure of the form",
    "after": "or the form {\\displaystyle y_{t}=a+w_{0}x_{t}+w_{1}x_{t-1}+w_{2}x_{t-2}+...+w_{n}x_{t-n}+{\\text{error term}},}",
    "url": "https://en.wikipedia.org/wiki/Distributed lag"
  },
  "{\\displaystyle y_{t}=a+w_{0}x_{t}+w_{1}x_{t-1}+w_{2}x_{t-2}+...+w_{n}x_{t-n}+{\\text{error term}},}": {
    "before": "{\\displaystyle y_{t}=a+w_{0}x_{t}+w_{1}x_{t-1}+w_{2}x_{t-2}+...+{\\text{error term}}} or the form",
    "after": "where y t is the value at time period t of the dependent variable y , a is the intercept term to be estimated, and w i is called the lag weight (also to be estimated) placed on the value i periods previously of the explanatory variable x . In the first equation, the dependent variable is assumed to be affected by values of the independent variable arbitrarily far in the past, so the number of lag weights is infinite and the model is called an infinite distributed lag model . In the alternative, second, equation, there are only a finite number of lag weights, indicating an assumption that there is a maximum lag beyond which values of the independent variable do not affect the dependent variable; a model based on this assumption is called a finite distributed lag model .",
    "url": "https://en.wikipedia.org/wiki/Distributed lag"
  },
  "{\\displaystyle w_{i}=\\sum _{j=0}^{n}a_{j}i^{j}}": {
    "before": "The most important structured finite distributed lag model is the Almon lag model .  This model allows the data to determine the shape of the lag structure, but the researcher must specify the maximum lag length; an incorrectly specified maximum lag length can distort the shape of the estimated lag structure as well as the cumulative effect of the independent variable. The Almon lag assumes that k + 1 lag weights are related to n + 1 linearly estimable underlying parameters ( n < k ) a j according to",
    "after": "for {\\displaystyle i=0,\\dots ,k.}",
    "url": "https://en.wikipedia.org/wiki/Distributed lag"
  },
  "{\\displaystyle y_{t}=a+\\lambda y_{t-1}+bx_{t}+{\\text{error term}},}": {
    "before": "The most common type of structured infinite distributed lag model is the geometric lag , also known as the Koyck lag . In this lag structure, the weights (magnitudes of influence) of the lagged independent variable values decline exponentially with the length of the lag; while the shape of the lag structure is thus fully imposed by the choice of this technique, the rate of decline as well as the overall magnitude of effect are determined by the data. Specification of the regression equation is very straightforward: one includes as explanators (right-hand side variables in the regression) the one-period-lagged value of the dependent variable and the current value of the independent variable:",
    "after": "where {\\displaystyle 0\\leq \\lambda <1} . In this model, the short-run (same-period) effect of a unit change in the independent variable is the value of b , while the long-run (cumulative) effect of a sustained unit change in the independent variable can be shown to be",
    "url": "https://en.wikipedia.org/wiki/Distributed lag"
  },
  "{\\displaystyle b+\\lambda b+\\lambda ^{2}b+...=b/(1-\\lambda ).}": {
    "before": "where {\\displaystyle 0\\leq \\lambda <1} . In this model, the short-run (same-period) effect of a unit change in the independent variable is the value of b , while the long-run (cumulative) effect of a sustained unit change in the independent variable can be shown to be",
    "after": "Other infinite distributed lag models have been proposed to allow the data to determine the shape of the lag structure. The polynomial inverse lag   assumes that the lag weights are related to underlying, linearly estimable parameters a j according to",
    "url": "https://en.wikipedia.org/wiki/Distributed lag"
  },
  "{\\displaystyle w_{i}=\\sum _{j=2}^{n}{\\frac {a_{j}}{(i+1)^{j}}},}": {
    "before": "Other infinite distributed lag models have been proposed to allow the data to determine the shape of the lag structure. The polynomial inverse lag   assumes that the lag weights are related to underlying, linearly estimable parameters a j according to",
    "after": "for {\\displaystyle i=0,\\dots ,\\infty .}",
    "url": "https://en.wikipedia.org/wiki/Distributed lag"
  },
  "{\\displaystyle w_{i}=\\sum _{j=2}^{n}a_{j}(1/j)^{i},}": {
    "before": "The geometric combination lag  assumes that the lags weights are related to underlying, linearly estimable parameters a j according to either",
    "after": "for {\\displaystyle i=0,\\dots ,\\infty } or",
    "url": "https://en.wikipedia.org/wiki/Distributed lag"
  },
  "{\\displaystyle w_{i}=\\sum _{j=1}^{n}a_{j}[j/(n+1)]^{i},}": {
    "before": "{\\displaystyle w_{i}=\\sum _{j=2}^{n}a_{j}(1/j)^{i},} for {\\displaystyle i=0,\\dots ,\\infty } or",
    "after": "for {\\displaystyle i=0,\\dots ,\\infty .}",
    "url": "https://en.wikipedia.org/wiki/Distributed lag"
  },
  "{\\displaystyle y=\\mathbf {x} ^{\\top }{\\boldsymbol {\\beta }}+\\varepsilon ,\\,}": {
    "before": "Consider the linear regression model for the scalar Y .",
    "after": "where {\\displaystyle \\mathbf {x} } is a k x 1 column vector of explanatory variables (features), {\\displaystyle {\\boldsymbol {\\beta }}} is a k × 1 column vector of parameters to be estimated, and {\\displaystyle \\varepsilon } is the residual error .",
    "url": "https://en.wikipedia.org/wiki/Heteroskedasticity-consistent standard errors"
  },
  "{\\displaystyle {\\widehat {\\boldsymbol {\\beta }}}_{\\mathrm {OLS} }=(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}\\mathbf {X} ^{\\top }\\mathbf {y} .\\,}": {
    "before": "where {\\displaystyle \\mathbf {x} } is a k x 1 column vector of explanatory variables (features), {\\displaystyle {\\boldsymbol {\\beta }}} is a k × 1 column vector of parameters to be estimated, and {\\displaystyle \\varepsilon } is the residual error .The ordinary least squares (OLS) estimator is",
    "after": "where {\\displaystyle \\mathbf {y} } is a vector of observations {\\displaystyle y_{i}} , and {\\displaystyle \\mathbf {X} } denotes the matrix of stacked {\\displaystyle \\mathbf {x} _{i}} values observed in the data.",
    "url": "https://en.wikipedia.org/wiki/Heteroskedasticity-consistent standard errors"
  },
  "{\\displaystyle {\\hat {\\mathbb {V} }}\\left[{\\widehat {\\boldsymbol {\\beta }}}_{\\mathrm {OLS} }\\right]=s^{2}(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1},\\quad s^{2}={\\frac {\\sum _{i}{\\widehat {\\varepsilon }}_{i}^{2}}{n-k}}}": {
    "before": "If the sample errors have equal variance {\\displaystyle \\sigma ^{2}} and are uncorrelated , then the least-squares estimate of {\\displaystyle {\\boldsymbol {\\beta }}} is BLUE (best linear unbiased estimator), and its variance is estimated with",
    "after": "where {\\displaystyle {\\widehat {\\varepsilon }}_{i}=y_{i}-\\mathbf {x} _{i}^{\\top }{\\widehat {\\boldsymbol {\\beta }}}_{\\mathrm {OLS} }} are the regression residuals.",
    "url": "https://en.wikipedia.org/wiki/Heteroskedasticity-consistent standard errors"
  },
  "{\\displaystyle \\mathbb {V} \\left[{\\widehat {\\boldsymbol {\\beta }}}_{\\mathrm {OLS} }\\right]=\\mathbb {V} {\\big [}(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}\\mathbf {X} ^{\\top }\\mathbf {y} {\\big ]}=(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}\\mathbf {X} ^{\\top }\\mathbf {\\Sigma } \\mathbf {X} (\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}}": {
    "before": "When the error terms do not have constant variance (i.e., the assumption of {\\displaystyle \\mathbb {E} [\\mathbf {u} \\mathbf {u} ^{\\top }]=\\sigma ^{2}\\mathbf {I} _{n}} is untrue), the OLS estimator loses its desirable properties. The formula for variance now cannot be simplified:",
    "after": "where {\\displaystyle \\mathbf {\\Sigma } =\\mathbb {V} [\\mathbf {u} ].}",
    "url": "https://en.wikipedia.org/wiki/Heteroskedasticity-consistent standard errors"
  },
  "{\\displaystyle {\\begin{aligned}{\\hat {\\mathbb {V} }}_{\\text{HCE}}{\\big [}{\\widehat {\\boldsymbol {\\beta }}}_{\\text{OLS}}{\\big ]}&={\\frac {1}{n}}{\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\bigg )}^{-1}{\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\widehat {\\varepsilon }}_{i}^{2}{\\bigg )}{\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\bigg )}^{-1}\\\\&=(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}(\\mathbf {X} ^{\\top }\\operatorname {diag} ({\\widehat {\\varepsilon }}_{1}^{2},\\ldots ,{\\widehat {\\varepsilon }}_{n}^{2})\\mathbf {X} )(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1},\\end{aligned}}}": {
    "before": "If the regression errors {\\displaystyle \\varepsilon _{i}} are independent, but have distinct variances {\\displaystyle \\sigma _{i}^{2}} , then {\\displaystyle \\mathbf {\\Sigma } =\\operatorname {diag} (\\sigma _{1}^{2},\\ldots ,\\sigma _{n}^{2})} which can be estimated with {\\displaystyle {\\widehat {\\sigma }}_{i}^{2}={\\widehat {\\varepsilon }}_{i}^{2}} . This provides White's (1980) estimator, often referred to as HCE (heteroskedasticity-consistent estimator):",
    "after": "where as above {\\displaystyle \\mathbf {X} } denotes the matrix of stacked {\\displaystyle \\mathbf {x} _{i}^{\\top }} values from the data. The estimator can be derived in terms of the generalized method of moments (GMM).",
    "url": "https://en.wikipedia.org/wiki/Heteroskedasticity-consistent standard errors"
  },
  "{\\displaystyle \\mathbf {\\Omega } =\\mathbb {E} [\\mathbf {X} \\mathbf {X} ^{\\top }]^{-1}\\mathbb {V} [\\mathbf {X} {\\boldsymbol {\\varepsilon }}]\\operatorname {\\mathbb {E} } [\\mathbf {X} \\mathbf {X} ^{\\top }]^{-1},}": {
    "before": "{\\displaystyle {\\sqrt {n}}({\\widehat {\\boldsymbol {\\beta }}}_{n}-{\\boldsymbol {\\beta }})\\,\\xrightarrow {d} \\,{\\mathcal {N}}(\\mathbf {0} ,\\mathbf {\\Omega } ),} where",
    "after": "and {\\displaystyle {\\begin{aligned}{\\widehat {\\mathbf {\\Omega } }}_{n}&={\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\bigg )}^{-1}{\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\widehat {\\varepsilon }}_{i}^{2}{\\bigg )}{\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\bigg )}^{-1}\\\\&=n(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}(\\mathbf {X} ^{\\top }\\operatorname {diag} ({\\widehat {\\varepsilon }}_{1}^{2},\\ldots ,{\\widehat {\\varepsilon }}_{n}^{2})\\mathbf {X} )(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}\\end{aligned}}}",
    "url": "https://en.wikipedia.org/wiki/Heteroskedasticity-consistent standard errors"
  },
  "{\\displaystyle {\\begin{aligned}{\\widehat {\\mathbf {\\Omega } }}_{n}&={\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\bigg )}^{-1}{\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\widehat {\\varepsilon }}_{i}^{2}{\\bigg )}{\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\bigg )}^{-1}\\\\&=n(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}(\\mathbf {X} ^{\\top }\\operatorname {diag} ({\\widehat {\\varepsilon }}_{1}^{2},\\ldots ,{\\widehat {\\varepsilon }}_{n}^{2})\\mathbf {X} )(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}\\end{aligned}}}": {
    "before": "{\\displaystyle \\mathbf {\\Omega } =\\mathbb {E} [\\mathbf {X} \\mathbf {X} ^{\\top }]^{-1}\\mathbb {V} [\\mathbf {X} {\\boldsymbol {\\varepsilon }}]\\operatorname {\\mathbb {E} } [\\mathbf {X} \\mathbf {X} ^{\\top }]^{-1},} and",
    "after": "Thus, {\\displaystyle {\\widehat {\\mathbf {\\Omega } }}_{n}=n\\cdot {\\hat {\\mathbb {V} }}_{\\text{HCE}}[{\\widehat {\\boldsymbol {\\beta }}}_{\\text{OLS}}]}",
    "url": "https://en.wikipedia.org/wiki/Heteroskedasticity-consistent standard errors"
  },
  "{\\displaystyle {\\widehat {\\mathbf {\\Omega } }}_{n}=n\\cdot {\\hat {\\mathbb {V} }}_{\\text{HCE}}[{\\widehat {\\boldsymbol {\\beta }}}_{\\text{OLS}}]}": {
    "before": "{\\displaystyle {\\begin{aligned}{\\widehat {\\mathbf {\\Omega } }}_{n}&={\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\bigg )}^{-1}{\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\widehat {\\varepsilon }}_{i}^{2}{\\bigg )}{\\bigg (}{\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\bigg )}^{-1}\\\\&=n(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}(\\mathbf {X} ^{\\top }\\operatorname {diag} ({\\widehat {\\varepsilon }}_{1}^{2},\\ldots ,{\\widehat {\\varepsilon }}_{n}^{2})\\mathbf {X} )(\\mathbf {X} ^{\\top }\\mathbf {X} )^{-1}\\end{aligned}}} Thus,",
    "after": "and {\\displaystyle {\\widehat {\\mathbb {V} }}[\\mathbf {X} {\\boldsymbol {\\varepsilon }}]={\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\widehat {\\varepsilon }}_{i}^{2}={\\frac {1}{n}}\\mathbf {X} ^{\\top }\\operatorname {diag} ({\\widehat {\\varepsilon }}_{1}^{2},\\ldots ,{\\widehat {\\varepsilon }}_{n}^{2})\\mathbf {X} .}",
    "url": "https://en.wikipedia.org/wiki/Heteroskedasticity-consistent standard errors"
  },
  "{\\displaystyle {\\widehat {\\mathbb {V} }}[\\mathbf {X} {\\boldsymbol {\\varepsilon }}]={\\frac {1}{n}}\\sum _{i}\\mathbf {x} _{i}\\mathbf {x} _{i}^{\\top }{\\widehat {\\varepsilon }}_{i}^{2}={\\frac {1}{n}}\\mathbf {X} ^{\\top }\\operatorname {diag} ({\\widehat {\\varepsilon }}_{1}^{2},\\ldots ,{\\widehat {\\varepsilon }}_{n}^{2})\\mathbf {X} .}": {
    "before": "{\\displaystyle {\\widehat {\\mathbf {\\Omega } }}_{n}=n\\cdot {\\hat {\\mathbb {V} }}_{\\text{HCE}}[{\\widehat {\\boldsymbol {\\beta }}}_{\\text{OLS}}]} and",
    "after": "Precisely which covariance matrix is of concern is a matter of context.",
    "url": "https://en.wikipedia.org/wiki/Heteroskedasticity-consistent standard errors"
  },
  "{\\displaystyle y_{t}=a+bx_{1t}+cx_{2t}+\\varepsilon .\\,}": {
    "before": "First Chow Test [ edit ]Suppose that we model our data as",
    "after": "If we split our data into two groups, then we have",
    "url": "https://en.wikipedia.org/wiki/Chow test"
  },
  "{\\displaystyle y_{t}=a_{1}+b_{1}x_{1t}+c_{1}x_{2t}+\\varepsilon \\,}": {
    "before": "If we split our data into two groups, then we have",
    "after": "and {\\displaystyle y_{t}=a_{2}+b_{2}x_{1t}+c_{2}x_{2t}+\\varepsilon .\\,}",
    "url": "https://en.wikipedia.org/wiki/Chow test"
  },
  "{\\displaystyle y_{t}=a_{2}+b_{2}x_{1t}+c_{2}x_{2t}+\\varepsilon .\\,}": {
    "before": "{\\displaystyle y_{t}=a_{1}+b_{1}x_{1t}+c_{1}x_{2t}+\\varepsilon \\,} and",
    "after": "The null hypothesis of the Chow test asserts that {\\displaystyle a_{1}=a_{2}} , {\\displaystyle b_{1}=b_{2}} , and {\\displaystyle c_{1}=c_{2}} , and there is the assumption that the model errors {\\displaystyle \\varepsilon } are independent and identically distributed from a normal distribution with unknown variance .",
    "url": "https://en.wikipedia.org/wiki/Chow test"
  },
  "{\\displaystyle y_{t}=\\beta _{0}+\\beta _{1}x_{1t}+\\beta _{2}x_{2t}+...+\\beta _{k}x_{kt}+\\gamma _{0}D_{t}+\\sum _{i=1}^{k}\\gamma _{i}x_{it}D_{t}+\\varepsilon _{t}.\\,}": {
    "before": "Consider the regression:",
    "after": "Which is run over i={1,...,n}.",
    "url": "https://en.wikipedia.org/wiki/Chow test"
  },
  "{\\displaystyle H_{0}:\\gamma _{0}=0,\\gamma _{1}=0,...,\\gamma _{k}=0}": {
    "before": "If both data sets can be explained fully by {\\displaystyle (\\beta _{0},\\beta _{1},...,\\beta _{k})} then there is no use in the dummy variable as the data set is explained fully by the restricted equation. That is, under the assumption of no structural change we have a null and alternative hypothesis of:",
    "after": "{\\displaystyle H_{1}:{\\text{otherwise}}}",
    "url": "https://en.wikipedia.org/wiki/Chow test"
  },
  "{\\displaystyle {\\text{P}}_{\\text{Conservatives}}={\\frac {1/3+1/3+1/3+1/3+3/3}{5}}={\\frac {7}{15}}\\approx 47\\%.}": {
    "before": "Table 1 contains the party representation index \"Popularity\", which is the average size of the group represented. For example, the Conservatives answer Questions 1 to 4 as 1/3 of all voters and Question 5 as all voters (3/3). That leads to",
    "after": "The popularity of the Socialists and Greens is calculated in the same way, giving 60% and 53%, respectively. The election winners are therefore the Socialists.",
    "url": "https://en.wikipedia.org/wiki/Third Vote"
  },
  "{\\displaystyle y_{t}=\\gamma _{0}+\\gamma _{1}y_{t-1}+\\gamma _{2}y_{t-2}+...+\\gamma _{p}y_{t-p}+\\epsilon _{t}.\\,}": {
    "before": "Consider a simple AR( p ) model for a time series y t",
    "after": "where: {\\displaystyle \\gamma _{i}\\,} for i =1,2,..., p are autoregressive coefficients, assumed to be constant over time; {\\displaystyle \\epsilon _{t}{\\stackrel {\\mathit {iid}}{\\sim }}WN(0;\\sigma ^{2})\\,} stands for white-noise error term with constant variance .",
    "url": "https://en.wikipedia.org/wiki/STAR model"
  },
  "{\\displaystyle \\gamma _{i}\\,} for i =1,2,..., p are autoregressive coefficients, assumed to be constant over time; {\\displaystyle \\epsilon _{t}\\sim ^{iid}WN(0;\\sigma ^{2})\\,} stands for white-noise error term with constant variance .": {
    "before": "{\\displaystyle y_{t}=\\gamma _{0}+\\gamma _{1}y_{t-1}+\\gamma _{2}y_{t-2}+...+\\gamma _{p}y_{t-p}+\\epsilon _{t}.\\,} where:",
    "after": "written in a following vector form:",
    "url": "https://en.wikipedia.org/wiki/SETAR (model)"
  },
  "{\\displaystyle y_{t}=\\mathbf {X_{t}\\gamma } +\\sigma \\epsilon _{t}.\\,}": {
    "before": "{\\displaystyle \\gamma _{i}\\,} for i =1,2,..., p are autoregressive coefficients, assumed to be constant over time; {\\displaystyle \\epsilon _{t}{\\stackrel {\\mathit {iid}}{\\sim }}WN(0;\\sigma ^{2})\\,} stands for white-noise error term with constant variance .written in a following vector form:",
    "after": "where: {\\displaystyle \\mathbf {X_{t}} =(1,y_{t-1},y_{t-2},\\ldots ,y_{t-p})\\,} is a column vector of variables; {\\displaystyle \\gamma \\,} is the vector of parameters : {\\displaystyle \\gamma _{0},\\gamma _{1},\\gamma _{2},...,\\gamma _{p}\\,} ; {\\displaystyle \\epsilon _{t}{\\stackrel {\\mathit {iid}}{\\sim }}WN(0;1)\\,} stands for white-noise error term with constant variance .",
    "url": "https://en.wikipedia.org/wiki/STAR model"
  },
  "{\\displaystyle \\mathbf {X_{t}} =(1,y_{t-1},y_{t-2},\\ldots ,y_{t-p})\\,} is a row vector of variables; {\\displaystyle \\gamma \\,} is the vector of parameters : {\\displaystyle \\gamma _{0},\\gamma _{1},\\gamma _{2},...,\\gamma _{p}\\,} ; {\\displaystyle \\epsilon _{t}\\sim ^{iid}WN(0;1)\\,} stands for white-noise error term with constant variance .": {
    "before": "{\\displaystyle y_{t}=\\mathbf {X_{t}\\gamma } +\\sigma \\epsilon _{t}.\\,} where:",
    "after": "SETAR as an Extension of the Autoregressive Model [ edit ]",
    "url": "https://en.wikipedia.org/wiki/SETAR (model)"
  },
  "{\\displaystyle y_{t}=\\mathbf {X_{t}} \\gamma ^{(j)}+\\sigma ^{(j)}\\epsilon _{t}\\,} if {\\displaystyle r_{j-1}<z_{t}<r_{j}.\\,}": {
    "before": "Defined in this way, SETAR model can be presented as follows:",
    "after": "where: {\\displaystyle X_{t}=(1,y_{t-1},y_{t-2},...,y_{t-p})\\,} is a column vector of variables; {\\displaystyle -\\infty =r_{0}<r_{1}<\\ldots <r_{k}=+\\infty \\,} are k+1 non-trivial thresholds dividing the domain of z t into k different regimes.",
    "url": "https://en.wikipedia.org/wiki/SETAR (model)"
  },
  "{\\displaystyle X_{t}=(1,y_{t-1},y_{t-2},...,y_{t-p})\\,} is a column vector of variables; {\\displaystyle -\\infty =r_{0}<r_{1}<\\ldots <r_{k}=+\\infty \\,} are k+1 non-trivial thresholds dividing the domain of z t into k different regimes.": {
    "before": "{\\displaystyle y_{t}=\\mathbf {X_{t}} \\gamma ^{(j)}+\\sigma ^{(j)}\\epsilon _{t}\\,} if {\\displaystyle r_{j-1}<z_{t}<r_{j}.\\,} where:",
    "after": "The SETAR model is a special case of Tong's general threshold autoregressive models (Tong and Lim, 1980, p. 248). The latter allows the threshold variable to be very flexible, such as an exogenous time series in the open-loop threshold autoregressive system (Tong and Lim, 1980, p. 249), a Markov chain in the Markov-chain driven threshold autoregressive model (Tong and Lim, 1980, p. 285), which is now also known as the Markov switching model.",
    "url": "https://en.wikipedia.org/wiki/SETAR (model)"
  },
  "{\\displaystyle \\gamma _{i}\\,} for i =1,2,..., p are autoregressive coefficients, assumed to be constant over time; {\\displaystyle \\epsilon _{t}{\\stackrel {\\mathit {iid}}{\\sim }}WN(0;\\sigma ^{2})\\,} stands for white-noise error term with constant variance .": {
    "before": "{\\displaystyle y_{t}=\\gamma _{0}+\\gamma _{1}y_{t-1}+\\gamma _{2}y_{t-2}+...+\\gamma _{p}y_{t-p}+\\epsilon _{t}.\\,} where:",
    "after": "written in a following vector form:",
    "url": "https://en.wikipedia.org/wiki/STAR model"
  },
  "{\\displaystyle \\mathbf {X_{t}} =(1,y_{t-1},y_{t-2},\\ldots ,y_{t-p})\\,} is a column vector of variables; {\\displaystyle \\gamma \\,} is the vector of parameters : {\\displaystyle \\gamma _{0},\\gamma _{1},\\gamma _{2},...,\\gamma _{p}\\,} ; {\\displaystyle \\epsilon _{t}{\\stackrel {\\mathit {iid}}{\\sim }}WN(0;1)\\,} stands for white-noise error term with constant variance .": {
    "before": "{\\displaystyle y_{t}=\\mathbf {X_{t}\\gamma } +\\sigma \\epsilon _{t}.\\,} where:",
    "after": "Exponential transition function for the ESTAR model with {\\displaystyle z_{t}} varying from -10 to +10, {\\displaystyle \\zeta } from 0 to 1 and two exponential roots ( {\\displaystyle c_{1}} and {\\displaystyle c_{2}} ) equal to -7 and +3.",
    "url": "https://en.wikipedia.org/wiki/STAR model"
  },
  "{\\displaystyle y_{t}=\\mathbf {X_{t}} +G(z_{t},\\zeta ,c)\\mathbf {X_{t}} +\\sigma ^{(j)}\\epsilon _{t}\\,}": {
    "before": "Defined in this way, STAR model can be presented as follows:",
    "after": "where: {\\displaystyle X_{t}=(1,y_{t-1},y_{t-2},...,y_{t-p})\\,} is a column vector of variables; {\\displaystyle G(z_{t},\\zeta ,c)} is the transition function bounded between 0 and 1.",
    "url": "https://en.wikipedia.org/wiki/STAR model"
  },
  "{\\displaystyle X_{t}=(1,y_{t-1},y_{t-2},...,y_{t-p})\\,} is a column vector of variables; {\\displaystyle G(z_{t},\\zeta ,c)} is the transition function bounded between 0 and 1.": {
    "before": "{\\displaystyle y_{t}=\\mathbf {X_{t}} +G(z_{t},\\zeta ,c)\\mathbf {X_{t}} +\\sigma ^{(j)}\\epsilon _{t}\\,} where:",
    "after": "Basic Structure [ edit ]",
    "url": "https://en.wikipedia.org/wiki/STAR model"
  },
  "{\\displaystyle G(z_{t},\\zeta ,c)=(1+exp(-\\zeta (z_{t}-c)))^{-1},\\zeta >0}": {
    "before": "first order logistic function - results in Logistic STAR ( LSTAR ) model:",
    "after": "exponential function - results in Exponential STAR ( ESTAR ) model:",
    "url": "https://en.wikipedia.org/wiki/STAR model"
  },
  "{\\displaystyle G(z_{t},\\zeta ,c)=1-exp(-\\zeta (z_{t}-c)^{2}),\\zeta >0}": {
    "before": "exponential function - results in Exponential STAR ( ESTAR ) model:",
    "after": "second order logistic function:",
    "url": "https://en.wikipedia.org/wiki/STAR model"
  },
  "{\\displaystyle G(z_{t},\\zeta ,c)=(1+exp(-\\zeta (z_{t}-c_{1})(z_{t}-c_{2})))^{-1},\\zeta >0}": {
    "before": "{\\displaystyle G(z_{t},\\zeta ,c)=1-exp(-\\zeta (z_{t}-c)^{2}),\\zeta >0} second order logistic function:",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/STAR model"
  },
  "The Rescaled Range is calculated for a time series, {\\displaystyle X=X_{1},X_{2},\\dots ,X_{n}\\,} , as follows: ": {
    "before": "Several researchers (including Peters , 1991) have found that the prices of many financial instruments (such as currency exchange rates, stock values, etc.) also have H > 1/2.  This means that they have a behavior that is distinct from a random walk, and therefore the time series is not generated by a stochastic process that has the nth value independent of all of the values before this. According to model  of Fractional Brownian motion this is referred to as long memory of positive linear autocorrelation. However it has been shown  that this measure is correct only for linear evaluation: complex nonlinear processes with memory need additional descriptive parameters. Several studies using Lo 's  modified rescaled range statistic have contradicted Peters' results as well.Calculation [ edit ]",
    "after": "Calculate the mean {\\displaystyle m={\\frac {1}{n}}\\sum _{i=1}^{n}X_{i}\\,} Create a mean adjusted series {\\displaystyle Y_{t}=X_{t}-m{\\text{ for }}t=1,2,\\dots ,n\\,} Calculate the cumulative deviate series Z; {\\displaystyle Z_{t}=\\sum _{i=1}^{t}Y_{i}{\\text{ for }}t=1,2,\\dots ,n\\,} Create a range series R; {\\displaystyle R_{t}=\\max \\left(Z_{1},Z_{2},\\dots ,Z_{t}\\right)-\\min \\left(Z_{1},Z_{2},\\dots ,Z_{t}\\right){\\text{ for }}t=1,2,\\dots ,n\\,} Create a standard deviation series S; {\\displaystyle S_{t}={\\sqrt {{\\frac {1}{t}}\\sum _{i=1}^{t}\\left(X_{i}-m(t)\\right)^{2}}}{\\text{ for }}t=1,2,\\dots ,n\\,} Where m(t) is the mean for the time series values through time {\\displaystyle t} {\\displaystyle X_{1},X_{2},\\dots ,X_{t}\\,} Calculate the rescaled range series (R/S) {\\displaystyle \\left(R/S\\right)_{t}={\\frac {R_{t}}{S_{t}}}{\\text{ for }}t=1,2,\\dots ,n\\,}",
    "url": "https://en.wikipedia.org/wiki/Rescaled range"
  },
  "{\\displaystyle m={\\frac {1}{n}}\\sum _{i=1}^{n}X_{i}\\,}": {
    "before": "Calculate themean",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Rescaled range"
  },
  "{\\displaystyle Y_{t}=X_{t}-m{\\text{ for }}t=1,2,\\dots ,n\\,}": {
    "before": "Create a mean adjusted series",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Rescaled range"
  },
  "{\\displaystyle Z_{t}=\\sum _{i=1}^{t}Y_{i}{\\text{ for }}t=1,2,\\dots ,n\\,}": {
    "before": "Calculate the cumulative deviate series Z;",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Rescaled range"
  },
  "{\\displaystyle R_{t}=\\max \\left(Z_{1},Z_{2},\\dots ,Z_{t}\\right)-\\min \\left(Z_{1},Z_{2},\\dots ,Z_{t}\\right){\\text{ for }}t=1,2,\\dots ,n\\,}": {
    "before": "Create a range series R;",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Rescaled range"
  },
  "{\\displaystyle S_{t}={\\sqrt {{\\frac {1}{t}}\\sum _{i=1}^{t}\\left(X_{i}-m(t)\\right)^{2}}}{\\text{ for }}t=1,2,\\dots ,n\\,} Where m(t) is the mean for the time series values through time {\\displaystyle t} {\\displaystyle X_{1},X_{2},\\dots ,X_{t}\\,}": {
    "before": "standard deviationseries S;",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Rescaled range"
  },
  "{\\displaystyle \\left(R/S\\right)_{t}={\\frac {R_{t}}{S_{t}}}{\\text{ for }}t=1,2,\\dots ,n\\,}": {
    "before": "Calculate the rescaled range series (R/S)",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Rescaled range"
  },
  "{\\displaystyle {\\hat {S}}^{2}=S^{2}+2\\sum _{j=1}^{q}\\left(1-{\\frac {j}{q+1}}\\right)C(j),}": {
    "before": "Lo (1991) advocates adjusting the standard deviation {\\displaystyle S} for the expected increase in range {\\displaystyle R} resulting from short-range autocorrelation in the time series.  This involves replacing {\\displaystyle S} by {\\displaystyle {\\hat {S}}} , which is the square root of",
    "after": "where {\\displaystyle q} is some maximum lag over which short-range autocorrelation might be substantial and {\\displaystyle C(j)} is the sample autocovariance at lag {\\displaystyle j} . Using this adjusted rescaled range, he concludes that stock market return time series show no evidence of long-range memory.",
    "url": "https://en.wikipedia.org/wiki/Rescaled range"
  },
  "|state=collapsed: {{Anarchist revolution|state=collapsed}} to show the template collapsed, i.e., hidden apart from its title bar": {
    "before": "To set this template's initial visibility, the |state= parameter may be used:",
    "after": "|state=expanded: {{Anarchist revolution|state=expanded}} to show the template expanded, i.e., fully visible",
    "url": "https://en.wikipedia.org/wiki/Template:Anarchist revolution"
  },
  "|state=expanded: {{Anarchist revolution|state=expanded}} to show the template expanded, i.e., fully visible": {
    "before": "|state=collapsed: {{Anarchist revolution|state=collapsed}} to show the template collapsed, i.e., hidden apart from its title bar",
    "after": "|state=autocollapse: {{Anarchist revolution|state=autocollapse}}",
    "url": "https://en.wikipedia.org/wiki/Template:Anarchist revolution"
  },
  "|state=autocollapse: {{Anarchist revolution|state=autocollapse}}": {
    "before": "|state=expanded: {{Anarchist revolution|state=expanded}} to show the template expanded, i.e., fully visible",
    "after": "shows the template collapsed to the title bar if there is a {{navbox}}, a {{sidebar}}, or some other table on the page with the collapsible attribute",
    "url": "https://en.wikipedia.org/wiki/Template:Anarchist revolution"
  },
  "Efficiency gap ={\\displaystyle {\\frac {222-23}{500}}=39.8\\%}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Efficiency gap"
  },
  "{\\displaystyle Y_{t}=g_{t}+C_{t}+I_{t}} ;": {
    "before": "The multiplier–accelerator model can be stated for a closed economy as follows:  First, the market-clearing level of economic activity is defined as that at which production exactly matches the total of government spending intentions, households' consumption intentions and firms' investing intentions.",
    "after": "then an equation to express the idea that households' consumption intentions depend upon some measure of economic activity, possibly with a lag:",
    "url": "https://en.wikipedia.org/wiki/Multiplier-accelerator model"
  },
  "{\\displaystyle C_{t}=\\alpha Y_{t-1}} ;": {
    "before": "then an equation to express the idea that households' consumption intentions depend upon some measure of economic activity, possibly with a lag:",
    "after": "then an equation that makes firms' investment intentions react to the pace of change of economic activity:",
    "url": "https://en.wikipedia.org/wiki/Multiplier-accelerator model"
  },
  "{\\displaystyle I_{t}=\\beta [C_{t}-C_{t-1}]} ;": {
    "before": "then an equation that makes firms' investment intentions react to the pace of change of economic activity:",
    "after": "and finally a statement that government spending intentions are not influenced by any of the other variables in the model. For example, the level of government spending could be used as the unit of account:",
    "url": "https://en.wikipedia.org/wiki/Multiplier-accelerator model"
  },
  "{\\displaystyle Y_{t}=1+\\alpha (1+\\beta )Y_{t-1}-\\alpha \\beta Y_{t-2}}": {
    "before": "where {\\displaystyle Y_{t}} is national income, {\\displaystyle g_{t}} is government expenditure, {\\displaystyle C_{t}} is consumption expenditure, {\\displaystyle I_{t}} is induced private investment, and the subscript {\\displaystyle t} is time. Here we can rearrange these equations and rewrite them as a second-order linear difference equation :   ",
    "after": "Samuelson demonstrated that there are several kinds of solution path for national income to be derived from this second order linear difference equation.   This solution path changes its form, depending on the values of the roots of the equation or the relationships between the parameter {\\displaystyle \\alpha } and {\\displaystyle \\beta } .  ",
    "url": "https://en.wikipedia.org/wiki/Multiplier-accelerator model"
  },
  "{\\displaystyle \\Gamma _{xy}(f)={\\mathcal {F}}\\{\\gamma _{xy}\\}(f)=\\sum _{\\tau =-\\infty }^{\\infty }\\,\\gamma _{xy}(\\tau )\\,e^{-2\\,\\pi \\,i\\,\\tau \\,f},}": {
    "before": "Let {\\displaystyle (X_{t},Y_{t})} represent a pair of stochastic processes that are jointly wide sense stationary with autocovariance functions {\\displaystyle \\gamma _{xx}} and {\\displaystyle \\gamma _{yy}} and cross-covariance function {\\displaystyle \\gamma _{xy}} . Then the cross-spectrum {\\displaystyle \\Gamma _{xy}} is defined as the Fourier transform of {\\displaystyle \\gamma _{xy}} ",
    "after": "where {\\displaystyle \\gamma _{xy}(\\tau )=\\operatorname {E} [(x_{t}-\\mu _{x})(y_{t+\\tau }-\\mu _{y})]} .",
    "url": "https://en.wikipedia.org/wiki/Cross-spectrum"
  },
  "{\\displaystyle \\gamma _{xy}(\\tau )=\\operatorname {E} [(x_{t}-\\mu _{x})(y_{t+\\tau }-\\mu _{y})]} .": {
    "before": "{\\displaystyle \\Gamma _{xy}(f)={\\mathcal {F}}\\{\\gamma _{xy}\\}(f)=\\sum _{\\tau =-\\infty }^{\\infty }\\,\\gamma _{xy}(\\tau )\\,e^{-2\\,\\pi \\,i\\,\\tau \\,f},} where",
    "after": "The cross-spectrum has representations as a decomposition into (i) its real part (co-spectrum) and (ii) its imaginary part (quadrature spectrum)",
    "url": "https://en.wikipedia.org/wiki/Cross-spectrum"
  },
  "{\\displaystyle \\Gamma _{xy}(f)=\\Lambda _{xy}(f)-i\\Psi _{xy}(f),}": {
    "before": "The cross-spectrum has representations as a decomposition into (i) its real part (co-spectrum) and (ii) its imaginary part (quadrature spectrum)",
    "after": "and (ii) in polar coordinates",
    "url": "https://en.wikipedia.org/wiki/Cross-spectrum"
  },
  "{\\displaystyle \\Gamma _{xy}(f)=A_{xy}(f)\\,e^{i\\phi _{xy}(f)}.}": {
    "before": "{\\displaystyle \\Gamma _{xy}(f)=\\Lambda _{xy}(f)-i\\Psi _{xy}(f),} and (ii) in polar coordinates",
    "after": "Here, the amplitude spectrum {\\displaystyle A_{xy}} is given by",
    "url": "https://en.wikipedia.org/wiki/Cross-spectrum"
  },
  "{\\displaystyle A_{xy}(f)=(\\Lambda _{xy}(f)^{2}+\\Psi _{xy}(f)^{2})^{\\frac {1}{2}},}": {
    "before": "Here, the amplitude spectrum {\\displaystyle A_{xy}} is given by",
    "after": "and the phase spectrum {\\displaystyle \\Phi _{xy}} is given by",
    "url": "https://en.wikipedia.org/wiki/Cross-spectrum"
  },
  "{\\displaystyle {\\begin{cases}\\tan ^{-1}(\\Psi _{xy}(f)/\\Lambda _{xy}(f))&{\\text{if }}\\Psi _{xy}(f)\\neq 0{\\text{ and }}\\Lambda _{xy}(f)\\neq 0\\\\0&{\\text{if }}\\Psi _{xy}(f)=0{\\text{ and }}\\Lambda _{xy}(f)>0\\\\\\pm \\pi &{\\text{if }}\\Psi _{xy}(f)=0{\\text{ and }}\\Lambda _{xy}(f)<0\\\\\\pi /2&{\\text{if }}\\Psi _{xy}(f)>0{\\text{ and }}\\Lambda _{xy}(f)=0\\\\-\\pi /2&{\\text{if }}\\Psi _{xy}(f)<0{\\text{ and }}\\Lambda _{xy}(f)=0\\\\\\end{cases}}}": {
    "before": "and the phase spectrum {\\displaystyle \\Phi _{xy}} is given by",
    "after": "Squared coherency spectrum [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Cross-spectrum"
  },
  "{\\displaystyle \\kappa _{xy}(f)={\\frac {A_{xy}^{2}}{\\Gamma _{xx}(f)\\Gamma _{yy}(f)}},}": {
    "before": "Squared coherency spectrum [ edit ]The squared coherency spectrum is given by",
    "after": "which expresses the amplitude spectrum in dimensionless units.",
    "url": "https://en.wikipedia.org/wiki/Cross-spectrum"
  },
  "{\\displaystyle y_{t}=\\nu +A_{1}y_{t-1}+\\dots +A_{p}y_{t-p}+u_{t}} .": {
    "before": "Calculating the forecast error variance [ edit ]For the VAR (p) of form",
    "after": "This can be changed to a VAR(1) structure by writing it in companion form (see general matrix notation of a VAR(p))",
    "url": "https://en.wikipedia.org/wiki/Variance decomposition of forecast errors"
  },
  "{\\displaystyle Y_{t}=V+AY_{t-1}+U_{t}} where": {
    "before": "This can be changed to a VAR(1) structure by writing it in companion form (see general matrix notation of a VAR(p))",
    "after": "{\\displaystyle A={\\begin{bmatrix}A_{1}&A_{2}&\\dots &A_{p-1}&A_{p}\\\\\\mathbf {I} _{k}&0&\\dots &0&0\\\\0&\\mathbf {I} _{k}&&0&0\\\\\\vdots &&\\ddots &\\vdots &\\vdots \\\\0&0&\\dots &\\mathbf {I} _{k}&0\\\\\\end{bmatrix}}} , {\\displaystyle Y={\\begin{bmatrix}y_{1}\\\\\\vdots \\\\y_{p}\\end{bmatrix}}} , {\\displaystyle V={\\begin{bmatrix}\\nu \\\\0\\\\\\vdots \\\\0\\end{bmatrix}}} and {\\displaystyle U_{t}={\\begin{bmatrix}u_{t}\\\\0\\\\\\vdots \\\\0\\end{bmatrix}}}",
    "url": "https://en.wikipedia.org/wiki/Variance decomposition of forecast errors"
  },
  "{\\displaystyle A={\\begin{bmatrix}A_{1}&A_{2}&\\dots &A_{p-1}&A_{p}\\\\\\mathbf {I} _{k}&0&\\dots &0&0\\\\0&\\mathbf {I} _{k}&&0&0\\\\\\vdots &&\\ddots &\\vdots &\\vdots \\\\0&0&\\dots &\\mathbf {I} _{k}&0\\\\\\end{bmatrix}}} , {\\displaystyle Y={\\begin{bmatrix}y_{1}\\\\\\vdots \\\\y_{p}\\end{bmatrix}}} , {\\displaystyle V={\\begin{bmatrix}\\nu \\\\0\\\\\\vdots \\\\0\\end{bmatrix}}} and {\\displaystyle U_{t}={\\begin{bmatrix}u_{t}\\\\0\\\\\\vdots \\\\0\\end{bmatrix}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Variance decomposition of forecast errors"
  },
  "{\\displaystyle \\mathbf {MSE} [y_{j,t}(h)]=\\sum _{i=0}^{h-1}\\sum _{l=1}^{k}(e_{j}'\\Theta _{i}e_{l})^{2}={\\bigg (}\\sum _{i=0}^{h-1}\\Theta _{i}\\Theta _{i}'{\\bigg )}_{jj}={\\bigg (}\\sum _{i=0}^{h-1}\\Phi _{i}\\Sigma _{u}\\Phi _{i}'{\\bigg )}_{jj},}": {
    "before": "The mean squared error of the h-step forecast of variable {\\displaystyle j} is",
    "after": "and where {\\displaystyle e_{j}} is the j th column of {\\displaystyle I_{k}} and the subscript {\\displaystyle jj} refers to that element of the matrix",
    "url": "https://en.wikipedia.org/wiki/Variance decomposition of forecast errors"
  },
  "{\\displaystyle \\Theta _{i}=\\Phi _{i}P,} where {\\displaystyle P} is a lower triangular matrix obtained by a Cholesky decomposition of {\\displaystyle \\Sigma _{u}} such that {\\displaystyle \\Sigma _{u}=PP'} , where {\\displaystyle \\Sigma _{u}} is the covariance matrix of the errors {\\displaystyle u_{t}}": {
    "before": "{\\displaystyle e_{j}} is the j th column of {\\displaystyle I_{k}} and the subscript {\\displaystyle jj} refers to that element of the matrix",
    "after": "{\\displaystyle \\Phi _{i}=JA^{i}J',} where {\\displaystyle J={\\begin{bmatrix}\\mathbf {I} _{k}&0&\\dots &0\\end{bmatrix}},} so that {\\displaystyle J} is a {\\displaystyle k} by {\\displaystyle kp} dimensional matrix.",
    "url": "https://en.wikipedia.org/wiki/Variance decomposition of forecast errors"
  },
  "{\\displaystyle \\Phi _{i}=JA^{i}J',} where {\\displaystyle J={\\begin{bmatrix}\\mathbf {I} _{k}&0&\\dots &0\\end{bmatrix}},} so that {\\displaystyle J} is a {\\displaystyle k} by {\\displaystyle kp} dimensional matrix.": {
    "before": "{\\displaystyle \\Theta _{i}=\\Phi _{i}P,} where {\\displaystyle P} is a lower triangular matrix obtained by a Cholesky decomposition of {\\displaystyle \\Sigma _{u}} such that {\\displaystyle \\Sigma _{u}=PP'} , where {\\displaystyle \\Sigma _{u}} is the covariance matrix of the errors {\\displaystyle u_{t}}",
    "after": "The amount of forecast error variance of variable {\\displaystyle j} accounted for by exogenous shocks to variable {\\displaystyle l} is given by {\\displaystyle \\omega _{jl,h},}",
    "url": "https://en.wikipedia.org/wiki/Variance decomposition of forecast errors"
  },
  "{\\displaystyle \\omega _{jl,h}=\\sum _{i=0}^{h-1}(e_{j}'\\Theta _{i}e_{l})^{2}/MSE[y_{j,t}(h)].}": {
    "before": "The amount of forecast error variance of variable {\\displaystyle j} accounted for by exogenous shocks to variable {\\displaystyle l} is given by {\\displaystyle \\omega _{jl,h},}",
    "after": "This article needs additional citations for verification . Please help improve this article by adding citations to reliable sources . Unsourced material may be challenged and removed. Find sources: \"Variance decomposition of forecast errors\" – news · newspapers · books · scholar · JSTOR ( March 2011 ) ( Learn how and when to remove this template message )",
    "url": "https://en.wikipedia.org/wiki/Variance decomposition of forecast errors"
  },
  "V = pB − C + D": {
    "before": "One such model was proposed by Anthony Downs (1957) and is adapted by William H. Riker and Peter Ordeshook , in “A Theory of the Calculus of Voting” (Riker and Ordeshook 1968)",
    "after": "whereV = the proxy for the probability that the voter will turn out p = probability of vote “mattering” B = “utility” benefit of voting--differential benefit of one candidate winning over the other C = costs of voting (time/effort spent) D = citizen duty, goodwill feeling, psychological and civic benefit of voting (this term is not included in Downs's original model)",
    "url": "https://en.wikipedia.org/wiki/Calculus of voting"
  },
  "V = the proxy for the probability that the voter will turn out p = probability of vote “mattering” B = “utility” benefit of voting--differential benefit of one candidate winning over the other C = costs of voting (time/effort spent) D = citizen duty, goodwill feeling, psychological and civic benefit of voting (this term is not included in Downs's original model)": {
    "before": "V = pB − C + Dwhere",
    "after": "A political science model based on rational choice used to explain why citizens do or do not vote.",
    "url": "https://en.wikipedia.org/wiki/Calculus of voting"
  },
  "V = pB + D > C": {
    "before": "A political science model based on rational choice used to explain why citizens do or do not vote.The alternative equation is",
    "after": "Where for voting to occur the (P)robability the vote will matter \"times\" the (B)enefit of one candidate winning over another combined with the feeling of civic (D)uty, must be greater than the (C)ost of voting",
    "url": "https://en.wikipedia.org/wiki/Calculus of voting"
  },
  "1. Yi = Ci + S = Ye= Ce+ I. 2. Yi = C↓+S↑ 3. Ye = Ce↓+I↑ 4. If S = I then Yi = Ye.": {
    "before": "In the simplest model, income Y is made up of either Consumption (C) or Saving (S) while expenditure (Yi) were either on consumption or investment goods. Here, we ignore government and foreign trade. This can seen from equation 1. Now, if the preferences of the income earners shift towards the future resulting in a fall in C and increase in S as shown in equation 2. In the simple classical model increase in savings cause a fall in the interest rates thereby inducing additional investment expenditure. This increase in Investment (I) implies a fall in (C) on the expenditure side as shown in equation 3. As given Ci= Ce, the increase in investment is equal to the increase in savings and a shift in intertemporal preferences does not disrupt the equality between income and expenditure and also there is no change in income. (Equation4)",
    "after": "Thus, we can see that monetary-equilibrium shares a lot with the classical model.",
    "url": "https://en.wikipedia.org/wiki/Monetary-disequilibrium theory"
  },
  "{\\displaystyle c_{ij}={\\frac {1}{N-|i-j|}}\\sum _{t=1}^{N-|i-j|}X(t)X(t+|i-j|).}": {
    "before": "In practice, SSA is a nonparametric spectral estimation method based on embedding a time series {\\displaystyle \\{X(t):t=1,\\ldots ,N\\}} in a vector space of dimension {\\displaystyle M} . SSA proceeds by diagonalizing the {\\displaystyle M\\times M} lag-covariance matrix {\\displaystyle {\\textbf {C}}_{X}} of {\\displaystyle X(t)} to obtain spectral information on the time series, assumed to be stationary in the weak sense. The matrix {\\displaystyle {\\textbf {C}}_{X}} can be estimated directly from the data as a Toeplitz matrix with constant diagonals (Vautard and Ghil, 1989), i.e., its entries {\\displaystyle c_{ij}} depend only on the lag {\\displaystyle |i-j|} :",
    "after": "An alternative way to compute {\\displaystyle {\\textbf {C}}_{X}} , is by using the {\\displaystyle N'\\times M} \"trajectory matrix\" {\\displaystyle {\\textbf {D}}} that is formed by {\\displaystyle M} lag-shifted copies of {\\displaystyle {\\it {X(t)}}} , which are {\\displaystyle N'=N-M+1} long; then",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "{\\displaystyle {\\textbf {C}}_{X}={\\frac {1}{N'}}{\\textbf {D}}^{\\rm {t}}{\\textbf {D}}.}": {
    "before": "An alternative way to compute {\\displaystyle {\\textbf {C}}_{X}} , is by using the {\\displaystyle N'\\times M} \"trajectory matrix\" {\\displaystyle {\\textbf {D}}} that is formed by {\\displaystyle M} lag-shifted copies of {\\displaystyle {\\it {X(t)}}} , which are {\\displaystyle N'=N-M+1} long; then",
    "after": "The {\\displaystyle M} eigenvectors {\\displaystyle {\\textbf {E}}_{k}} of the lag-covariance matrix {\\displaystyle {\\textbf {C}}_{X}} are called temporal empirical orthogonal functions (EOFs) . The eigenvalues {\\displaystyle \\lambda _{k}} of {\\displaystyle {\\textbf {C}}_{X}} account for the partial variance in the direction {\\displaystyle {\\textbf {E}}_{k}} and the sum of the eigenvalues, i.e., the trace of {\\displaystyle {\\textbf {C}}_{X}} , gives the total variance of the original time series {\\displaystyle X(t)} . The name of the method derives from the singular values {\\displaystyle \\lambda _{k}^{1/2}} of {\\displaystyle {\\textbf {C}}_{X}.}",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "{\\displaystyle A_{k}(t)=\\sum _{j=1}^{M}X(t+j-1)E_{k}(j).}": {
    "before": "Projecting the time series onto each EOF yields the corresponding temporal principal components (PCs) {\\displaystyle {\\textbf {A}}_{k}} :",
    "after": "An oscillatory mode is characterized by a pair of nearly equal SSA eigenvalues and associated PCs that are in approximate phase quadrature (Ghil et al., 2002). Such a pair can represent efficiently a nonlinear, anharmonic oscillation. This is due to the fact that a single pair of data-adaptive SSA eigenmodes often will capture better the basic periodicity of an oscillatory mode than methods with fixed basis functions , such as the sines and cosines used in the Fourier transform .",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "{\\displaystyle R_{K}(t)={\\frac {1}{M_{t}}}\\sum _{k\\in {\\textit {K}}}\\sum _{j={L_{t}}}^{U_{t}}A_{k}(t-j+1)E_{k}(j);}": {
    "before": "A Monte-Carlo test (Allen and Smith, 1996; Allen and Robertson, 1996; Groth and Ghil, 2015) can be applied to ascertain the statistical significance of the oscillatory pairs detected by SSA. The entire time series or parts of it that correspond to trends, oscillatory modes or noise can be reconstructed by using linear combinations of the PCs and EOFs, which provide the reconstructed components (RCs) {\\displaystyle {\\textbf {R}}_{K}} :",
    "after": "here {\\displaystyle K} is the set of EOFs on which the reconstruction is based. The values of the normalization factor {\\displaystyle M_{t}} , as well as of the lower and upper bound of summation {\\displaystyle L_{t}} and {\\displaystyle U_{t}} , differ between the central part of the time series and the vicinity of its endpoints (Ghil et al., 2002).",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "{\\displaystyle \\mathbf {X} =[X_{1}:\\ldots :X_{K}]=(x_{ij})_{i,j=1}^{L,K}={\\begin{bmatrix}x_{1}&x_{2}&x_{3}&\\ldots &x_{K}\\\\x_{2}&x_{3}&x_{4}&\\ldots &x_{K+1}\\\\x_{3}&x_{4}&x_{5}&\\ldots &x_{K+2}\\\\\\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\x_{L}&x_{L+1}&x_{L+2}&\\ldots &x_{N}\\\\\\end{bmatrix}}}": {
    "before": "Form the trajectory matrix of the series {\\displaystyle \\mathbb {X} } , which is the {\\displaystyle L\\!\\times \\!K} matrix",
    "after": "where {\\displaystyle X_{i}=(x_{i},\\ldots ,x_{i+L-1})^{\\mathrm {T} }\\;\\quad (1\\leq i\\leq K)} are lagged vectors of size {\\displaystyle L} . The matrix {\\displaystyle \\mathbf {X} } is a Hankel matrix which means that {\\displaystyle \\mathbf {X} } has equal elements {\\displaystyle x_{ij}} on the anti-diagonals {\\displaystyle i+j=\\,{\\rm {const}}} .",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "{\\displaystyle \\mathbf {X} =\\mathbf {X} _{1}+\\ldots +\\mathbf {X} _{d},}": {
    "before": "Set {\\displaystyle d=\\mathop {\\mathrm {rank} } \\mathbf {X} =\\max\\{i,\\ {\\mbox{such that}}\\ \\lambda _{i}>0\\}} (note that {\\displaystyle d=L} for a typical real-life series) and {\\displaystyle V_{i}=\\mathbf {X} ^{\\mathrm {T} }U_{i}/{\\sqrt {\\lambda _{i}}}} {\\displaystyle (i=1,\\ldots ,d)} . In this notation, the SVD of the trajectory matrix {\\displaystyle \\mathbf {X} } can be written as",
    "after": "where {\\displaystyle \\mathbf {X} _{i}={\\sqrt {\\lambda _{i}}}U_{i}V_{i}^{\\mathrm {T} }}",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "{\\displaystyle \\mathbf {X} _{i}={\\sqrt {\\lambda _{i}}}U_{i}V_{i}^{\\mathrm {T} }}": {
    "before": "{\\displaystyle \\mathbf {X} =\\mathbf {X} _{1}+\\ldots +\\mathbf {X} _{d},} where",
    "after": "are matrices having rank 1; these are called elementary matrices . The collection {\\displaystyle ({\\sqrt {\\lambda _{i}}},U_{i},V_{i})} will be called the {\\displaystyle i} th eigentriple (abbreviated as ET) of the SVD. Vectors {\\displaystyle U_{i}} are the left singular vectors of the matrix {\\displaystyle \\mathbf {X} } , numbers {\\displaystyle {\\sqrt {\\lambda _{i}}}} are the singular values and provide the singular spectrum of {\\displaystyle \\mathbf {X} } ; this gives the name to SSA. Vectors {\\displaystyle {\\sqrt {\\lambda _{i}}}V_{i}=\\mathbf {X} ^{\\mathrm {T} }U_{i}} are called vectors of principal components (PCs).",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "{\\displaystyle \\mathbf {X} =\\mathbf {X} _{I_{1}}+\\ldots +\\mathbf {X} _{I_{m}}.}": {
    "before": "Let {\\displaystyle I=\\{i_{1},\\ldots ,i_{p}\\}} . Then the resultant matrix {\\displaystyle \\mathbf {X} _{I}} corresponding to the group {\\displaystyle I} is defined as {\\displaystyle \\mathbf {X} _{I}=\\mathbf {X} _{i_{1}}+\\ldots +\\mathbf {X} _{i_{p}}} . The resultant matrices are computed for the groups {\\displaystyle I=I_{1},\\ldots ,I_{m}} and the grouped SVD expansion of {\\displaystyle \\mathbf {X} } can now be written as",
    "after": "4th step: Diagonal averaging.",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "{\\displaystyle x_{n}=\\sum \\limits _{k=1}^{m}{\\widetilde {x}}_{n}^{(k)}\\ \\ (n=1,2,\\ldots ,N).}": {
    "before": "Each matrix {\\displaystyle \\mathbf {X} _{I_{j}}} of the grouped decomposition is hankelized and then the obtained Hankel matrix is transformed into a new series of length {\\displaystyle N} using the one-to-one correspondence between Hankel matrices and time series. Diagonal averaging applied to a resultant matrix {\\displaystyle \\mathbf {X} _{I_{k}}} produces a reconstructed series {\\displaystyle {\\widetilde {\\mathbb {X} }}^{(k)}=({\\widetilde {x}}_{1}^{(k)},\\ldots ,{\\widetilde {x}}_{N}^{(k)})} . In this way, the initial series {\\displaystyle x_{1},\\ldots ,x_{N}} is decomposed into a sum of {\\displaystyle m} reconstructed subseries:",
    "after": "This decomposition is the main result of the SSA algorithm. The decomposition is meaningful if each reconstructed subseries could be classified as a part of either trend or some periodic component or noise.",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "Autoregression Typical model for SSA is {\\displaystyle x_{n}=s_{n}+e_{n}} , where {\\displaystyle s_{n}=\\sum _{k=1}^{r}a_{k}s_{n-k}} (signal satisfying an LRR) and {\\displaystyle e_{n}} is noise. The model of AR is {\\displaystyle x_{n}=\\sum _{k=1}^{r}a_{k}x_{n-k}+e_{n}} . Despite these two models look similar they are very different. SSA considers AR as a noise component only. AR(1), which is red noise, is typical model of noise for Monte-Carlo SSA (Allen and Smith, 1996).": {
    "before": "In this way, SSA could be used for change detection not only in trends but also in the variability of the series, in the mechanism that determines dependence between different series and even in the noise structure. The method have proved to be useful in different engineering problems (e.g. Mohammad and Nishida (2011) in robotics), and has been extended to the multivariate case with corresponding analysis of detection delay and false positive rate.  Relation between SSA and other methods [ edit ]",
    "after": "Spectral Fourier Analysis In contrast with Fourier analysis with fixed basis of sine and cosine functions, SSA uses an adaptive basis generated by the time series itself. As a result, the underlying model in SSA is more general and SSA can extract amplitude-modulated sine wave components with frequencies different from {\\displaystyle k/N} . SSA-related methods like ESPRIT can estimate frequencies with higher resolution than spectral Fourier analysis .",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "Linear Recurrence Relations Let the signal be modeled by a series, which satisfies a linear recurrence relation {\\displaystyle s_{n}=\\sum _{k=1}^{r}a_{k}s_{n-k}} ; that is, a series that can be represented as sums of products of exponential, polynomial and sine wave functions. This includes the sum of dumped sinusoids model whose complex-valued form is {\\displaystyle s_{n}=\\sum _{k}C_{k}\\rho _{k}^{n}e^{i2\\pi \\omega _{k}n}} . SSA-related methods allow estimation of frequencies {\\displaystyle \\omega _{k}} and exponential factors {\\displaystyle \\rho _{k}} (Golyandina and Zhigljavsky, 2013, Sect 3.8). Coefficients {\\displaystyle C_{k}} can be estimated by the least squares method. Extension of the model, where {\\displaystyle C_{k}} are replaced by polynomials of {\\displaystyle n} , can be also considered within the SSA-related methods (Badeau et al., 2008).": {
    "before": "Spectral Fourier Analysis In contrast with Fourier analysis with fixed basis of sine and cosine functions, SSA uses an adaptive basis generated by the time series itself. As a result, the underlying model in SSA is more general and SSA can extract amplitude-modulated sine wave components with frequencies different from {\\displaystyle k/N} . SSA-related methods like ESPRIT can estimate frequencies with higher resolution than spectral Fourier analysis .",
    "after": "Signal Subspace methods SSA can be considered as a subspace-based method, since it allows estimation of the signal subspace of dimension {\\displaystyle r} by {\\displaystyle \\mathop {\\mathrm {span} } (U_{1},\\ldots ,U_{r})} .",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "State Space Models The main model behind SSA is {\\displaystyle x_{n}=s_{n}+e_{n}} , where {\\displaystyle s_{n}=\\sum _{k=1}^{r}a_{k}s_{n-k}} and {\\displaystyle e_{n}} is noise. Formally, this model belongs to the general class of state space models. The specifics of SSA is in the facts that parameter estimation is a problem of secondary importance in SSA and the data analysis procedures in SSA are nonlinear as they are based on the SVD of either trajectory or lag-covariance matrix.": {
    "before": "Signal Subspace methods SSA can be considered as a subspace-based method, since it allows estimation of the signal subspace of dimension {\\displaystyle r} by {\\displaystyle \\mathop {\\mathrm {span} } (U_{1},\\ldots ,U_{r})} .",
    "after": "Independent Component Analysis (ICA) SSA is used in blind source separation by ICA as a preprocessing step (Pietilä et al., 2006). On the other hand, ICA can be used as a replacement of the SVD step in the SSA algorithm for achieving better separability (Golyandina and Zhigljavsky, 2013, Sect. 2.5.4).",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "Linear Filters The reconstruction of the series by SSA can be considered as adaptive linear filtration. If the window length {\\displaystyle L} is small, then each eigenvector {\\displaystyle U_{i}=(u_{1},\\ldots ,u_{L})^{\\mathrm {T} }} generates a linear filter of width {\\displaystyle 2L-1} for reconstruction of the middle of the series {\\displaystyle {\\widetilde {x}}_{s}} , {\\displaystyle L\\leq s\\leq K} . The filtration is non-causal. However, the so-called Last-point SSA can be used as a causal filter (Golyandina and Zhigljavsky 2013, Sect. 3.9).": {
    "before": "Regression SSA is able to extract polynomial and exponential trends. However, unlike regression, SSA does not assume any parametric model which may give significant advantage when an exploratory data analysis is performed with no obvious model in hand (Golyandina et al., 2001, Ch.1).",
    "after": "Density Estimation Since SSA can be used as a method of data smoothing it can be used as a method of non-parametric density estimation (Golyandina et al., 2012).",
    "url": "https://en.wikipedia.org/wiki/Singular spectrum analysis"
  },
  "{\\displaystyle Y_{t}=\\beta _{1}+\\beta _{2}X_{t,1}+\\beta _{3}X_{t,2}+u_{t}\\,}": {
    "before": "Consider a linear regression of any form, for example",
    "after": "where the errors might follow an AR( p ) autoregressive scheme, as follows:",
    "url": "https://en.wikipedia.org/wiki/Breusch–Godfrey test"
  },
  "{\\displaystyle u_{t}=\\rho _{1}u_{t-1}+\\rho _{2}u_{t-2}+\\cdots +\\rho _{p}u_{t-p}+\\varepsilon _{t}.\\,}": {
    "before": "where the errors might follow an AR( p ) autoregressive scheme, as follows:",
    "after": "The simple regression model is first fitted by ordinary least squares to obtain a set of sample residuals {\\displaystyle {\\hat {u}}_{t}} .",
    "url": "https://en.wikipedia.org/wiki/Breusch–Godfrey test"
  },
  "{\\displaystyle {\\hat {u}}_{t}=\\alpha _{0}+\\alpha _{1}X_{t,1}+\\alpha _{2}X_{t,2}+\\rho _{1}{\\hat {u}}_{t-1}+\\rho _{2}{\\hat {u}}_{t-2}+\\cdots +\\rho _{p}{\\hat {u}}_{t-p}+\\varepsilon _{t}\\,}": {
    "before": "Breusch and Godfrey [ citation needed ] proved that, if the following auxiliary regression model is fitted",
    "after": "and if the usual {\\displaystyle R^{2}} statistic is calculated for this model, then the following asymptotic approximation can be used for the distribution of the test statistic",
    "url": "https://en.wikipedia.org/wiki/Breusch–Godfrey test"
  },
  "{\\displaystyle n=T-p,\\,}": {
    "before": "when the null hypothesis {\\displaystyle {H_{0}:\\lbrace \\rho _{i}=0{\\text{ for all }}i\\rbrace }} holds (that is, there is no serial correlation of any order up to p ). Here n is the number of data-points available for the second regression, that for {\\displaystyle {\\hat {u}}_{t}} ,",
    "after": "where T is the number of observations in the basic series. Note that the value of n depends on the number of lags of the error term ( p ).",
    "url": "https://en.wikipedia.org/wiki/Breusch–Godfrey test"
  },
  "{\\displaystyle {\\frac {P_{f}}{P}}=\\theta }": {
    "before": "To see how a small sector with a fixed price can affect the way rest of the flexible prices behave, suppose that there are two sectors in the economy: a proportion a with flexible prices P f and a proportion 1-a that are affected by menu costs with sticky prices P m . Suppose that the flexible price sector price P f has the market clearing condition of the following form:",
    "after": "where {\\displaystyle P=P_{f}^{a}P_{m}^{1-a}} is the aggregate price index (which would result if consumers had Cobb-Douglas preferences over the two goods). The equilibrium condition says that the real flexible price equals some constant (for example {\\displaystyle {\\theta }} could be real marginal cost). Now we have a remarkable result: no matter how small the menu cost sector, so long as a<1 , the flexible prices get \"pegged\" to the fixed price.  Using the aggregate price index the equilibrium condition becomes",
    "url": "https://en.wikipedia.org/wiki/Nominal rigidity"
  },
  "{\\displaystyle {\\frac {P_{f}}{P_{f}^{a}P_{m}^{1-a}}}=\\theta }": {
    "before": "where {\\displaystyle P=P_{f}^{a}P_{m}^{1-a}} is the aggregate price index (which would result if consumers had Cobb-Douglas preferences over the two goods). The equilibrium condition says that the real flexible price equals some constant (for example {\\displaystyle {\\theta }} could be real marginal cost). Now we have a remarkable result: no matter how small the menu cost sector, so long as a<1 , the flexible prices get \"pegged\" to the fixed price.  Using the aggregate price index the equilibrium condition becomes",
    "after": "which implies that",
    "url": "https://en.wikipedia.org/wiki/Nominal rigidity"
  },
  "{\\displaystyle P_{f}^{1-a}=P_{m}^{1-a}\\theta } ,": {
    "before": "{\\displaystyle {\\frac {P_{f}}{P_{f}^{a}P_{m}^{1-a}}}=\\theta } which implies that",
    "after": "so that {\\displaystyle P_{f}=P_{m}\\theta ^{\\frac {1}{1-a}}} .",
    "url": "https://en.wikipedia.org/wiki/Nominal rigidity"
  },
  "{\\displaystyle P_{f}=P_{m}\\theta ^{\\frac {1}{1-a}}} .": {
    "before": "{\\displaystyle P_{f}^{1-a}=P_{m}^{1-a}\\theta } ,so that",
    "after": "What this result says is that no matter how small the sector affected by menu-costs, it will tie down the flexible price. In macroeconomic terms all nominal prices will be sticky, even those in the potentially flexible price sector, so that changes in nominal demand will feed through into changes in output in both the menu-cost sector and the flexible price sector.",
    "url": "https://en.wikipedia.org/wiki/Nominal rigidity"
  },
  "{\\displaystyle P_{f}=P_{m}\\theta (Y)^{\\frac {1}{1-a}}}": {
    "before": "Now, this is of course an extreme result resulting from the real rigidity taking the form of a constant real marginal cost. For example, if we allowed for the real marginal cost to vary with aggregate output Y , then we would have",
    "after": "so that the flexible prices would vary with output Y . However, the presence of the fixed prices in the menu-cost sector would still act to dampen the responsiveness of the flexible prices, although this would now depend upon the size of the menu-cost sector a , the sensitivity of {\\displaystyle {\\theta }} to Y and so on.",
    "url": "https://en.wikipedia.org/wiki/Nominal rigidity"
  },
  "{\\displaystyle \\Sigma _{i}\\mathbf {p} \\cdot \\mathbf {x_{i}} >\\Sigma _{i}w_{i}=\\Sigma _{j}\\mathbf {p} \\cdot \\mathbf {y_{j}^{*}} } .": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fundamental theorems of welfare economics"
  },
  "i. {\\displaystyle p\\cdot y_{j}\\leq p\\cdot y_{j}^{*}} for all {\\displaystyle y_{j}\\in Y_{j}} (firms maximize profit by producing {\\displaystyle y_{j}^{*}} ) ii. For all i , if {\\displaystyle x_{i}>_{i}x_{i}^{*}} then {\\displaystyle p\\cdot x_{i}\\geq w_{i}} (if {\\displaystyle x_{i}} is strictly preferred to {\\displaystyle x_{i}^{*}} then it cannot cost less than {\\displaystyle x_{i}^{*}} ) iii. {\\displaystyle \\Sigma _{i}x_{i}^{*}=\\omega +\\Sigma _{j}y_{j}^{*}} (budget constraint satisfied)": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fundamental theorems of welfare economics"
  },
  "{\\displaystyle p\\cdot (\\omega +y_{j}+\\Sigma _{h}y_{h}^{*})\\leq r=p\\cdot (\\omega +y_{j}^{*}+\\Sigma _{h}y_{h}^{*})} for {\\displaystyle h\\neq j}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fundamental theorems of welfare economics"
  },
  "{\\displaystyle p\\cdot (x_{i}+\\Sigma _{k}x_{k}^{*})\\geq r=p\\cdot (x_{i}^{*}+\\Sigma _{k}x_{k}^{*})} for {\\displaystyle k\\neq i}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Fundamental theorems of welfare economics"
  },
  "{\\displaystyle KZ_{m,k}[X(t)]=\\sum _{s=-k(m-1)/2}^{k(m-1)/2}{X(t+s)\\times {a_{s}^{m,k}}}}": {
    "before": "Let {\\displaystyle \\{X(t)\\},t=0,\\pm 1,\\pm 2,\\dots } be a real-valued time series , the KZ filter with parameters {\\displaystyle m} and {\\displaystyle k} is defined as",
    "after": "where coefficients",
    "url": "https://en.wikipedia.org/wiki/Kolmogorov–Zurbenko filter"
  },
  "{\\displaystyle a_{s}^{m,k}={\\frac {c_{s}^{k,m}}{m^{k}}},s={\\frac {-k(m-1)}{2}},\\dots ,{\\frac {k(m-1)}{2}}}": {
    "before": "{\\displaystyle KZ_{m,k}[X(t)]=\\sum _{s=-k(m-1)/2}^{k(m-1)/2}{X(t+s)\\times {a_{s}^{m,k}}}} where coefficients",
    "after": "are given by the polynomial coefficients obtained from equation",
    "url": "https://en.wikipedia.org/wiki/Kolmogorov–Zurbenko filter"
  },
  "{\\displaystyle \\sum _{r=0}^{k(m-1)}{z^{r}c_{r-k(m-1)/2}^{k,m}=(1+z+\\dots +z^{m-1})^{k}}}": {
    "before": "are given by the polynomial coefficients obtained from equation",
    "after": "From another point of view, the KZ filter with parameters {\\displaystyle m} and {\\displaystyle k} can be defined as {\\displaystyle k} time iterations of a moving average (MA) filter of {\\displaystyle m} points. It can be obtained through iterations.",
    "url": "https://en.wikipedia.org/wiki/Kolmogorov–Zurbenko filter"
  },
  "{\\displaystyle KZ_{m,k=1}[X(t)]=\\sum _{s=-(m-1)/2}^{(m-1)/2}{X(t+s)}\\times {\\frac {1}{m}}}": {
    "before": "First iteration is to apply a MA filter over process {\\displaystyle X(t)}",
    "after": "The second iteration is to apply the MA operation to the result of the first iteration,",
    "url": "https://en.wikipedia.org/wiki/Kolmogorov–Zurbenko filter"
  },
  "{\\displaystyle {\\begin{aligned}&KZ_{m,k=2}[X(t)]=\\sum _{s=-(m-1)/2}^{(m-1)/2}{KZ_{m,k=1}[X(t+s)]\\times {\\frac {1}{m}}}\\\\={}&\\sum _{s=-2(m-1)/2}^{2(m-1)/2}{X(t+s)\\times {a_{s}^{m,k=2}}}\\end{aligned}}}": {
    "before": "The second iteration is to apply the MA operation to the result of the first iteration,",
    "after": "Generally the k th iteration is an application of the MA filter to the ( k − 1)th iteration. The iteration process of a simple operation of MA is very convenient computationally.",
    "url": "https://en.wikipedia.org/wiki/Kolmogorov–Zurbenko filter"
  },
  "{\\displaystyle |B_{m,k}(\\omega )|^{2}=\\left\\{{\\frac {1}{m}}{\\frac {\\sin(\\pi m\\omega )}{\\sin(\\pi \\omega )}}\\right\\}^{2k}.}": {
    "before": "The impulse response function of the product of filters is the convolution of impulse responses. The coefficients of the KZ filter a m , k s , can be interpreted as a distribution obtained by the convolution of k uniform discrete distributions on the interval [ −( m − 1)/2 , ( m − 1)/2 ] where m is an odd integer. Therefore, the coefficient a forms a tapering window which has finite support [ ( m − 1) k + 1] . The KZ filter a has main weight concentrated on a length of m √ k with weights vanishing to zero outside. The impulse response function of the KZ filter has k − 2 continuous derivatives and is asymptotically Gaussian distributed. Zero derivatives at the edges for the impulse response function make from it a sharply declining function, what is resolving in high frequency resolution. The energy transfer function of the KZ filter is",
    "after": "It is a low-pass filter with a cut-off frequency of",
    "url": "https://en.wikipedia.org/wiki/Kolmogorov–Zurbenko filter"
  },
  "{\\displaystyle KZFT_{m,k,\\nu _{0}}[X(t)]=\\sum _{s=-k(m-1)/2}^{k(m-1)/2}{X(t+s)\\times {a_{s}^{m,k}\\times {e^{-i(2m\\nu _{0})s}}}}}": {
    "before": "Formally, we have a process X ( t ) , t = ...,−1,0,1,... , the KZFT filter with parameters m and k , computed at frequency ν 0 , produces an output process, which is defined as following:",
    "after": "where a m , k s is defined as: a m , k s = C m , k s / m k , s = −k(m − 1) / 2 ,..., −k(m − 1) / 2 and the polynomial coefficients C m , k s is given by Σ k ( m − 1) r = 0 z r C k,m r − k ( m − 1)/2 = (1 + z + ... + z ( m − 1) ) k . Apparently KZFT m,k,ν 0 (t) [ X ( t )] filter is equivalent to the application of KZFT m,k ( t ) filter to the process X ( t + s ) e − i 2( mν 0 ) s . Similarly, the KZFT filter can be obtained through iterations in the same way as KZ filter.",
    "url": "https://en.wikipedia.org/wiki/Kolmogorov–Zurbenko filter"
  },
  "{\\displaystyle \\operatorname {KZP} (t,m,k,\\nu _{0})=2\\left|{\\frac {1}{2S\\rho _{0}}}\\sum _{\\tau =-S\\rho _{0}}^{S\\rho _{0}}2\\operatorname {Re} [KZFT_{m,k,\\nu +0}[X(\\tau +t)]]^{2}\\right|}": {
    "before": "The average of the square of KZFT in time over S periods of ρ 0 = 1 / ν 0 will provide an estimate of the square amplitude of the wave at frequency ν 0 or KZ periodogram (KZP) based on 2 Sρ 0 observations around moment t :",
    "after": "Transfer function of KZFT is provided in Figure 2 has a very sharp frequency resolution with bandwidth limited by c /( m √ k ) . For a complex-valued process X ( t ) = e i(2mν 0 )t , the KZFT m,k,ν 0 ( t ) outcome is unchanged. For a real-valued process, it distributes energy evenly over the real and complex domains. In other words, 2Re[ KZFT m,k,ν 0 ( t )] reconstructs a cosine or sine wave at the same frequency ν 0 . It follows that 2Re[ KZFT m,k,ν 0 ( t )] correctly reconstructs the amplitude and phase of an unknown wave with frequency ν 0 . Figure below is providing power transfer function of KZFT filtration. It clearly display that it perfectly captured frequency of interest ν 0 = 0.4 and provide practically no spectral leakage from a side lobes which control by parameter k of filtration. For practical purposes choice of k within range 3–5 is usually sufficient, when regular FFT ( k = 1) is providing strong leakage of about 5%.",
    "url": "https://en.wikipedia.org/wiki/Kolmogorov–Zurbenko filter"
  },
  "The base signal is a step function y = −1/7300t + sin(2πt), with t < 3452 and y= −1/7300(t − 3452) + sin(2πt) with 3452 < t < 7300. The application of a low-pass smoothing filter KZ3,365 to the original data results in an over smoothing of the break as shown in Figure 6. The position of the break is no longer obvious. The application of an adaptive version of the KZ filter (KZA) finds the break as shown in Figure 5b. The construction of KZA is based on an adaptive version of the iterated smoothing filter KZ. The idea is to change the size of the filtering window based on the trends found with KZ. This will cause the filter to zoom in on the areas where the data is changing; the more rapid the change, the tighter the zoom will be. The first step in constructing KZA is to use KZ; KZq,k[X(t)] where k is iterations and q is the filter length, where KZq,k is an iterated moving average yi= 1/(2q+1)Σqj=-qXi+j where xi are the original data and yi are the filtered data. This result is used to build an adaptive version of the filter. The filter is composed of a head and tail (qf and qb) respectively, with f = head and b = tail) that adjust in size in response to the data, effectively zooming in on regions where the data are changing rapidly. The head qf shrinks in response to the break in the data. The difference vector built from KZ; D(t) = |Z(t + q) − Z(t − q)| is used to find the discrete equivalent of the derivative D'(t) = D(t + 1) − D(t) . This result determines the sizes of the head and the tail (qf and qb respectively) of the filtering window. If the slope is positive the head will shrink and the tail will expand to full size (D'(t) > 0, then qf(t) = f(D(t))q and qb(t) = q) with f(D(t)) = 1 - D(t)/max[D(t)]. If the slope is negative the head of the window will be full sized while the tail will shrink (D'(t) < 0, then qf(t) = q and qb(t) = f(D(t))q. Detailed code of KZA is available.": {
    "before": "As an example of break point detection, we simulate a long-term trend containing a break buried in seasonality and noise. Figure 2 is a plot of a seasonal sine wave with amplitude of 1 unit, normally distributed noise (σ = 1), and a base signal with a break. To make things more challenging, the base signal contains an overall downward trend of 1 unit and an upward break of 0.5 units. The downward trend and break are hardly visible in the original data.",
    "after": "Figure 7: Reconstruction of square image of the 2-dimensional signal of level 1 buried in the normal noise with σ=2. Left is noisy image, right is application to it of 2-dimensional KZA. Total field of display is 100x100 points, original image is 30x30 in the center.",
    "url": "https://en.wikipedia.org/wiki/Kolmogorov–Zurbenko filter"
  },
  "\"[...] But if, on the contrary, players of such a game were motivated to outscore, they would find that {\\displaystyle 1/4,} is beaten by a higher ratio, {\\displaystyle x^{*}} ; the value of {\\displaystyle x} which gives its player the greatest possible advantage over the player playing {\\displaystyle x_{0}} , is found to be given by the relationship {\\displaystyle x^{*}=(2x_{0})^{1/2}-x_{0}} and shows {\\displaystyle 1/2} to be the unbeatable play.\" Hamilton (1967).": {
    "before": "\"In the way in which the success of a chosen sex ratio depends on choices made by the co-parasitizing females, this problem resembles certain problems discussed in the \"theory of games.\" In the foregoing analysis a game-like element, of a kind, was present and made necessary the use of the word unbeatable to describe the ratio finally established. This word was applied in just the same sense in which it could be applied to the \"minimax\" strategy of a zero-sum two-person game. Such a strategy should not, without qualification, be called optimum because it is not optimum against -although unbeaten by- any strategy differing from itself. This is exactly the case with the \"unbeatable\" sex ratios referred to.\" Hamilton (1967).",
    "after": "The concept can be traced through R.A. Fisher (1930)  to Darwin (1859);  see Edwards (1998).  Hamilton did not explicitly define the term \"unbeatable strategy\" or apply the concept beyond the evolution of sex-ratios, but the idea was very influential. George R. Price generalised the verbal argument, which was then formalised mathematically by John Maynard Smith , into the evolutionarily stable strategy (ESS). ",
    "url": "https://en.wikipedia.org/wiki/Unbeatable strategy"
  },
  "An example of the function, where Y=output, L=labor, MPL=marginal product of labor. The technology shock increases the output given the same level of, in this case, labor. The marginal product of labor is higher after the positive technology shock, this can be seen in the MPL (blue) line being steeper.": {
    "before": "This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: \"Technology shock\" – news · newspapers · books · scholar · JSTOR (August 2014) (Learn how and when to remove this template message)",
    "after": "Technology shocks are sudden changes in technology that significantly affect economic, social, political or other outcomes. In economics, the term technology shock usually refers to events in a macroeconomic model, that change the production function. Usually this is modeled with an aggregate production function that has a scaling factor.",
    "url": "https://en.wikipedia.org/wiki/Technology shock"
  },
  "For b = 1, ..., B : Sample, with replacement, n training examples from X , Y ; call these X b , Y b . Train a classification or regression tree f b on X b , Y b .": {
    "before": "The training algorithm for random forests applies the general technique of bootstrap aggregating , or bagging, to tree learners. Given a training set X = x 1 , ..., x n with responses Y = y 1 , ..., y n , bagging repeatedly ( B times) selects a random sample with replacement of the training set and fits trees to these samples:",
    "after": "After training, predictions for unseen samples x' can be made by averaging the predictions from all the individual regression trees on x' :",
    "url": "https://en.wikipedia.org/wiki/Random forest"
  },
  "{\\displaystyle {\\hat {f}}={\\frac {1}{B}}\\sum _{b=1}^{B}f_{b}(x')}": {
    "before": "After training, predictions for unseen samples x' can be made by averaging the predictions from all the individual regression trees on x' :",
    "after": "or by taking the majority vote [ clarify ] in the case of classification trees.",
    "url": "https://en.wikipedia.org/wiki/Random forest"
  },
  "{\\displaystyle \\sigma ={\\sqrt {\\frac {\\sum _{b=1}^{B}(f_{b}(x')-{\\hat {f}})^{2}}{B-1}}}.}": {
    "before": "Additionally, an estimate of the uncertainty of the prediction can be made as the standard deviation of the predictions from all the individual regression trees on x' :",
    "after": "The number of samples/trees, B , is a free parameter. Typically, a few hundred to several thousand trees are used, depending on the size and nature of the training set. An optimal number of trees B can be found using cross-validation , or by observing the out-of-bag error : the mean prediction error on each training sample x i , using only the trees that did not have x i in their bootstrap sample.  The training and test error tend to level off after some number of trees have been fit.",
    "url": "https://en.wikipedia.org/wiki/Random forest"
  },
  "{\\displaystyle {\\hat {y}}=\\sum _{i=1}^{n}W(x_{i},x')\\,y_{i}.}": {
    "before": "A relationship between random forests and the k -nearest neighbor algorithm ( k -NN) was pointed out by Lin and Jeon in 2002.  It turns out that both can be viewed as so-called weighted neighborhoods schemes . These are models built from a training set {\\displaystyle \\{(x_{i},y_{i})\\}_{i=1}^{n}} that make predictions {\\displaystyle {\\hat {y}}} for new points x' by looking at the \"neighborhood\" of the point, formalized by a weight function W :",
    "after": "Here, {\\displaystyle W(x_{i},x')} is the non-negative weight of the i 'th training point relative to the new point x' in the same tree. For any particular x' , the weights for points {\\displaystyle x_{i}} must sum to one. Weight functions are given as follows:",
    "url": "https://en.wikipedia.org/wiki/Random forest"
  },
  "{\\displaystyle {\\hat {y}}={\\frac {1}{m}}\\sum _{j=1}^{m}\\sum _{i=1}^{n}W_{j}(x_{i},x')\\,y_{i}=\\sum _{i=1}^{n}\\left({\\frac {1}{m}}\\sum _{j=1}^{m}W_{j}(x_{i},x')\\right)\\,y_{i}.}": {
    "before": "Since a forest averages the predictions of a set of m trees with individual weight functions {\\displaystyle W_{j}} , its predictions are",
    "after": "This shows that the whole forest is again a weighted neighborhood scheme, with weights that average those of the individual trees. The neighbors of x' in this interpretation are the points {\\displaystyle x_{i}} sharing the same leaf in any tree {\\displaystyle j} . In this way, the neighborhood of x' depends in a complex way on the structure of the trees, and thus on the structure of the training set. Lin and Jeon show that the shape of the neighborhood used by a random forest adapts to the local importance of each feature. ",
    "url": "https://en.wikipedia.org/wiki/Random forest"
  },
  "{\\displaystyle {\\tilde {m}}_{M,n}(\\mathbf {x} ,\\Theta _{1},\\ldots ,\\Theta _{M})={\\frac {1}{\\sum _{j=1}^{M}N_{n}(\\mathbf {x} ,\\Theta _{j})}}\\sum _{j=1}^{M}\\sum _{i=1}^{n}Y_{i}\\mathbf {1} _{\\mathbf {X} _{i}\\in A_{n}(\\mathbf {x} ,\\Theta _{j})},}": {
    "before": "Thus random forest estimates satisfy, for all {\\displaystyle \\mathbf {x} \\in [0,1]^{d}} , {\\displaystyle m_{M,n}(\\mathbf {x} ,\\Theta _{1},\\ldots ,\\Theta _{M})={\\frac {1}{M}}\\sum _{j=1}^{M}\\left(\\sum _{i=1}^{n}{\\frac {Y_{i}\\mathbf {1} _{\\mathbf {X} _{i}\\in A_{n}(\\mathbf {x} ,\\Theta _{j})}}{N_{n}(\\mathbf {x} ,\\Theta _{j})}}\\right)} . Random regression forest has two levels of averaging, first over the samples in the target cell of a tree, then over all trees. Thus the contributions of observations that are in cells with a high density of data points are smaller than that of observations which belong to less populated cells. In order to improve the random forest methods and compensate the misestimation, Scornet  defined KeRF by",
    "after": "which is equal to the mean of the {\\displaystyle Y_{i}} 's falling in the cells containing {\\displaystyle \\mathbf {x} } in the forest. If we define the connection function of the {\\displaystyle M} finite forest as {\\displaystyle K_{M,n}(\\mathbf {x} ,\\mathbf {z} )={\\frac {1}{M}}\\sum _{j=1}^{M}\\mathbf {1} _{\\mathbf {z} \\in A_{n}(\\mathbf {x} ,\\Theta _{j})}} , i.e. the proportion of cells shared between {\\displaystyle \\mathbf {x} } and {\\displaystyle \\mathbf {z} } , then almost surely we have {\\displaystyle {\\tilde {m}}_{M,n}(\\mathbf {x} ,\\Theta _{1},\\ldots ,\\Theta _{M})={\\frac {\\sum _{i=1}^{n}Y_{i}K_{M,n}(\\mathbf {x} ,\\mathbf {x} _{i})}{\\sum _{\\ell =1}^{n}K_{M,n}(\\mathbf {x} ,\\mathbf {x} _{\\ell })}}} , which defines the KeRF.",
    "url": "https://en.wikipedia.org/wiki/Random forest"
  },
  "{\\displaystyle {\\begin{aligned}K_{k}^{cc}(\\mathbf {x} ,\\mathbf {z} )=\\sum _{k_{1},\\ldots ,k_{d},\\sum _{j=1}^{d}k_{j}=k}&{\\frac {k!}{k_{1}!\\cdots k_{d}!}}\\left({\\frac {1}{d}}\\right)^{k}\\prod _{j=1}^{d}\\mathbf {1} _{\\lceil 2^{k_{j}}x_{j}\\rceil =\\lceil 2^{k_{j}}z_{j}\\rceil },\\\\&{\\text{ for all }}\\mathbf {x} ,\\mathbf {z} \\in [0,1]^{d}.\\end{aligned}}}": {
    "before": "The construction of Centered KeRF of level {\\displaystyle k} is the same as for centered forest, except that predictions are made by {\\displaystyle {\\tilde {m}}_{M,n}(\\mathbf {x} ,\\Theta _{1},\\ldots ,\\Theta _{M})} , the corresponding kernel function, or connection function is",
    "after": "Uniform KeRF [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Random forest"
  },
  "{\\displaystyle K_{k}^{uf}(\\mathbf {0} ,\\mathbf {x} )=\\sum _{k_{1},\\ldots ,k_{d},\\sum _{j=1}^{d}k_{j}=k}{\\frac {k!}{k_{1}!\\ldots k_{d}!}}\\left({\\frac {1}{d}}\\right)^{k}\\prod _{m=1}^{d}\\left(1-|x_{m}|\\sum _{j=0}^{k_{m}-1}{\\frac {(-\\ln |x_{m}|)^{j}}{j!}}\\right){\\text{ for all }}\\mathbf {x} \\in [0,1]^{d}.}": {
    "before": "Uniform KeRF is built in the same way as uniform forest, except that predictions are made by {\\displaystyle {\\tilde {m}}_{M,n}(\\mathbf {x} ,\\Theta _{1},\\ldots ,\\Theta _{M})} , the corresponding kernel function, or connection function is",
    "after": "Properties [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Random forest"
  },
  "{\\displaystyle a_{n}\\leq N_{n}(\\mathbf {x} ,\\Theta )\\leq b_{n}{\\text{ and }}a_{n}\\leq {\\frac {1}{M}}\\sum _{m=1}^{M}N_{n}{\\mathbf {x} ,\\Theta _{m}}\\leq b_{n}.}": {
    "before": "Assume that there exist sequences {\\displaystyle (a_{n}),(b_{n})} such that, almost surely,",
    "after": "Then almost surely,",
    "url": "https://en.wikipedia.org/wiki/Random forest"
  },
  "R = (BP) − C": {
    "before": "The standard model of voter calculus was articulated by Riker and Ordeshook in their 1968 article \"A Theory of the Calculus of Voting\" in The American Political Science Review .  The basic utility hypothesis for the calculus of voting they gave was:",
    "after": "Where B is the expected differential utility a voter personally receives from his preferred candidate winning; P is the probability of the voter bringing about B (that is, turning the election for his preferred candidate); C is the individual's cost of voting in the election; and R is the individual's expected reward from voting. If R > 0, then the expected utility of voting outweighs its costs, and it is reasonable to vote. But if R ≤ 0, the costs outweigh the benefits and a strictly rational individual would not be expected to vote.",
    "url": "https://en.wikipedia.org/wiki/Altruism theory of voting"
  },
  "R = (BP) − C + D": {
    "before": "Because simple selfishness cannot explain why large numbers of people consistently choose to vote, Riker and Ordeshook introduced another term to the equation, D , to symbolize the personal or social benefits conferred by the act of voting itself, rather than by affecting the outcome of the election.",
    "after": "This drew a distinction between expressive voting , intended only to signal support or demonstrate civic responsibility, and instrumental voting , intended to actually change the outcome. The benefits here did not come from actually influencing the election, but rather from the social payoffs of participating in it. Because the term BP was assumed to be zero, D was presumed to be the only important factor in determining elections. ",
    "url": "https://en.wikipedia.org/wiki/Altruism theory of voting"
  },
  "{\\displaystyle {\\mbox{Quota}}={\\frac {\\mbox{Total population of the six states}}{\\mbox{Number of senators for the states x 2}}}}": {
    "before": "Under the current method, the AEC firstly calculates a quota, as follows:",
    "after": "State entitlements [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Redistribution (Australia)"
  },
  "{\\displaystyle {\\mbox{Quotient of each state}}={\\frac {\\mbox{Population of each state }}{\\mbox{Quota}}}}": {
    "before": "After the quota is calculated, the number of members to be chosen in each State is the number of people of the State divided by the quota, and if on such division there is a remainder greater than one-half of the quota, one more member shall be chosen in the State. ",
    "after": "In simpler terms, the entitlement of each state is the quotient rounded to the nearest whole number. However, each Original State is entitled to a minimum of five members under the Australian Constitution, thus giving Tasmania two more seats than its population would normally justify. ",
    "url": "https://en.wikipedia.org/wiki/Redistribution (Australia)"
  },
  "{\\displaystyle {\\mbox{Quotient of each territory}}={\\frac {\\mbox{Population of each territory }}{\\mbox{Quota}}}}": {
    "before": "The calculation of the territory's quotient is first determined in the same way used for state entitlement:",
    "after": "In accordance with Section 48 of the Commonwealth Electoral Act 1918 , the calculation of the entitlement of each territory varies on the quotient calculated:",
    "url": "https://en.wikipedia.org/wiki/Redistribution (Australia)"
  },
  "{\\displaystyle {\\mbox{Minimum number of members}}={\\mbox{Quotient rounded down to the nearest whole number}}}": {
    "before": "If the quotient is less than or equal to 0.5, then the territory is not entitled to have any members in the House of Representatives, except in the case of the Northern Territory and Australian Capital Territory (both are entitled to a minimum of one member each).  If the quotient is greater than 0.5, but less than or equal to 1, the territory is entitled to one member in the House of Representatives. If the quotient is more than 3, then the entitlement of the territory is the quotient rounded to the nearest whole number (the same method as state entitlement). If the quotient is more than 1, but less than or equal to 3, the entitlement is calculated via the harmonic mean method below. If the quotient is larger than its corresponding harmonic mean, then the entitlement is the quotient rounded up to the nearest whole number; otherwise, the entitlement is the quotient rounded down to the nearest whole number.  ",
    "after": "{\\displaystyle {\\mbox{Harmonic mean}}={\\frac {\\mbox{2 x Minimum number of members x (Minimum number of members + 1)}}{\\mbox{Minimum number of members + (Minimum number of members + 1)}}}}",
    "url": "https://en.wikipedia.org/wiki/Redistribution (Australia)"
  },
  "{\\displaystyle {\\mbox{Harmonic mean}}={\\frac {\\mbox{2 x Minimum number of members x (Minimum number of members + 1)}}{\\mbox{Minimum number of members + (Minimum number of members + 1)}}}}": {
    "before": "{\\displaystyle {\\mbox{Minimum number of members}}={\\mbox{Quotient rounded down to the nearest whole number}}}",
    "after": "Quotient Minimum number of members Harmonic mean Seat Entitlement 1 to 1.3332 1 1.3333 1 1.3333 to 2 2 2 to 2.39 2 2.4000 2 2.40 to 3 3",
    "url": "https://en.wikipedia.org/wiki/Redistribution (Australia)"
  },
  "{\\displaystyle Y_{i}=C+\\alpha \\sin(\\omega T_{i}+\\phi )+E_{i}}": {
    "before": "In statistics , signal processing , and time series analysis , a sinusoidal model is used to approximate a sequence Y i to a sine function:",
    "after": "where C is constant defining a mean level, α is an amplitude for the sine , ω is the angular frequency , T i is a time variable, φ is the phase-shift , and E i is the error sequence.",
    "url": "https://en.wikipedia.org/wiki/Sinusoidal model"
  },
  "{\\displaystyle Y_{i}=(B_{0}+B_{1}T_{i})+\\alpha \\sin(2\\pi \\omega T_{i}+\\phi )+E_{i}}": {
    "before": "A good starting value for C can be obtained by calculating the mean of the data. If the data show a trend , i.e., the assumption of constant location is violated, one can replace C with a linear or quadratic least squares fit. That is, the model becomes",
    "after": "or {\\displaystyle Y_{i}=(B_{0}+B_{1}T_{i}+B_{2}T_{i}^{2})+\\alpha \\sin(2\\pi \\omega T_{i}+\\phi )+E_{i}}",
    "url": "https://en.wikipedia.org/wiki/Sinusoidal model"
  },
  "{\\displaystyle Y_{i}=(B_{0}+B_{1}T_{i}+B_{2}T_{i}^{2})+\\alpha \\sin(2\\pi \\omega T_{i}+\\phi )+E_{i}}": {
    "before": "{\\displaystyle Y_{i}=(B_{0}+B_{1}T_{i})+\\alpha \\sin(2\\pi \\omega T_{i}+\\phi )+E_{i}} or",
    "after": "Good starting value for frequency [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Sinusoidal model"
  },
  "{\\displaystyle Y_{i}=C+(B_{0}+B_{1}T_{i})\\sin(2\\pi \\omega T_{i}+\\phi )+E_{i}}": {
    "before": "The root mean square of the detrended data can be scaled by the square root of two to obtain an estimate of the sinusoid amplitude. A complex demodulation amplitude plot can be used to find a good starting value for the amplitude. In addition, this plot can indicate whether or not the amplitude is constant over the entire range of the data or if it varies. If the plot is essentially flat, i.e., zero slope, then it is reasonable to assume a constant amplitude in the non-linear model. However, if the slope varies over the range of the plot, one may need to adjust the model to be:",
    "after": "That is, one may replace α with a function of time. A linear fit is specified in the model above, but this can be replaced with a more elaborate function if needed.",
    "url": "https://en.wikipedia.org/wiki/Sinusoidal model"
  },
  "( x 1 , y 1 ) + ( x 2 , y 2 ) = ( x 1 + x 2 , y 1 + y 2 );": {
    "before": "A real vector space of two dimensions can be given a Cartesian coordinate system in which every point is identified by an ordered pair of real numbers, called \"coordinates\", which are conventionally denoted by x and y . Two points in the Cartesian plane can be added coordinate-wise",
    "after": "further, a point can be multiplied by each real number λ coordinate-wise",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "λ ( x , y ) = ( λx , λy ).": {
    "before": "further, a point can be multiplied by each real number λ coordinate-wise",
    "after": "More generally, any real vector space of (finite) dimension {\\displaystyle D} can be viewed as the set of all {\\displaystyle D} -tuples of {\\displaystyle D} real numbers { ( v 1 , v 2 , . . . , v D ) } on which two operations are defined: vector addition and multiplication by a real number . For finite-dimensional vector spaces, the operations of vector addition and real-number multiplication can each be defined coordinate-wise, following the example of the Cartesian plane. ",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "{\\displaystyle y_{it}=X_{it}\\mathbf {\\beta } +\\alpha _{i}+u_{it}} for {\\displaystyle t=1,\\ldots ,T} and {\\displaystyle i=1,\\ldots ,N}": {
    "before": "Consider the static linear unobserved effects model for {\\displaystyle N} observations and {\\displaystyle T} time periods:",
    "after": "where {\\displaystyle y_{it}} is the dependent variable observed for individual {\\displaystyle i} at time {\\displaystyle t,} {\\displaystyle X_{it}} is the time-variant {\\displaystyle 1\\times k} regressor matrix, {\\displaystyle \\alpha _{i}} is the unobserved time-invariant individual effect and {\\displaystyle u_{it}} is the error term . Unlike {\\displaystyle X_{it}} , {\\displaystyle \\alpha _{i}} cannot be observed by the econometrician. Common examples for time-invariant effects {\\displaystyle \\alpha _{i}} are innate ability for individuals or historical and institutional factors for countries.",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle y_{it}=X_{it}\\mathbf {\\beta } +\\rho y_{it-1}+\\alpha _{i}+u_{it}{\\text{ for }}t=1,\\ldots ,T{\\text{ and }}i=1,\\ldots ,N}": {
    "before": "Unlike a static panel data model, a dynamic panel model also contains lags of the dependent variable as regressors, accounting for concepts such as momentum and inertia. In addition to the regressors outlined above, consider a case where one lag of the dependent variable is included as a regressor, {\\displaystyle y_{it-1}} .",
    "after": "Taking the first difference of this equation to eliminate the individual effect,",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle \\Delta y_{it}=y_{it}-y_{it-1}=\\Delta X_{it}\\beta +\\rho \\Delta \\ y_{it-1}+\\Delta u_{it}{\\text{ for }}t=1,\\ldots ,T{\\text{ and }}i=1,\\ldots ,N.}": {
    "before": "Taking the first difference of this equation to eliminate the individual effect,",
    "after": "Note that if {\\displaystyle \\alpha _{i}} had a time varying coefficient, then differencing the equation will not remove the individual effect. This equation can be re-written as,",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle \\Delta y=\\Delta R\\pi +\\Delta u.}": {
    "before": "Note that if {\\displaystyle \\alpha _{i}} had a time varying coefficient, then differencing the equation will not remove the individual effect. This equation can be re-written as,",
    "after": "Applying the formula for the Efficient Generalized Method of Moments Estimator, which is,",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle \\pi _{\\text{EGMM}}=[\\Delta R'Z(Z'\\Omega Z)^{-1}Z'\\,\\Delta R]^{-1}\\,\\Delta R'Z(Z'\\Omega Z)^{-1}Z'\\Delta y}": {
    "before": "Applying the formula for the Efficient Generalized Method of Moments Estimator, which is,",
    "after": "where {\\displaystyle Z} is the instrument matrix for {\\displaystyle \\Delta R} .",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle E(y_{it-I}\\,\\Delta u_{it})=0{\\text{ with }}I\\geq 2{\\text{ for each }}t\\geq 3.}": {
    "before": "The original Anderson and Hsiao (1981) IV estimator uses the following moment conditions:",
    "after": "Using the single instrument {\\displaystyle y_{it-2}} , these moment conditions form the basis for the instrument matrix {\\displaystyle Z_{di}} :",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle Z_{di}={\\begin{bmatrix}NA&(t=2)\\\\y_{i1}&(t=3)\\\\y_{i2}&(t=4)\\\\\\vdots &\\vdots \\\\y_{T-2}&(t=T)\\end{bmatrix}}}": {
    "before": "Using the single instrument {\\displaystyle y_{it-2}} , these moment conditions form the basis for the instrument matrix {\\displaystyle Z_{di}} :",
    "after": "Note: The first possible observation is t = 2 due to the first difference transformation",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle E(y_{it-I}\\,\\Delta u_{it})=0{\\text{ for }}t\\geq 3,\\,I\\geq 2.}": {
    "before": "The Arellano–Bond estimator uses the following moment conditions",
    "after": "Using these moment conditions, the instrument matrix {\\displaystyle Z_{di}} now becomes:",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle Z_{di}={\\begin{bmatrix}y_{i1}&0&0&0&0&0&\\cdots \\\\0&y_{i2}&y_{i1}&0&0&0&\\cdots \\\\0&0&0&y_{i3}&y_{i2}&y_{i1}&\\cdots \\\\\\vdots &\\vdots &\\vdots &\\vdots &\\vdots &\\vdots &\\ddots \\end{bmatrix}}}": {
    "before": "Using these moment conditions, the instrument matrix {\\displaystyle Z_{di}} now becomes:",
    "after": "Note that the number of moments is increasing in the time period: this is how the efficiency - sample size tradeoff is avoided. Time periods further in the future have more lags available to use as instruments.",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle \\Delta u_{i}={\\begin{bmatrix}\\Delta u_{i3}\\\\\\Delta u_{i4}\\\\\\Delta u_{i5}\\\\\\vdots \\end{bmatrix}}}": {
    "before": "Note that the number of moments is increasing in the time period: this is how the efficiency - sample size tradeoff is avoided. Time periods further in the future have more lags available to use as instruments.Then if one defines:",
    "after": "The moment conditions can be summarized as:",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle \\operatorname {E} (\\Delta y_{it-1}(\\alpha _{i}+u_{it}))=0{\\text{ for }}t\\geq 3} (1)": {
    "before": "Blundell and Bond (1998) derived a condition under which it is possible to use an additional set of moment conditions.  These additional moment conditions can be used to improve the small sample performance of the Arellano–Bond estimator. Specifically, they advocated using the moment conditions:",
    "after": "These additional moment conditions are valid under conditions provided in their paper. In this case, the full set of moment conditions can be written:",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle P_{i}={\\begin{pmatrix}\\Delta u_{i}\\\\u_{i3}\\\\u_{i4}\\\\u_{i5}\\\\\\vdots \\end{pmatrix}}}": {
    "before": "{\\displaystyle \\operatorname {E} (Z_{SYS,i}^{T}P_{i})=0} where",
    "after": "and {\\displaystyle Z_{SYS,i}={\\begin{pmatrix}Z_{di}&0&0&0\\\\0&\\Delta y_{i2}&0&0\\\\0&0&\\Delta y_{i3}&0\\\\0&0&0&\\ddots \\end{pmatrix}}.}",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle Z_{SYS,i}={\\begin{pmatrix}Z_{di}&0&0&0\\\\0&\\Delta y_{i2}&0&0\\\\0&0&\\Delta y_{i3}&0\\\\0&0&0&\\ddots \\end{pmatrix}}.}": {
    "before": "{\\displaystyle P_{i}={\\begin{pmatrix}\\Delta u_{i}\\\\u_{i3}\\\\u_{i4}\\\\u_{i5}\\\\\\vdots \\end{pmatrix}}} and",
    "after": "This method is known as system GMM. Note that the consistency and efficiency of the estimator depends on validity of the assumption that the errors can be decomposed as in equation (1). This assumption can be tested in empirical applications and likelihood ratio test often reject the simple random effects decomposition. ",
    "url": "https://en.wikipedia.org/wiki/Arellano–Bond estimator"
  },
  "{\\displaystyle {\\bar {f}}_{k}\\left({\\boldsymbol {\\pi }}_{-k}\\right)=\\left\\lbrace {\\boldsymbol {\\pi }}_{k}\\in \\triangle \\left({\\mathcal {A}}_{k}\\right):\\mathrm {Pr} \\left(a_{k}\\in f_{k}\\left({\\boldsymbol {a}}_{-k}\\right)|a_{k}\\sim {\\boldsymbol {\\pi }}_{k},{\\boldsymbol {a}}_{-k}\\sim {\\boldsymbol {\\pi }}_{-k}\\right)=1\\right\\rbrace .}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Satisfaction equilibrium"
  },
  "{\\displaystyle {\\bar {\\bar {f}}}_{k}\\left({\\boldsymbol {\\pi }}_{-k}^{*}\\right)=\\left\\lbrace {\\boldsymbol {\\pi }}_{k}\\in \\triangle \\left({\\mathcal {A}}_{k}\\right):\\mathrm {Pr} \\left(a_{k}\\in f_{k}\\left({\\boldsymbol {a}}_{-k}\\right)|a_{k}\\sim {\\boldsymbol {\\pi }}_{k},{\\boldsymbol {a}}_{-k}\\sim {\\boldsymbol {\\pi }}_{-k}^{*}\\right)\\geqslant 1-\\epsilon \\right\\rbrace .}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Satisfaction equilibrium"
  },
  "{\\displaystyle \\sum _{k=1}^{K}c_{k}\\left(a_{k}^{\\star }\\right)\\leqslant \\sum _{k=1}^{K}c_{k}\\left(a_{k}\\right)} .": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Satisfaction equilibrium"
  },
  "{\\displaystyle g({\\boldsymbol {a}}_{-k})={\\bar {\\bar {f}}}_{k}\\left({\\boldsymbol {\\pi }}_{-k}^{*}\\right),}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Satisfaction equilibrium"
  },
  "{\\displaystyle {\\boldsymbol {\\pi }}_{k}^{*}\\in {\\bar {\\bar {f}}}_{k}\\left({\\boldsymbol {\\pi }}_{-k}^{*}\\right)} ,": {
    "before": "",
    "after": "{\\displaystyle {\\bar {\\bar {f}}}_{k}\\left({\\boldsymbol {\\pi }}_{-k}^{*}\\right)=\\left\\lbrace {\\boldsymbol {\\pi }}_{k}\\in \\triangle \\left({\\mathcal {A}}_{k}\\right):\\mathrm {Pr} \\left(a_{k}\\in f_{k}\\left({\\boldsymbol {a}}_{-k}\\right)|a_{k}\\sim {\\boldsymbol {\\pi }}_{k},{\\boldsymbol {a}}_{-k}\\sim {\\boldsymbol {\\pi }}_{-k}^{*}\\right)\\geqslant 1-\\epsilon \\right\\rbrace .}",
    "url": "https://en.wikipedia.org/wiki/Satisfaction equilibrium"
  },
  "{\\displaystyle {\\text{Activity}}={\\text{var}}(y(t)).}": {
    "before": "The activity parameter represents the signal power, the variance of a time function. This can indicate the surface of power spectrum in the frequency domain. This is represented by the following equation:",
    "after": "Where y(t) represents the signal.",
    "url": "https://en.wikipedia.org/wiki/Hjorth parameters"
  },
  "{\\displaystyle {\\text{Mobility}}={\\sqrt {\\frac {{\\text{var}}({\\frac {dy(t)}{dt}})}{{\\text{var}}(y(t))}}}.}": {
    "before": "The mobility parameter represents the mean frequency or the proportion of standard deviation of the power spectrum. This is defined as the square root of variance of the first derivative of the signal y(t) divided by variance of the signal y(t).",
    "after": "Hjorth Complexity [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Hjorth parameters"
  },
  "{\\displaystyle {\\text{Complexity}}={\\frac {{\\text{Mobility}}({\\frac {dy(t)}{dt}})}{{\\text{Mobility}}(y(t))}}.}": {
    "before": "The Complexity parameter represents the change in frequency. The parameter compares the signal's similarity to a pure sine wave , where the value converges to 1 if the signal is more similar.",
    "after": "Tactile Signal Analysis [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Hjorth parameters"
  },
  "{\\displaystyle X^{\\operatorname {T} }\\Sigma X={\\frac {1}{T}}\\sum _{t=1}^{T}e_{t}^{2}x_{t}x_{t}^{\\operatorname {T} }+{\\frac {1}{T}}\\sum _{\\ell =1}^{L}\\sum _{t=\\ell +1}^{T}w_{\\ell }e_{t}e_{t-\\ell }(x_{t}x_{t-\\ell }^{\\operatorname {T} }+x_{t-\\ell }x_{t}^{\\operatorname {T} })}": {
    "before": "Regression models estimated with time series data often exhibit autocorrelation; that is, the error terms are correlated over time. The heteroscedastic consistent estimator of the error covariance is constructed from a term {\\displaystyle X^{\\operatorname {T} }\\Sigma X} , where {\\displaystyle X} is the design matrix for the regression problem and {\\displaystyle \\Sigma } is the covariance matrix of the residuals. The least squares estimator {\\displaystyle b} is a consistent estimator of {\\displaystyle \\beta } . This implies that the least squares residuals {\\displaystyle e_{i}} are \"point-wise\" consistent estimators of their population counterparts {\\displaystyle E_{i}} . The general approach, then, will be to use {\\displaystyle X} and {\\displaystyle e} to devise an estimator of {\\displaystyle X^{\\operatorname {T} }\\Sigma X} .  This means that as the time between error terms increases, the correlation between the error terms decreases. The estimator thus can be used to improve the ordinary least squares (OLS) regression when the residuals are heteroskedastic and/or autocorrelated.",
    "after": "{\\displaystyle w_{\\ell }=1-{\\frac {\\ell }{L+1}}}",
    "url": "https://en.wikipedia.org/wiki/Newey–West estimator"
  },
  "{\\displaystyle w_{\\ell }=1-{\\frac {\\ell }{L+1}}}": {
    "before": "{\\displaystyle X^{\\operatorname {T} }\\Sigma X={\\frac {1}{T}}\\sum _{t=1}^{T}e_{t}^{2}x_{t}x_{t}^{\\operatorname {T} }+{\\frac {1}{T}}\\sum _{\\ell =1}^{L}\\sum _{t=\\ell +1}^{T}w_{\\ell }e_{t}e_{t-\\ell }(x_{t}x_{t-\\ell }^{\\operatorname {T} }+x_{t-\\ell }x_{t}^{\\operatorname {T} })}",
    "after": "where T is the sample size, {\\displaystyle e_{t}} is the {\\displaystyle t^{th}} residual and {\\displaystyle x_{t}} is the {\\displaystyle t^{th}} row of the design matrix, and {\\displaystyle w_{\\ell }} is the Bartlett Kernel  and can be thought of as a weight that decreases with increasing separation between samples. Disturbances that are farther apart from each other are given lower weight, while those with equal subscripts are given a weight of 1. This ensures that second term converges (in some appropriate sense) to a finite matrix. This weighting scheme also ensures that the resulting covariance matrix is positive semi-definite .  L=0 reduces the Newy-West estimator to Huber–White standard error .  L specifies the \"maximum lag considered for the control of autocorrelation. A common choice for L\" is {\\displaystyle T^{1/4}} .  ",
    "url": "https://en.wikipedia.org/wiki/Newey–West estimator"
  },
  "{\\displaystyle y_{t}=F(y_{t-1},y_{t-2},y_{t-3},\\ldots ,u_{t},u_{t-1},u_{t-2},u_{t-3},\\ldots )+\\varepsilon _{t}}": {
    "before": "In addition, the model contains an error term which relates to the fact that knowledge of other terms will not enable the current value of the time series to be predicted exactly.Such a model can be stated algebraically as",
    "after": "Here y is the variable of interest, and u is the externally determined variable. In this scheme, information about u helps predict y , as do previous values of y itself. Here ε is the error term (sometimes called noise). For example, y may be air temperature at noon, and u may be the day of the year (day-number within year).",
    "url": "https://en.wikipedia.org/wiki/Nonlinear autoregressive exogenous model"
  },
  "{\\displaystyle \\varphi _{i}(v)=\\sum _{S\\subseteq N\\setminus \\{i\\}}{\\frac {|S|!\\;(n-|S|-1)!}{n!}}(v(S\\cup \\{i\\})-v(S))} {\\displaystyle \\quad \\quad \\quad =\\sum _{S\\subseteq N\\setminus \\{i\\}}{n \\choose 1,|S|,n-|S|-1}^{-1}(v(S\\cup \\{i\\})-v(S))}": {
    "before": "The Shapley value is one way to distribute the total gains to the players, assuming that they all collaborate. It is a \"fair\" distribution in the sense that it is the only distribution with certain desirable properties listed below. According to the Shapley value,  the amount that player i is given in a coalitional game {\\displaystyle (v,N)} is",
    "after": "where n is the total number of players and the sum extends over all subsets S of N not containing player i . Also note that {\\displaystyle {n \\choose a,b,c}} is the multinomial coefficient . The formula can be interpreted as follows: imagine the coalition being formed one actor at a time, with each actor demanding their contribution {\\displaystyle v} ( S ∪{ i }) − {\\displaystyle v} ( S ) as a fair compensation, and then for each actor take the average of this contribution over the possible different permutations in which the coalition can be formed.",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{i}(v)={\\frac {1}{n!}}\\sum _{R}\\left[v(P_{i}^{R}\\cup \\left\\{i\\right\\})-v(P_{i}^{R})\\right]}": {
    "before": "An alternative equivalent formula for the Shapley value is:",
    "after": "where the sum ranges over all {\\displaystyle n!} orders {\\displaystyle R} of the players and {\\displaystyle P_{i}^{R}} is the set of players in {\\displaystyle N} which precede {\\displaystyle i} in the order {\\displaystyle R} . Finally, it can also be expressed as",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{i}(v)={\\frac {1}{n}}\\sum _{S\\subseteq N\\setminus \\{i\\}}{\\binom {n-1}{|S|}}^{-1}(v(S\\cup \\{i\\})-v(S))}": {
    "before": "where the sum ranges over all {\\displaystyle n!} orders {\\displaystyle R} of the players and {\\displaystyle P_{i}^{R}} is the set of players in {\\displaystyle N} which precede {\\displaystyle i} in the order {\\displaystyle R} . Finally, it can also be expressed as",
    "after": "which can be interpreted as",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{i}(v)={\\frac {1}{\\text{number of players}}}\\sum _{{\\text{coalitions excluding }}i}{\\frac {{\\text{marginal contribution of }}i{\\text{ to coalition}}}{{\\text{number of coalitions excluding }}i{\\text{ of this size}}}}}": {
    "before": "{\\displaystyle \\varphi _{i}(v)={\\frac {1}{n}}\\sum _{S\\subseteq N\\setminus \\{i\\}}{\\binom {n-1}{|S|}}^{-1}(v(S\\cup \\{i\\})-v(S))} which can be interpreted as",
    "after": "In terms of synergy [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle v(S)=\\sum _{R\\subseteq S}w(R)}": {
    "before": "From the characteristic function {\\displaystyle v} one can compute the synergy that each group of players provides. The synergy is the unique function {\\displaystyle w\\colon 2^{N}\\to \\mathbb {R} } , such that",
    "after": "for any subset {\\displaystyle S\\subseteq N} of players. In other words, the 'total value' of the coalition {\\displaystyle S} comes from summing up the synergies of each possible subset of {\\displaystyle S} .",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle w(S)=\\sum _{R\\subseteq S}(-1)^{|S|-|R|}v(R)}": {
    "before": "Given a characteristic function {\\displaystyle v} , the synergy function {\\displaystyle w} is calculated via",
    "after": "using the Inclusion exclusion principle . In other words, the synergy of coalition {\\displaystyle S} is the value {\\displaystyle v(S)} , which is not already accounted for by its subsets.",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{i}(v)=\\sum _{i\\in S\\subseteq N}{\\frac {w(S)}{|S|}}}": {
    "before": "The Shapley values are given in terms of the synergy function by  ",
    "after": "where the sum is over all subsets {\\displaystyle S} of {\\displaystyle N} that include player {\\displaystyle i} .",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{i}(v)=\\sum _{\\text{coalitions including i}}{\\frac {\\text{synergy of the coalition}}{\\text{members in the coalition}}}}": {
    "before": "where the sum is over all subsets {\\displaystyle S} of {\\displaystyle N} that include player {\\displaystyle i} .This can be interpreted as",
    "after": "In other words, the synergy of each coalition is divided equally between all members.",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle N=\\{o,w_{1},\\ldots ,w_{m}\\}.}": {
    "before": "Consider a simplified description of a business. An owner, o , provides crucial capital in the sense that, without him/her, no gains can be obtained. There are m workers w 1 ,..., w m , each of whom contributes an amount p to the total profit. Let",
    "after": "The value function for this coalitional game is",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle v(S)={\\begin{cases}mp,&{\\text{if }}o\\in S\\\\0,&{\\text{otherwise}}\\\\\\end{cases}}}": {
    "before": "{\\displaystyle N=\\{o,w_{1},\\ldots ,w_{m}\\}.} The value function for this coalitional game is",
    "after": "where m is the cardinality of {\\displaystyle S\\setminus \\{o\\}} . Computing the Shapley value for this coalition game leads to a value of mp / 2 for the owner and p / 2 for each one of the m workers.",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle w(S)={\\begin{cases}p,&{\\text{if }}S=\\{o,w_{i}\\}\\\\0,&{\\text{otherwise}}\\\\\\end{cases}}}": {
    "before": "This can be understood from the perspective of synergy. The synergy function {\\displaystyle w} is",
    "after": "so the only coalitions that generate synergy are one-to-one between the owner and any individual worker.",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{w_{i}}={\\frac {w(\\{o,w_{i}\\})}{2}}={\\frac {p}{2}}}": {
    "before": "Using the above formula for the Shapley value in terms of {\\displaystyle w} we compute",
    "after": "and {\\displaystyle \\varphi _{o}=\\sum _{i=1}^{m}{\\frac {w(\\{o,w_{i}\\})}{2}}={\\frac {mp}{2}}}",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{o}=\\sum _{i=1}^{m}{\\frac {w(\\{o,w_{i}\\})}{2}}={\\frac {mp}{2}}}": {
    "before": "{\\displaystyle \\varphi _{w_{i}}={\\frac {w(\\{o,w_{i}\\})}{2}}={\\frac {p}{2}}} and",
    "after": "Glove game [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle v(S)={\\begin{cases}1&{\\text{if }}S\\in \\left\\{\\{1,3\\},\\{2,3\\},\\{1,2,3\\}\\right\\};\\\\0&{\\text{otherwise}}.\\\\\\end{cases}}}": {
    "before": "where players 1 and 2 have right-hand gloves and player 3 has a left-hand glove.The value function for this coalitional game is",
    "after": "The formula for calculating the Shapley value is",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{i}(v)={\\frac {1}{|N|!}}\\sum _{R}\\left[v(P_{i}^{R}\\cup \\left\\{i\\right\\})-v(P_{i}^{R})\\right],}": {
    "before": "{\\displaystyle v(S)={\\begin{cases}1&{\\text{if }}S\\in \\left\\{\\{1,3\\},\\{2,3\\},\\{1,2,3\\}\\right\\};\\\\0&{\\text{otherwise}}.\\\\\\end{cases}}} The formula for calculating the Shapley value is",
    "after": "where R is an ordering of the players and {\\displaystyle P_{i}^{R}} is the set of players in N which precede i in the order R .",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle {\\begin{array}{|c|r|}{\\text{Order }}R\\,\\!&MC_{1}\\\\\\hline {1,2,3}&v(\\{1\\})-v(\\varnothing )=0-0=0\\\\{1,3,2}&v(\\{1\\})-v(\\varnothing )=0-0=0\\\\{2,1,3}&v(\\{1,2\\})-v(\\{2\\})=0-0=0\\\\{2,3,1}&v(\\{1,2,3\\})-v(\\{2,3\\})=1-1=0\\\\{3,1,2}&v(\\{1,3\\})-v(\\{3\\})=1-0=1\\\\{3,2,1}&v(\\{1,3,2\\})-v(\\{3,2\\})=1-1=0\\end{array}}}": {
    "before": "The following table displays the marginal contributions of Player 1.",
    "after": "Observe {\\displaystyle \\varphi _{1}(v)=\\!\\left({\\frac {1}{6}}\\right)(1)={\\frac {1}{6}}.}",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{1}(v)=\\!\\left({\\frac {1}{6}}\\right)(1)={\\frac {1}{6}}.}": {
    "before": "{\\displaystyle {\\begin{array}{|c|r|}{\\text{Order }}R\\,\\!&MC_{1}\\\\\\hline {1,2,3}&v(\\{1\\})-v(\\varnothing )=0-0=0\\\\{1,3,2}&v(\\{1\\})-v(\\varnothing )=0-0=0\\\\{2,1,3}&v(\\{1,2\\})-v(\\{2\\})=0-0=0\\\\{2,3,1}&v(\\{1,2,3\\})-v(\\{2,3\\})=1-1=0\\\\{3,1,2}&v(\\{1,3\\})-v(\\{3\\})=1-0=1\\\\{3,2,1}&v(\\{1,3,2\\})-v(\\{3,2\\})=1-1=0\\end{array}}} Observe",
    "after": "By a symmetry argument it can be shown that",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{2}(v)=\\varphi _{1}(v)={\\frac {1}{6}}.}": {
    "before": "{\\displaystyle \\varphi _{1}(v)=\\!\\left({\\frac {1}{6}}\\right)(1)={\\frac {1}{6}}.} By a symmetry argument it can be shown that",
    "after": "Due to the efficiency axiom, the sum of all the Shapley values is equal to 1, which means that",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{3}(v)={\\frac {4}{6}}={\\frac {2}{3}}.}": {
    "before": "Due to the efficiency axiom, the sum of all the Shapley values is equal to 1, which means that",
    "after": "Properties [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\sum _{i\\in N}\\varphi _{i}(v)=v(N)}": {
    "before": "The sum of the Shapley values of all agents equals the value of the grand coalition, so that all the gain is distributed among the agents:",
    "after": "Proof : {\\displaystyle \\sum _{i\\in N}\\varphi _{i}(v)={\\frac {1}{|N|!}}\\sum _{R}\\sum _{i\\in N}v(P_{i}^{R}\\cup \\left\\{i\\right\\})-v(P_{i}^{R})={\\frac {1}{|N|!}}\\sum _{R}v(N)={\\frac {1}{|N|!}}|N|!\\cdot v(N)=v(N)}",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle v(S\\cup \\{i\\})=v(S\\cup \\{j\\})}": {
    "before": "If {\\displaystyle i} and {\\displaystyle j} are two actors who are equivalent in the sense that",
    "after": "for every subset {\\displaystyle S} of {\\displaystyle N} which contains neither {\\displaystyle i} nor {\\displaystyle j} , then {\\displaystyle \\varphi _{i}(v)=\\varphi _{j}(v)} .",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{i}(v+w)=\\varphi _{i}(v)+\\varphi _{i}(w)}": {
    "before": "If two coalition games described by gain functions {\\displaystyle v} and {\\displaystyle w} are combined, then the distributed gains should correspond to the gains derived from {\\displaystyle v} and the gains derived from {\\displaystyle w} :",
    "after": "for every {\\displaystyle i} in {\\displaystyle N} . Also, for any real number {\\displaystyle a} ,",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{i}(av)=a\\varphi _{i}(v)}": {
    "before": "for every {\\displaystyle i} in {\\displaystyle N} . Also, for any real number {\\displaystyle a} ,",
    "after": "for every {\\displaystyle i} in {\\displaystyle N} .",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle (Sv)(ds)=\\int _{0}^{1}(\\,v(tI+ds)-v(tI)\\,)\\,dt.}": {
    "before": "Symbolically, if v is the coalitional worth function associating to each coalition c measured subset of a measurable set I that can be thought as {\\displaystyle I=[0,1]} without loss of generality.",
    "after": "where {\\displaystyle (Sv)(ds)} denotes the Shapley value of the infinitesimal player ds in the game, tI is a perfect sample of the all-player set I containing a proportion t of all the players, and {\\displaystyle tI+ds} is the coalition obtained after ds joins tI . This is the heuristic form of the diagonal formula .",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\mu (tI)=t\\mu (I)} ,": {
    "before": "Assuming some regularity of the worth function, for example assuming v can be represented as differentiable function of a non-atomic measure on I , μ , {\\displaystyle v(c)=f(\\mu (c))} with density function {\\displaystyle \\varphi } , with {\\displaystyle \\mu (c)=\\int 1_{c}(u)\\varphi (u)\\,du,} ( {\\displaystyle 1_{c}()} the characteristic function of c ). Under such conditions",
    "after": "as can be shown by approximating the density by a step function and keeping the proportion t for each level of the density function, and",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle v(tI+ds)=f(t\\mu (I))+f'(t\\mu (I))\\mu (ds).}": {
    "before": "as can be shown by approximating the density by a step function and keeping the proportion t for each level of the density function, and",
    "after": "The diagonal formula has then the form developed by Aumann and Shapley (1974)",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle (Sv)(ds)=\\int _{0}^{1}f'_{t\\mu (I)}(\\mu (ds))\\,dt}": {
    "before": "The diagonal formula has then the form developed by Aumann and Shapley (1974)",
    "after": "Above μ can be vector valued (as long as the function is defined and differentiable on the range of μ , the above formula makes sense).",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle (Sv)(ds)=\\lim _{\\varepsilon \\to 0,\\varepsilon >0}{\\frac {1}{\\varepsilon }}\\int _{0}^{1-\\varepsilon }(f(t+\\varepsilon \\mu (ds))-f(t))\\,dt}": {
    "before": "Two approaches were deployed to extend this diagonal formula when the function f is no longer differentiable. Mertens goes back to the original formula and takes the derivative after the integral thereby benefiting from the smoothing effect. Neyman took a different approach. Going back to an elementary application of Mertens's approach from Mertens (1980): ",
    "after": "This works for example for majority games—while the original diagonal formula cannot be used directly. How Mertens further extends this by identifying symmetries that the Shapley value should be invariant upon, and averaging over such symmetries to create further smoothing effect commuting averages with the derivative operation as above.  A survey for non atomic value is found in Neyman (2002) ",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{C}(v)=\\sum _{T\\subseteq N\\setminus C}{\\frac {(n-|T|-|C|)!\\;|T|!}{(n-|C|+1)!}}\\sum _{S\\subseteq C}(-1)^{|C|-|S|}v(S\\cup T)\\;.}": {
    "before": "The Shapley value only assigns values to the individual agents. It has been generalized  to apply to a group of agents C as,",
    "after": "In terms of the synergy function {\\displaystyle w} above, this reads  ",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{C}(v)=\\sum _{C\\subseteq T\\subseteq N}{\\frac {w(T)}{|T|-|C|+1}}}": {
    "before": "In terms of the synergy function {\\displaystyle w} above, this reads  ",
    "after": "where the sum goes over all subsets {\\displaystyle T} of {\\displaystyle N} that contain {\\displaystyle C} .",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{ij}(v)=\\sum _{S\\subseteq N}{\\frac {(|S|-1)!\\;(n-|S|)!}{n!}}(v(S)-v(S\\setminus \\{i\\})-v(S\\setminus \\{j\\})+v(S\\setminus \\{i,j\\}))\\sum _{t=|S|}^{n}{\\frac {1}{t}}}": {
    "before": "The Shapley value {\\displaystyle \\varphi _{i}(v)} was decomposed in  into a matrix of values",
    "after": "Each value {\\displaystyle \\varphi _{ij}(v)} represents the value of player {\\displaystyle i} to player {\\displaystyle j} . This matrix satisfies",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{i}(v)=\\sum _{j\\in N}\\varphi _{ij}(v)}": {
    "before": "Each value {\\displaystyle \\varphi _{ij}(v)} represents the value of player {\\displaystyle i} to player {\\displaystyle j} . This matrix satisfies",
    "after": "i.e. the value of player {\\displaystyle i} to the whole game is the sum of their value to all individual players.",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\varphi _{ij}(v)=\\sum _{\\{i,j\\}\\subseteq S\\subseteq N}{\\frac {w(S)}{|S|^{2}}}}": {
    "before": "In terms of the synergy {\\displaystyle w} defined above, this reads",
    "after": "where the sum goes over all subsets {\\displaystyle S} of {\\displaystyle N} that contain {\\displaystyle i} and {\\displaystyle j} .",
    "url": "https://en.wikipedia.org/wiki/Shapley value"
  },
  "{\\displaystyle \\lambda ={\\frac {1}{2}}\\sigma ^{2}\\theta }": {
    "before": "we can obtain an ( approximate ) closed form solution which has already been given above",
    "after": "A special case of the above formula occurs if utility is logarithmic, {\\displaystyle u(c_{t})=ln(c_{t})} which corresponds to the case of {\\displaystyle \\theta =1} , which means that the above simplifies to {\\displaystyle \\lambda =.5\\sigma ^{2}} . In other words, with log utility the cost of fluctuations is equal to one half the variance of the natural logarithm of consumption. ",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "{\\displaystyle \\lambda ={\\frac {1}{2}}(.032)^{2}=.0005.}": {
    "before": "As an illustrative example consider the case of log utility (see below) in which case {\\displaystyle \\theta =1} . In this case the welfare cost of fluctuations is",
    "after": "In other words, eliminating all the fluctuations from a person's consumption path (i.e., eliminating the business cycle entirely) is worth only 1/20 of 1 percent of average annual consumption. For example, an individual who consumes $50,000 worth of goods a year on average would be willing to pay only $25 to eliminate consumption fluctuations.",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "{\\displaystyle \\lambda ={\\frac {1}{2}}(.032)^{2}4=.002}": {
    "before": "If {\\displaystyle \\theta } is at the upper range of estimates found in literature, around 4, then",
    "after": "or 1/5 of 1 percent. An individual with average consumption of $50,000 would be willing to pay $100 to eliminate fluctuations. This is still a very small amount compared to the implications of long run growth on income.",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "{\\displaystyle r=\\rho +\\theta g}": {
    "before": "One way to get an upper bound on the degree of risk aversion is to use the Ramsey model of intertemporal savings and consumption. In that case, the equilibrium real interest rate is given by",
    "after": "where {\\displaystyle r} is the real (after tax) rate of return on capital (the real interest rate), {\\displaystyle \\rho } is the subjective rate of time preference (which measures impatience) and {\\displaystyle g} is the annual growth rate of consumption. {\\displaystyle r} is generally estimated to be around 5% (.05) and the annual growth rate of consumption is about 2% (.02). Then the upper bound on the cost of fluctuations occurs when {\\displaystyle \\theta } is at its highest, which in this case occurs if {\\displaystyle \\rho =0} . This implies that the highest possible degree of risk aversion is",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "{\\displaystyle \\theta ^{Max}=r/g=.05/.02=2.5}": {
    "before": "where {\\displaystyle r} is the real (after tax) rate of return on capital (the real interest rate), {\\displaystyle \\rho } is the subjective rate of time preference (which measures impatience) and {\\displaystyle g} is the annual growth rate of consumption. {\\displaystyle r} is generally estimated to be around 5% (.05) and the annual growth rate of consumption is about 2% (.02). Then the upper bound on the cost of fluctuations occurs when {\\displaystyle \\theta } is at its highest, which in this case occurs if {\\displaystyle \\rho =0} . This implies that the highest possible degree of risk aversion is",
    "after": "which in turn, combined with estimates given above, yields a cost of fluctuations as",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "{\\displaystyle \\lambda ={\\frac {1}{2}}(.032)^{2}2.5=.0013}": {
    "before": "which in turn, combined with estimates given above, yields a cost of fluctuations as",
    "after": "which is still extremely small (13% of 1%).",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "{\\displaystyle U=\\sum _{t=0}^{\\infty }\\beta ^{t}u(c_{t})}": {
    "before": "Lucas sets up an infinitely lived representative agent model where total lifetime utility ( {\\displaystyle U} ) is given by the present discounted value (with {\\displaystyle \\beta } representing the discount factor ) of per period utilities ( {\\displaystyle u(.)} ) which in turn depend on consumption in each period ( {\\displaystyle c_{t}} ) ",
    "after": "In the case of a certain consumption path, consumption in each period is given by",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "{\\displaystyle c_{t}^{cert}=Ae^{gt}}": {
    "before": "In the case of a certain consumption path, consumption in each period is given by",
    "after": "where {\\displaystyle A} is initial consumption and {\\displaystyle g} is the growth rate of consumption (neither of these parameters turns out to matter for costs of fluctuations in the baseline model, so they can be normalized to 1 and 0 respectively).",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "{\\displaystyle c_{t}^{vol}=(1+\\lambda )Ae^{gt}e^{-{\\frac {1}{2}}\\sigma ^{2}}\\epsilon _{t}}": {
    "before": "In the case of a volatile, uncertain consumption path, consumption in each period is given by",
    "after": "where {\\displaystyle \\sigma } is the standard deviation of the natural log of consumption and {\\displaystyle \\epsilon } is a random shock which is assumed to be log-normally distributed so that the mean of {\\displaystyle ln(\\epsilon _{t})} is zero, which in turn implies that the expected value of {\\displaystyle e^{-{\\frac {1}{2}}\\sigma ^{2}}\\epsilon _{t}} is 1 (i.e., on average, volatile consumption is same as certain consumption). In this case {\\displaystyle \\lambda } is the \"compensation parameter\" which measures the percentage by which average consumption has to be increased for the consumer to be indifferent between the certain path of consumption and the volatile one. {\\displaystyle \\lambda } is the cost of fluctuations.",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "{\\displaystyle \\sum _{t=0}^{\\infty }\\beta ^{t}u(c_{t}^{cert})=\\sum _{t=0}^{\\infty }\\beta ^{t}u(c_{t}^{vol})}": {
    "before": "where {\\displaystyle \\sigma } is the standard deviation of the natural log of consumption and {\\displaystyle \\epsilon } is a random shock which is assumed to be log-normally distributed so that the mean of {\\displaystyle ln(\\epsilon _{t})} is zero, which in turn implies that the expected value of {\\displaystyle e^{-{\\frac {1}{2}}\\sigma ^{2}}\\epsilon _{t}} is 1 (i.e., on average, volatile consumption is same as certain consumption). In this case {\\displaystyle \\lambda } is the \"compensation parameter\" which measures the percentage by which average consumption has to be increased for the consumer to be indifferent between the certain path of consumption and the volatile one. {\\displaystyle \\lambda } is the cost of fluctuations.We find this cost of fluctuations by setting",
    "after": "and solving for {\\displaystyle \\lambda }",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "{\\displaystyle u(c_{t})={\\frac {c_{t}^{1-\\theta }-1}{1-\\theta }}}": {
    "before": "and solving for {\\displaystyle \\lambda } For the case of isoelastic utility , given by",
    "after": "we can obtain an ( approximate ) closed form solution which has already been given above",
    "url": "https://en.wikipedia.org/wiki/Welfare cost of business cycles"
  },
  "v ( t ) = A cos(2π f 0 t ).": {
    "before": "Phase noise is a noise in the phase of the signal. Consider the following noise free signal:",
    "after": "Phase noise is added to this signal by adding a stochastic process represented by φ to the signal as follows:",
    "url": "https://en.wikipedia.org/wiki/Oscillator linewidth"
  },
  "v ( t ) = A cos(2π f 0 t + φ( t )).": {
    "before": "Phase noise is added to this signal by adding a stochastic process represented by φ to the signal as follows:",
    "after": "If the phase noise in an oscillator stems from white noise sources, then the power spectral density (PSD) of the phase noise produced by an oscillator will be S φ ( f ) = n / f 2 , where n specifies the amount of noise. The PSD of the output signal would then be",
    "url": "https://en.wikipedia.org/wiki/Oscillator linewidth"
  },
  "{\\displaystyle S_{v}(f)={\\frac {A^{2}}{2}}{\\frac {cf_{0}^{2}}{c^{2}\\pi ^{2}f_{0}^{4}+(f-f_{0})^{2}}},}": {
    "before": "If the phase noise in an oscillator stems from white noise sources, then the power spectral density (PSD) of the phase noise produced by an oscillator will be S φ ( f ) = n / f 2 , where n specifies the amount of noise. The PSD of the output signal would then be",
    "after": "where n = 2 cf 0 2 . Define the corner frequency f Δ = c π f 0 2 as the linewidth of the oscillator. Then",
    "url": "https://en.wikipedia.org/wiki/Oscillator linewidth"
  },
  "{\\displaystyle S_{v}(f_{0}+\\Delta f)={\\frac {A^{2}}{2\\pi }}{\\frac {f_{\\Delta }}{f_{\\Delta }^{2}+\\Delta f^{2}}}.}": {
    "before": "where n = 2 cf 0 2 . Define the corner frequency f Δ = c π f 0 2 as the linewidth of the oscillator. Then",
    "after": "It is more common to report oscillator phase noise as L , the ratio of the single-sideband (SSB) phase noise power to the power in the fundamental (in dBc/Hz). In this case",
    "url": "https://en.wikipedia.org/wiki/Oscillator linewidth"
  },
  "{\\displaystyle L(\\Delta f)={\\frac {1}{\\pi }}{\\frac {f_{\\Delta }}{f_{\\Delta }^{2}+\\Delta f^{2}}}.}": {
    "before": "It is more common to report oscillator phase noise as L , the ratio of the single-sideband (SSB) phase noise power to the power in the fundamental (in dBc/Hz). In this case",
    "after": "Adding phase noise neither increases nor decreases the power of the signal. It simply redistributes the power by increasing the bandwidth over which the signal is present while decreasing the amplitude of the signal that occurs at the nominal oscillation frequency. The total noise power, as found by integrating the power spectral density over all frequencies, remains constant regardless of the amount of phase noise. This is illustrated in the figures on the right. It can be proven by integrating L over all frequencies to compute the total power of the signal.",
    "url": "https://en.wikipedia.org/wiki/Oscillator linewidth"
  },
  "{\\displaystyle \\int _{-\\infty }^{\\infty }L(\\Delta f)d\\Delta f={\\frac {f_{\\Delta }}{\\pi }}\\int _{-\\infty }^{\\infty }{\\frac {d\\Delta f}{f_{\\Delta }^{2}+\\Delta f^{2}}}=\\left.{\\frac {1}{\\pi }}\\tan ^{-1}({\\frac {\\Delta f}{f_{\\Delta }}})\\right|_{-\\infty }^{\\infty }=1}": {
    "before": "Adding phase noise neither increases nor decreases the power of the signal. It simply redistributes the power by increasing the bandwidth over which the signal is present while decreasing the amplitude of the signal that occurs at the nominal oscillation frequency. The total noise power, as found by integrating the power spectral density over all frequencies, remains constant regardless of the amount of phase noise. This is illustrated in the figures on the right. It can be proven by integrating L over all frequencies to compute the total power of the signal.",
    "after": "See also [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Oscillator linewidth"
  },
  "{\\displaystyle u\\left({C_{t},N_{t}}\\right)={\\frac {\\left(C_{t}-\\psi N_{t}^{\\theta }X_{t}\\right)^{1-\\sigma }-1}{1-\\sigma }},}": {
    "before": "Let {\\displaystyle C_{t}} denote consumption and let {\\displaystyle N_{t}} denote hours worked at period {\\displaystyle t} . The instantaneous utility has the form",
    "after": "where {\\displaystyle X_{t}=C_{t}^{\\gamma }X_{t-1}^{1-\\gamma }.}",
    "url": "https://en.wikipedia.org/wiki/Jaimovich–Rebelo preferences"
  },
  "{\\displaystyle X_{t}=C_{t}^{\\gamma }X_{t-1}^{1-\\gamma }.}": {
    "before": "where",
    "after": "It is assumed that {\\displaystyle \\theta >1} , {\\displaystyle \\psi >0} , and {\\displaystyle \\sigma >0} .",
    "url": "https://en.wikipedia.org/wiki/Jaimovich–Rebelo preferences"
  },
  "{\\displaystyle U=E_{0}\\sum _{t=0}^{\\infty }\\beta ^{t}u\\left({C_{t},N_{t}}\\right),}": {
    "before": "The agents in the model economy maximize their lifetime utility, {\\displaystyle U} , defined over sequences of consumption and hours worked,",
    "after": "where {\\displaystyle E_{0}} denotes the expectation conditional on the information available at time zero, and the agents internalize the dynamics of {\\displaystyle X_{t}} in their maximization problem.",
    "url": "https://en.wikipedia.org/wiki/Jaimovich–Rebelo preferences"
  },
  "{\\displaystyle u\\left({C_{t},N_{t}}\\right)={\\frac {\\left(C_{t}\\left(1-\\psi N_{t}^{\\theta }\\right)\\right)^{1-\\sigma }-1}{1-\\sigma }},}": {
    "before": "When {\\displaystyle \\gamma =1} , the scaling variable {\\displaystyle X_{t}} reduces to {\\displaystyle X_{t}=C_{t},} and the instantaneous utility simplifies to",
    "after": "corresponding to the KPR preferences .",
    "url": "https://en.wikipedia.org/wiki/Jaimovich–Rebelo preferences"
  },
  "{\\displaystyle u\\left({C_{t},N_{t}}\\right)={\\frac {\\left(C_{t}-\\psi XN_{t}^{\\theta }\\right)^{1-\\sigma }-1}{1-\\sigma }},}": {
    "before": "When {\\displaystyle \\gamma \\rightarrow 0} , and if the economy does not present exogenous growth, then the scaling variable {\\displaystyle X_{t}} reduces to a constant {\\displaystyle X_{t}=X>0,} and the instantaneous utility simplifies to",
    "after": "corresponding to the original GHH preferences , in which the wealth effect on the labor supply is completely shut off.",
    "url": "https://en.wikipedia.org/wiki/Jaimovich–Rebelo preferences"
  },
  "{\\displaystyle {\\frac {X_{t}}{z_{t}}}={\\frac {X_{t-1}}{z_{t-1}}}{\\frac {z_{t-1}}{z_{t}}},}": {
    "before": "Let {\\displaystyle z_{t}} denote the level of labor augmenting technology. Then, in a balanced growth path, consumption {\\displaystyle C_{t}} and the scaling variable {\\displaystyle X_{t}} grow at the same rate as {\\displaystyle z_{t}} . When {\\displaystyle \\gamma \\rightarrow 0} , the stationary variable {\\displaystyle {\\frac {X_{t}}{z_{t}}}} satisfies the relation",
    "after": "which implies that",
    "url": "https://en.wikipedia.org/wiki/Jaimovich–Rebelo preferences"
  },
  "{\\displaystyle X_{t}=Xz_{t},}": {
    "before": "which implies that",
    "after": "for some constant {\\displaystyle X>0} .",
    "url": "https://en.wikipedia.org/wiki/Jaimovich–Rebelo preferences"
  },
  "{\\displaystyle u\\left({C_{t},N_{t}}\\right)={\\frac {\\left(C_{t}-z_{t}\\psi XN_{t}^{\\theta }\\right)^{1-\\sigma }-1}{1-\\sigma }},}": {
    "before": "Then, the instantaneous utility simplifies to",
    "after": "consistent with the shortcut of introducing a scaling factor containing the level of labor augmenting technology before the hours worked term.",
    "url": "https://en.wikipedia.org/wiki/Jaimovich–Rebelo preferences"
  },
  "{\\displaystyle y_{t}=D_{t}+z_{t}+\\varepsilon _{t}}": {
    "before": "In general, the approach to unit root testing implicitly assumes that the time series to be tested {\\displaystyle [y_{t}]_{t=1}^{T}} can be written as,",
    "after": "where, {\\displaystyle D_{t}} is the deterministic component (trend, seasonal component, etc.) {\\displaystyle z_{t}} is the stochastic component. {\\displaystyle \\varepsilon _{t}} is the stationary error process.",
    "url": "https://en.wikipedia.org/wiki/Unit root test"
  },
  "{\\displaystyle X_{t}=\\mu +\\varepsilon _{t}+\\theta _{1}\\varepsilon _{t-1}+\\cdots +\\theta _{q}\\varepsilon _{t-q}=\\mu +\\sum _{i=1}^{q}\\theta _{i}\\varepsilon _{t-i}+\\varepsilon _{t},}": {
    "before": "The notation MA( q ) refers to the moving average model of order q :",
    "after": "where {\\displaystyle \\mu } is the mean of the series, the {\\displaystyle \\theta _{1},...,\\theta _{q}} are the parameters of the model [ example needed ] and the {\\displaystyle \\varepsilon _{t},\\varepsilon _{t-1},...,\\varepsilon _{t-q}} are white noise error terms. The value of q is called the order of the MA model. This can be equivalently written in terms of the backshift operator B as ",
    "url": "https://en.wikipedia.org/wiki/Moving-average model"
  },
  "{\\displaystyle X_{t}=\\mu +(1+\\theta _{1}B+\\cdots +\\theta _{q}B^{q})\\varepsilon _{t}.}": {
    "before": "where {\\displaystyle \\mu } is the mean of the series, the {\\displaystyle \\theta _{1},...,\\theta _{q}} are the parameters of the model [ example needed ] and the {\\displaystyle \\varepsilon _{t},\\varepsilon _{t-1},...,\\varepsilon _{t-q}} are white noise error terms. The value of q is called the order of the MA model. This can be equivalently written in terms of the backshift operator B as ",
    "after": "Thus, a moving-average model is conceptually a linear regression of the current value of the series against current and previous (observed) white noise error terms or random shocks. The random shocks at each point are assumed to be mutually independent and to come from the same distribution, typically a normal distribution , with location at zero and constant scale.",
    "url": "https://en.wikipedia.org/wiki/Moving-average model"
  },
  "{\\displaystyle R_{x}(t,\\tau )=\\operatorname {E} \\{x(t+\\tau )x^{*}(t)\\},\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle \\operatorname {E} [x(t)]=\\operatorname {E} [x(t+T_{0})]{\\text{ for all }}t}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle R_{x}(t,\\tau )=R_{x}(t+T_{0};\\tau ){\\text{ for all }}t,\\tau .}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle R_{x}(t,\\tau )=\\sum _{n=-\\infty }^{\\infty }R_{x}^{n/T_{0}}(\\tau )e^{j2\\pi {\\frac {n}{T_{0}}}t}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle R_{x}^{n/T_{0}}(\\tau )={\\frac {1}{T_{0}}}\\int _{-T_{0}/2}^{T_{0}/2}R_{x}(t,\\tau )e^{-j2\\pi {\\frac {n}{T_{0}}}t}\\mathrm {d} t.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle {\\widehat {R}}_{x}^{n/T_{0}}(\\tau )=\\lim _{T\\rightarrow +\\infty }{\\frac {1}{T}}\\int _{-T/2}^{T/2}x(t+\\tau )x^{*}(t)e^{-j2\\pi {\\frac {n}{T_{0}}}t}\\mathrm {d} t.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle S_{x}^{\\alpha }(f)=\\int _{-\\infty }^{+\\infty }R_{x}^{\\alpha }(\\tau )e^{-j2\\pi f\\tau }\\mathrm {d} \\tau .}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle x(t)=\\sum _{k=-\\infty }^{\\infty }a_{k}p(t-kT_{0})}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle {\\begin{aligned}R_{x}(t,\\tau )&=\\operatorname {E} [x(t+\\tau )x^{*}(t)]\\\\[6pt]&=\\sum _{k,n}\\operatorname {E} [a_{k}a_{n}^{*}]p(t+\\tau -kT_{0})p^{*}(t-nT_{0})\\\\[6pt]&=\\sigma _{a}^{2}\\sum _{k}p(t+\\tau -kT_{0})p^{*}(t-kT_{0}).\\end{aligned}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle {\\begin{aligned}R_{x}^{n/T_{0}}(\\tau )&={\\frac {1}{T_{0}}}\\int _{-T_{0}/2}^{T_{0}/2}R_{x}(t,\\tau )e^{-j2\\pi {\\frac {n}{T_{0}}}t}\\,\\mathrm {d} t\\\\[6pt]&={\\frac {1}{T_{0}}}\\int _{-T_{0}/2}^{T_{0}/2}\\sigma _{a}^{2}\\sum _{k=-\\infty }^{\\infty }p(t+\\tau -kT_{0})p^{*}(t-kT_{0})e^{-j2\\pi {\\frac {n}{T_{0}}}t}\\mathrm {d} t\\\\[6pt]&={\\frac {\\sigma _{a}^{2}}{T_{0}}}\\sum _{k=-\\infty }^{\\infty }\\int _{-T_{0}/2-kT_{0}}^{T_{0}/2-kT_{0}}p(\\lambda +\\tau )p^{*}(\\lambda )e^{-j2\\pi {\\frac {n}{T_{0}}}(\\lambda +kT_{0})}\\mathrm {d} \\lambda \\\\[6pt]&={\\frac {\\sigma _{a}^{2}}{T_{0}}}\\int _{-\\infty }^{\\infty }p(\\lambda +\\tau )p^{*}(\\lambda )e^{-j2\\pi {\\frac {n}{T_{0}}}\\lambda }\\mathrm {d} \\lambda \\\\[6pt]&={\\frac {\\sigma _{a}^{2}}{T_{0}}}p(\\tau )*\\left\\{p^{*}(-\\tau )e^{j2\\pi {\\frac {n}{T_{0}}}\\tau }\\right\\}.\\end{aligned}}}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle S_{x}^{n/T_{0}}(f)={\\frac {\\sigma _{a}^{2}}{T_{0}}}P(f)P^{*}\\left(f-{\\frac {n}{T_{0}}}\\right).}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle R_{x}(\\theta ,\\tau )=\\operatorname {E} \\{x(t(\\theta )+\\tau )x^{*}(t(\\theta ))\\},\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle S_{x}^{\\alpha }(f)=\\lim _{S\\rightarrow +\\infty }{\\frac {1}{S}}\\int _{-S/2}^{S/2}\\int _{-\\infty }^{+\\infty }R_{x}(\\theta ,\\tau )e^{-j2\\pi f\\tau }e^{-j2\\pi \\alpha {\\frac {\\theta }{\\Theta }}}\\,\\mathrm {d} \\tau \\,\\mathrm {d} \\theta }": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Cyclostationary process"
  },
  "{\\displaystyle {\\sqrt {2/3}}}= 81.6%, with some systems increasing with more candidates.)": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Social utility efficiency"
  },
  "{\\displaystyle y_{t}=at+b+e_{t}\\,}": {
    "before": "To analyse a (time) series of data, we assume that it may be represented as trend plus noise:",
    "after": "where {\\displaystyle a} and {\\displaystyle b} are unknown constants and the {\\displaystyle e} 's are randomly distributed errors . If one can reject the null hypothesis that the errors are non-stationary , then the non-stationary series { y t } is called trend-stationary . The least squares method assumes the errors to be independently distributed with a normal distribution . If this is not the case, hypothesis tests about the unknown parameters a and b may be inaccurate. It is simplest if the {\\displaystyle e} 's all have the same distribution, but if not (if some have higher variance , meaning that those data points are effectively less certain) then this can be taken into account during the least squares fitting, by weighting each point by the inverse of the variance of that point.",
    "url": "https://en.wikipedia.org/wiki/Linear trend estimation"
  },
  "{\\displaystyle {\\hat {y}}={\\hat {a}}t+{\\hat {b}}}": {
    "before": "In most cases, where only a single time series exists to be analysed, the variance of the {\\displaystyle e} 's is estimated by fitting a trend to obtain the estimated parameter values {\\displaystyle {\\hat {a}}} and {\\displaystyle {\\hat {b}},} thus allowing the predicted values",
    "after": "to be subtracted from the data {\\displaystyle y_{t}} (thus detrending the data) and leaving the residuals {\\displaystyle {\\hat {e}}_{t}} as the detrended data , and estimating the variance of the {\\displaystyle e_{t}} 's from the residuals — this is often the only way of estimating the variance of the {\\displaystyle e_{t}} 's.",
    "url": "https://en.wikipedia.org/wiki/Linear trend estimation"
  },
  "Each agent i then computes Σni=1 Ni (mod n), and then takes the agent with the Nth highest id in the set to be the leader. (If some agent j does not send i a random number, then i sets its output to Null.)": {
    "before": "Agent i chooses a random number Ni in {0, ..., n−1} and sends it to all the other agents.",
    "after": "This protocol correctly elects a leader while reaching equilibrium and is truthful since no agent can benefit by lying about its input.",
    "url": "https://en.wikipedia.org/wiki/Distributed algorithmic mechanism design"
  },
  "{\\displaystyle u_{i}:=v_{i}(x)+p_{i}}": {
    "before": "It is assumed that the agents have Quasilinear utility functions; this means that, if the outcome is {\\displaystyle x} and in addition the agent receives a payment {\\displaystyle p_{i}} (positive or negative), then the total utility of agent {\\displaystyle i} is:",
    "after": "The vector of all value-functions is denoted by {\\displaystyle v} .",
    "url": "https://en.wikipedia.org/wiki/Strategyproofness"
  },
  "{\\displaystyle Outcome(v_{i},v_{-i})=Outcome(v_{i}',v_{-i})}": {
    "before": "1. The payment to agent {\\displaystyle i} is a function of the chosen outcome and of the valuations of the other agents {\\displaystyle v_{-i}} - but not a direct function of the agent's own valuation {\\displaystyle v_{i}} . Formally, there exists a price function {\\displaystyle Price_{i}} , that takes as input an outcome {\\displaystyle x\\in X} and a valuation vector for the other agents {\\displaystyle v_{-i}} , and returns the payment for agent {\\displaystyle i} , such that for every {\\displaystyle v_{i},v_{i}',v_{-i}} , if:",
    "after": "then: {\\displaystyle Payment_{i}(v_{i},v_{-i})=Payment_{i}(v_{i}',v_{-i})}",
    "url": "https://en.wikipedia.org/wiki/Strategyproofness"
  },
  "{\\displaystyle Payment_{i}(v_{i},v_{-i})=Payment_{i}(v_{i}',v_{-i})}": {
    "before": "{\\displaystyle Outcome(v_{i},v_{-i})=Outcome(v_{i}',v_{-i})} then:",
    "after": "PROOF: If {\\displaystyle Payment_{i}(v_{i},v_{-i})>Payment_{i}(v_{i}',v_{-i})} then an agent with valuation {\\displaystyle v_{i}'} prefers to report {\\displaystyle v_{i}} , since it gives him the same outcome and a larger payment; similarly, if {\\displaystyle Payment_{i}(v_{i},v_{-i})<Payment_{i}(v_{i}',v_{-i})} then an agent with valuation {\\displaystyle v_{i}} prefers to report {\\displaystyle v_{i}'} .",
    "url": "https://en.wikipedia.org/wiki/Strategyproofness"
  },
  "{\\displaystyle Outcome(v_{i},v_{-i})=x}": {
    "before": "As a corollary, there exists a \"price-tag\" function, {\\displaystyle Price_{i}} , that takes as input an outcome {\\displaystyle x\\in X} and a valuation vector for the other agents {\\displaystyle v_{-i}} , and returns the payment for agent {\\displaystyle i} For every {\\displaystyle v_{i},v_{-i}} , if:",
    "after": "then: {\\displaystyle Payment_{i}(v_{i},v_{-i})=Price_{i}(x,v_{-i})}",
    "url": "https://en.wikipedia.org/wiki/Strategyproofness"
  },
  "{\\displaystyle Payment_{i}(v_{i},v_{-i})=Price_{i}(x,v_{-i})}": {
    "before": "{\\displaystyle Outcome(v_{i},v_{-i})=x} then:",
    "after": "2. The selected outcome is optimal for agent {\\displaystyle i} , given the other agents' valuations. Formally:",
    "url": "https://en.wikipedia.org/wiki/Strategyproofness"
  },
  "{\\displaystyle x:=Outcome(v_{i},v_{-i})} - the outcome when the agent acts truthfully. {\\displaystyle x':=Outcome(v_{i}',v_{-i})} - the outcome when the agent acts untruthfully.": {
    "before": "PROOF: Fix an agent {\\displaystyle i} and valuations {\\displaystyle v_{i},v_{i}',v_{-i}} . Denote:",
    "after": "By property 1, the utility of the agent when playing truthfully is:",
    "url": "https://en.wikipedia.org/wiki/Strategyproofness"
  },
  "{\\displaystyle u_{i}(v_{i})=v_{i}(x)+Price_{i}(x,v_{-i})}": {
    "before": "By property 1, the utility of the agent when playing truthfully is:",
    "after": "and the utility of the agent when playing untruthfully is:",
    "url": "https://en.wikipedia.org/wiki/Strategyproofness"
  },
  "{\\displaystyle u_{i}(v_{i}')=v_{i}(x')+Price_{i}(x',v_{-i})}": {
    "before": "and the utility of the agent when playing untruthfully is:",
    "after": "By property 2: {\\displaystyle u_{i}(v_{i})\\geq u_{i}(v_{i}')}",
    "url": "https://en.wikipedia.org/wiki/Strategyproofness"
  },
  "{\\displaystyle P(a)=\\left({\\frac {\\mu ^{a}}{a!}}\\right)e^{-\\mu },}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle P(d)=\\left({\\frac {\\lambda ^{d}}{d!}}\\right)e^{-\\lambda },}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle P[T\\geq \\ t]=e^{-t/h},\\,}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle \\lim _{x\\to \\infty }e^{\\lambda x}\\Pr[X>x]=\\infty \\quad {\\mbox{for all }}\\lambda >0.\\,}": {
    "before": "Main article: heavy-tailed distributionA distribution is said to have a heavy tail if",
    "after": "One simple example of a heavy-tailed distribution is the Pareto distribution .",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle Y=(Y_{i}:i=0,1,2,...,N)}": {
    "before": "Leland et al have provided a mathematical formalism to describe self-similar stochastic processes.  For the sequence of numbers",
    "after": "with mean {\\displaystyle {\\hat {\\mu }}={\\text{E}}(Y_{i})} ,",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle {\\hat {\\mu }}={\\text{E}}(Y_{i})} ,": {
    "before": "{\\displaystyle Y=(Y_{i}:i=0,1,2,...,N)} with mean",
    "after": "deviations {\\displaystyle y_{i}=Y_{i}-{\\hat {\\mu }}} ,",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle y_{i}=Y_{i}-{\\hat {\\mu }}} ,": {
    "before": "{\\displaystyle {\\hat {\\mu }}={\\text{E}}(Y_{i})} ,deviations",
    "after": "variance {\\displaystyle {\\hat {\\sigma }}^{2}={\\text{E}}(y_{i}^{2})} ,",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle {\\hat {\\sigma }}^{2}={\\text{E}}(y_{i}^{2})} ,": {
    "before": "{\\displaystyle y_{i}=Y_{i}-{\\hat {\\mu }}} ,variance",
    "after": "and autocorrelation function",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle r(k)={\\text{E}}(y_{i},y_{i+k})/{\\text{E}}(y_{i}^{2})}": {
    "before": "{\\displaystyle {\\hat {\\sigma }}^{2}={\\text{E}}(y_{i}^{2})} ,and autocorrelation function",
    "after": "with lag k , if the autocorrelation of this sequence has the long range behavior",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle Y_{i}^{(m)}=(Y_{im-m+1}+...+Y_{im})/m} .": {
    "before": "The method of expanding bins can be used to analyze self-similar processes. Consider a set of equal-sized non-overlapping bins that divides the original sequence of N elements into groups of m equal-sized segments ( N/m is integer) so that new reproductive sequences, based on the mean values, can be defined:",
    "after": "The variance determined from this sequence will scale as the bin size changes such that",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle {\\text{var}}[Y^{(m)}]={\\hat {\\sigma }}^{2}m^{-d}}": {
    "before": "The variance determined from this sequence will scale as the bin size changes such that",
    "after": "if and only if the autocorrelation has the limiting form ",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle \\lim _{k\\to \\infty }r(k)/k^{-d}=(2-d)(1-d)/2} .": {
    "before": "if and only if the autocorrelation has the limiting form ",
    "after": "One can also construct a set of corresponding additive sequences",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle Z_{i}^{(m)}=mY_{i}^{(m)}} ,": {
    "before": "One can also construct a set of corresponding additive sequences",
    "after": "based on the expanding bins,",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle Z_{i}^{(m)}=(Y_{im-m+1}+...+Y_{im})} .": {
    "before": "{\\displaystyle Z_{i}^{(m)}=mY_{i}^{(m)}} ,based on the expanding bins,",
    "after": "Provided the autocorrelation function exhibits the same behavior, the additive sequences will obey the relationship",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle {\\text{var}}[Z_{i}^{(m)}]=m^{2}{\\text{var}}[Y^{(m)}]=({\\hat {\\sigma }}^{2}/{\\hat {\\mu }}^{2-d}){\\text{E}}[Z_{i}^{(m)}]^{2-d}}": {
    "before": "Provided the autocorrelation function exhibits the same behavior, the additive sequences will obey the relationship",
    "after": "Since {\\displaystyle {\\hat {\\mu }}} and {\\displaystyle {\\hat {\\sigma }}^{2}} are constants this relationship constitutes a variance-to-mean power law ( Taylor's law ), with p =2- d . ",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle {\\text{var}}\\,(Y)=a[{\\text{E}}\\,(Y)]^{p},}": {
    "before": "These Tweedie distributions are characterized by an inherent scale invariance and thus for any random variable Y that obeys a Tweedie distribution, the variance var( Y ) relates to the mean E( Y ) by the power law,",
    "after": "where a and p are positive constants. The exponent p for the variance to mean power law associated with certain self-similar stochastic processes ranges between 1 and 2 and thus may be modeled in part by a Tweedie compound Poisson–gamma distribution . ",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle K_{p}^{*}(s;\\theta ,\\lambda )=\\lambda \\kappa _{p}(\\theta )[(1+s/\\theta )^{\\alpha }-1]} ,": {
    "before": "The additive form of the Tweedie compound Poisson-gamma model has the cumulant generating function (CGF),",
    "after": "where {\\displaystyle \\kappa _{p}(\\theta )={\\dfrac {\\alpha -1}{\\alpha }}\\left({\\dfrac {\\theta }{\\alpha -1}}\\right)^{\\alpha }} ,",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle \\kappa _{p}(\\theta )={\\dfrac {\\alpha -1}{\\alpha }}\\left({\\dfrac {\\theta }{\\alpha -1}}\\right)^{\\alpha }} ,": {
    "before": "{\\displaystyle K_{p}^{*}(s;\\theta ,\\lambda )=\\lambda \\kappa _{p}(\\theta )[(1+s/\\theta )^{\\alpha }-1]} ,where",
    "after": "is the cumulant function, α is the Tweedie exponent",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "{\\displaystyle \\alpha ={\\dfrac {p-2}{p-1}}} ,": {
    "before": "is the cumulant function, α is the Tweedie exponent",
    "after": "s is the generating function variable, θ is the canonical parameter and λ is the index parameter.",
    "url": "https://en.wikipedia.org/wiki/Self-similar process"
  },
  "'Blue Labour + Red Tory = Christian Democracy?' – an article by Nicholas Townsend, April 2015": {
    "before": "'Conservativism and Christian Democracy' – an essay by former (1992–2015) UK Conservative MP David Willetts",
    "after": "vteChristian democracyOrganisations",
    "url": "https://en.wikipedia.org/wiki/Christian democracy"
  },
  "{\\displaystyle {\\frac {\\partial p(x,t\\mid x_{0})}{\\partial t}}=D{\\frac {\\partial ^{2}p(x,t\\mid x_{0})}{\\partial x^{2}}},}": {
    "before": "The probability density function (PDF) for a particle in one dimension is found by solving the one-dimensional diffusion equation . (This equation states that the position probability density diffuses outward over time. It is analogous to say, cream in a cup of coffee if the cream was all contained within some small location initially. After a long time the cream has diffused throughout the entire drink evenly.) Namely,",
    "after": "given the initial condition {\\displaystyle p(x,t={0}\\mid x_{0})=\\delta (x-x_{0})} ; where {\\displaystyle x(t)} is the position of the particle at some given time, {\\displaystyle x_{0}} is the tagged particle's initial position, and {\\displaystyle D} is the diffusion constant with the S.I. units {\\displaystyle m^{2}s^{-1}} (an indirect measure of the particle's speed). The bar in the argument of the instantaneous probability refers to the conditional probability. The diffusion equation states that the rate of change over time in the probability of finding the particle at {\\displaystyle x(t)} position depends on the deceleration over distance of such probability at that position.",
    "url": "https://en.wikipedia.org/wiki/First-hitting-time model"
  },
  "{\\displaystyle p(x,t;x_{0})={\\frac {1}{\\sqrt {4\\pi Dt}}}\\exp \\left(-{\\frac {(x-x_{0})^{2}}{4Dt}}\\right).}": {
    "before": "given the initial condition {\\displaystyle p(x,t={0}\\mid x_{0})=\\delta (x-x_{0})} ; where {\\displaystyle x(t)} is the position of the particle at some given time, {\\displaystyle x_{0}} is the tagged particle's initial position, and {\\displaystyle D} is the diffusion constant with the S.I. units {\\displaystyle m^{2}s^{-1}} (an indirect measure of the particle's speed). The bar in the argument of the instantaneous probability refers to the conditional probability. The diffusion equation states that the rate of change over time in the probability of finding the particle at {\\displaystyle x(t)} position depends on the deceleration over distance of such probability at that position.It can be shown that the one-dimensional PDF is",
    "after": "This states that the probability of finding the particle at {\\displaystyle x(t)} is Gaussian, and the width of the Gaussian is time dependent. More specifically the Full Width at Half Maximum (FWHM) – technically, this is actually the Full Duration at Half Maximum as the independent variable is time – scales like",
    "url": "https://en.wikipedia.org/wiki/First-hitting-time model"
  },
  "{\\displaystyle p(x,t;x_{0},x_{c})={\\frac {1}{\\sqrt {4\\pi Dt}}}\\left(\\exp \\left(-{\\frac {(x-x_{0})^{2}}{4Dt}}\\right)-\\exp \\left(-{\\frac {(x-(2x_{c}-x_{0}))^{2}}{4Dt}}\\right)\\right),}": {
    "before": "The First Passage Time Density (FPTD) is the probability that a particle has first reached a point {\\displaystyle x_{c}} at exactly time {\\displaystyle t} (not at some time during the interval up to {\\displaystyle t} ). This probability density is calculable from the Survival probability (a more common probability measure in statistics). Consider the absorbing boundary condition {\\displaystyle p(x_{c},t)=0} (The subscript c for the absorption point {\\displaystyle x_{c}} is an abbreviation for cliff used in many texts as an analogy to an absorption point). The PDF satisfying this boundary condition is given by",
    "after": "for {\\displaystyle x<x_{c}} . The survival probability, the probability that the particle has remained at a position {\\displaystyle x<x_{c}} for all times up to {\\displaystyle t} , is given by",
    "url": "https://en.wikipedia.org/wiki/First-hitting-time model"
  },
  "{\\displaystyle S(t)\\equiv \\int _{-\\infty }^{x_{c}}p(x,t;x_{0},x_{c})\\,dx=\\operatorname {erf} \\left({\\frac {x_{c}-x_{0}}{2{\\sqrt {Dt}}}}\\right),}": {
    "before": "for {\\displaystyle x<x_{c}} . The survival probability, the probability that the particle has remained at a position {\\displaystyle x<x_{c}} for all times up to {\\displaystyle t} , is given by",
    "after": "where {\\displaystyle \\operatorname {erf} } is the error function . The relation between the Survival probability and the FPTD is as follows: the probability that a particle has reached the absorption point between times {\\displaystyle t} and {\\displaystyle t+dt} is {\\displaystyle f(t)\\,dt=S(t)-S(t+dt)} . If one uses the first-order Taylor approximation, the definition of the FPTD follows):",
    "url": "https://en.wikipedia.org/wiki/First-hitting-time model"
  },
  "{\\displaystyle f(t)=-{\\frac {\\partial S(t)}{\\partial t}}.}": {
    "before": "where {\\displaystyle \\operatorname {erf} } is the error function . The relation between the Survival probability and the FPTD is as follows: the probability that a particle has reached the absorption point between times {\\displaystyle t} and {\\displaystyle t+dt} is {\\displaystyle f(t)\\,dt=S(t)-S(t+dt)} . If one uses the first-order Taylor approximation, the definition of the FPTD follows):",
    "after": "By using the diffusion equation and integrating, the explicit FPTD is",
    "url": "https://en.wikipedia.org/wiki/First-hitting-time model"
  },
  "{\\displaystyle f(t)={\\frac {\\Delta x}{\\sqrt {4\\pi Dt^{3}}}}\\sim t^{-3/2},}": {
    "before": "For {\\displaystyle t\\gg {\\frac {(x_{c}-x_{0})^{2}}{4D}}} , it follows from above that",
    "after": "where {\\displaystyle \\Delta x\\equiv |x_{c}-x_{0}|} . This equation states that the probability for a Brownian particle achieving a first passage at some long time (defined in the paragraph above) becomes increasingly small, but always finite .",
    "url": "https://en.wikipedia.org/wiki/First-hitting-time model"
  },
  "{\\displaystyle \\tau _{\\rm {ty}}={\\frac {\\Delta x^{2}}{6D}}.}": {
    "before": "The first moment of the FPTD diverges (as it is a so-called heavy-tailed distribution), therefore one cannot calculate the average FPT, so instead, one can calculate the typical time, the time when the FPTD is at a maximum ( {\\displaystyle \\partial f/\\partial t=0} ), i.e.,",
    "after": "First-hitting-time applications in many families of stochastic processes [ edit ]",
    "url": "https://en.wikipedia.org/wiki/First-hitting-time model"
  },
  "{\\displaystyle \\mathbf {y} =\\mathbf {X} \\mathbf {\\beta } +\\mathbf {\\varepsilon } ,\\qquad \\operatorname {E} [\\varepsilon \\mid \\mathbf {X} ]=0,\\ \\operatorname {Cov} [\\varepsilon \\mid \\mathbf {X} ]=\\mathbf {\\Omega } .}": {
    "before": "In standard linear regression models we observe data {\\displaystyle \\{y_{i},x_{ij}\\}_{i=1,\\dots ,n,j=2,\\dots ,k}} on n statistical units . The response values are placed in a vector {\\displaystyle \\mathbf {y} =\\left(y_{1},\\dots ,y_{n}\\right)^{\\mathsf {T}}} , and the predictor values are placed in the design matrix {\\displaystyle \\mathbf {X} =\\left(\\mathbf {x} _{1}^{\\mathsf {T}},\\dots ,\\mathbf {x} _{n}^{\\mathsf {T}}\\right)^{\\mathsf {T}}} , where {\\displaystyle \\mathbf {x} _{i}=\\left(1,x_{i2},\\dots ,x_{ik}\\right)} is a vector of the k predictor variables (including a constant) for the i th unit. The model forces the conditional mean of {\\displaystyle \\mathbf {y} } given {\\displaystyle \\mathbf {X} } to be a linear function of {\\displaystyle \\mathbf {X} } , and assumes the conditional variance of the error term given {\\displaystyle \\mathbf {X} } is a known nonsingular covariance matrix {\\displaystyle \\mathbf {\\Omega } } . This is usually written as",
    "after": "Here {\\displaystyle \\beta \\in \\mathbb {R} ^{k}} is a vector of unknown constants (known as “regression coefficients”) that must be estimated from the data.",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle {\\begin{aligned}\\mathbf {\\hat {\\beta }} &={\\underset {b}{\\operatorname {argmin} }}\\,(\\mathbf {y} -\\mathbf {X} \\mathbf {b} )^{\\mathsf {T}}\\mathbf {\\Omega } ^{-1}(\\mathbf {y} -\\mathbf {X} \\mathbf {b} )\\\\&={\\underset {b}{\\operatorname {argmin} }}\\,\\mathbf {y} ^{\\mathsf {T}}\\,\\mathbf {\\Omega } ^{-1}\\mathbf {y} +(\\mathbf {X} \\mathbf {b} )^{\\mathsf {T}}\\mathbf {\\Omega } ^{-1}\\mathbf {X} \\mathbf {b} -\\mathbf {y} ^{\\mathsf {T}}\\mathbf {\\Omega } ^{-1}\\mathbf {X} \\mathbf {b} -(\\mathbf {X} \\mathbf {b} )^{\\mathsf {T}}\\mathbf {\\Omega } ^{-1}\\mathbf {y} \\,,\\end{aligned}}}": {
    "before": "Suppose {\\displaystyle \\mathbf {b} } is a candidate estimate for {\\displaystyle \\mathbf {\\beta } } . Then the residual vector for {\\displaystyle \\mathbf {b} } will be {\\displaystyle \\mathbf {y} -\\mathbf {X} \\mathbf {b} } . The generalized least squares method estimates {\\displaystyle \\mathbf {\\beta } } by minimizing the squared Mahalanobis length of this residual vector:",
    "after": "where the last two terms evaluate to scalars, resulting in",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle \\mathbf {\\hat {\\beta }} ={\\underset {b}{\\operatorname {argmin} }}\\,\\mathbf {y} ^{\\mathsf {T}}\\,\\mathbf {\\Omega } ^{-1}\\mathbf {y} +\\mathbf {b} ^{\\mathsf {T}}\\mathbf {X} ^{\\mathsf {T}}\\mathbf {\\Omega } ^{-1}\\mathbf {X} \\mathbf {b} -2\\mathbf {b} ^{\\mathsf {T}}\\mathbf {X} ^{\\mathsf {T}}\\mathbf {\\Omega } ^{-1}\\mathbf {y} \\,.}": {
    "before": "where the last two terms evaluate to scalars, resulting in",
    "after": "This objective is a quadratic form in {\\displaystyle \\mathbf {b} } .",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle \\mathbf {\\hat {\\beta }} =\\left(\\mathbf {X} ^{\\mathsf {T}}\\mathbf {\\Omega } ^{-1}\\mathbf {X} \\right)^{-1}\\mathbf {X} ^{\\mathsf {T}}\\mathbf {\\Omega } ^{-1}\\mathbf {y} .}": {
    "before": "Therefore, the minimum of the objective function can be computed yielding the explicit formula:",
    "after": "The quantity {\\displaystyle \\mathbf {\\Omega } ^{-1}} is known as the precision matrix (or dispersion matrix ), a generalization of the diagonal weight matrix .",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle \\left(\\mathbf {y} ^{*}-\\mathbf {X} ^{*}\\mathbf {\\beta } \\right)^{\\mathsf {T}}(\\mathbf {y} ^{*}-\\mathbf {X} ^{*}\\mathbf {\\beta } )=(\\mathbf {y} -\\mathbf {X} \\mathbf {b} )^{\\mathsf {T}}\\,\\mathbf {\\Omega } ^{-1}(\\mathbf {y} -\\mathbf {X} \\mathbf {b} ).}": {
    "before": "The GLS estimator is unbiased , consistent , efficient , and asymptotically normal with {\\displaystyle \\operatorname {E} [{\\hat {\\beta }}\\mid \\mathbf {X} ]=\\beta } and {\\displaystyle \\operatorname {Cov} [{\\hat {\\beta }}\\mid \\mathbf {X} ]=(\\mathbf {X} ^{\\mathsf {T}}\\Omega ^{-1}\\mathbf {X} )^{-1}} . GLS is equivalent to applying ordinary least squares to a linearly transformed version of the data. To see this, factor {\\displaystyle \\mathbf {\\Omega } =\\mathbf {C} \\mathbf {C} ^{\\mathsf {T}}} , for instance using the Cholesky decomposition . Then if we pre-multiply both sides of the equation {\\displaystyle \\mathbf {y} =\\mathbf {X} \\mathbf {\\beta } +\\mathbf {\\varepsilon } } by {\\displaystyle \\mathbf {C} ^{-1}} , we get an equivalent linear model {\\displaystyle \\mathbf {y} ^{*}=\\mathbf {X} ^{*}\\mathbf {\\beta } +\\mathbf {\\varepsilon } ^{*}} where {\\displaystyle \\mathbf {y} ^{*}=\\mathbf {C} ^{-1}\\mathbf {y} } , {\\displaystyle \\mathbf {X} ^{*}=\\mathbf {C} ^{-1}\\mathbf {X} } , and {\\displaystyle \\mathbf {\\varepsilon } ^{*}=\\mathbf {C} ^{-1}\\mathbf {\\varepsilon } } . In this model {\\displaystyle \\operatorname {Var} [\\varepsilon ^{*}\\mid \\mathbf {X} ]=\\mathbf {C} ^{-1}\\mathbf {\\Omega } \\left(\\mathbf {C} ^{-1}\\right)^{\\mathsf {T}}=\\mathbf {I} } , where {\\displaystyle \\mathbf {I} } is the identity matrix . Thus we can efficiently estimate {\\displaystyle \\mathbf {\\beta } } by applying Ordinary least squares (OLS) to the transformed data, which requires minimizing",
    "after": "This has the effect of standardizing the scale of the errors and “de-correlating” them. Since OLS is applied to data with homoscedastic errors, the Gauss–Markov theorem applies, and therefore the GLS estimate is the best linear unbiased estimator for β .",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle {\\widehat {\\beta }}_{\\text{OLS}}=(X'X)^{-1}X'y}": {
    "before": "The ordinary least squares (OLS) estimator is calculated as usual by",
    "after": "and estimates of the residuals {\\displaystyle {\\widehat {u}}_{j}=(Y-X{\\widehat {\\beta }}_{\\text{OLS}})_{j}} are constructed.",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle {\\widehat {\\Omega }}_{\\text{OLS}}=\\operatorname {diag} ({\\widehat {\\sigma }}_{1}^{2},{\\widehat {\\sigma }}_{2}^{2},\\dots ,{\\widehat {\\sigma }}_{n}^{2}).}": {
    "before": "For simplicity consider the model for heteroscedastic and not autocorrelated errors. Assume that the variance-covariance matrix {\\displaystyle \\Omega } of the error vector is diagonal, or equivalently that errors from distinct observations are uncorrelated. Then each diagonal entry may be estimated by the fitted residuals {\\displaystyle {\\widehat {u}}_{j}} so {\\displaystyle {\\widehat {\\Omega }}_{OLS}} may be constructed by",
    "after": "It is important to notice that the squared residuals cannot be used in the previous expression; we need an estimator of the errors variances. To do so, we can use a parametric heteroskedasticity model, or a nonparametric estimator. Once this step is fulfilled, we can proceed:",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle {\\widehat {\\beta }}_{FGLS1}=(X'{\\widehat {\\Omega }}_{\\text{OLS}}^{-1}X)^{-1}X'{\\widehat {\\Omega }}_{\\text{OLS}}^{-1}y}": {
    "before": "Estimate {\\displaystyle \\beta _{FGLS1}} using {\\displaystyle {\\widehat {\\Omega }}_{\\text{OLS}}} using  weighted least squares",
    "after": "The procedure can be iterated. The first iteration is given by",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle {\\widehat {u}}_{FGLS1}=Y-X{\\widehat {\\beta }}_{FGLS1}}": {
    "before": "The procedure can be iterated. The first iteration is given by",
    "after": "{\\displaystyle {\\widehat {\\Omega }}_{FGLS1}=\\operatorname {diag} ({\\widehat {\\sigma }}_{FGLS1,1}^{2},{\\widehat {\\sigma }}_{FGLS1,2}^{2},\\dots ,{\\widehat {\\sigma }}_{FGLS1,n}^{2})}",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle {\\widehat {\\Omega }}_{FGLS1}=\\operatorname {diag} ({\\widehat {\\sigma }}_{FGLS1,1}^{2},{\\widehat {\\sigma }}_{FGLS1,2}^{2},\\dots ,{\\widehat {\\sigma }}_{FGLS1,n}^{2})}": {
    "before": "{\\displaystyle {\\widehat {u}}_{FGLS1}=Y-X{\\widehat {\\beta }}_{FGLS1}}",
    "after": "{\\displaystyle {\\widehat {\\beta }}_{FGLS2}=(X'{\\widehat {\\Omega }}_{FGLS1}^{-1}X)^{-1}X'{\\widehat {\\Omega }}_{FGLS1}^{-1}y}",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle {\\widehat {\\beta }}_{FGLS2}=(X'{\\widehat {\\Omega }}_{FGLS1}^{-1}X)^{-1}X'{\\widehat {\\Omega }}_{FGLS1}^{-1}y}": {
    "before": "{\\displaystyle {\\widehat {\\Omega }}_{FGLS1}=\\operatorname {diag} ({\\widehat {\\sigma }}_{FGLS1,1}^{2},{\\widehat {\\sigma }}_{FGLS1,2}^{2},\\dots ,{\\widehat {\\sigma }}_{FGLS1,n}^{2})}",
    "after": "This estimation of {\\displaystyle {\\widehat {\\Omega }}} can be iterated to convergence.",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle V=\\operatorname {p-lim} (X'\\Omega ^{-1}X/n)}": {
    "before": "{\\displaystyle {\\sqrt {n}}({\\hat {\\beta }}_{FGLS}-\\beta )\\ {\\xrightarrow {d}}\\ {\\mathcal {N}}\\!\\left(0,\\,V\\right).} where n is the sample size and",
    "after": "here p-lim means limit in probability",
    "url": "https://en.wikipedia.org/wiki/Generalized least squares"
  },
  "{\\displaystyle P_{t}={\\frac {x_{t}+x_{t-1}}{2}}} .": {
    "before": "The economy is divided into two sectors of equal size: in each sector there are unions which set nominal wages for two periods. The sectors reset their wages in alternate periods (hence the overlapping or staggered nature of contracts). The reset wage in period t is denoted {\\displaystyle x_{t}} . Nominal prices are a markup on the wages in each sector, so that the price can be expressed as a markup on the prevailing wages: the reset wage for this period and wage in the other sector which was set in the previous period:",
    "after": "We can define the optimal flex-wage {\\displaystyle x_{t}^{*}} as the wage the union would like to set if it were free to reset the wage every period. This is usually assumed to take the form:",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle x_{t}^{*}=P_{t}+\\gamma .Y_{t}} .": {
    "before": "We can define the optimal flex-wage {\\displaystyle x_{t}^{*}} as the wage the union would like to set if it were free to reset the wage every period. This is usually assumed to take the form:",
    "after": "where {\\displaystyle Y_{t}} is GDP and {\\displaystyle \\gamma >0} is a coefficient which captures the sensitivity of wages to demand. If {\\displaystyle \\gamma =0} , then the optimal flex wage depends only on prices and is insensitive to the level of demand (in effect, we have real rigidity). Larger values of {\\displaystyle \\gamma >0} indicate that the nominal wage responds to demand: more output means a higher real wage. The microfoundations for the optimal flex-wage or price can be found in Walsh (2011) chapter 5 and Woodford (2003) chapter 3.",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle x_{t}={\\frac {x_{t}^{*}+E_{t}x_{t+1}^{*}}{2}}}": {
    "before": "In the Taylor model, the union has to set the same nominal wage for two periods. The reset wage is thus the expected average of the optimal flex wage over the next two periods:",
    "after": "where {\\displaystyle x_{t}E_{t}x_{t+1}^{*}} is the expectation of {\\displaystyle x_{t+1}^{*}} conditional on information at t.",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle Y_{t}=M_{t}-P_{t}}": {
    "before": "To close the model we need a simple model of output determination. For simplicity, we can assume the simple Quantity Theory (QT) model with a constant velocity. Letting {\\displaystyle M_{t}} be the money supply:",
    "after": "Using the optimal flex wage equation we can substitute {\\displaystyle x_{t}^{*}} in terms of output and price (current and expected) to give the reset wage:",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle x_{t}={\\frac {P_{t}+E_{t}P_{t+1}+\\gamma .(Y_{t}+E_{t}Y_{t+1})}{2}}} .": {
    "before": "Using the optimal flex wage equation we can substitute {\\displaystyle x_{t}^{*}} in terms of output and price (current and expected) to give the reset wage:",
    "after": "Using the QT equation, we can then eliminate {\\displaystyle Y_{t}} in terms of the money supply and price:",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle x_{t}={\\frac {P_{t}(1-\\gamma )+E_{t}P_{t+1}(1-\\gamma )+\\gamma .(M_{t}+E_{t}M_{t+1})}{2}}} .": {
    "before": "Using the QT equation, we can then eliminate {\\displaystyle Y_{t}} in terms of the money supply and price:",
    "after": "Using the markup equation, we can express the price in each period in terms of the reset wages, to give us the second order stochastic difference equation in {\\displaystyle x_{t}}",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle x_{t}=A.(x_{t}+E_{t}x_{t+1})+(1-2A).M_{t}} .": {
    "before": "Using the markup equation, we can express the price in each period in terms of the reset wages, to give us the second order stochastic difference equation in {\\displaystyle x_{t}}",
    "after": "where {\\displaystyle A={\\frac {1}{2}}{\\frac {1-\\gamma }{1+\\gamma }}} .",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle M_{t}=M_{t-1}+\\epsilon _{t}}": {
    "before": "Lastly, we need to assume something about the stochastic process driving the money supply. The simplest case to consider is a random walk:",
    "after": "where {\\displaystyle \\epsilon _{t}} is a monetary shock with mean zero mean and no serial correlation (so called white noise). In this case, the solution for the nominal reset wage can be shown to be:",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle x_{t}=\\lambda .x_{t-1}+(1-\\lambda )m_{t}}": {
    "before": "where {\\displaystyle \\epsilon _{t}} is a monetary shock with mean zero mean and no serial correlation (so called white noise). In this case, the solution for the nominal reset wage can be shown to be:",
    "after": "where {\\displaystyle \\lambda ^{*}} is the stable eigenvalue:",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle \\lambda ^{*}={\\frac {1-\\gamma }{1+\\gamma }}}": {
    "before": "where {\\displaystyle \\lambda ^{*}} is the stable eigenvalue:",
    "after": "If {\\displaystyle \\lambda ^{*}=1} there is perfect nominal rigidity and the reset wage this period is the same as the reset wage last period. wages and price remain fixed in both real and nominal terms. For {\\displaystyle \\lambda ^{*}<1} nominal prices adjust to the new steady state. Since money follows a random walk, the monetary shock lasts forever and the new steady state price and wage are equal to {\\displaystyle M_{t}} . The wage will adjust towards the new steady state more quickly the smaller {\\displaystyle \\lambda ^{*}} is. We can rewrite the above solution as:",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle x_{t}-m_{t}=\\lambda .(x_{t-1}-m_{t})}": {
    "before": "If {\\displaystyle \\lambda ^{*}=1} there is perfect nominal rigidity and the reset wage this period is the same as the reset wage last period. wages and price remain fixed in both real and nominal terms. For {\\displaystyle \\lambda ^{*}<1} nominal prices adjust to the new steady state. Since money follows a random walk, the monetary shock lasts forever and the new steady state price and wage are equal to {\\displaystyle M_{t}} . The wage will adjust towards the new steady state more quickly the smaller {\\displaystyle \\lambda ^{*}} is. We can rewrite the above solution as:",
    "after": "The left hand side expresses the gap between the current reset wage and the new steady-state: this is a proportion {\\displaystyle \\lambda ^{*}} of the preceding gap. Thus a smaller {\\displaystyle \\lambda ^{*}} implies that the gap will shrink more rapidly. The value of {\\displaystyle \\lambda ^{*}} thus determines how rapidly the nominal wage adjusts to its new steady-state value.",
    "url": "https://en.wikipedia.org/wiki/Taylor contract (economics)"
  },
  "{\\displaystyle x(n)=\\sum _{k=0}^{q}b_{n}(k)d(n-k)+v(n)}": {
    "before": "RLS was discovered by Gauss but lay unused or ignored until 1950 when Plackett rediscovered the original work of Gauss from 1821. In general, the RLS can be used to solve any problem that can be solved by adaptive filters . For example, suppose that a signal {\\displaystyle d(n)} is transmitted over an echoey, noisy channel that causes it to be received as",
    "after": "where {\\displaystyle v(n)} represents additive noise . The intent of the RLS filter is to recover the desired signal {\\displaystyle d(n)} by use of a {\\displaystyle p+1} -tap FIR filter, {\\displaystyle \\mathbf {w} } :",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle d(n)\\approx \\sum _{k=0}^{p}w(k)x(n-k)=\\mathbf {w} ^{\\mathit {T}}\\mathbf {x} _{n}}": {
    "before": "where {\\displaystyle v(n)} represents additive noise . The intent of the RLS filter is to recover the desired signal {\\displaystyle d(n)} by use of a {\\displaystyle p+1} -tap FIR filter, {\\displaystyle \\mathbf {w} } :",
    "after": "where {\\displaystyle \\mathbf {x} _{n}=[x(n)\\quad x(n-1)\\quad \\ldots \\quad x(n-p)]^{T}} is the column vector containing the {\\displaystyle p+1} most recent samples of {\\displaystyle x(n)} . The estimate of the recovered desired signal is",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle {\\hat {d}}(n)=\\sum _{k=0}^{p}w_{n}(k)x(n-k)=\\mathbf {w} _{n}^{\\mathit {T}}\\mathbf {x} _{n}}": {
    "before": "where {\\displaystyle \\mathbf {x} _{n}=[x(n)\\quad x(n-1)\\quad \\ldots \\quad x(n-p)]^{T}} is the column vector containing the {\\displaystyle p+1} most recent samples of {\\displaystyle x(n)} . The estimate of the recovered desired signal is",
    "after": "The goal is to estimate the parameters of the filter {\\displaystyle \\mathbf {w} } , and at each time {\\displaystyle n} we refer to the current estimate as {\\displaystyle \\mathbf {w} _{n}} and the adapted least-squares estimate by {\\displaystyle \\mathbf {w} _{n+1}} . {\\displaystyle \\mathbf {w} _{n}} is also a column vector, as shown below, and the transpose , {\\displaystyle \\mathbf {w} _{n}^{\\mathit {T}}} , is a row vector . The matrix product {\\displaystyle \\mathbf {w} _{n}^{\\mathit {T}}\\mathbf {x} _{n}} (which is the dot product of {\\displaystyle \\mathbf {w} _{n}} and {\\displaystyle \\mathbf {x} _{n}} ) is {\\displaystyle {\\hat {d}}(n)} , a scalar. The estimate is \"good\" if {\\displaystyle {\\hat {d}}(n)-d(n)} is small in magnitude in some least squares sense.",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle e(n)=d(n)-{\\hat {d}}(n)}": {
    "before": "The error implicitly depends on the filter coefficients through the estimate {\\displaystyle {\\hat {d}}(n)} :",
    "after": "The weighted least squares error function {\\displaystyle C} —the cost function we desire to minimize—being a function of {\\displaystyle e(n)} is therefore also dependent on the filter coefficients:",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle C(\\mathbf {w} _{n})=\\sum _{i=0}^{n}\\lambda ^{n-i}e^{2}(i)}": {
    "before": "The weighted least squares error function {\\displaystyle C} —the cost function we desire to minimize—being a function of {\\displaystyle e(n)} is therefore also dependent on the filter coefficients:",
    "after": "where {\\displaystyle 0<\\lambda \\leq 1} is the \"forgetting factor\" which gives exponentially less weight to older error samples.",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle {\\frac {\\partial C(\\mathbf {w} _{n})}{\\partial w_{n}(k)}}=\\sum _{i=0}^{n}2\\lambda ^{n-i}e(i)\\cdot {\\frac {\\partial e(i)}{\\partial w_{n}(k)}}=-\\sum _{i=0}^{n}2\\lambda ^{n-i}e(i)\\,x(i-k)=0\\qquad k=0,1,\\ldots ,p}": {
    "before": "The cost function is minimized by taking the partial derivatives for all entries {\\displaystyle k} of the coefficient vector {\\displaystyle \\mathbf {w} _{n}} and setting the results to zero",
    "after": "Next, replace {\\displaystyle e(n)} with the definition of the error signal",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\sum _{i=0}^{n}\\lambda ^{n-i}\\left[d(i)-\\sum _{\\ell =0}^{p}w_{n}(\\ell )x(i-\\ell )\\right]x(i-k)=0\\qquad k=0,1,\\ldots ,p}": {
    "before": "Next, replace {\\displaystyle e(n)} with the definition of the error signal",
    "after": "Rearranging the equation yields",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\sum _{\\ell =0}^{p}w_{n}(\\ell )\\left[\\sum _{i=0}^{n}\\lambda ^{n-i}\\,x(i-l)x(i-k)\\right]=\\sum _{i=0}^{n}\\lambda ^{n-i}d(i)x(i-k)\\qquad k=0,1,\\ldots ,p}": {
    "before": "{\\displaystyle \\sum _{i=0}^{n}\\lambda ^{n-i}\\left[d(i)-\\sum _{\\ell =0}^{p}w_{n}(\\ell )x(i-\\ell )\\right]x(i-k)=0\\qquad k=0,1,\\ldots ,p} Rearranging the equation yields",
    "after": "This form can be expressed in terms of matrices",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {R} _{x}(n)\\,\\mathbf {w} _{n}=\\mathbf {r} _{dx}(n)}": {
    "before": "{\\displaystyle \\sum _{\\ell =0}^{p}w_{n}(\\ell )\\left[\\sum _{i=0}^{n}\\lambda ^{n-i}\\,x(i-l)x(i-k)\\right]=\\sum _{i=0}^{n}\\lambda ^{n-i}d(i)x(i-k)\\qquad k=0,1,\\ldots ,p} This form can be expressed in terms of matrices",
    "after": "where {\\displaystyle \\mathbf {R} _{x}(n)} is the weighted sample covariance matrix for {\\displaystyle x(n)} , and {\\displaystyle \\mathbf {r} _{dx}(n)} is the equivalent estimate for the cross-covariance between {\\displaystyle d(n)} and {\\displaystyle x(n)} . Based on this expression we find the coefficients which minimize the cost function as",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {w} _{n}=\\mathbf {R} _{x}^{-1}(n)\\,\\mathbf {r} _{dx}(n)}": {
    "before": "where {\\displaystyle \\mathbf {R} _{x}(n)} is the weighted sample covariance matrix for {\\displaystyle x(n)} , and {\\displaystyle \\mathbf {r} _{dx}(n)} is the equivalent estimate for the cross-covariance between {\\displaystyle d(n)} and {\\displaystyle x(n)} . Based on this expression we find the coefficients which minimize the cost function as",
    "after": "This is the main result of the discussion.",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {w} _{n}=\\mathbf {w} _{n-1}+\\Delta \\mathbf {w} _{n-1}}": {
    "before": "The discussion resulted in a single equation to determine a coefficient vector which minimizes the cost function. In this section we want to derive a recursive solution of the form",
    "after": "where {\\displaystyle \\Delta \\mathbf {w} _{n-1}} is a correction factor at time {\\displaystyle {n-1}} . We start the derivation of the recursive algorithm by expressing the cross covariance {\\displaystyle \\mathbf {r} _{dx}(n)} in terms of {\\displaystyle \\mathbf {r} _{dx}(n-1)}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {r} _{dx}(n)} {\\displaystyle =\\sum _{i=0}^{n}\\lambda ^{n-i}d(i)\\mathbf {x} (i)} {\\displaystyle =\\sum _{i=0}^{n-1}\\lambda ^{n-i}d(i)\\mathbf {x} (i)+\\lambda ^{0}d(n)\\mathbf {x} (n)} {\\displaystyle =\\lambda \\mathbf {r} _{dx}(n-1)+d(n)\\mathbf {x} (n)}": {
    "before": "where {\\displaystyle \\Delta \\mathbf {w} _{n-1}} is a correction factor at time {\\displaystyle {n-1}} . We start the derivation of the recursive algorithm by expressing the cross covariance {\\displaystyle \\mathbf {r} _{dx}(n)} in terms of {\\displaystyle \\mathbf {r} _{dx}(n-1)}",
    "after": "where {\\displaystyle \\mathbf {x} (i)} is the {\\displaystyle {p+1}} dimensional data vector",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {x} (i)=[x(i),x(i-1),\\dots ,x(i-p)]^{T}}": {
    "before": "where {\\displaystyle \\mathbf {x} (i)} is the {\\displaystyle {p+1}} dimensional data vector",
    "after": "Similarly we express {\\displaystyle \\mathbf {R} _{x}(n)} in terms of {\\displaystyle \\mathbf {R} _{x}(n-1)} by",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {R} _{x}(n)} {\\displaystyle =\\sum _{i=0}^{n}\\lambda ^{n-i}\\mathbf {x} (i)\\mathbf {x} ^{T}(i)} {\\displaystyle =\\lambda \\mathbf {R} _{x}(n-1)+\\mathbf {x} (n)\\mathbf {x} ^{T}(n)}": {
    "before": "Similarly we express {\\displaystyle \\mathbf {R} _{x}(n)} in terms of {\\displaystyle \\mathbf {R} _{x}(n-1)} by",
    "after": "In order to generate the coefficient vector we are interested in the inverse of the deterministic auto-covariance matrix. For that task the Woodbury matrix identity comes in handy. With",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle A} {\\displaystyle =\\lambda \\mathbf {R} _{x}(n-1)} is {\\displaystyle (p+1)} -by- {\\displaystyle (p+1)} {\\displaystyle U} {\\displaystyle =\\mathbf {x} (n)} is {\\displaystyle (p+1)} -by-1 (column vector) {\\displaystyle V} {\\displaystyle =\\mathbf {x} ^{T}(n)} is 1-by- {\\displaystyle (p+1)} (row vector) {\\displaystyle C} {\\displaystyle =\\mathbf {I} _{1}} is the 1-by-1 identity matrix": {
    "before": "In order to generate the coefficient vector we are interested in the inverse of the deterministic auto-covariance matrix. For that task the Woodbury matrix identity comes in handy. With",
    "after": "The Woodbury matrix identity follows",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {R} _{x}^{-1}(n)} {\\displaystyle =} {\\displaystyle \\left[\\lambda \\mathbf {R} _{x}(n-1)+\\mathbf {x} (n)\\mathbf {x} ^{T}(n)\\right]^{-1}} {\\displaystyle =} {\\displaystyle \\lambda ^{-1}\\mathbf {R} _{x}^{-1}(n-1)} {\\displaystyle -\\lambda ^{-1}\\mathbf {R} _{x}^{-1}(n-1)\\mathbf {x} (n)} {\\displaystyle \\left\\{1+\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {R} _{x}^{-1}(n-1)\\mathbf {x} (n)\\right\\}^{-1}\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {R} _{x}^{-1}(n-1)}": {
    "before": "{\\displaystyle A} {\\displaystyle =\\lambda \\mathbf {R} _{x}(n-1)} is {\\displaystyle (p+1)} -by- {\\displaystyle (p+1)} {\\displaystyle U} {\\displaystyle =\\mathbf {x} (n)} is {\\displaystyle (p+1)} -by-1 (column vector) {\\displaystyle V} {\\displaystyle =\\mathbf {x} ^{T}(n)} is 1-by- {\\displaystyle (p+1)} (row vector) {\\displaystyle C} {\\displaystyle =\\mathbf {I} _{1}} is the 1-by-1 identity matrix The Woodbury matrix identity follows",
    "after": "To come in line with the standard literature, we define",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {P} (n)} {\\displaystyle =\\mathbf {R} _{x}^{-1}(n)} {\\displaystyle =\\lambda ^{-1}\\mathbf {P} (n-1)-\\mathbf {g} (n)\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {P} (n-1)}": {
    "before": "To come in line with the standard literature, we define",
    "after": "where the gain vector {\\displaystyle g(n)} is",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {g} (n)} {\\displaystyle =\\lambda ^{-1}\\mathbf {P} (n-1)\\mathbf {x} (n)\\left\\{1+\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {P} (n-1)\\mathbf {x} (n)\\right\\}^{-1}} {\\displaystyle =\\mathbf {P} (n-1)\\mathbf {x} (n)\\left\\{\\lambda +\\mathbf {x} ^{T}(n)\\mathbf {P} (n-1)\\mathbf {x} (n)\\right\\}^{-1}}": {
    "before": "where the gain vector {\\displaystyle g(n)} is",
    "after": "Before we move on, it is necessary to bring {\\displaystyle \\mathbf {g} (n)} into another form",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {g} (n)\\left\\{1+\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {P} (n-1)\\mathbf {x} (n)\\right\\}} {\\displaystyle =\\lambda ^{-1}\\mathbf {P} (n-1)\\mathbf {x} (n)} {\\displaystyle \\mathbf {g} (n)+\\mathbf {g} (n)\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {P} (n-1)\\mathbf {x} (n)} {\\displaystyle =\\lambda ^{-1}\\mathbf {P} (n-1)\\mathbf {x} (n)}": {
    "before": "Before we move on, it is necessary to bring {\\displaystyle \\mathbf {g} (n)} into another form",
    "after": "Subtracting the second term on the left side yields",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {g} (n)} {\\displaystyle =\\lambda ^{-1}\\mathbf {P} (n-1)\\mathbf {x} (n)-\\mathbf {g} (n)\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {P} (n-1)\\mathbf {x} (n)} {\\displaystyle =\\lambda ^{-1}\\left[\\mathbf {P} (n-1)-\\mathbf {g} (n)\\mathbf {x} ^{T}(n)\\mathbf {P} (n-1)\\right]\\mathbf {x} (n)}": {
    "before": "Subtracting the second term on the left side yields",
    "after": "With the recursive definition of {\\displaystyle \\mathbf {P} (n)} the desired form follows",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {g} (n)=\\mathbf {P} (n)\\mathbf {x} (n)}": {
    "before": "With the recursive definition of {\\displaystyle \\mathbf {P} (n)} the desired form follows",
    "after": "Now we are ready to complete the recursion. As discussed",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {w} _{n}} {\\displaystyle =\\mathbf {P} (n)\\,\\mathbf {r} _{dx}(n)} {\\displaystyle =\\lambda \\mathbf {P} (n)\\,\\mathbf {r} _{dx}(n-1)+d(n)\\mathbf {P} (n)\\,\\mathbf {x} (n)}": {
    "before": "Now we are ready to complete the recursion. As discussed",
    "after": "The second step follows from the recursive definition of {\\displaystyle \\mathbf {r} _{dx}(n)} . Next we incorporate the recursive definition of {\\displaystyle \\mathbf {P} (n)} together with the alternate form of {\\displaystyle \\mathbf {g} (n)} and get",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {w} _{n}} {\\displaystyle =\\lambda \\left[\\lambda ^{-1}\\mathbf {P} (n-1)-\\mathbf {g} (n)\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {P} (n-1)\\right]\\mathbf {r} _{dx}(n-1)+d(n)\\mathbf {g} (n)} {\\displaystyle =\\mathbf {P} (n-1)\\mathbf {r} _{dx}(n-1)-\\mathbf {g} (n)\\mathbf {x} ^{T}(n)\\mathbf {P} (n-1)\\mathbf {r} _{dx}(n-1)+d(n)\\mathbf {g} (n)} {\\displaystyle =\\mathbf {P} (n-1)\\mathbf {r} _{dx}(n-1)+\\mathbf {g} (n)\\left[d(n)-\\mathbf {x} ^{T}(n)\\mathbf {P} (n-1)\\mathbf {r} _{dx}(n-1)\\right]}": {
    "before": "The second step follows from the recursive definition of {\\displaystyle \\mathbf {r} _{dx}(n)} . Next we incorporate the recursive definition of {\\displaystyle \\mathbf {P} (n)} together with the alternate form of {\\displaystyle \\mathbf {g} (n)} and get",
    "after": "With {\\displaystyle \\mathbf {w} _{n-1}=\\mathbf {P} (n-1)\\mathbf {r} _{dx}(n-1)} we arrive at the update equation",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {w} _{n}} {\\displaystyle =\\mathbf {w} _{n-1}+\\mathbf {g} (n)\\left[d(n)-\\mathbf {x} ^{T}(n)\\mathbf {w} _{n-1}\\right]} {\\displaystyle =\\mathbf {w} _{n-1}+\\mathbf {g} (n)\\alpha (n)}": {
    "before": "With {\\displaystyle \\mathbf {w} _{n-1}=\\mathbf {P} (n-1)\\mathbf {r} _{dx}(n-1)} we arrive at the update equation",
    "after": "where {\\displaystyle \\alpha (n)=d(n)-\\mathbf {x} ^{T}(n)\\mathbf {w} _{n-1}} is the a priori error. Compare this with the a posteriori error; the error calculated after the filter is updated:",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle e(n)=d(n)-\\mathbf {x} ^{T}(n)\\mathbf {w} _{n}}": {
    "before": "where {\\displaystyle \\alpha (n)=d(n)-\\mathbf {x} ^{T}(n)\\mathbf {w} _{n-1}} is the a priori error. Compare this with the a posteriori error; the error calculated after the filter is updated:",
    "after": "That means we found the correction factor",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\Delta \\mathbf {w} _{n-1}=\\mathbf {g} (n)\\alpha (n)}": {
    "before": "{\\displaystyle e(n)=d(n)-\\mathbf {x} ^{T}(n)\\mathbf {w} _{n}} That means we found the correction factor",
    "after": "This intuitively satisfying result indicates that the correction factor is directly proportional to both the error and the gain vector, which controls how much sensitivity is desired, through the weighting factor, {\\displaystyle \\lambda } .",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle d(k)=0,k=-p,\\dots ,-1}": {
    "before": "{\\displaystyle d(k)=0,k=-p,\\dots ,-1}",
    "after": "{\\displaystyle \\mathbf {P} (0)=\\delta I} where {\\displaystyle I} is the identity matrix of rank {\\displaystyle p+1}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {x} (n)=\\left[{\\begin{matrix}x(n)\\\\x(n-1)\\\\\\vdots \\\\x(n-p)\\end{matrix}}\\right]}": {
    "before": "{\\displaystyle \\mathbf {x} (n)=\\left[{\\begin{matrix}x(n)\\\\x(n-1)\\\\\\vdots \\\\x(n-p)\\end{matrix}}\\right]}",
    "after": "{\\displaystyle \\mathbf {x} (n)=\\left[{\\begin{matrix}x(n)\\\\x(n-1)\\\\\\vdots \\\\x(n-p)\\end{matrix}}\\right]}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\alpha (n)=d(n)-\\mathbf {x} ^{T}(n)\\mathbf {w} (n-1)}": {
    "before": "{\\displaystyle \\alpha (n)=d(n)-\\mathbf {x} ^{T}(n)\\mathbf {w} (n-1)}",
    "after": "{\\displaystyle \\mathbf {g} (n)=\\mathbf {P} (n-1)\\mathbf {x} (n)\\left\\{\\lambda +\\mathbf {x} ^{T}(n)\\mathbf {P} (n-1)\\mathbf {x} (n)\\right\\}^{-1}}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {g} (n)=\\mathbf {P} (n-1)\\mathbf {x} (n)\\left\\{\\lambda +\\mathbf {x} ^{T}(n)\\mathbf {P} (n-1)\\mathbf {x} (n)\\right\\}^{-1}}": {
    "before": "{\\displaystyle \\mathbf {g} (n)=\\mathbf {P} (n-1)\\mathbf {x} (n)\\left\\{\\lambda +\\mathbf {x} ^{T}(n)\\mathbf {P} (n-1)\\mathbf {x} (n)\\right\\}^{-1}}",
    "after": "{\\displaystyle \\mathbf {P} (n)=\\lambda ^{-1}\\mathbf {P} (n-1)-\\mathbf {g} (n)\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {P} (n-1)}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\mathbf {P} (n)=\\lambda ^{-1}\\mathbf {P} (n-1)-\\mathbf {g} (n)\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {P} (n-1)}": {
    "before": "{\\displaystyle \\mathbf {P} (n)=\\lambda ^{-1}\\mathbf {P} (n-1)-\\mathbf {g} (n)\\mathbf {x} ^{T}(n)\\lambda ^{-1}\\mathbf {P} (n-1)}",
    "after": "{\\displaystyle \\mathbf {w} (n)=\\mathbf {w} (n-1)+\\,\\alpha (n)\\mathbf {g} (n)} .",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\xi _{b_{\\min }}^{d}(-1,i)=\\xi _{f_{\\min }}^{d}(-1,i)=\\varepsilon }": {
    "before": "{\\displaystyle \\xi _{b_{\\min }}^{d}(-1,i)=\\xi _{f_{\\min }}^{d}(-1,i)=\\varepsilon }",
    "after": "{\\displaystyle \\gamma (-1,i)=1\\,\\!}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle e_{b}(k,0)=e_{f}(k,0)=x(k)\\,\\!}": {
    "before": "{\\displaystyle e_{b}(k,0)=e_{f}(k,0)=x(k)\\,\\!}",
    "after": "{\\displaystyle \\xi _{b_{\\min }}^{d}(k,0)=\\xi _{f_{\\min }}^{d}(k,0)=x^{2}(k)+\\lambda \\xi _{f_{\\min }}^{d}(k-1,0)\\,\\!}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\xi _{b_{\\min }}^{d}(k,0)=\\xi _{f_{\\min }}^{d}(k,0)=x^{2}(k)+\\lambda \\xi _{f_{\\min }}^{d}(k-1,0)\\,\\!}": {
    "before": "{\\displaystyle \\xi _{b_{\\min }}^{d}(k,0)=\\xi _{f_{\\min }}^{d}(k,0)=x^{2}(k)+\\lambda \\xi _{f_{\\min }}^{d}(k-1,0)\\,\\!}",
    "after": "{\\displaystyle e(k,0)=d(k)\\,\\!}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle e(k,0)=d(k)\\,\\!}": {
    "before": "{\\displaystyle e(k,0)=d(k)\\,\\!}",
    "after": "For {\\textstyle i=0,1,\\ldots ,N}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\delta (k,i)=\\lambda \\delta (k-1,i)+{\\frac {e_{b}(k-1,i)e_{f}(k,i)}{\\gamma (k-1,i)}}}": {
    "before": "{\\displaystyle \\delta (k,i)=\\lambda \\delta (k-1,i)+{\\frac {e_{b}(k-1,i)e_{f}(k,i)}{\\gamma (k-1,i)}}}",
    "after": "{\\displaystyle \\gamma (k,i+1)=\\gamma (k,i)-{\\frac {e_{b}^{2}(k,i)}{\\xi _{b_{\\min }}^{d}(k,i)}}}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\gamma (k,i+1)=\\gamma (k,i)-{\\frac {e_{b}^{2}(k,i)}{\\xi _{b_{\\min }}^{d}(k,i)}}}": {
    "before": "{\\displaystyle \\gamma (k,i+1)=\\gamma (k,i)-{\\frac {e_{b}^{2}(k,i)}{\\xi _{b_{\\min }}^{d}(k,i)}}}",
    "after": "{\\displaystyle \\kappa _{b}(k,i)={\\frac {\\delta (k,i)}{\\xi _{f_{\\min }}^{d}(k,i)}}}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\kappa _{b}(k,i)={\\frac {\\delta (k,i)}{\\xi _{f_{\\min }}^{d}(k,i)}}}": {
    "before": "{\\displaystyle \\kappa _{b}(k,i)={\\frac {\\delta (k,i)}{\\xi _{f_{\\min }}^{d}(k,i)}}}",
    "after": "{\\displaystyle \\kappa _{f}(k,i)={\\frac {\\delta (k,i)}{\\xi _{b_{\\min }}^{d}(k-1,i)}}}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\kappa _{f}(k,i)={\\frac {\\delta (k,i)}{\\xi _{b_{\\min }}^{d}(k-1,i)}}}": {
    "before": "{\\displaystyle \\kappa _{f}(k,i)={\\frac {\\delta (k,i)}{\\xi _{b_{\\min }}^{d}(k-1,i)}}}",
    "after": "{\\displaystyle e_{b}(k,i+1)=e_{b}(k-1,i)-\\kappa _{b}(k,i)e_{f}(k,i)\\,\\!}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle e_{b}(k,i+1)=e_{b}(k-1,i)-\\kappa _{b}(k,i)e_{f}(k,i)\\,\\!}": {
    "before": "{\\displaystyle e_{b}(k,i+1)=e_{b}(k-1,i)-\\kappa _{b}(k,i)e_{f}(k,i)\\,\\!}",
    "after": "{\\displaystyle e_{f}(k,i+1)=e_{f}(k,i)-\\kappa _{f}(k,i)e_{b}(k-1,i)\\,\\!}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle e_{f}(k,i+1)=e_{f}(k,i)-\\kappa _{f}(k,i)e_{b}(k-1,i)\\,\\!}": {
    "before": "{\\displaystyle e_{f}(k,i+1)=e_{f}(k,i)-\\kappa _{f}(k,i)e_{b}(k-1,i)\\,\\!}",
    "after": "{\\displaystyle \\xi _{b_{\\min }}^{d}(k,i+1)=\\xi _{b_{\\min }}^{d}(k-1,i)-\\delta (k,i)\\kappa _{b}(k,i)}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\xi _{b_{\\min }}^{d}(k,i+1)=\\xi _{b_{\\min }}^{d}(k-1,i)-\\delta (k,i)\\kappa _{b}(k,i)}": {
    "before": "{\\displaystyle \\xi _{b_{\\min }}^{d}(k,i+1)=\\xi _{b_{\\min }}^{d}(k-1,i)-\\delta (k,i)\\kappa _{b}(k,i)}",
    "after": "{\\displaystyle \\xi _{f_{\\min }}^{d}(k,i+1)=\\xi _{f_{\\min }}^{d}(k,i)-\\delta (k,i)\\kappa _{f}(k,i)}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\xi _{f_{\\min }}^{d}(k,i+1)=\\xi _{f_{\\min }}^{d}(k,i)-\\delta (k,i)\\kappa _{f}(k,i)}": {
    "before": "{\\displaystyle \\xi _{f_{\\min }}^{d}(k,i+1)=\\xi _{f_{\\min }}^{d}(k,i)-\\delta (k,i)\\kappa _{f}(k,i)}",
    "after": "Feedforward filtering",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\delta _{D}(k,i)=\\lambda \\delta _{D}(k-1,i)+{\\frac {e(k,i)e_{b}(k,i)}{\\gamma (k,i)}}}": {
    "before": "{\\displaystyle \\delta _{D}(k,i)=\\lambda \\delta _{D}(k-1,i)+{\\frac {e(k,i)e_{b}(k,i)}{\\gamma (k,i)}}}",
    "after": "{\\displaystyle v_{i}(k)={\\frac {\\delta _{D}(k,i)}{\\xi _{b_{\\min }}^{d}(k,i)}}}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle v_{i}(k)={\\frac {\\delta _{D}(k,i)}{\\xi _{b_{\\min }}^{d}(k,i)}}}": {
    "before": "{\\displaystyle v_{i}(k)={\\frac {\\delta _{D}(k,i)}{\\xi _{b_{\\min }}^{d}(k,i)}}}",
    "after": "{\\displaystyle e(k,i+1)=e(k,i)-v_{i}(k)e_{b}(k,i)\\,\\!}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle e(k,i+1)=e(k,i)-v_{i}(k)e_{b}(k,i)\\,\\!}": {
    "before": "{\\displaystyle e(k,i+1)=e(k,i)-v_{i}(k)e_{b}(k,i)\\,\\!}",
    "after": "End End",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle \\sigma _{x}^{2}(-1)=\\lambda \\sigma _{d}^{2}(-1)=\\varepsilon \\,\\!}": {
    "before": "{\\displaystyle \\sigma _{x}^{2}(-1)=\\lambda \\sigma _{d}^{2}(-1)=\\varepsilon \\,\\!}",
    "after": "Computation: For {\\textstyle k\\geq 0}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle {\\overline {e}}_{b}(k,0)={\\overline {e}}_{f}(k,0)={\\frac {x(k)}{\\sigma _{x}(k)}}\\,\\!}": {
    "before": "{\\displaystyle {\\overline {e}}_{b}(k,0)={\\overline {e}}_{f}(k,0)={\\frac {x(k)}{\\sigma _{x}(k)}}\\,\\!}",
    "after": "{\\displaystyle {\\overline {e}}(k,0)={\\frac {d(k)}{\\sigma _{d}(k)}}\\,\\!}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle {\\overline {e}}(k,0)={\\frac {d(k)}{\\sigma _{d}(k)}}\\,\\!}": {
    "before": "{\\displaystyle {\\overline {e}}(k,0)={\\frac {d(k)}{\\sigma _{d}(k)}}\\,\\!}",
    "after": "For {\\textstyle i=0,1,\\ldots ,N}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle {\\overline {\\delta }}(k,i)=\\delta (k-1,i){\\sqrt {(1-{\\overline {e}}_{b}^{2}(k-1,i))(1-{\\overline {e}}_{f}^{2}(k,i))}}+{\\overline {e}}_{b}(k-1,i){\\overline {e}}_{f}(k,i)}": {
    "before": "{\\displaystyle {\\overline {\\delta }}(k,i)=\\delta (k-1,i){\\sqrt {(1-{\\overline {e}}_{b}^{2}(k-1,i))(1-{\\overline {e}}_{f}^{2}(k,i))}}+{\\overline {e}}_{b}(k-1,i){\\overline {e}}_{f}(k,i)}",
    "after": "{\\displaystyle {\\overline {e}}_{b}(k,i+1)={\\frac {{\\overline {e}}_{b}(k-1,i)-{\\overline {\\delta }}(k,i){\\overline {e}}_{f}(k,i)}{\\sqrt {(1-{\\overline {\\delta }}^{2}(k,i))(1-{\\overline {e}}_{f}^{2}(k,i))}}}}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle {\\overline {e}}_{b}(k,i+1)={\\frac {{\\overline {e}}_{b}(k-1,i)-{\\overline {\\delta }}(k,i){\\overline {e}}_{f}(k,i)}{\\sqrt {(1-{\\overline {\\delta }}^{2}(k,i))(1-{\\overline {e}}_{f}^{2}(k,i))}}}}": {
    "before": "{\\displaystyle {\\overline {e}}_{b}(k,i+1)={\\frac {{\\overline {e}}_{b}(k-1,i)-{\\overline {\\delta }}(k,i){\\overline {e}}_{f}(k,i)}{\\sqrt {(1-{\\overline {\\delta }}^{2}(k,i))(1-{\\overline {e}}_{f}^{2}(k,i))}}}}",
    "after": "{\\displaystyle {\\overline {e}}_{f}(k,i+1)={\\frac {{\\overline {e}}_{f}(k,i)-{\\overline {\\delta }}(k,i){\\overline {e}}_{b}(k-1,i)}{\\sqrt {(1-{\\overline {\\delta }}^{2}(k,i))(1-{\\overline {e}}_{b}^{2}(k-1,i))}}}}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle {\\overline {e}}_{f}(k,i+1)={\\frac {{\\overline {e}}_{f}(k,i)-{\\overline {\\delta }}(k,i){\\overline {e}}_{b}(k-1,i)}{\\sqrt {(1-{\\overline {\\delta }}^{2}(k,i))(1-{\\overline {e}}_{b}^{2}(k-1,i))}}}}": {
    "before": "{\\displaystyle {\\overline {e}}_{f}(k,i+1)={\\frac {{\\overline {e}}_{f}(k,i)-{\\overline {\\delta }}(k,i){\\overline {e}}_{b}(k-1,i)}{\\sqrt {(1-{\\overline {\\delta }}^{2}(k,i))(1-{\\overline {e}}_{b}^{2}(k-1,i))}}}}",
    "after": "Feedforward filter",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle {\\overline {\\delta }}_{D}(k,i)={\\overline {\\delta }}_{D}(k-1,i){\\sqrt {(1-{\\overline {e}}_{b}^{2}(k,i))(1-{\\overline {e}}^{2}(k,i))}}+{\\overline {e}}(k,i){\\overline {e}}_{b}(k,i)}": {
    "before": "{\\displaystyle {\\overline {\\delta }}_{D}(k,i)={\\overline {\\delta }}_{D}(k-1,i){\\sqrt {(1-{\\overline {e}}_{b}^{2}(k,i))(1-{\\overline {e}}^{2}(k,i))}}+{\\overline {e}}(k,i){\\overline {e}}_{b}(k,i)}",
    "after": "{\\displaystyle {\\overline {e}}(k,i+1)={\\frac {1}{\\sqrt {(1-{\\overline {e}}_{b}^{2}(k,i))(1-{\\overline {\\delta }}_{D}^{2}(k,i))}}}[{\\overline {e}}(k,i)-{\\overline {\\delta }}_{D}(k,i){\\overline {e}}_{b}(k,i)]}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle {\\overline {e}}(k,i+1)={\\frac {1}{\\sqrt {(1-{\\overline {e}}_{b}^{2}(k,i))(1-{\\overline {\\delta }}_{D}^{2}(k,i))}}}[{\\overline {e}}(k,i)-{\\overline {\\delta }}_{D}(k,i){\\overline {e}}_{b}(k,i)]}": {
    "before": "{\\displaystyle {\\overline {e}}(k,i+1)={\\frac {1}{\\sqrt {(1-{\\overline {e}}_{b}^{2}(k,i))(1-{\\overline {\\delta }}_{D}^{2}(k,i))}}}[{\\overline {e}}(k,i)-{\\overline {\\delta }}_{D}(k,i){\\overline {e}}_{b}(k,i)]}",
    "after": "End End",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\textstyle i=0,1,\\ldots ,N.}": {
    "before": "For",
    "after": "{\\displaystyle {\\overline {\\delta }}(-1,i)=0\\,\\!}",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\textstyle x(k)=d(k)=0}": {
    "before": "(if",
    "after": "for",
    "url": "https://en.wikipedia.org/wiki/Recursive least squares filter"
  },
  "{\\displaystyle y_{t}=a_{0}+a_{1}y_{t-1}+a_{2}y_{t-2}+\\cdots +a_{m}y_{t-m}+{\\text{error}}_{t}.}": {
    "before": "Let y and x be stationary time series. To test the null hypothesis that x does not Granger-cause y , one first finds the proper lagged values of y to include in an univariate autoregression of y :",
    "after": "Next, the autoregression is augmented by including lagged values of x :",
    "url": "https://en.wikipedia.org/wiki/Granger causality"
  },
  "{\\displaystyle y_{t}=a_{0}+a_{1}y_{t-1}+a_{2}y_{t-2}+\\cdots +a_{m}y_{t-m}+b_{p}x_{t-p}+\\cdots +b_{q}x_{t-q}+{\\text{error}}_{t}.}": {
    "before": "Next, the autoregression is augmented by including lagged values of x :",
    "after": "One retains in this regression all lagged values of x that are individually significant according to their t-statistics, provided that collectively they add explanatory power to the regression according to an F-test (whose null hypothesis is no explanatory power jointly added by the x' s). In the notation of the above augmented regression, p is the shortest, and q is the longest, lag length for which the lagged value of x is significant.",
    "url": "https://en.wikipedia.org/wiki/Granger causality"
  },
  "{\\displaystyle X(t)=\\sum _{\\tau =1}^{L}A_{\\tau }X(t-\\tau )+\\varepsilon (t),}": {
    "before": "Multivariate Granger causality analysis is usually performed by fitting a vector autoregressive model (VAR) to the time series. In particular, let {\\displaystyle X(t)\\in \\mathbb {R} ^{d\\times 1}} for {\\displaystyle t=1,\\ldots ,T} be a {\\displaystyle d} -dimensional multivariate time series. Granger causality is performed by fitting a VAR model with {\\displaystyle L} time lags as follows:",
    "after": "where {\\displaystyle \\varepsilon (t)} is a white Gaussian random vector, and {\\displaystyle A_{\\tau }} is a matrix for every {\\displaystyle \\tau } . A time series {\\displaystyle X_{i}} is called a Granger cause of another time series {\\displaystyle X_{j}} , if at least one of the elements {\\displaystyle A_{\\tau }(j,i)} for {\\displaystyle \\tau =1,\\ldots ,L} is significantly larger than zero (in absolute value). ",
    "url": "https://en.wikipedia.org/wiki/Granger causality"
  },
  "Y'(N) = W/P": {
    "before": "Some immediate consequences can be drawn. The 'first postulate of classical economics' asserts that the wage is equal to the marginal product, so we might be tempted to write:",
    "after": "Unfortunately this isn't quite correct, since it is necessary to differentiate real output and multiply the result by P rather than differentiating output in money terms. Hicks avoids this difficulty by giving the equation an unusual form, differentiating an independent with respect to a dependent variable [Px = w (dNx/dx)]. He then gives a further equation [written I=wx (dNx/dx)+wy (dNy/dy)] in which the price levels by sector determine the relation between output and income; but if we avoid representing income and output by different symbols we can dispense with this equation.",
    "url": "https://en.wikipedia.org/wiki/Mr. Keynes and the \"Classics\""
  },
  "M = Y/V": {
    "before": "Hicks starts with the quantity theory of money:",
    "after": "where V is the velocity of money. [He himself writes M=kI (where k=1/V). k is Keynes's symbol for the multiplier.]",
    "url": "https://en.wikipedia.org/wiki/Mr. Keynes and the \"Classics\""
  },
  "I (r) = S(Y,r)": {
    "before": "His second equation can be written:",
    "after": "where I (r) is 'the amount of investment (looked at as the demand for capital)' which is 'what becomes of the marginal-efficiency-of-capital schedule in Mr. Keynes's work'. S(Y,r) is the propensity to save (expressed as a function of money income). He suggests that the presence of Y as an argument to S is unnecessary given that it is by now determined by the quantity theory.",
    "url": "https://en.wikipedia.org/wiki/Mr. Keynes and the \"Classics\""
  },
  "M = Y/V I(r) = S(Y,r)": {
    "before": "He contrasts the equations of 'classical' theory:",
    "after": "with those adopted by Keynes:",
    "url": "https://en.wikipedia.org/wiki/Mr. Keynes and the \"Classics\""
  },
  "M = L(r) I(r) = S(Y)": {
    "before": "with those adopted by Keynes:",
    "after": "These differ from the classical equations in two ways. On the one hand, the demand for money is conceived as depending upon the rate of interest (Liquidity Preference)...",
    "url": "https://en.wikipedia.org/wiki/Mr. Keynes and the \"Classics\""
  },
  "M = L(Y,r) I(r) = S(Y)": {
    "before": "Hicks revises the equations to take account of the Chapter 15 theory of liquidity preference:",
    "after": "'With this revision, Mr Keynes takes a big step back to Marshallian orthodoxy.' In fact Keynes considers liquidity preference to be the sum of two functions so that it may be written:",
    "url": "https://en.wikipedia.org/wiki/Mr. Keynes and the \"Classics\""
  },
  "L(Y,r) = L1(Y) + L2(r)": {
    "before": "'With this revision, Mr Keynes takes a big step back to Marshallian orthodoxy.' In fact Keynes considers liquidity preference to be the sum of two functions so that it may be written:",
    "after": "IS-LM model.Here L1 is the sum of transactions and precautionary demands and L2 is speculative demand. The form L(Y,r) is slightly more general than Keynes's L1(Y) + L2(r) but the difference is purely notational.",
    "url": "https://en.wikipedia.org/wiki/Mr. Keynes and the \"Classics\""
  },
  "M = M1 + M2 = L1(Y) + L2(r)": {
    "before": "In Chapter 15 Keynes offers a new model of liquidity preference. He writes M1 and M2 as the amounts of money held in the first case for the transactions and precautionary motives combined, in the second for the speculative motive, and writes L1 and L2 as the associated demands. He then writes (on p199)",
    "after": "This is the source of Hicks's M = L(Y,r). It follows that 'the quantity of money... in conjunction with liquidity-preference' can no longer determine the 'actual rate of interest' on their own and that the statement of Keynes's theory in Chapter 14 needs to be modified.",
    "url": "https://en.wikipedia.org/wiki/Mr. Keynes and the \"Classics\""
  },
  "This is the source of Hicks's M = L(Y,r). It follows that 'the quantity of money... in conjunction with liquidity-preference' can no longer determine the 'actual rate of interest' on their own and that the statement of Keynes's theory in Chapter 14 needs to be modified.": {
    "before": "M = M1 + M2 = L1(Y) + L2(r)",
    "after": "It is not hard to see how to do this. Liquidity preference imposes a relationship between the interest rate and income for a given quantity of money, and this can be combined with the equation I(r) = S(Y) exactly as was done by Hicks. It is not a step which Keynes himself took. In his Chapter 18 'restatement' he recapitulates the account he has already presented in Chapter 14, but remarking in addition that a change in employment is liable 'to raise (or lower) the schedule of liquidity-preference' and that 'the position of equilibrium will be influenced by these repercussions'. Hicks put this in systematic form. When 'Mr Keynes and the Classics' was published, Keynes gave its 'IS-LL equilibrium model' his 'largely unqualified acceptance'.",
    "url": "https://en.wikipedia.org/wiki/Mr. Keynes and the \"Classics\""
  },
  "L(Y,r) = Y + 1/(r–ε)": {
    "before": "The full orange line in the graph shows an LM curve satisfying Keynes's and Hicks's postulates. It corresponds to the liquidity preference function",
    "after": "and is a standard rectangular hyperbola. The 'maximum to the level of income which can possibly be financed with the given level of money' is M itself, and the 'minimum below which the rate of interest is unlikely to go' might be taken as either ε or ε+1/M according to preference, and ε can be taken as positive, negative, or zero to accommodate different views of this minimum. As r approaches ε from above the speculative demand for money becomes infinite, and r can decrease no further.",
    "url": "https://en.wikipedia.org/wiki/Mr. Keynes and the \"Classics\""
  },
  "{\\displaystyle C_{t}=C_{0}+cY_{t-1}} {\\displaystyle 1/(1-c(1-t)+m)}": {
    "before": "American Economist Paul Samuelson credited Alvin Hansen for the inspiration behind his seminal 1939 contribution. The original Samuelson multiplier-accelerator model (or, as he belatedly baptised it, the \"Hansen-Samuelson\" model) relies on a multiplier mechanism that is based on a simple Keynesian consumption function with a Robertsonian lag:",
    "after": "so present consumption is a function of past income (with c as the marginal propensity to consume ). Here, t is the tax rate and m is the ratio of imports to GDP. Investment, in turn, is assumed to be composed of three parts:",
    "url": "https://en.wikipedia.org/wiki/Multiplier (economics)"
  },
  "{\\displaystyle I_{t}=I_{0}+I(r)+b(C_{t}-C_{t-1})}": {
    "before": "so present consumption is a function of past income (with c as the marginal propensity to consume ). Here, t is the tax rate and m is the ratio of imports to GDP. Investment, in turn, is assumed to be composed of three parts:",
    "after": "The first part is autonomous investment, the second is investment induced by interest rates and the final part is investment induced by changes in consumption demand (the \" acceleration \" principle). It is assumed that b > 0. As we are concentrating on the income-expenditure side, let us assume I(r) = 0 (or alternatively, constant interest), so that:",
    "url": "https://en.wikipedia.org/wiki/Multiplier (economics)"
  },
  "{\\displaystyle I_{t}=I_{0}+b(C_{t}-C_{t-1})}": {
    "before": "The first part is autonomous investment, the second is investment induced by interest rates and the final part is investment induced by changes in consumption demand (the \" acceleration \" principle). It is assumed that b > 0. As we are concentrating on the income-expenditure side, let us assume I(r) = 0 (or alternatively, constant interest), so that:",
    "after": "Now, assuming away government and foreign sector, aggregate demand at time t is:",
    "url": "https://en.wikipedia.org/wiki/Multiplier (economics)"
  },
  "{\\displaystyle Ytd=C_{t}+I_{t}=C_{0}+I_{0}+cY_{t-1}+b(C_{t}-C_{t-1})}": {
    "before": "Now, assuming away government and foreign sector, aggregate demand at time t is:",
    "after": "assuming goods market equilibrium (so {\\displaystyle Y_{t}=Ytd} ), then in equilibrium:",
    "url": "https://en.wikipedia.org/wiki/Multiplier (economics)"
  },
  "{\\displaystyle Y_{t}=C_{0}+I_{0}+cY_{t-1}+b(C_{t}-C_{t-1})}": {
    "before": "assuming goods market equilibrium (so {\\displaystyle Y_{t}=Ytd} ), then in equilibrium:",
    "after": "But we know the values of {\\displaystyle C_{t}} and {\\displaystyle C_{t-1}} are merely {\\displaystyle C_{t}=C_{0}+cY_{t-1}} and {\\displaystyle C_{t-1}=C_{0}+cY_{t-2}} respectively, then substituting these in:",
    "url": "https://en.wikipedia.org/wiki/Multiplier (economics)"
  },
  "{\\displaystyle Y_{t}=C_{0}+I_{0}+cY_{t-1}+b(C_{0}+cY_{t-1}-C_{0}-cY_{t-2})}": {
    "before": "But we know the values of {\\displaystyle C_{t}} and {\\displaystyle C_{t-1}} are merely {\\displaystyle C_{t}=C_{0}+cY_{t-1}} and {\\displaystyle C_{t-1}=C_{0}+cY_{t-2}} respectively, then substituting these in:",
    "after": "or, rearranging and rewriting as a second order linear difference equation :",
    "url": "https://en.wikipedia.org/wiki/Multiplier (economics)"
  },
  "{\\displaystyle Y_{t}-(1+b)cY_{t-1}+bcY_{t-2}=(C_{0}+I_{0})}": {
    "before": "or, rearranging and rewriting as a second order linear difference equation :",
    "after": "The solution to this system then becomes elementary. The equilibrium level of Y (call it {\\displaystyle Y_{p}} , the particular solution) is easily solved by letting {\\displaystyle Y_{t}=Y_{t-1}=Y_{t-2}=Y_{p}} , or:",
    "url": "https://en.wikipedia.org/wiki/Multiplier (economics)"
  },
  "{\\displaystyle (1-c-bc+bc)Y_{p}=(C_{0}+I_{0})}": {
    "before": "The solution to this system then becomes elementary. The equilibrium level of Y (call it {\\displaystyle Y_{p}} , the particular solution) is easily solved by letting {\\displaystyle Y_{t}=Y_{t-1}=Y_{t-2}=Y_{p}} , or:",
    "after": "so: {\\displaystyle Y_{p}=(C_{0}+I_{0})/(1-c)}",
    "url": "https://en.wikipedia.org/wiki/Multiplier (economics)"
  },
  "{\\displaystyle Y_{p}=(C_{0}+I_{0})/(1-c)}": {
    "before": "{\\displaystyle (1-c-bc+bc)Y_{p}=(C_{0}+I_{0})} so:",
    "after": "The complementary function, {\\displaystyle Y_{c}} is also easy to determine. Namely, we know that it will have the form {\\displaystyle Y_{c}=A_{1}r_{1}t+A_{2}r_{2}t} where {\\displaystyle A_{1}} and {\\displaystyle A_{2}} are arbitrary constants to be defined and where {\\displaystyle r_{1}} and {\\displaystyle r_{2}} are the two eigenvalues (characteristic roots) of the following characteristic equation:",
    "url": "https://en.wikipedia.org/wiki/Multiplier (economics)"
  },
  "{\\displaystyle \\tan 2\\theta _{0}={\\frac {K\\sum _{k=0}^{K-1}\\sin 2\\omega t_{k}-2\\left(\\sum _{k=0}^{K-1}\\cos \\omega t_{k}\\right)\\left(\\sum _{k=0}^{K-1}\\sin \\omega t_{k}\\right)}{K\\sum _{k=0}^{K-1}\\cos 2\\omega t_{k}-{\\big (}\\sum _{k=0}^{K-1}\\cos \\omega t_{k}{\\big )}^{2}+{\\big (}\\sum _{k=0}^{K-1}\\sin \\omega t_{k}{\\big )}^{2}}},}": {
    "before": "Considering a time series to be represented by a set of {\\displaystyle K} pairs {\\displaystyle (t_{k},x_{k})} , the amplitude pdf of white noise in Fourier space , depending on frequency and phase angle may be described in terms of three parameters, {\\displaystyle \\alpha _{0}} , {\\displaystyle \\beta _{0}} , {\\displaystyle \\theta _{0}} , defining the “sampling profile”, according to",
    "after": "{\\displaystyle \\alpha _{0}={\\sqrt {{\\frac {2}{K^{2}}}\\left(K\\sum _{k=0}^{K-1}\\cos ^{2}\\left(\\omega t_{k}-\\theta _{0}\\right)-\\left[\\sum _{l=0}^{K-1}\\cos \\left(\\omega t_{k}-\\theta _{0}\\right)\\right]^{2}\\right)}},}",
    "url": "https://en.wikipedia.org/wiki/SigSpec"
  },
  "{\\displaystyle \\alpha _{0}={\\sqrt {{\\frac {2}{K^{2}}}\\left(K\\sum _{k=0}^{K-1}\\cos ^{2}\\left(\\omega t_{k}-\\theta _{0}\\right)-\\left[\\sum _{l=0}^{K-1}\\cos \\left(\\omega t_{k}-\\theta _{0}\\right)\\right]^{2}\\right)}},}": {
    "before": "{\\displaystyle \\tan 2\\theta _{0}={\\frac {K\\sum _{k=0}^{K-1}\\sin 2\\omega t_{k}-2\\left(\\sum _{k=0}^{K-1}\\cos \\omega t_{k}\\right)\\left(\\sum _{k=0}^{K-1}\\sin \\omega t_{k}\\right)}{K\\sum _{k=0}^{K-1}\\cos 2\\omega t_{k}-{\\big (}\\sum _{k=0}^{K-1}\\cos \\omega t_{k}{\\big )}^{2}+{\\big (}\\sum _{k=0}^{K-1}\\sin \\omega t_{k}{\\big )}^{2}}},}",
    "after": "{\\displaystyle \\beta _{0}={\\sqrt {{\\frac {2}{K^{2}}}\\left(K\\sum _{k=0}^{K-1}\\sin ^{2}\\left(\\omega t_{k}-\\theta _{0}\\right)-\\left[\\sum _{l=0}^{K-1}\\sin \\left(\\omega t_{k}-\\theta _{0}\\right)\\right]^{2}\\right)}}.}",
    "url": "https://en.wikipedia.org/wiki/SigSpec"
  },
  "{\\displaystyle \\beta _{0}={\\sqrt {{\\frac {2}{K^{2}}}\\left(K\\sum _{k=0}^{K-1}\\sin ^{2}\\left(\\omega t_{k}-\\theta _{0}\\right)-\\left[\\sum _{l=0}^{K-1}\\sin \\left(\\omega t_{k}-\\theta _{0}\\right)\\right]^{2}\\right)}}.}": {
    "before": "{\\displaystyle \\alpha _{0}={\\sqrt {{\\frac {2}{K^{2}}}\\left(K\\sum _{k=0}^{K-1}\\cos ^{2}\\left(\\omega t_{k}-\\theta _{0}\\right)-\\left[\\sum _{l=0}^{K-1}\\cos \\left(\\omega t_{k}-\\theta _{0}\\right)\\right]^{2}\\right)}},}",
    "after": "In terms of the phase angle in Fourier space, {\\displaystyle \\theta } , with",
    "url": "https://en.wikipedia.org/wiki/SigSpec"
  },
  "{\\displaystyle \\tan \\theta ={\\frac {\\sum _{k=0}^{K-1}\\sin \\omega t_{k}}{\\sum _{k=0}^{K-1}\\cos \\omega t_{k}}},}": {
    "before": "In terms of the phase angle in Fourier space, {\\displaystyle \\theta } , with",
    "after": "the probability density of amplitudes is given by",
    "url": "https://en.wikipedia.org/wiki/SigSpec"
  },
  "{\\displaystyle \\phi (A)={\\frac {KA\\cdot \\operatorname {sock} }{2<x^{2}>}}\\exp \\left(-{\\frac {KA^{2}}{4<x^{2}>}}\\cdot \\operatorname {sock} \\right),}": {
    "before": "{\\displaystyle \\tan \\theta ={\\frac {\\sum _{k=0}^{K-1}\\sin \\omega t_{k}}{\\sum _{k=0}^{K-1}\\cos \\omega t_{k}}},} the probability density of amplitudes is given by",
    "after": "where the sock function is defined by",
    "url": "https://en.wikipedia.org/wiki/SigSpec"
  },
  "{\\displaystyle \\operatorname {sock} (\\omega ,\\theta )=\\left[{\\frac {\\cos ^{2}\\left(\\theta -\\theta _{0}\\right)}{\\alpha _{0}^{2}}}+{\\frac {\\sin ^{2}\\left(\\theta -\\theta _{0}\\right)}{\\beta _{0}^{2}}}\\right]}": {
    "before": "{\\displaystyle \\phi (A)={\\frac {KA\\cdot \\operatorname {sock} }{2<x^{2}>}}\\exp \\left(-{\\frac {KA^{2}}{4<x^{2}>}}\\cdot \\operatorname {sock} \\right),} where the sock function is defined by",
    "after": "and {\\displaystyle <x^{2}>} denotes the variance of the dependent variable {\\displaystyle x_{k}} .",
    "url": "https://en.wikipedia.org/wiki/SigSpec"
  },
  "{\\displaystyle \\Phi _{\\operatorname {FA} }(A)=\\exp \\left(-{\\frac {KA^{2}}{4<x^{2}>}}\\cdot \\operatorname {sock} \\right).}": {
    "before": "Integration of the pdf yields the false-alarm probability that white noise in the time domain produces an amplitude of at least {\\displaystyle A} ,",
    "after": "The sig is defined as the negative logarithm of the false-alarm probability and evaluates to",
    "url": "https://en.wikipedia.org/wiki/SigSpec"
  },
  "{\\displaystyle \\operatorname {sig} (A)={\\frac {KA^{2}\\log e}{4<x^{2}>}}\\cdot \\operatorname {sock} .}": {
    "before": "The sig is defined as the negative logarithm of the false-alarm probability and evaluates to",
    "after": "It returns the number of random time series one would have to examine to obtain one amplitude exceeding {\\displaystyle A} at the given frequency and phase.",
    "url": "https://en.wikipedia.org/wiki/SigSpec"
  },
  "{\\displaystyle L=0.25A+0.75B}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Von Neumann–Morgenstern utility theorem"
  },
  "{\\displaystyle L=\\sum p_{i}A_{i},}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Von Neumann–Morgenstern utility theorem"
  },
  "{\\displaystyle Eu(p_{1}A_{1}+\\cdots +p_{n}A_{n})=p_{1}u(A_{1})+\\cdots +p_{n}u(A_{n}).}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Von Neumann–Morgenstern utility theorem"
  },
  "{\\displaystyle u(A_{1})=0} and {\\displaystyle u(A_{n})=1}": {
    "before": "We assume that at least one of the inequalities is strict (otherwise the utility function is trivial—a constant). So {\\displaystyle A_{1}\\prec A_{n}} . We use these two extreme outcomes—the worst and the best—as the scaling unit of our utility function, and define:",
    "after": "For every probability {\\displaystyle p\\in [0,1]} , define a lottery that selects the best outcome with probability {\\displaystyle p} and the worst outcome otherwise:",
    "url": "https://en.wikipedia.org/wiki/Von Neumann–Morgenstern utility theorem"
  },
  "{\\displaystyle L(p)=p\\cdot A_{n}+(1-p)\\cdot A_{1}}": {
    "before": "For every probability {\\displaystyle p\\in [0,1]} , define a lottery that selects the best outcome with probability {\\displaystyle p} and the worst outcome otherwise:",
    "after": "Note that {\\displaystyle L(0)\\sim A_{1}} and {\\displaystyle L(1)\\sim A_{n}} .",
    "url": "https://en.wikipedia.org/wiki/Von Neumann–Morgenstern utility theorem"
  },
  "{\\displaystyle 0=q_{1}\\leq q_{2}\\leq \\cdots \\leq q_{n}=1}": {
    "before": "{\\displaystyle L(q_{i})\\sim A_{i}} and",
    "after": "For every {\\displaystyle i} , the utility function for outcome {\\displaystyle A_{i}} is defined as",
    "url": "https://en.wikipedia.org/wiki/Von Neumann–Morgenstern utility theorem"
  },
  "{\\displaystyle u(A_{i})=q_{i}}": {
    "before": "For every {\\displaystyle i} , the utility function for outcome {\\displaystyle A_{i}} is defined as",
    "after": "so the utility of every lottery {\\displaystyle M=\\sum _{i}p_{i}A_{i}} is the expectation of u :",
    "url": "https://en.wikipedia.org/wiki/Von Neumann–Morgenstern utility theorem"
  },
  "{\\displaystyle u(M)=u\\left(\\sum _{i}p_{i}A_{i}\\right)=\\sum _{i}p_{i}u(A_{i})=\\sum _{i}p_{i}q_{i}}": {
    "before": "so the utility of every lottery {\\displaystyle M=\\sum _{i}p_{i}A_{i}} is the expectation of u :",
    "after": "To see why this utility function makes sense, consider a lottery {\\displaystyle M=\\sum _{i}p_{i}A_{i}} , which selects outcome {\\displaystyle A_{i}} with probability {\\displaystyle p_{i}} . But, by our assumption, the decision maker is indifferent between the sure outcome {\\displaystyle A_{i}} and the lottery {\\displaystyle q_{i}\\cdot A_{n}+(1-q_{i})\\cdot A_{1}} . So, by the Reduction axiom, he is indifferent between the lottery {\\displaystyle M} and the following lottery:",
    "url": "https://en.wikipedia.org/wiki/Von Neumann–Morgenstern utility theorem"
  },
  "{\\displaystyle M'=\\sum _{i}p_{i}[q_{i}\\cdot A_{n}+(1-q_{i})\\cdot A_{1}]} {\\displaystyle M'=\\left(\\sum _{i}p_{i}q_{i}\\right)\\cdot A_{n}+\\left(\\sum _{i}p_{i}(1-q_{i})\\right)\\cdot A_{1}} {\\displaystyle M'=u(M)\\cdot A_{n}+(1-u(M))\\cdot A_{1}}": {
    "before": "To see why this utility function makes sense, consider a lottery {\\displaystyle M=\\sum _{i}p_{i}A_{i}} , which selects outcome {\\displaystyle A_{i}} with probability {\\displaystyle p_{i}} . But, by our assumption, the decision maker is indifferent between the sure outcome {\\displaystyle A_{i}} and the lottery {\\displaystyle q_{i}\\cdot A_{n}+(1-q_{i})\\cdot A_{1}} . So, by the Reduction axiom, he is indifferent between the lottery {\\displaystyle M} and the following lottery:",
    "after": "The lottery {\\displaystyle M'} is, in effect, a lottery in which the best outcome is won with probability {\\displaystyle u(M)} , and the worst outcome otherwise.",
    "url": "https://en.wikipedia.org/wiki/Von Neumann–Morgenstern utility theorem"
  },
  "denotes a scenario where P(A) = 25% is the probability of A occurring and P(B) = 75% (and exactly one of them will occur). More generally, for a lottery with many possible outcomes Ai, we write:": {
    "before": "{\\displaystyle L=0.25A+0.75B}",
    "after": "{\\displaystyle L=\\sum p_{i}A_{i},}",
    "url": "https://en.wikipedia.org/wiki/Von Neumann–Morgenstern utility theorem"
  },
  "{\\displaystyle X(t)=K\\exp \\left(\\log \\left({\\frac {X(0)}{K}}\\right)\\exp \\left(-\\alpha t\\right)\\right)}": {
    "before": "In the 1960s A.K. Laird  for the first time successfully used the Gompertz curve to fit data of growth of tumors. In fact, tumors are cellular populations growing in a confined space where the availability of nutrients is limited. Denoting the tumor size as X(t) it is useful to write the Gompertz Curve as follows:",
    "after": "where: {\\textstyle X(0)} is the tumor size at the starting observation time; {\\textstyle K} is the carrying capacity, i.e. the maximum size that can be reached with the available nutrients. In fact it is: {\\displaystyle \\lim _{t\\rightarrow +\\infty }X(t)=K}",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "{\\displaystyle k^{r}\\propto {\\frac {1}{y(t)}}}": {
    "before": "",
    "after": "{\\textstyle r={\\frac {y'(t)}{y(t)}}} is the rate of growth k is an arbitrary constant.",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "{\\displaystyle N(t)=N_{0}\\exp(\\ln(N_{I}/N_{0})(1-\\exp(-bt)))}": {
    "before": "",
    "after": "{\\textstyle t} is time {\\textstyle N_{0}} is the initial density of cells {\\textstyle N_{I}} is the plateau cell/population density {\\textstyle b} is the initial rate of tumor growth",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "{\\textstyle \\lim _{t\\to \\infty }a\\mathrm {e} ^{-b\\mathrm {e} ^{-ct}}=a\\mathrm {e} ^{0}=a}": {
    "before": "a is an asymptote, since",
    "after": "b sets the displacement along the x-axis (translates the graph to the left or right).",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "{\\textstyle f(t)=a/2}": {
    "before": "The halfway point is found by solving",
    "after": "for t.",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "{\\textstyle B}= energy organism uses at rest": {
    "before": "{\\displaystyle B=\\sum _{C}(N_{C}B_{C})+\\left(E_{C}{\\operatorname {d} \\!N_{C} \\over \\operatorname {d} \\!t}\\right)}",
    "after": "{\\textstyle N_{C}}",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "{\\textstyle N_{C}}= number of cells in the given organism": {
    "before": "= energy organism uses at rest",
    "after": "{\\textstyle B_{C}}",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "{\\textstyle B_{C}}= metabolic rate of an individual cell": {
    "before": "= number of cells in the given organism",
    "after": "{\\textstyle N_{C}B_{C}}",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "{\\textstyle N_{C}B_{C}}= energy required to maintain the existing tissue": {
    "before": "= metabolic rate of an individual cell",
    "after": "{\\textstyle E_{C}}",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "{\\textstyle E_{C}}= energy required to create new tissue from an individual cell": {
    "before": "= energy required to maintain the existing tissue",
    "after": "The differentiation between energy used at rest and metabolic rate work allows for the model to more precisely determine the rate of growth. The energy at rest is lower than the energy used to maintain a tissue, and together represent the energy required to maintain the existing tissue. The use of these two factors, alongside the energy required to create new tissue, comprehensively map the rate of growth, and moreover, lead in to an accurate representation of the lag phase.",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "{\\textstyle \\lim _{t\\to \\infty }a\\mathrm {e} ^{-\\mathrm {e} ^{b-ct}}+d=a\\mathrm {e} ^{0}+d=a+d}": {
    "before": "a is the distance from the base to the second asymptote, since",
    "after": "b sets the displacement along the x-axis (translates the graph to the left or right).",
    "url": "https://en.wikipedia.org/wiki/Gompertz function"
  },
  "Vote=a(Saliency of the party's issues)+b(Saliency of the party's issues)": {
    "before": "The Linear Position Model attempts to predict how strongly an individual will issue vote in an election. The model suggests that the more a voter and candidate agree on a particular issue, the better chance the candidate has of receiving the individual's vote.   In this model, a graph is used to display the relationship between the number of people voting for the party and the consistency of the issue position.   The equation “Y = a + bX” is used, where the variable “a” represents the minimal numbert of people voting for the party, “b” is a variable used to ensure that there is a positive gradient, \"X\" represents the consistency of the party's issue position, and Y represents the number of people who vote for the party.   The Spatial Model attempts to show the perceptions and decisions of voters when issue voting strategies are used in elections.  This model assumes that if someone's issue preferences are placed on a hypothetical spatial field along with all possible candidates’ policy positions, the individual will vote for the candidate whose political stances are closest to their own.   Other models that follow the idea of “closeness” are called proximity models.  The Salience Model asserts that the two major parties in the United States are associated with certain goals or views on an issue, and that the voter's decision in selecting a candidate depends on the actual salience of the issue to the voter.   This model is important when considering issue voting because it utilizes election agenda data to predict election outcome.   A simple view of this model can be summarized with the equation:",
    "after": "where \"a\"=Party 1, and \"b\"=Party 2. The more important the issue becomes, the more a voter favors a particular candidate or party on the issue.  ",
    "url": "https://en.wikipedia.org/wiki/Issue voting"
  },
  "{\\displaystyle M\\cdot V_{T}=\\sum _{i}(p_{i}\\cdot q_{i})=\\mathbf {p} ^{\\mathrm {T} }\\mathbf {q} }": {
    "before": "In its modern form, the quantity theory builds upon the following definitional relationship.",
    "after": "where {\\displaystyle M\\,} is the total amount of money in circulation on average in an economy during the period, say a year. {\\displaystyle V_{T}\\,} is the transactions velocity of money , that is the average frequency across all transactions with which a unit of money is spent. This reflects availability of financial institutions, economic variables, and choices made as to how fast people turn over their money. {\\displaystyle p_{i}\\,} and {\\displaystyle q_{i}\\,} are the price and quantity of the i-th transaction. {\\displaystyle \\mathbf {p} } is a column vector of the {\\displaystyle p_{i}\\,} , and the superscript T is the transpose operator. {\\displaystyle \\mathbf {q} } is a column vector of the {\\displaystyle q_{i}\\,} .",
    "url": "https://en.wikipedia.org/wiki/Quantity theory of money"
  },
  "{\\displaystyle M\\cdot V_{T}=P_{T}\\cdot T}": {
    "before": "Mainstream economics accepts a simplification, the equation of exchange :",
    "after": "where {\\displaystyle P_{T}} is the price level associated with transactions for the economy during the period {\\displaystyle T} is an index of the real value of aggregate transactions.",
    "url": "https://en.wikipedia.org/wiki/Quantity theory of money"
  },
  "{\\displaystyle M^{\\textit {d}}={\\textit {k}}\\cdot P\\cdot Y}": {
    "before": "Economists Alfred Marshall , A.C. Pigou , and John Maynard Keynes (before he developed his own, eponymous school of thought) associated with Cambridge University , took a slightly different approach to the quantity theory, focusing on money demand instead of money supply. They argued that a certain portion of the money supply will not be used for transactions; instead, it will be held for the convenience and security of having cash on hand. This portion of cash is commonly represented as k , a portion of nominal income ( {\\displaystyle P\\cdot Y} ). The Cambridge economists also thought wealth would play a role, but wealth is often omitted for simplicity. The Cambridge equation is thus:",
    "after": "Assuming that the economy is at equilibrium ( {\\displaystyle M^{\\textit {d}}=M} ), {\\displaystyle Y} is exogenous , and k is fixed in the short run, the Cambridge equation is equivalent to the equation of exchange with velocity equal to the inverse of k :",
    "url": "https://en.wikipedia.org/wiki/Quantity theory of money"
  },
  "{\\displaystyle M\\cdot {\\frac {1}{k}}=P\\cdot Y}": {
    "before": "Assuming that the economy is at equilibrium ( {\\displaystyle M^{\\textit {d}}=M} ), {\\displaystyle Y} is exogenous , and k is fixed in the short run, the Cambridge equation is equivalent to the equation of exchange with velocity equal to the inverse of k :",
    "after": "The Cambridge version of the quantity theory led to both Keynes's attack on the quantity theory and the Monetarist revival of the theory. ",
    "url": "https://en.wikipedia.org/wiki/Quantity theory of money"
  },
  "{\\displaystyle (1)PQ={f}({\\overset {+}{M}})} {\\displaystyle (2)P={g}({\\overset {+}{M}})}": {
    "before": "As restated by Milton Friedman, the quantity theory emphasizes the following relationship of the nominal value of expenditures {\\displaystyle PQ} and the price level {\\displaystyle P} to the quantity of money {\\displaystyle M} :",
    "after": "The plus signs indicate that a change in the money supply is hypothesized to change nominal expenditures and the price level in the same direction (for other variables held constant ).",
    "url": "https://en.wikipedia.org/wiki/Quantity theory of money"
  },
  "{\\displaystyle MM=1\\div RR}": {
    "before": "Friedman also developed the \"Money Multiplier\" , which demonstrated how much a change in the reserve ratio of banks would change the money supply.  In the formula, {\\displaystyle RR} represents the reserve ratio, while {\\displaystyle MM} represents the money multiplier. ",
    "after": "Principles [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Quantity theory of money"
  },
  ">> x = 'hat'": {
    "before": "17",
    "after": "x =",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "x =hat": {
    "before": ">> x = 'hat'",
    "after": ">> x = [3*4, pi/2]",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  ">> x = [3*4, pi/2]": {
    "before": "hat",
    "after": "x =",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  ">> y = 3*sin(x)": {
    "before": "12.0000 1.5708",
    "after": "y =",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  ">> A = [1 ; 2], B = A.', C = transpose(A)": {
    "before": "Transposing a vector or a matrix is done either by the function transpose or by adding dot-prime after the matrix (without the dot, prime will perform conjugate transpose for complex arrays):",
    "after": "A =",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  ">> D = [0, 3 ; 1, 5], D.'": {
    "before": "1 2",
    "after": "D =",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "[J,I] = meshgrid(1:n);": {
    "before": "Most functions accept arrays as input and operate element-wise on each element. For example, mod(2*J,n) will multiply every element in J by 2, and then reduce each element modulo n. MATLAB does include standard for and while loops, but (as in other similar applications such as R), using the vectorized notation is encouraged and is often faster to execute. The following code, excerpted from the function magic.m, creates a magic square M for odd values of n (MATLAB function meshgrid is used here to generate square matrices I and J containing 1:n):",
    "after": "A = mod(I + J - (n + 3) / 2, n);",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "A = mod(I + J - (n + 3) / 2, n);": {
    "before": "[J,I] = meshgrid(1:n);",
    "after": "B = mod(I + 2 * J - 2, n);",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "B = mod(I + 2 * J - 2, n);": {
    "before": "A = mod(I + J - (n + 3) / 2, n);",
    "after": "M = n * A + B + 1;",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "M = n * A + B + 1;": {
    "before": "B = mod(I + 2 * J - 2, n);",
    "after": "Structures[edit]",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "rgbImage = imread('ecg.png');": {
    "before": "When creating a MATLAB function, the name of the file should match the name of the first function in the file. Valid function names begin with an alphabetic character, and can contain letters, numbers, or underscores. Variables and functions are case sensitive.",
    "after": "grayImage = rgb2gray(rgbImage); % for non-indexed images",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "grayImage = rgb2gray(rgbImage); % for non-indexed images": {
    "before": "rgbImage = imread('ecg.png');",
    "after": "level = graythresh(grayImage); % threshold for converting image to binary,",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "level = graythresh(grayImage); % threshold for converting image to binary,": {
    "before": "grayImage = rgb2gray(rgbImage); % for non-indexed images",
    "after": "binaryImage = im2bw(grayImage, level);",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "binaryImage = im2bw(grayImage, level);": {
    "before": "level = graythresh(grayImage); % threshold for converting image to binary,",
    "after": "% Extract the individual red, green, and blue color channels.",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "redChannel = rgbImage(:, :, 1);": {
    "before": "% Extract the individual red, green, and blue color channels.",
    "after": "greenChannel = rgbImage(:, :, 2);",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "greenChannel = rgbImage(:, :, 2);": {
    "before": "redChannel = rgbImage(:, :, 1);",
    "after": "blueChannel = rgbImage(:, :, 3);",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "blueChannel = rgbImage(:, :, 3);": {
    "before": "greenChannel = rgbImage(:, :, 2);",
    "after": "% Make the black parts pure red.",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "rgbImageOut = cat(3, redChannel, greenChannel, blueChannel);": {
    "before": "% Now recombine to form the output image.",
    "after": "imshow(rgbImageOut);",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  ">> x = Hello();": {
    "before": "When put into a file named hello.m, this can be executed with the following commands:",
    "after": ">> x.greet();",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "x = 0:pi/100:2*pi;": {
    "before": "MATLAB has tightly integrated graph-plotting features. For example, the function plot can be used to produce a graph from two vectors x and y. The code:",
    "after": "y = sin(x);",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "y = sin(x);": {
    "before": "x = 0:pi/100:2*pi;",
    "after": "plot(x,y)",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "[X,Y] = meshgrid(-10:0.25:10,-10:0.25:10);": {
    "before": "hidden off",
    "after": "f = sinc(sqrt((X/pi).^2+(Y/pi).^2));",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "f = sinc(sqrt((X/pi).^2+(Y/pi).^2));": {
    "before": "[X,Y] = meshgrid(-10:0.25:10,-10:0.25:10);",
    "after": "surf(X,Y,f);",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "new name=value syntax for passing function arguments; new Class Diagram tool; new MATLAB API for XML Processing (MAXP) matlab.io.xml.*; new bubblecloud graphics function.": {
    "before": "March 11, 2021",
    "after": "9.11",
    "url": "https://en.wikipedia.org/wiki/MATLAB"
  },
  "{\\displaystyle X_{t}=\\sum _{i=1}^{p}\\varphi _{i}B^{i}X_{t}+\\varepsilon _{t}}": {
    "before": "where {\\displaystyle \\varphi _{1},\\ldots ,\\varphi _{p}} are the parameters of the model, and {\\displaystyle \\varepsilon _{t}} is white noise .   This can be equivalently written using the backshift operator B as",
    "after": "so that, moving the summation term to the left side and using polynomial notation , we have",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\phi [B]X_{t}=\\varepsilon _{t}}": {
    "before": "so that, moving the summation term to the left side and using polynomial notation , we have",
    "after": "An autoregressive model can thus be viewed as the output of an all- pole infinite impulse response filter whose input is white noise.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\phi (B)X_{t}=\\varepsilon _{t}\\,}": {
    "before": "Because each shock affects X values infinitely far into the future from when they occur, any given value X t is affected by shocks occurring infinitely far into the past. This can also be seen by rewriting the autoregression",
    "after": "(where the constant term has been suppressed by assuming that the variable has been measured as deviations from its mean) as",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle X_{t}={\\frac {1}{\\phi (B)}}\\varepsilon _{t}\\,.}": {
    "before": "(where the constant term has been suppressed by assuming that the variable has been measured as deviations from its mean) as",
    "after": "When the polynomial division on the right side is carried out, the polynomial in the backshift operator applied to {\\displaystyle \\varepsilon _{t}} has an infinite order—that is, an infinite number of lagged values of {\\displaystyle \\varepsilon _{t}} appear on the right side of the equation.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\rho (\\tau )=\\sum _{k=1}^{p}a_{k}y_{k}^{-|\\tau |},}": {
    "before": "The autocorrelation function of an AR( p ) process can be expressed as [ citation needed ]",
    "after": "where {\\displaystyle y_{k}} are the roots of the polynomial",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\phi (B)=1-\\sum _{k=1}^{p}\\varphi _{k}B^{k}}": {
    "before": "where {\\displaystyle y_{k}} are the roots of the polynomial",
    "after": "where B is the backshift operator , where {\\displaystyle \\phi (\\cdot )} is the function defining the autoregression, and where {\\displaystyle \\varphi _{k}} are the coefficients in the autoregression. The formula is valid only if all the roots have multiplicity 1. [ citation needed ]",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle {\\textrm {var}}(X_{t})=\\operatorname {E} (X_{t}^{2})-\\mu ^{2}={\\frac {\\sigma _{\\varepsilon }^{2}}{1-\\varphi ^{2}}},}": {
    "before": "{\\displaystyle \\mu =0.} The variance is",
    "after": "where {\\displaystyle \\sigma _{\\varepsilon }} is the standard deviation of {\\displaystyle \\varepsilon _{t}} . This can be shown by noting that",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle {\\textrm {var}}(X_{t})=\\varphi ^{2}{\\textrm {var}}(X_{t-1})+\\sigma _{\\varepsilon }^{2},}": {
    "before": "where {\\displaystyle \\sigma _{\\varepsilon }} is the standard deviation of {\\displaystyle \\varepsilon _{t}} . This can be shown by noting that",
    "after": "and then by noticing that the quantity above is a stable fixed point of this relation.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle B_{n}=\\operatorname {E} (X_{t+n}X_{t})-\\mu ^{2}={\\frac {\\sigma _{\\varepsilon }^{2}}{1-\\varphi ^{2}}}\\,\\,\\varphi ^{|n|}.}": {
    "before": "and then by noticing that the quantity above is a stable fixed point of this relation.The autocovariance is given by",
    "after": "It can be seen that the autocovariance function decays with a decay time (also called time constant ) of {\\displaystyle \\tau =1-\\varphi } . ",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\Phi (\\omega )={\\frac {1}{\\sqrt {2\\pi }}}\\,\\sum _{n=-\\infty }^{\\infty }B_{n}e^{-i\\omega n}={\\frac {1}{\\sqrt {2\\pi }}}\\,\\left({\\frac {\\sigma _{\\varepsilon }^{2}}{1+\\varphi ^{2}-2\\varphi \\cos(\\omega )}}\\right).}": {
    "before": "The spectral density function is the Fourier transform of the autocovariance function. In discrete terms this will be the discrete-time Fourier transform:",
    "after": "This expression is periodic due to the discrete nature of the {\\displaystyle X_{j}} , which is manifested as the cosine term in the denominator. If we assume that the sampling time ( {\\displaystyle \\Delta t=1} ) is much smaller than the decay time ( {\\displaystyle \\tau } ), then we can use a continuum approximation to {\\displaystyle B_{n}} :",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\Phi (\\omega )={\\frac {1}{\\sqrt {2\\pi }}}\\,{\\frac {\\sigma _{\\varepsilon }^{2}}{1-\\varphi ^{2}}}\\,{\\frac {\\gamma }{\\pi (\\gamma ^{2}+\\omega ^{2})}}}": {
    "before": "which yields a Lorentzian profile for the spectral density:",
    "after": "where {\\displaystyle \\gamma =1/\\tau } is the angular frequency associated with the decay time {\\displaystyle \\tau } .",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle X_{t}=\\varphi ^{N}X_{t-N}+\\sum _{k=0}^{N-1}\\varphi ^{k}\\varepsilon _{t-k}.}": {
    "before": "An alternative expression for {\\displaystyle X_{t}} can be derived by first substituting {\\displaystyle \\varphi X_{t-2}+\\varepsilon _{t-1}} for {\\displaystyle X_{t-1}} in the defining equation. Continuing this process N times yields",
    "after": "For N approaching infinity, {\\displaystyle \\varphi ^{N}} will approach zero and:",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle X_{t}=\\sum _{k=0}^{\\infty }\\varphi ^{k}\\varepsilon _{t-k}.}": {
    "before": "For N approaching infinity, {\\displaystyle \\varphi ^{N}} will approach zero and:",
    "after": "It is seen that {\\displaystyle X_{t}} is white noise convolved with the {\\displaystyle \\varphi ^{k}} kernel plus the constant mean. If the white noise {\\displaystyle \\varepsilon _{t}} is a Gaussian process then {\\displaystyle X_{t}} is also a Gaussian process. In other cases, the central limit theorem indicates that {\\displaystyle X_{t}} will be approximately normally distributed when {\\displaystyle \\varphi } is close to one.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle X_{t+1}=X_{t}+(1-\\theta )(\\mu -X_{t})+\\varepsilon _{t+1}} , where {\\displaystyle |\\theta |<1\\,} and {\\displaystyle \\mu } is the model mean.": {
    "before": "The AR(1) model is the discrete time analogy of the continuous Ornstein-Uhlenbeck process . It is therefore sometimes useful to understand the properties of the AR(1) model cast in an equivalent form. In this form, the AR(1) model, with process parameter {\\displaystyle \\theta } is given by:",
    "after": "By putting this in the form {\\displaystyle X_{t+1}=\\phi X_{t}+\\varepsilon _{t+1}} , and then expanding the series for {\\displaystyle X_{t+n}} , one can show that:",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\operatorname {E} (X_{t+n}|X_{t})=\\mu \\left[1-\\theta ^{n}\\right]+X_{t}\\theta ^{n}} , and {\\displaystyle \\operatorname {Var} (X_{t+n}|X_{t})=\\sigma ^{2}{\\frac {1-\\theta ^{2n}}{1-\\theta ^{2}}}} .": {
    "before": "By putting this in the form {\\displaystyle X_{t+1}=\\phi X_{t}+\\varepsilon _{t+1}} , and then expanding the series for {\\displaystyle X_{t+n}} , one can show that:",
    "after": "Choosing the maximum lag [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle X_{t}=\\sum _{i=1}^{p}\\varphi _{i}X_{t-i}+\\varepsilon _{t}.\\,}": {
    "before": "There are many ways to estimate the coefficients, such as the ordinary least squares procedure or method of moments (through Yule–Walker equations).The AR( p ) model is given by the equation",
    "after": "It is based on parameters {\\displaystyle \\varphi _{i}} where i = 1, ..., p . There is a direct correspondence between these parameters and the covariance function of the process, and this correspondence can be inverted to determine the parameters from the autocorrelation function (which is itself obtained from the covariances). This is done using the Yule–Walker equations.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\gamma _{m}=\\sum _{k=1}^{p}\\varphi _{k}\\gamma _{m-k}+\\sigma _{\\varepsilon }^{2}\\delta _{m,0},}": {
    "before": "The Yule–Walker equations, named for Udny Yule and Gilbert Walker ,   are the following set of equations. ",
    "after": "where m = 0, …, p , yielding p + 1 equations. Here {\\displaystyle \\gamma _{m}} is the autocovariance function of X t , {\\displaystyle \\sigma _{\\varepsilon }} is the standard deviation of the input noise process, and {\\displaystyle \\delta _{m,0}} is the Kronecker delta function .",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle {\\begin{bmatrix}\\gamma _{1}\\\\\\gamma _{2}\\\\\\gamma _{3}\\\\\\vdots \\\\\\gamma _{p}\\\\\\end{bmatrix}}={\\begin{bmatrix}\\gamma _{0}&\\gamma _{-1}&\\gamma _{-2}&\\cdots \\\\\\gamma _{1}&\\gamma _{0}&\\gamma _{-1}&\\cdots \\\\\\gamma _{2}&\\gamma _{1}&\\gamma _{0}&\\cdots \\\\\\vdots &\\vdots &\\vdots &\\ddots \\\\\\gamma _{p-1}&\\gamma _{p-2}&\\gamma _{p-3}&\\cdots \\\\\\end{bmatrix}}{\\begin{bmatrix}\\varphi _{1}\\\\\\varphi _{2}\\\\\\varphi _{3}\\\\\\vdots \\\\\\varphi _{p}\\\\\\end{bmatrix}}}": {
    "before": "Because the last part of an individual equation is non-zero only if m = 0 , the set of equations can be solved by representing the equations for m > 0 in matrix form, thus getting the equation",
    "after": "which can be solved for all {\\displaystyle \\{\\varphi _{m};m=1,2,\\dots ,p\\}.} The remaining equation for m = 0 is",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\gamma _{0}=\\sum _{k=1}^{p}\\varphi _{k}\\gamma _{-k}+\\sigma _{\\varepsilon }^{2},}": {
    "before": "which can be solved for all {\\displaystyle \\{\\varphi _{m};m=1,2,\\dots ,p\\}.} The remaining equation for m = 0 is",
    "after": "which, once {\\displaystyle \\{\\varphi _{m};m=1,2,\\dots ,p\\}} are known, can be solved for {\\displaystyle \\sigma _{\\varepsilon }^{2}.}",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\rho (\\tau )=\\sum _{k=1}^{p}\\varphi _{k}\\rho (k-\\tau )}": {
    "before": "An alternative formulation is in terms of the autocorrelation function . The AR parameters are determined by the first p +1 elements {\\displaystyle \\rho (\\tau )} of the autocorrelation function. The full autocorrelation function can then be derived by recursively calculating ",
    "after": "Examples for some Low-order AR( p ) processes",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\gamma _{1}=\\varphi _{1}\\gamma _{0}+\\varphi _{2}\\gamma _{-1}} {\\displaystyle \\gamma _{2}=\\varphi _{1}\\gamma _{1}+\\varphi _{2}\\gamma _{0}}": {
    "before": "The Yule–Walker equations for an AR(2) process are",
    "after": "Remember that {\\displaystyle \\gamma _{-k}=\\gamma _{k}} Using the first equation yields {\\displaystyle \\rho _{1}=\\gamma _{1}/\\gamma _{0}={\\frac {\\varphi _{1}}{1-\\varphi _{2}}}} Using the recursion formula yields {\\displaystyle \\rho _{2}=\\gamma _{2}/\\gamma _{0}={\\frac {\\varphi _{1}^{2}-\\varphi _{2}^{2}+\\varphi _{2}}{1-\\varphi _{2}}}}",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle X_{t}=\\sum _{i=1}^{p}\\varphi _{i}X_{t-i}+\\varepsilon _{t}^{*}\\,.} Here predicted values of X t would be based on the p future values of the same series. [ clarification needed ] This way of estimating the AR parameters is due to John Parker Burg,  and is called the Burg method:  Burg and later authors called these particular estimates \"maximum entropy estimates\",  but the reasoning behind this applies to the use of any set of estimated AR parameters. Compared to the estimation scheme using only the forward prediction equations, different estimates of the autocovariances are produced, and the estimates have different stability properties. Burg estimates are particularly associated with maximum entropy spectral estimation . ": {
    "before": "Estimation of autocovariances or autocorrelations. Here each of these terms is estimated separately, using conventional estimates. There are different ways of doing this and the choice between these affects the properties of the estimation scheme. For example, negative estimates of the variance can be produced by some choices. Formulation as a least squares regression problem in which an ordinary least squares prediction problem is constructed, basing prediction of values of X t on the p previous values of the same series. This can be thought of as a forward-prediction scheme. The normal equations for this problem can be seen to correspond to an approximation of the matrix form of the Yule–Walker equations in which each appearance of an autocovariance of the same lag is replaced by a slightly different estimate. Formulation as an extended form of ordinary least squares prediction problem. Here two sets of prediction equations are combined into a single estimation scheme and a single set of normal equations. One set is the set of forward-prediction equations and the other is a corresponding set of backward prediction equations, relating to the backward representation of the AR model:",
    "after": "Other possible approaches to estimation include maximum likelihood estimation . Two distinct variants of maximum likelihood are available: in one (broadly equivalent to the forward prediction least squares scheme) the likelihood function considered is that corresponding to the conditional distribution of later values in the series given the initial p values in the series; in the second, the likelihood function considered is that corresponding to the unconditional joint distribution of all the values in the observed series. Substantial differences in the results of these approaches can occur if the observed series is short, or if the process is close to non-stationarity.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle X_{t}=\\sum _{i=1}^{p}\\varphi _{i}X_{t-i}+\\varepsilon _{t}^{*}\\,.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle S(f)={\\frac {\\sigma _{Z}^{2}}{|1-\\sum _{k=1}^{p}\\varphi _{k}e^{-i2\\pi fk}|^{2}}}.}": {
    "before": "The power spectral density (PSD) of an AR( p ) process with noise variance {\\displaystyle \\mathrm {Var} (Z_{t})=\\sigma _{Z}^{2}} is ",
    "after": "AR(0) [ edit ]For white noise (AR(0))",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle S(f)=\\sigma _{Z}^{2}.}": {
    "before": "AR(0) [ edit ]For white noise (AR(0))",
    "after": "AR(1) [ edit ]For AR(1)",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle S(f)={\\frac {\\sigma _{Z}^{2}}{|1-\\varphi _{1}e^{-2\\pi if}|^{2}}}={\\frac {\\sigma _{Z}^{2}}{1+\\varphi _{1}^{2}-2\\varphi _{1}\\cos 2\\pi f}}}": {
    "before": "AR(1) [ edit ]For AR(1)",
    "after": "If {\\displaystyle \\varphi _{1}>0} there is a single spectral peak at f=0, often referred to as red noise . As {\\displaystyle \\varphi _{1}} becomes nearer 1, there is stronger power at low frequencies, i.e. larger time lags. This is then a low-pass filter, when applied to full spectrum light, everything except for the red light will be filtered. If {\\displaystyle \\varphi _{1}<0} there is a minimum at f=0, often referred to as blue noise . This similarly acts as a high-pass filter, everything except for blue light will be filtered.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle z_{1},z_{2}=-{\\frac {1}{2\\varphi _{2}}}\\left(\\varphi _{1}\\pm {\\sqrt {\\varphi _{1}^{2}+4\\varphi _{2}}}\\right)}": {
    "before": "AR(2) processes can be split into three groups depending on the characteristics of their roots:",
    "after": "When {\\displaystyle \\varphi _{1}^{2}+4\\varphi _{2}<0} , the process has a pair of complex-conjugate roots, creating a mid-frequency peak at:",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle f^{*}={\\frac {1}{2\\pi }}\\cos ^{-1}\\left({\\frac {\\varphi _{1}(\\varphi _{2}-1)}{4\\varphi _{2}}}\\right)}": {
    "before": "When {\\displaystyle \\varphi _{1}^{2}+4\\varphi _{2}<0} , the process has a pair of complex-conjugate roots, creating a mid-frequency peak at:",
    "after": "Otherwise the process has real roots, and:",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle S(f)={\\frac {\\sigma _{Z}^{2}}{1+\\varphi _{1}^{2}+\\varphi _{2}^{2}-2\\varphi _{1}(1-\\varphi _{2})\\cos(2\\pi f)-2\\varphi _{2}\\cos(4\\pi f)}}}": {
    "before": "The full PSD function can be expressed in real form as:",
    "after": "Implementations in statistics packages [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle X_{t}=\\sum _{i=1}^{p}\\varphi _{i}X_{t-i}+\\varepsilon _{t}\\,}": {
    "before": "n -step-ahead forecasting [ edit ]Once the parameters of the autoregression",
    "after": "have been estimated, the autoregression can be used to forecast an arbitrary number of periods into the future. First use t to refer to the first period for which data is not yet available; substitute the known preceding values X t-i for i= 1, ..., p into the autoregressive equation while setting the error term {\\displaystyle \\varepsilon _{t}} equal to zero (because we forecast X t to equal its expected value, and the expected value of the unobserved error term is zero). The output of the autoregressive equation is the forecast for the first unobserved period. Next, use t to refer to the next period for which data is not yet available; again the autoregressive equation is used to make the forecast, with one difference: the value of X one period prior to the one now being forecast is not known, so its expected value—the predicted value arising from the previous forecasting step—is used instead. Then for future periods the same procedure is used, each time using one more forecast value on the right side of the predictive equation until, after p predictions, all p right-side values are predicted values from preceding steps.",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle \\gamma _{1}=\\varphi _{1}\\gamma _{0}}": {
    "before": "=1",
    "after": "Hence {\\displaystyle \\rho _{1}=\\gamma _{1}/\\gamma _{0}=\\varphi _{1}}",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "at say time t=1 affects": {
    "before": "{\\displaystyle \\varepsilon _{t}}",
    "after": "{\\displaystyle X_{1}}",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "where m = 0, …, p, yielding p + 1 equations. Here": {
    "before": "{\\displaystyle \\gamma _{m}=\\sum _{k=1}^{p}\\varphi _{k}\\gamma _{m-k}+\\sigma _{\\varepsilon }^{2}\\delta _{m,0},}",
    "after": "{\\displaystyle \\gamma _{m}}",
    "url": "https://en.wikipedia.org/wiki/Autoregressive model"
  },
  "{\\displaystyle y_{t}=c+A_{1}y_{t-1}+A_{2}y_{t-2}+\\cdots +A_{p}y_{t-p}+e_{t},\\,}": {
    "before": "VAR models are characterized by their order , which refers to the number of earlier time periods the model will use. Continuing the above example, a 5th-order VAR would model each year's wheat price as a linear combination of the last five years of wheat prices. A lag is the value of a variable in a previous time period. So in general a p th-order VAR refers to a VAR model which includes lags for the last p time periods. A p th-order VAR is denoted \"VAR( p )\" and sometimes called \"a VAR with p lags\". A p th-order VAR model is written as",
    "after": "The variables of the form y t −i indicate that variable's value i time periods earlier and are called the \"i th lag\" of y t . The variable c is a k -vector of constants serving as the intercept of the model. A i is a time-invariant ( k × k )-matrix and e t is a k -vector of error terms. The error terms must satisfy three conditions:",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle Y=BZ+U\\,}": {
    "before": "Starting from the concise matrix notation (for details see this annex ):",
    "after": "The multivariate least squares (MLS) approach for estimating B yields:",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle {\\begin{bmatrix}y_{1,t}\\\\y_{2,t}\\end{bmatrix}}={\\begin{bmatrix}c_{1}\\\\c_{2}\\end{bmatrix}}+{\\begin{bmatrix}a_{1,1}&a_{1,2}\\\\a_{2,1}&a_{2,2}\\end{bmatrix}}{\\begin{bmatrix}y_{1,t-1}\\\\y_{2,t-1}\\end{bmatrix}}+{\\begin{bmatrix}e_{1,t}\\\\e_{2,t}\\end{bmatrix}},}": {
    "before": "A VAR(1) in two variables can be written in matrix form (more compact notation) as",
    "after": "(in which only a single A matrix appears because this example has a maximum lag p equal to 1), or, equivalently, as the following system of two equations",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle y_{1,t}=c_{1}+a_{1,1}y_{1,t-1}+a_{1,2}y_{2,t-1}+e_{1,t}\\,} {\\displaystyle y_{2,t}=c_{2}+a_{2,1}y_{1,t-1}+a_{2,2}y_{2,t-1}+e_{2,t}.\\,}": {
    "before": "(in which only a single A matrix appears because this example has a maximum lag p equal to 1), or, equivalently, as the following system of two equations",
    "after": "Each variable in the model has one equation. The current (time t ) observation of each variable depends on its own lagged values as well as on the lagged values of each other variable in the VAR.",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle y_{t}=c+A_{1}y_{t-1}+A_{2}y_{t-2}+e_{t}}": {
    "before": "A VAR with p lags can always be equivalently rewritten as a VAR with only one lag by appropriately redefining the dependent variable. The transformation amounts to stacking the lags of the VAR( p ) variable in the new VAR(1) dependent variable and appending identities to complete the number of equations.For example, the VAR(2) model",
    "after": "can be recast as the VAR(1) model",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle {\\begin{bmatrix}y_{t}\\\\y_{t-1}\\end{bmatrix}}={\\begin{bmatrix}c\\\\0\\end{bmatrix}}+{\\begin{bmatrix}A_{1}&A_{2}\\\\I&0\\end{bmatrix}}{\\begin{bmatrix}y_{t-1}\\\\y_{t-2}\\end{bmatrix}}+{\\begin{bmatrix}e_{t}\\\\0\\end{bmatrix}},}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle B_{0}y_{t}=c_{0}+B_{1}y_{t-1}+B_{2}y_{t-2}+\\cdots +B_{p}y_{t-p}+\\epsilon _{t},}": {
    "before": "A structural VAR with p lags (sometimes abbreviated SVAR ) is",
    "after": "where c 0 is a k × 1 vector of constants, B i is a k × k matrix (for every i = 0, ..., p ) and ε t is a k × 1 vector of error terms. The main diagonal terms of the B 0 matrix (the coefficients on the i th variable in the i th equation) are scaled to 1.",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle {\\begin{bmatrix}1&B_{0;1,2}\\\\B_{0;2,1}&1\\end{bmatrix}}{\\begin{bmatrix}y_{1,t}\\\\y_{2,t}\\end{bmatrix}}={\\begin{bmatrix}c_{0;1}\\\\c_{0;2}\\end{bmatrix}}+{\\begin{bmatrix}B_{1;1,1}&B_{1;1,2}\\\\B_{1;2,1}&B_{1;2,2}\\end{bmatrix}}{\\begin{bmatrix}y_{1,t-1}\\\\y_{2,t-1}\\end{bmatrix}}+{\\begin{bmatrix}\\epsilon _{1,t}\\\\\\epsilon _{2,t}\\end{bmatrix}},}": {
    "before": "The error terms ε t ( structural shocks ) satisfy the conditions (1) - (3) in the definition above, with the particularity that all the elements in the off diagonal of the covariance matrix {\\displaystyle \\mathrm {E} (\\epsilon _{t}\\epsilon _{t}')=\\Sigma } are zero. That is, the structural shocks are uncorrelated.For example, a two variable structural VAR(1) is:",
    "after": "where {\\displaystyle \\Sigma =\\mathrm {E} (\\epsilon _{t}\\epsilon _{t}')={\\begin{bmatrix}\\sigma _{1}^{2}&0\\\\0&\\sigma _{2}^{2}\\end{bmatrix}};}",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle \\Sigma =\\mathrm {E} (\\epsilon _{t}\\epsilon _{t}')={\\begin{bmatrix}\\sigma _{1}^{2}&0\\\\0&\\sigma _{2}^{2}\\end{bmatrix}};}": {
    "before": "{\\displaystyle {\\begin{bmatrix}1&B_{0;1,2}\\\\B_{0;2,1}&1\\end{bmatrix}}{\\begin{bmatrix}y_{1,t}\\\\y_{2,t}\\end{bmatrix}}={\\begin{bmatrix}c_{0;1}\\\\c_{0;2}\\end{bmatrix}}+{\\begin{bmatrix}B_{1;1,1}&B_{1;1,2}\\\\B_{1;2,1}&B_{1;2,2}\\end{bmatrix}}{\\begin{bmatrix}y_{1,t-1}\\\\y_{2,t-1}\\end{bmatrix}}+{\\begin{bmatrix}\\epsilon _{1,t}\\\\\\epsilon _{2,t}\\end{bmatrix}},} where",
    "after": "that is, the variances of the structural shocks are denoted {\\displaystyle \\mathrm {var} (\\epsilon _{i})=\\sigma _{i}^{2}} ( i = 1, 2) and the covariance is {\\displaystyle \\mathrm {cov} (\\epsilon _{1},\\epsilon _{2})=0} .",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle y_{1,t}=c_{0;1}-B_{0;1,2}y_{2,t}+B_{1;1,1}y_{1,t-1}+B_{1;1,2}y_{2,t-1}+\\epsilon _{1,t}\\,}": {
    "before": "Writing the first equation explicitly and passing y 2,t to the right hand side one obtains",
    "after": "Note that y 2, t can have a contemporaneous effect on y 1,t if B 0;1,2 is not zero. This is different from the case when B 0 is the identity matrix (all off-diagonal elements are zero — the case in the initial definition), when y 2, t can impact directly y 1, t +1 and subsequent future values, but not y 1, t .",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle y_{t}=B_{0}^{-1}c_{0}+B_{0}^{-1}B_{1}y_{t-1}+B_{0}^{-1}B_{2}y_{t-2}+\\cdots +B_{0}^{-1}B_{p}y_{t-p}+B_{0}^{-1}\\epsilon _{t},}": {
    "before": "By premultiplying the structural VAR with the inverse of B 0",
    "after": "and denoting {\\displaystyle B_{0}^{-1}c_{0}=c,\\quad B_{0}^{-1}B_{i}=A_{i}{\\text{ for }}i=1,\\dots ,p{\\text{ and }}B_{0}^{-1}\\epsilon _{t}=e_{t}}",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle B_{0}^{-1}c_{0}=c,\\quad B_{0}^{-1}B_{i}=A_{i}{\\text{ for }}i=1,\\dots ,p{\\text{ and }}B_{0}^{-1}\\epsilon _{t}=e_{t}}": {
    "before": "{\\displaystyle y_{t}=B_{0}^{-1}c_{0}+B_{0}^{-1}B_{1}y_{t-1}+B_{0}^{-1}B_{2}y_{t-2}+\\cdots +B_{0}^{-1}B_{p}y_{t-p}+B_{0}^{-1}\\epsilon _{t},} and denoting",
    "after": "one obtains the p th order reduced VAR",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle y_{t}=c+A_{1}y_{t-1}+A_{2}y_{t-2}+\\cdots +A_{p}y_{t-p}+e_{t}}": {
    "before": "{\\displaystyle B_{0}^{-1}c_{0}=c,\\quad B_{0}^{-1}B_{i}=A_{i}{\\text{ for }}i=1,\\dots ,p{\\text{ and }}B_{0}^{-1}\\epsilon _{t}=e_{t}} one obtains the p th order reduced VAR",
    "after": "Note that in the reduced form all right hand side variables are predetermined at time t . As there are no time t endogenous variables on the right hand side, no variable has a direct contemporaneous effect on other variables in the model.",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle \\Omega =\\mathrm {E} (e_{t}e_{t}')=\\mathrm {E} (B_{0}^{-1}\\epsilon _{t}\\epsilon _{t}'(B_{0}^{-1})')=B_{0}^{-1}\\Sigma (B_{0}^{-1})'\\,}": {
    "before": "However, the error terms in the reduced VAR are composites of the structural shocks e t = B 0 −1 ε t . Thus, the occurrence of one structural shock ε i,t can potentially lead to the occurrence of shocks in all error terms e j,t , thus creating contemporaneous movement in all endogenous variables. Consequently, the covariance matrix of the reduced VAR",
    "after": "can have non-zero off-diagonal elements, thus allowing non-zero correlation between error terms.",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle {\\hat {B}}=YZ'(ZZ')^{-1}.}": {
    "before": "The multivariate least squares (MLS) approach for estimating B yields:",
    "after": "This can be written alternatively as:",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle \\operatorname {Vec} ({\\hat {B}})=((ZZ')^{-1}Z\\otimes I_{k})\\ \\operatorname {Vec} (Y),}": {
    "before": "{\\displaystyle {\\hat {B}}=YZ'(ZZ')^{-1}.} This can be written alternatively as:",
    "after": "where {\\displaystyle \\otimes } denotes the Kronecker product and Vec the vectorization of the indicated matrix.",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle {\\hat {\\Sigma }}={\\frac {1}{T-kp-1}}(Y-{\\hat {B}}Z)(Y-{\\hat {B}}Z)'.}": {
    "before": "OLS estimator: [ citation needed ] {\\displaystyle {\\hat {\\Sigma }}={\\frac {1}{T-kp-1}}\\sum _{t=1}^{T}{\\hat {\\epsilon }}_{t}{\\hat {\\epsilon }}_{t}'} for a model with a constant, k variables and p lags.In a matrix notation, this gives:",
    "after": "Estimation of the estimator's covariance matrix [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle {\\widehat {\\mbox{Cov}}}({\\mbox{Vec}}({\\hat {B}}))=({ZZ'})^{-1}\\otimes {\\hat {\\Sigma }}.\\,}": {
    "before": "The covariance matrix of the parameters can be estimated as [ citation needed ]",
    "after": "Degrees of freedom [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle y_{t}=Ay_{t-1}+e_{t},}": {
    "before": "Consider the first-order case (i.e., with only one lag), with equation of evolution",
    "after": "for evolving (state) vector {\\displaystyle y} and vector {\\displaystyle e} of shocks. To find, say, the effect of the j -th element of the vector of shocks upon the i -th element of the state vector 2 periods later, which is a particular impulse response, first write the above equation of evolution one period lagged:",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle y_{t-1}=Ay_{t-2}+e_{t-1}.}": {
    "before": "for evolving (state) vector {\\displaystyle y} and vector {\\displaystyle e} of shocks. To find, say, the effect of the j -th element of the vector of shocks upon the i -th element of the state vector 2 periods later, which is a particular impulse response, first write the above equation of evolution one period lagged:",
    "after": "Use this in the original equation of evolution to obtain",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle y_{t}=A^{2}y_{t-2}+Ae_{t-1}+e_{t};}": {
    "before": "Use this in the original equation of evolution to obtain",
    "after": "then repeat using the twice lagged equation of evolution, to obtain",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle y_{t}=A^{3}y_{t-3}+A^{2}e_{t-2}+Ae_{t-1}+e_{t}.}": {
    "before": "then repeat using the twice lagged equation of evolution, to obtain",
    "after": "From this, the effect of the j -th component of {\\displaystyle e_{t-2}} upon the i -th component of {\\displaystyle y_{t}} is the i, j element of the matrix {\\displaystyle A^{2}.}",
    "url": "https://en.wikipedia.org/wiki/Vector autoregression"
  },
  "{\\displaystyle \\ y[n]=\\sum _{k=-\\infty }^{\\infty }h[n-k]x[k],}": {
    "before": "The matched filter is the linear filter, {\\displaystyle h} , that maximizes the output signal-to-noise ratio .",
    "after": "where {\\displaystyle x[k]} is the input as a function of the independent variable {\\displaystyle k} , and {\\displaystyle y[n]} is the filtered output. Though we most often express filters as the impulse response of convolution systems, as above (see LTI system theory ), it is easiest to think of the matched filter in the context of the inner product , which we will see shortly.",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ x=s+v.\\,}": {
    "before": "Our observed signal consists of the desirable signal {\\displaystyle s} and additive noise {\\displaystyle v} :",
    "after": "Let us define the covariance matrix of the noise, reminding ourselves that this matrix has Hermitian symmetry , a property that will become useful in the derivation:",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ R_{v}=E\\{vv^{\\mathrm {H} }\\}\\,}": {
    "before": "Let us define the covariance matrix of the noise, reminding ourselves that this matrix has Hermitian symmetry , a property that will become useful in the derivation:",
    "after": "where {\\displaystyle v^{\\mathrm {H} }} denotes the conjugate transpose of {\\displaystyle v} , and {\\displaystyle E} denotes expectation . Let us call our output, {\\displaystyle y} , the inner product of our filter and the observed signal such that",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ y=\\sum _{k=-\\infty }^{\\infty }h^{*}[k]x[k]=h^{\\mathrm {H} }x=h^{\\mathrm {H} }s+h^{\\mathrm {H} }v=y_{s}+y_{v}.}": {
    "before": "where {\\displaystyle v^{\\mathrm {H} }} denotes the conjugate transpose of {\\displaystyle v} , and {\\displaystyle E} denotes expectation . Let us call our output, {\\displaystyle y} , the inner product of our filter and the observed signal such that",
    "after": "We now define the signal-to-noise ratio, which is our objective function, to be the ratio of the power of the output due to the desired signal to the power of the output due to the noise:",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\mathrm {SNR} ={\\frac {|y_{s}|^{2}}{E\\{|y_{v}|^{2}\\}}}.}": {
    "before": "We now define the signal-to-noise ratio, which is our objective function, to be the ratio of the power of the output due to the desired signal to the power of the output due to the noise:",
    "after": "We rewrite the above:",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\mathrm {SNR} ={\\frac {|h^{\\mathrm {H} }s|^{2}}{E\\{|h^{\\mathrm {H} }v|^{2}\\}}}.}": {
    "before": "{\\displaystyle \\mathrm {SNR} ={\\frac {|y_{s}|^{2}}{E\\{|y_{v}|^{2}\\}}}.} We rewrite the above:",
    "after": "We wish to maximize this quantity by choosing {\\displaystyle h} . Expanding the denominator of our objective function, we have",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ E\\{|h^{\\mathrm {H} }v|^{2}\\}=E\\{(h^{\\mathrm {H} }v){(h^{\\mathrm {H} }v)}^{\\mathrm {H} }\\}=h^{\\mathrm {H} }E\\{vv^{\\mathrm {H} }\\}h=h^{\\mathrm {H} }R_{v}h.\\,}": {
    "before": "We wish to maximize this quantity by choosing {\\displaystyle h} . Expanding the denominator of our objective function, we have",
    "after": "Now, our {\\displaystyle \\mathrm {SNR} } becomes",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\mathrm {SNR} ={\\frac {|h^{\\mathrm {H} }s|^{2}}{h^{\\mathrm {H} }R_{v}h}}.}": {
    "before": "Now, our {\\displaystyle \\mathrm {SNR} } becomes",
    "after": "We will rewrite this expression with some matrix manipulation. The reason for this seemingly counterproductive measure will become evident shortly. Exploiting the Hermitian symmetry of the covariance matrix {\\displaystyle R_{v}} , we can write",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\mathrm {SNR} ={\\frac {|{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{-1/2}s)|^{2}}{{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{1/2}h)}},}": {
    "before": "We will rewrite this expression with some matrix manipulation. The reason for this seemingly counterproductive measure will become evident shortly. Exploiting the Hermitian symmetry of the covariance matrix {\\displaystyle R_{v}} , we can write",
    "after": "We would like to find an upper bound on this expression. To do so, we first recognize a form of the Cauchy–Schwarz inequality :",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\mathrm {SNR} ={\\frac {|{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{-1/2}s)|^{2}}{{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{1/2}h)}}\\leq {\\frac {\\left[{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{1/2}h)\\right]\\left[{(R_{v}^{-1/2}s)}^{\\mathrm {H} }(R_{v}^{-1/2}s)\\right]}{{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{1/2}h)}}.}": {
    "before": "which is to say that the square of the inner product of two vectors can only be as large as the product of the individual inner products of the vectors. This concept returns to the intuition behind the matched filter: this upper bound is achieved when the two vectors {\\displaystyle a} and {\\displaystyle b} are parallel. We resume our derivation by expressing the upper bound on our {\\displaystyle \\mathrm {SNR} } in light of the geometric inequality above:",
    "after": "Our valiant matrix manipulation has now paid off. We see that the expression for our upper bound can be greatly simplified:",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\mathrm {SNR} ={\\frac {|{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{-1/2}s)|^{2}}{{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{1/2}h)}}\\leq s^{\\mathrm {H} }R_{v}^{-1}s.}": {
    "before": "Our valiant matrix manipulation has now paid off. We see that the expression for our upper bound can be greatly simplified:",
    "after": "We can achieve this upper bound if we choose,",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ R_{v}^{1/2}h=\\alpha R_{v}^{-1/2}s}": {
    "before": "{\\displaystyle \\mathrm {SNR} ={\\frac {|{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{-1/2}s)|^{2}}{{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{1/2}h)}}\\leq s^{\\mathrm {H} }R_{v}^{-1}s.} We can achieve this upper bound if we choose,",
    "after": "where {\\displaystyle \\alpha } is an arbitrary real number. To verify this, we plug into our expression for the output {\\displaystyle \\mathrm {SNR} } :",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\mathrm {SNR} ={\\frac {|{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{-1/2}s)|^{2}}{{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{1/2}h)}}={\\frac {\\alpha ^{2}|{(R_{v}^{-1/2}s)}^{\\mathrm {H} }(R_{v}^{-1/2}s)|^{2}}{\\alpha ^{2}{(R_{v}^{-1/2}s)}^{\\mathrm {H} }(R_{v}^{-1/2}s)}}={\\frac {|s^{\\mathrm {H} }R_{v}^{-1}s|^{2}}{s^{\\mathrm {H} }R_{v}^{-1}s}}=s^{\\mathrm {H} }R_{v}^{-1}s.}": {
    "before": "where {\\displaystyle \\alpha } is an arbitrary real number. To verify this, we plug into our expression for the output {\\displaystyle \\mathrm {SNR} } :",
    "after": "Thus, our optimal matched filter is",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ h=\\alpha R_{v}^{-1}s.}": {
    "before": "{\\displaystyle \\mathrm {SNR} ={\\frac {|{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{-1/2}s)|^{2}}{{(R_{v}^{1/2}h)}^{\\mathrm {H} }(R_{v}^{1/2}h)}}={\\frac {\\alpha ^{2}|{(R_{v}^{-1/2}s)}^{\\mathrm {H} }(R_{v}^{-1/2}s)|^{2}}{\\alpha ^{2}{(R_{v}^{-1/2}s)}^{\\mathrm {H} }(R_{v}^{-1/2}s)}}={\\frac {|s^{\\mathrm {H} }R_{v}^{-1}s|^{2}}{s^{\\mathrm {H} }R_{v}^{-1}s}}=s^{\\mathrm {H} }R_{v}^{-1}s.} Thus, our optimal matched filter is",
    "after": "We often choose to normalize the expected value of the power of the filter output due to the noise to unity. That is, we constrain",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ E\\{|y_{v}|^{2}\\}=\\alpha ^{2}s^{\\mathrm {H} }R_{v}^{-1}s=1,}": {
    "before": "This constraint implies a value of {\\displaystyle \\alpha } , for which we can solve:",
    "after": "yielding {\\displaystyle \\ \\alpha ={\\frac {1}{\\sqrt {s^{\\mathrm {H} }R_{v}^{-1}s}}},}",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ \\alpha ={\\frac {1}{\\sqrt {s^{\\mathrm {H} }R_{v}^{-1}s}}},}": {
    "before": "{\\displaystyle \\ E\\{|y_{v}|^{2}\\}=\\alpha ^{2}s^{\\mathrm {H} }R_{v}^{-1}s=1,} yielding",
    "after": "giving us our normalized filter,",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ h={\\frac {1}{\\sqrt {s^{\\mathrm {H} }R_{v}^{-1}s}}}R_{v}^{-1}s.}": {
    "before": "{\\displaystyle \\ \\lambda _{\\max }=s^{\\mathrm {H} }R_{v}^{-1}s,} yielding the following optimal matched filter",
    "after": "This is the same result found in the previous subsection.",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ x=s+v,\\,}": {
    "before": "Alternatively, we may solve for the matched filter by solving our maximization problem with a Lagrangian. Again, the matched filter endeavors to maximize the output signal-to-noise ratio ( {\\displaystyle \\mathrm {SNR} } ) of a filtered deterministic signal in stochastic additive noise. The observed sequence, again, is",
    "after": "with the noise covariance matrix,",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ R_{v}=E\\{vv^{\\mathrm {H} }\\}.\\,}": {
    "before": "{\\displaystyle \\ x=s+v,\\,} with the noise covariance matrix,",
    "after": "The signal-to-noise ratio is",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\mathrm {SNR} ={\\frac {|y_{s}|^{2}}{E\\{|y_{v}|^{2}\\}}},}": {
    "before": "{\\displaystyle \\ R_{v}=E\\{vv^{\\mathrm {H} }\\}.\\,} The signal-to-noise ratio is",
    "after": "where {\\displaystyle y_{s}=h^{\\mathrm {H} }s} and {\\displaystyle y_{v}=h^{\\mathrm {H} }v} .",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ |y_{s}|^{2}={y_{s}}^{\\mathrm {H} }y_{s}=h^{\\mathrm {H} }ss^{\\mathrm {H} }h.\\,}": {
    "before": "Evaluating the expression in the numerator, we have",
    "after": "and in the denominator,",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ E\\{|y_{v}|^{2}\\}=E\\{{y_{v}}^{\\mathrm {H} }y_{v}\\}=E\\{h^{\\mathrm {H} }vv^{\\mathrm {H} }h\\}=h^{\\mathrm {H} }R_{v}h.\\,}": {
    "before": "{\\displaystyle \\ |y_{s}|^{2}={y_{s}}^{\\mathrm {H} }y_{s}=h^{\\mathrm {H} }ss^{\\mathrm {H} }h.\\,} and in the denominator,",
    "after": "The signal-to-noise ratio becomes",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\mathrm {SNR} ={\\frac {h^{\\mathrm {H} }ss^{\\mathrm {H} }h}{h^{\\mathrm {H} }R_{v}h}}.}": {
    "before": "{\\displaystyle \\ E\\{|y_{v}|^{2}\\}=E\\{{y_{v}}^{\\mathrm {H} }y_{v}\\}=E\\{h^{\\mathrm {H} }vv^{\\mathrm {H} }h\\}=h^{\\mathrm {H} }R_{v}h.\\,} The signal-to-noise ratio becomes",
    "after": "If we now constrain the denominator to be 1, the problem of maximizing {\\displaystyle \\mathrm {SNR} } is reduced to maximizing the numerator. We can then formulate the problem using a Lagrange multiplier :",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ h^{\\mathrm {H} }R_{v}h=1} {\\displaystyle \\ {\\mathcal {L}}=h^{\\mathrm {H} }ss^{\\mathrm {H} }h+\\lambda (1-h^{\\mathrm {H} }R_{v}h)} {\\displaystyle \\ \\nabla _{h^{*}}{\\mathcal {L}}=ss^{\\mathrm {H} }h-\\lambda R_{v}h=0} {\\displaystyle \\ (ss^{\\mathrm {H} })h=\\lambda R_{v}h}": {
    "before": "If we now constrain the denominator to be 1, the problem of maximizing {\\displaystyle \\mathrm {SNR} } is reduced to maximizing the numerator. We can then formulate the problem using a Lagrange multiplier :",
    "after": "which we recognize as a generalized eigenvalue problem",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ h^{\\mathrm {H} }(ss^{\\mathrm {H} })h=\\lambda h^{\\mathrm {H} }R_{v}h.}": {
    "before": "which we recognize as a generalized eigenvalue problem",
    "after": "Since {\\displaystyle ss^{\\mathrm {H} }} is of unit rank, it has only one nonzero eigenvalue. It can be shown that this eigenvalue equals",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ \\lambda _{\\max }=s^{\\mathrm {H} }R_{v}^{-1}s,}": {
    "before": "Since {\\displaystyle ss^{\\mathrm {H} }} is of unit rank, it has only one nonzero eigenvalue. It can be shown that this eigenvalue equals",
    "after": "yielding the following optimal matched filter",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ x_{k}=s_{k}+v_{k},\\,}": {
    "before": "Matched filtering can also be interpreted as a least-squares estimator for the optimal location and scaling of a given model or template. Once again, let the observed sequence be defined as",
    "after": "where {\\displaystyle v_{k}} is uncorrelated zero mean noise. The signal {\\displaystyle s_{k}} is assumed to be a scaled and shifted version of a known model sequence {\\displaystyle f_{k}} :",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ s_{k}=\\mu _{0}\\cdot f_{k-j_{0}}}": {
    "before": "where {\\displaystyle v_{k}} is uncorrelated zero mean noise. The signal {\\displaystyle s_{k}} is assumed to be a scaled and shifted version of a known model sequence {\\displaystyle f_{k}} :",
    "after": "We want to find optimal estimates {\\displaystyle j^{*}} and {\\displaystyle \\mu ^{*}} for the unknown shift {\\displaystyle j_{0}} and scaling {\\displaystyle \\mu _{0}} by minimizing the least-squares residual between the observed sequence {\\displaystyle x_{k}} and a \"probing sequence\" {\\displaystyle h_{j-k}} :",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ j^{*},\\mu ^{*}=\\arg \\min _{j,\\mu }\\sum _{k}\\left(x_{k}-\\mu \\cdot h_{j-k}\\right)^{2}}": {
    "before": "We want to find optimal estimates {\\displaystyle j^{*}} and {\\displaystyle \\mu ^{*}} for the unknown shift {\\displaystyle j_{0}} and scaling {\\displaystyle \\mu _{0}} by minimizing the least-squares residual between the observed sequence {\\displaystyle x_{k}} and a \"probing sequence\" {\\displaystyle h_{j-k}} :",
    "after": "The appropriate {\\displaystyle h_{j-k}} will later turn out to be the matched filter, but is as yet unspecified. Expanding {\\displaystyle x_{k}} and the square within the sum yields",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ j^{*},\\mu ^{*}=\\arg \\min _{j,\\mu }\\left[\\sum _{k}(s_{k}+v_{k})^{2}+\\mu ^{2}\\sum _{k}h_{j-k}^{2}-2\\mu \\sum _{k}s_{k}h_{j-k}-2\\mu \\sum _{k}v_{k}h_{j-k}\\right].}": {
    "before": "The appropriate {\\displaystyle h_{j-k}} will later turn out to be the matched filter, but is as yet unspecified. Expanding {\\displaystyle x_{k}} and the square within the sum yields",
    "after": "The first term in brackets is a constant (since the observed signal is given) and has no influence on the optimal solution. The last term has constant expected value because the noise is uncorrelated and has zero mean. We can therefore drop both terms from the optimization. After reversing the sign, we obtain the equivalent optimization problem",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ j^{*},\\mu ^{*}=\\arg \\max _{j,\\mu }\\left[2\\mu \\sum _{k}s_{k}h_{j-k}-\\mu ^{2}\\sum _{k}h_{j-k}^{2}\\right].}": {
    "before": "The first term in brackets is a constant (since the observed signal is given) and has no influence on the optimal solution. The last term has constant expected value because the noise is uncorrelated and has zero mean. We can therefore drop both terms from the optimization. After reversing the sign, we obtain the equivalent optimization problem",
    "after": "Setting the derivative w.r.t. {\\displaystyle \\mu } to zero gives an analytic solution for {\\displaystyle \\mu ^{*}} :",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ \\mu ^{*}={\\frac {\\sum _{k}s_{k}h_{j-k}}{\\sum _{k}h_{j-k}^{2}}}.}": {
    "before": "Setting the derivative w.r.t. {\\displaystyle \\mu } to zero gives an analytic solution for {\\displaystyle \\mu ^{*}} :",
    "after": "Inserting this into our objective function yields a reduced maximization problem for just {\\displaystyle j^{*}} :",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ j^{*}=\\arg \\max _{j}{\\frac {\\left(\\sum _{k}s_{k}h_{j-k}\\right)^{2}}{\\sum _{k}h_{j-k}^{2}}}.}": {
    "before": "Inserting this into our objective function yields a reduced maximization problem for just {\\displaystyle j^{*}} :",
    "after": "The numerator can be upper-bounded by means of the Cauchy–Schwarz inequality :",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ {\\frac {\\left(\\sum _{k}s_{k}h_{j-k}\\right)^{2}}{\\sum _{k}h_{j-k}^{2}}}\\leq {\\frac {\\sum _{k}s_{k}^{2}\\cdot \\sum _{k}h_{j-k}^{2}}{\\sum _{k}h_{j-k}^{2}}}=\\sum _{k}s_{k}^{2}={\\text{constant}}.}": {
    "before": "The numerator can be upper-bounded by means of the Cauchy–Schwarz inequality :",
    "after": "The optimization problem assumes its maximum when equality holds in this expression. According to the properties of the Cauchy–Schwarz inequality, this is only possible when",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ h_{j-k}=\\nu \\cdot s_{k}=\\kappa \\cdot f_{k-j_{0}}.}": {
    "before": "The optimization problem assumes its maximum when equality holds in this expression. According to the properties of the Cauchy–Schwarz inequality, this is only possible when",
    "after": "for arbitrary non-zero constants {\\displaystyle \\nu } or {\\displaystyle \\kappa } , and the optimal solution is obtained at {\\displaystyle j^{*}=j_{0}} as desired. Thus, our \"probing sequence\" {\\displaystyle h_{j-k}} must be proportional to the signal model {\\displaystyle f_{k-j_{0}}} , and the convenient choice {\\displaystyle \\kappa =1} yields the matched filter",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ h_{k}=f_{-k}.}": {
    "before": "for arbitrary non-zero constants {\\displaystyle \\nu } or {\\displaystyle \\kappa } , and the optimal solution is obtained at {\\displaystyle j^{*}=j_{0}} as desired. Thus, our \"probing sequence\" {\\displaystyle h_{j-k}} must be proportional to the signal model {\\displaystyle f_{k-j_{0}}} , and the convenient choice {\\displaystyle \\kappa =1} yields the matched filter",
    "after": "Note that the filter is the mirrored signal model. This ensures that the operation {\\displaystyle \\sum _{k}x_{k}h_{j-k}} to be applied in order to find the optimum is indeed the convolution between the observed sequence {\\displaystyle x_{k}} and the matched filter {\\displaystyle h_{k}} . The filtered sequence assumes its maximum at the position where the observed sequence {\\displaystyle x_{k}} best matches (in a least-squares sense) the signal model {\\displaystyle f_{k}} .",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ a_{k}={\\begin{cases}+1,&{\\text{if bit }}k{\\text{ is }}1,\\\\-1,&{\\text{if bit }}k{\\text{ is }}0.\\end{cases}}}": {
    "before": "Mathematically, a sequence in NRZ code can be described as a sequence of unit pulses or shifted rect functions , each pulse being weighted by +1 if the bit is \"1\" and by -1 if the bit is \"0\". Formally, the scaling factor for the {\\displaystyle k^{\\mathrm {th} }} bit is,",
    "after": "We can represent our message, {\\displaystyle M(t)} , as the sum of shifted unit pulses:",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ M(t)=\\sum _{k=-\\infty }^{\\infty }a_{k}\\times \\Pi \\left({\\frac {t-kT}{T}}\\right).}": {
    "before": "We can represent our message, {\\displaystyle M(t)} , as the sum of shifted unit pulses:",
    "after": "where {\\displaystyle T} is the time length of one bit and {\\displaystyle \\Pi (x)} is the rectangular function .",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ h(t)=\\Pi \\left({\\frac {t}{T}}\\right).}": {
    "before": "To increase our signal-to-noise ratio, we pass the received signal through a matched filter. In this case, the filter should be matched to an NRZ pulse (equivalent to a \"1\" coded in NRZ code). Precisely, the impulse response of the ideal matched filter, assuming white (uncorrelated) noise should be a time-reversed complex-conjugated scaled version of the signal that we are seeking. We choose",
    "after": "In this case, due to symmetry, the time-reversed complex conjugate of {\\displaystyle h(t)} is in fact {\\displaystyle h(t)} , allowing us to call {\\displaystyle h(t)} the impulse response of our matched filter convolution system.",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle \\ M_{\\mathrm {filtered} }(t)=(M*h)(t)}": {
    "before": "After convolving with the correct matched filter, the resulting signal, {\\displaystyle M_{\\mathrm {filtered} }(t)} is,",
    "after": "where {\\displaystyle *} denotes convolution.",
    "url": "https://en.wikipedia.org/wiki/Matched filter"
  },
  "{\\displaystyle {\\mathit {ARA}}(w)=-{\\frac {u''(w)}{u'(w)}},}": {
    "before": "Since the risk attitudes are unchanged under affine transformations of u , the second derivative u'' is not an adequate measure of the risk aversion of a utility function. Instead, it needs to be normalized. This leads to the definition of the Arrow–Pratt   measure of absolute risk aversion:",
    "after": "where {\\displaystyle w} is wealth.",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "{\\displaystyle {\\mathit {RRA}}(w)=-{\\frac {wu''(w)}{u'(w)}}}": {
    "before": "The Arrow–Pratt measure of relative risk aversion is:",
    "after": "Special classes of utility functions are the CRRA ( constant relative risk aversion ) functions, where RRA(w) is constant, and the CARA ( constant absolute risk aversion ) functions, where ARA(w) is constant. They are often used in economics for simplification.",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "{\\displaystyle P(E)=(1-U(m))(U(b)-U(w))} ": {
    "before": "In 1926, Frank Ramsey introduced the Ramsey's Representation Theorem. This representation theorem for expected utility assumed that preferences are defined over set of bets where each option has a different yield. Ramsey believed that we always choose decisions to receive the best expected outcome according to our personal preferences. This implies that if we are able to understand the priorities and personal preferences of an individual we can anticipate what choices they are going to take.  In this model he defined numerical utilities for each option to exploit the richness of the space of prices. The outcome of each preference is exclusive from each other. For example, if you study, then you can't see your friends, however you will get a good grade in your course. In this scenario, if we analyze what are his personal preferences and beliefs we will be able to predict which he might choose. (e.g. if someone prioritizes their social life more than academic results, they will go out with their friends). Assuming that the decisions of a person are rational , according to this theorem we should be able to know the beliefs and utilities from a person just by looking the choices someone takes (which is wrong). Ramsey defines a proposition as \" ethically neutral \" when two possible outcome has an equal value. In other words, if the probability can be defined in terms of preference, each proposition should have ½ in order to be indifferent between both options.  Ramsey shows that",
    "after": "Savage's subjective expected utility representation [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "{\\displaystyle u(w)=-e^{-aw}}": {
    "before": "The utility function {\\displaystyle u(w)=\\log(w)} was originally suggested by Bernoulli (see above). It has relative risk aversion constant and equal to one, and is still sometimes assumed in economic analyses. The utility function",
    "after": "exhibits constant absolute risk aversion, and for this reason is often avoided, although it has the advantage of offering substantial mathematical tractability when asset returns are normally distributed. Note that, as per the affine transformation property alluded to above, the utility function {\\displaystyle K-e^{-aw}} gives exactly the same preferences orderings as does {\\displaystyle -e^{-aw}} ; thus it is irrelevant that the values of {\\displaystyle -e^{-aw}} and its expected value are always negative: what matters for preference ordering is which of two gambles gives the higher expected utility, not the numerical values of those expected utilities.",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "{\\displaystyle u(w)=\\log(w)}": {
    "before": "The class of constant relative risk aversion utility functions contains three categories. Bernoulli's utility function",
    "after": "has relative risk aversion equal to 1. The functions",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "{\\displaystyle u(w)=w^{\\alpha }}": {
    "before": "has relative risk aversion equal to 1. The functions",
    "after": "for {\\displaystyle \\alpha \\in (0,1)} have relative risk aversion equal to {\\displaystyle 1-\\alpha \\in (0,1)} . And the functions",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "{\\displaystyle u(w)=-w^{\\alpha }}": {
    "before": "for {\\displaystyle \\alpha \\in (0,1)} have relative risk aversion equal to {\\displaystyle 1-\\alpha \\in (0,1)} . And the functions",
    "after": "for {\\displaystyle \\alpha <0} have relative risk aversion equal to {\\displaystyle 1-\\alpha >1.}",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "{\\displaystyle \\operatorname {E} [u(x)]=p_{1}\\cdot u(x_{1})+p_{2}\\cdot u(x_{2})+\\cdots }": {
    "before": "When the entity {\\displaystyle x} whose value {\\displaystyle x_{i}} affects a person's utility takes on one of a set of discrete values , the formula for expected utility, which is assumed to be maximized, is",
    "after": "where the left side is the subjective valuation of the gamble as a whole, {\\displaystyle x_{i}} is the i th possible outcome, {\\displaystyle u(x_{i})} is its valuation, and {\\displaystyle p_{i}} is its probability. There could be either a finite set of possible values {\\displaystyle x_{i},} in which case the right side of this equation has a finite number of terms; or there could be an infinite set of discrete values, in which case the right side has an infinite number of terms.",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "{\\displaystyle \\operatorname {E} [u(x)]=\\int _{-\\infty }^{\\infty }u(x)f(x)\\,dx,}": {
    "before": "When {\\displaystyle x} can take on any of a continuous range of values, the expected utility is given by",
    "after": "where {\\displaystyle f(x)} is the probability density function of {\\displaystyle x.}",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "{\\displaystyle u(w)=w-be^{-aw}}": {
    "before": "Often people refer to \"risk\" in the sense of a potentially quantifiable entity. In the context of mean-variance analysis , variance is used as a risk measure for portfolio return; however, this is only valid if returns are normally distributed or otherwise jointly elliptically distributed ,    or in the unlikely case in which the utility function has a quadratic form. However, David E. Bell proposed a measure of risk which follows naturally from a certain class of von Neumann–Morgenstern utility functions.  Let utility of wealth be given by",
    "after": "for individual-specific positive parameters a and b . Then expected utility is given by",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "{\\displaystyle {\\begin{aligned}\\operatorname {E} [u(w)]&=\\operatorname {E} [w]-b\\operatorname {E} [e^{-aw}]\\\\&=\\operatorname {E} [w]-b\\operatorname {E} [e^{-a\\operatorname {E} [w]-a(w-\\operatorname {E} [w])}]\\\\&=\\operatorname {E} [w]-be^{-a\\operatorname {E} [w]}\\operatorname {E} [e^{-a(w-\\operatorname {E} [w])}]\\\\&={\\text{expected wealth}}-b\\cdot e^{-a\\cdot {\\text{expected wealth}}}\\cdot {\\text{risk}}.\\end{aligned}}}": {
    "before": "for individual-specific positive parameters a and b . Then expected utility is given by",
    "after": "Thus the risk measure is {\\displaystyle \\operatorname {E} (e^{-a(w-\\operatorname {E} w)})} , which differs between two individuals if they have different values of the parameter {\\displaystyle a,} allowing different people to disagree about the degree of risk associated with any given portfolio. Individuals sharing a given risk measure (based on given value of a ) may choose different portfolios because they may have different values of b . See also Entropic risk measure .",
    "url": "https://en.wikipedia.org/wiki/Expected utility hypothesis"
  },
  "Proof: Assume {\\displaystyle s'\\geq _{S}s} and {\\displaystyle x\\in F_{Y}(s)} , and {\\displaystyle x'\\in F_{Y}(s')} . We have to show that {\\displaystyle \\max\\{x',x\\}\\in F_{Y}(s')} and {\\displaystyle \\min\\{x',x\\}\\in F_{Y}(s)} . We only need to consider the case where {\\displaystyle x>x'} . Since {\\displaystyle x\\in F_{Y}(s)} , we obtain {\\displaystyle f(x;s)\\geq f(x';s)} , which guarantees that {\\displaystyle x\\in F_{Y'}(s')} . Furthermore, {\\displaystyle f(x;s)=f(x';s)} so that {\\displaystyle x'\\in F_{Y}(s)} . If not, {\\displaystyle f(x;s)>f(x';s)} which implies (by single crossing differences) that {\\displaystyle f(x;s')>f(x';s')} , contradicting the optimality of {\\displaystyle x'} at {\\displaystyle s'} . To show the necessity of single crossing differences, set {\\displaystyle Y:=\\{x,{\\bar {x}}\\}} , where {\\displaystyle {\\bar {x}}\\geq x} . Then {\\displaystyle F_{Y}(s')\\geq _{SSO}F_{Y}(s)} for any {\\displaystyle s'\\geq _{S}s} guarantees that, if {\\displaystyle f({\\bar {x}};s)\\geq (>)\\ f(x;s)} , then {\\displaystyle f({\\bar {x}};s')\\geq (>)\\ f(x;s')} . Q.E.D.": {
    "before": "Theorem 1:  Define {\\displaystyle F_{Y}(s):=\\arg \\max _{x\\in Y}f(x;s)} . The family {\\displaystyle \\{f(\\cdot ;s)\\}_{s\\in S}} obey single crossing differences if and only if for all {\\displaystyle Y\\subseteq X} , we have {\\displaystyle F_{Y}(s')\\geq _{SSO}F_{Y}(s)} for any {\\displaystyle s'\\geq _{S}s} .",
    "after": "Application (monopoly output and changes in costs): A monopolist chooses {\\displaystyle x\\in X\\subseteq \\mathbb {R} _{+}} to maximise its profit {\\displaystyle \\Pi (x;-c)=xP(x)-cx} , where {\\displaystyle P:\\mathbb {R} _{+}\\to \\mathbb {R} _{+}} is the inverse demand function and {\\displaystyle c\\geq 0} is the constant marginal cost. Note that {\\displaystyle \\{\\Pi (\\cdot ,-c)\\}_{(-c)\\in \\mathbb {R} _{-}}} obey single crossing differences. Indeed, take any {\\displaystyle x'\\geq x} and assume that {\\displaystyle x'P(x')-cx'\\geq (>)\\ xP(x)-cx} ; for any {\\displaystyle c'} such that {\\displaystyle (-c')\\geq (-c)} , we obtain {\\displaystyle x'P(x')-c'x'\\geq (>)\\ xP(x)-c'x} . By Theorem 1, the profit-maximizing output decreases as the marginal cost of output increases, i.e., as {\\displaystyle (-c)} decreases.",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "Proof: To show the sufficiency of IDO, take any two {\\displaystyle s'\\geq _{S}s} , and assume that {\\displaystyle x'\\in F_{Y}(s)} and {\\displaystyle x''\\in F_{Y}(s')} . We only need to consider the case where {\\displaystyle x'>x''} . By definition {\\displaystyle f(x';s)\\geq f(x;s)} , for all {\\displaystyle x\\in [x'',x']\\subset Y} . Moreover, by IDO we have {\\displaystyle f(x';s')\\geq f(x'';s')} . Therefore, {\\displaystyle x'\\in F_{Y}(s')} . Furthermore, it must be that {\\displaystyle f(x';s)=f(x'';s)} . Otherwise, i.e., if {\\displaystyle f(x';s)>f(x'';s)} , then by IDO we have {\\displaystyle f(x';s')>f(x'';s')} , which contradicts that {\\displaystyle x''\\in F_{Y}(s')} . To show the necessity of IDO, assume that there is an interval {\\displaystyle [x'',x']} such that {\\displaystyle f(x';s)\\geq f(x;s)} for all {\\displaystyle x\\in [x'',x']} . This means that {\\displaystyle x'\\in \\arg \\max _{x\\in [x'',x']}f(x;s)} . There are two possible violations of IDO. One possibility is that {\\displaystyle f(x'';s')>f(x';s')} . In this case, by the regularity of {\\displaystyle f(\\cdot ;s')} , the set {\\displaystyle \\arg \\max _{x\\in [x'',x']}f(x;s')} is non-empty but does not contain {\\displaystyle x'} which is impossible since {\\displaystyle \\arg \\max _{x\\in [x'',x']}f(x;s)} increases in {\\displaystyle s} . Another possible violation of IDO occurs if {\\displaystyle f(x'';s')=f(x';s')} but {\\displaystyle f(x'';s)<f(x';s)} . In this case, the set {\\displaystyle \\arg \\max _{x\\in [x'',x']}f(x;s')} either contains {\\displaystyle x''} , which is not possible since {\\displaystyle \\arg \\max _{x\\in [x'',x']}f(x;s)} increases in {\\displaystyle s} (note that in this case {\\displaystyle x''\\not \\in \\arg \\max _{x\\in [x'',x']}f(x;s')} ) or it does not contain {\\displaystyle x'} , which also violates monotonicity of {\\displaystyle \\arg \\max _{x\\in [x'',x']}f(x;s)} . Q.E.D.": {
    "before": "Theorem 2:  Denote {\\displaystyle F_{Y}(s):=\\arg \\max _{x\\in Y}f(x;s)} . A family of regular functions {\\displaystyle \\{f(\\cdot ;s)\\}_{s\\in S}} obeys the interval dominance order if and only if {\\displaystyle F_{Y}(s)} is increasing in {\\displaystyle s} for all intervals {\\displaystyle Y\\subseteq X} .",
    "after": "The next result gives useful sufficient conditions for single crossing differences and IDO.",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "{\\displaystyle V(x;-r)=\\int _{0}^{x}e^{-rt}\\pi (t)dt,}": {
    "before": "Application (Optimal stopping problem):  At each moment in time, agent gains profit of {\\displaystyle \\pi (t)} , which can be positive or negative. If agent decides to stop at time {\\displaystyle x} , the present value of his accumulated profit is",
    "after": "where {\\displaystyle r>0} is the discount rate. Since {\\displaystyle V'(x;-r)=e^{-rx}\\pi (x)} , the function {\\displaystyle V} has many turning points and they do not vary with the discount rate. We claim that the optimal stopping time is decreasing in {\\displaystyle r} , i.e., if {\\displaystyle r'>r>0} then {\\displaystyle \\arg \\max _{x\\geq 0}V(x;-r)\\geq _{SSO}\\arg \\max _{x\\geq 0}V(x;-r')} . Take any {\\displaystyle r'<r} . Then, {\\displaystyle V'(x;-r)=e^{-rx}\\pi (x)=e^{(r'-r)x}V'(x;-r').} Since {\\displaystyle \\alpha (x)=e^{(r'-r)x}} is positive and increasing, Proposition 1 says that {\\displaystyle \\{V(\\cdot ;-r)\\}_{(-r)<0}} obey IDO and, by Theorem 2, the set of optimal stopping times is decreasing.",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "{\\displaystyle (\\Rightarrow )} . Set {\\displaystyle Y':=\\{x',x'\\vee x\\}} and {\\displaystyle Y:=\\{x,x'\\wedge x\\}} . Then, {\\displaystyle Y'\\geq _{SSO}Y} and thus {\\displaystyle F_{Y'}(s)\\geq _{SSO}F_{Y}(s)} , which guarantees that, if {\\displaystyle f(x;s)\\geq (>)\\ f(x'\\wedge x;s)} , then {\\displaystyle f(x'\\vee x;s)\\geq (>)\\ f(x';s)} . To show that single crossing differences also hold, set {\\displaystyle Y:=\\{x,{\\bar {x}}\\}} , where {\\displaystyle {\\bar {x}}\\geq x} . Then {\\displaystyle F_{Y}(s')\\geq _{SSO}F_{Y}(s)} for any {\\displaystyle s'\\geq _{S}s} guarantees that, if {\\displaystyle f({\\bar {x}};s)\\geq (>)\\ f(x;s)} , then {\\displaystyle f({\\bar {x}};s')\\geq (>)\\ f(x;s')} . Q.E.D.": {
    "before": "Proof: {\\displaystyle (\\Leftarrow )} . Let {\\displaystyle Y'\\geq _{SSO}Y} , {\\displaystyle s'\\geq _{S}s} , and {\\displaystyle x'\\in F_{Y'}(s')} , {\\displaystyle x\\in F_{Y}(s)} . Since {\\displaystyle x\\in F_{Y}(s)} and {\\displaystyle Y'\\geq _{SSO}Y} , then {\\displaystyle f(x;s)\\geq f(x'\\wedge x;s)} . By quasisupermodularity, {\\displaystyle f(x'\\vee x;s)\\geq f(x';s)} , and by the single crossing differences, {\\displaystyle f(x'\\vee x;s')\\geq f(x';s')} . Hence {\\displaystyle x'\\vee x\\in F_{Y'}(s')} . Now assume that {\\displaystyle x'\\wedge x\\not \\in F_{Y}(s)} . Then {\\displaystyle f(x;s)>f(x'\\wedge x;s)} . By quasisupermodularity, {\\displaystyle f(x'\\vee x;s)>f(x';s)} , and by single crossing differences {\\displaystyle f(x'\\vee x;s')>f(x';s')} . But this contradicts that {\\displaystyle x'\\in F_{Y'}(s')} . Hence, {\\displaystyle x'\\wedge x\\in F_{Y}(s)} .",
    "after": "Application (Production with multiple goods):  Let {\\displaystyle x} denote the vector of inputs (drawn from a sublattice {\\displaystyle X} of {\\displaystyle \\mathbb {R} _{+}^{l}} ) of a profit-maximizing firm, {\\displaystyle p\\in \\mathbb {R} _{++}^{l}} be the vector of input prices, and {\\displaystyle V} the revenue function mapping input vector {\\displaystyle x} to revenue (in {\\displaystyle \\mathbb {R} } ). The firm's profit is {\\displaystyle \\Pi (x;p)=V(x)-p\\cdot x} . For any {\\displaystyle x'} , {\\displaystyle x\\in X} , {\\displaystyle x'\\geq x} , {\\displaystyle V(x')-V(x)+(-p)(x'-x)} is increasing in {\\displaystyle (-p)} . Hence, {\\displaystyle \\{\\Pi (\\cdot ;p)\\}_{p\\in \\mathbb {R} _{++}^{l}}} has increasing differences (and so it obeys single crossing differences). Moreover, if {\\displaystyle V} is supermodular, then so is {\\displaystyle \\Pi (\\cdot ;p)} . Therefore, it is quasisupermodular and by Theorem 3, {\\displaystyle \\arg \\max _{x\\in X}\\Pi (x;p)\\geq _{SSO}\\arg \\max _{x\\in X}\\Pi (x;p')} for {\\displaystyle p'\\geq p} .",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "{\\displaystyle F(x;t)=\\int _{S}f(x;s)\\,\\lambda (s;t)\\,ds.}": {
    "before": "Let {\\displaystyle X\\subset \\mathbb {R} } , and {\\displaystyle \\{f(\\cdot ;s)\\}_{s\\in S}} be a family of real-valued functions defined on {\\displaystyle X} that obey single crossing differences or the interval dominance order. Theorem 1 and 3 tell us that {\\displaystyle \\arg \\max _{x\\in X}f(x,;s)} is increasing in {\\displaystyle s} . Interpreting {\\displaystyle s} to be the state of the world, this says that the optimal action is increasing in the state if the state is known. Suppose, however, that the action {\\displaystyle x} is taken before {\\displaystyle s} is realized; then it seems reasonable that the optimal action should increase with the likelihood of higher states. To capture this notion formally, let {\\displaystyle \\{\\lambda (\\cdot ;t)\\}_{t\\in T}} be a family of density functions parameterized by {\\displaystyle t} in the poset {\\displaystyle (T,\\geq _{T})} , where higher {\\displaystyle t} is associated with a higher likelihood of higher states, either in the sense of first order stochastic dominance or the monotone likelihood ratio property. Choosing under uncertainty, the agent maximizes",
    "after": "For {\\displaystyle \\arg \\max _{x\\in X}F(x;t)} to be increasing in {\\displaystyle t} , it suffices (by Theorems 1 and 2) that family {\\displaystyle \\{F(\\cdot ;t)\\}_{t\\in T}} obey single crossing differences or the interval dominance order. The results in this section give condition under which this holds.",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "Proof: For any {\\displaystyle x',x\\in X} , define {\\displaystyle \\phi (s):=f(x';s)-f(x;s)} . Then, {\\displaystyle F(x';t)-F(x;t)=\\int _{S}[f(x';s)-f(x;s)]\\lambda (s;t)ds} , or equivalently {\\displaystyle F(x';t)-F(x;t)=\\int _{S}\\phi (s)\\lambda (s;t)ds} . Since {\\displaystyle \\{f(\\cdot ;s)\\}_{s\\in S}} obeys increasing differences, {\\displaystyle \\phi } is increasing in {\\displaystyle s} and first order stochastic dominance guarantees {\\displaystyle F(x';t)-F(x;t)} is increasing in {\\displaystyle t} . Q.E.D.": {
    "before": "Theorem 5: Suppose {\\displaystyle \\{f(\\cdot ;s)\\}_{s\\in S}} {\\displaystyle (S\\subseteq \\mathbb {R} )} obeys increasing differences. If {\\displaystyle \\{\\lambda (\\cdot ;t)\\}_{t\\in T}} is ordered with respect to first order stochastic dominance, then {\\displaystyle \\{F(\\cdot ;t)\\}_{t\\in T}} obeys increasing differences.",
    "after": "In the following theorem, X can be either ``single crossing differences\" or ``the interval dominance order\".",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "{\\displaystyle V(x;t):=\\int _{S}u((w-x)R+xs)\\lambda (s;t)\\,ds.}": {
    "before": "Application (Optimal portfolio problem): An agent maximizes expected utility with the strictly increasing Bernoulli utility function {\\displaystyle u:\\mathbb {R} _{+}\\to \\mathbb {R} } . (Concavity is not assumed, so we allow the agent to be risk loving.) The wealth of the agent, {\\displaystyle w>0} , can be invested in a safe or risky asset. The prices of the two assets are normalized at 1. The safe asset gives a constant return {\\displaystyle R\\geq 0} , while the return of the risky asset {\\displaystyle s} is governed by the probability distribution {\\displaystyle \\lambda (s;t)} . Let {\\displaystyle x} denote the agent's investment in the risky asset. Then the wealth of the agent in state {\\displaystyle s} is {\\displaystyle (w-x)R+xs} . The agent chooses {\\displaystyle x} to maximize",
    "after": "Note that {\\displaystyle \\{{\\hat {u}}(\\cdot ;s)\\}_{s\\in S}} , where {\\displaystyle {\\hat {u}}(x;s):=u(wR+x(s-R))} , obeys single crossing (though not necessarily increasing) differences. By Theorem 6, {\\displaystyle \\{V(\\cdot ;t)\\}_{t\\in T}} obeys single crossing differences, and hence {\\displaystyle \\arg \\max _{x\\geq 0}V(x;t)} is increasing in {\\displaystyle t} , if {\\displaystyle \\lambda (\\cdot ;t)\\}_{t\\in T}} is ordered with respect to the monotone likelihood ratio property.",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "Proof: Suppose that {\\displaystyle f(s)>0} and {\\displaystyle g(s)<0} . Define {\\displaystyle \\alpha ^{*}=-g(s)/f(s)} , so that {\\displaystyle \\alpha ^{*}f(s)+g(s)=0} . Since {\\displaystyle \\alpha ^{*}f(s)+g(s)} is a single crossing function, it must be that {\\displaystyle \\alpha ^{*}f(s')+g(s')\\geq 0} , for any {\\displaystyle s'\\geq s} . Moreover, recall that since {\\displaystyle f} is a single crossing function, then {\\displaystyle f(s')>0} . By rearranging the above inequality, we conclude that": {
    "before": "Proposition 3: Let {\\displaystyle f} and {\\displaystyle g} be two single crossing functions. Then {\\displaystyle \\alpha f+\\beta g} is a single crossing function for any non{-}negative scalars {\\displaystyle \\alpha } and {\\displaystyle \\beta } if and only if {\\displaystyle f} and {\\displaystyle g} obey signed-ratio monotonicity.",
    "after": "{\\displaystyle \\alpha ^{*}=-{\\frac {g(s)}{f(s)}}\\geq -{\\frac {g(s')}{f(s')}}.}",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "{\\displaystyle \\alpha ^{*}=-{\\frac {g(s)}{f(s)}}\\geq -{\\frac {g(s')}{f(s')}}.}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "To prove the converse, without loss of generality assume that {\\displaystyle \\beta =1} . Suppose that {\\displaystyle \\alpha f(s)+g(s)\\geq (>)0.} If both {\\displaystyle f(s)\\geq 0} and {\\displaystyle g(s)\\geq 0} , then {\\displaystyle f(s')\\geq 0} and {\\displaystyle g(s')\\geq 0} since both functions are single crossing. Hence, {\\displaystyle \\alpha f(s')+g(s')\\geq (>)0} . Suppose that {\\displaystyle g(s)<0} and {\\displaystyle f(s)>0} . Since {\\displaystyle f} and {\\displaystyle g} obey signed{-}ratio monotonicity it must be that": {
    "before": "{\\displaystyle \\alpha ^{*}=-{\\frac {g(s)}{f(s)}}\\geq -{\\frac {g(s')}{f(s')}}.}",
    "after": "{\\displaystyle \\alpha \\geq (>)-{\\frac {g(s)}{f(s)}}\\geq -{\\frac {g(s')}{f(s')}}.}",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "{\\displaystyle V(x;-c)=\\int _{T}u(\\Pi (x;-c,t))d\\lambda (t),}": {
    "before": "Application (Monopoly problem under uncertainty):  A firm faces uncertainty over the demand for its output {\\displaystyle x} and the profit at state {\\displaystyle t\\in T\\subset \\mathbb {R} } is given by {\\displaystyle \\Pi (x;-c,t)=xP(x;t)-cx} , where {\\displaystyle c} is the marginal cost and {\\displaystyle P(x,t)} is the inverse demand function in state {\\displaystyle t} . The firm maximizes",
    "after": "where {\\displaystyle \\lambda } is the probability of state {\\displaystyle t} and {\\displaystyle u:\\mathbb {R} \\to \\mathbb {R} } is the Bernoulli utility function representing the firm’s attitude towards uncertainty. By Theorem 1, {\\displaystyle \\arg \\max _{x\\geq 0}V(x;-c)} is increasing in {\\displaystyle -c} (i.e., output falls with marginal cost) if the family {\\displaystyle \\{V(x;-c)\\}_{c\\in \\mathbb {R} _{+}}} obeys single crossing differences. By definition, the latter says that, for any {\\displaystyle x'\\geq x} , the function",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "{\\displaystyle \\Delta (-c)=\\int _{T}[u(\\Pi (x';-c,t))-u(\\Pi (x;-c,t))]\\,d\\lambda (t),}": {
    "before": "where {\\displaystyle \\lambda } is the probability of state {\\displaystyle t} and {\\displaystyle u:\\mathbb {R} \\to \\mathbb {R} } is the Bernoulli utility function representing the firm’s attitude towards uncertainty. By Theorem 1, {\\displaystyle \\arg \\max _{x\\geq 0}V(x;-c)} is increasing in {\\displaystyle -c} (i.e., output falls with marginal cost) if the family {\\displaystyle \\{V(x;-c)\\}_{c\\in \\mathbb {R} _{+}}} obeys single crossing differences. By definition, the latter says that, for any {\\displaystyle x'\\geq x} , the function",
    "after": "is a single crossing function. For each {\\displaystyle t} , {\\displaystyle \\delta (-c,t)=u(\\Pi (x';-c,t))-u(\\Pi (x;-c,t))} is s single crossing function of {\\displaystyle -c} . However, unless {\\displaystyle u} is linear, {\\displaystyle \\delta } will not, in general, be increasing in {\\displaystyle -c} . Applying Theorem 6, {\\displaystyle \\Delta } is a single crossing function if, for any {\\displaystyle t',t\\in T} , the functions {\\displaystyle \\delta (-c,t)} and {\\displaystyle \\delta (-c,t')} (of {\\displaystyle -c} ) obey signed-ratio monotonicity. This is guaranteed when (i) {\\displaystyle P} is decreasing in {\\displaystyle x} and increasing in {\\displaystyle t} and {\\displaystyle \\{\\log(P(\\cdot ,t))\\}_{t\\in T}} obeys increasing differences; and (ii) {\\displaystyle u:\\mathbb {R} \\to \\mathbb {R} } is twice differentiable, with {\\displaystyle u'>0} , and obeys decreasing absolute risk aversion (DARA).",
    "url": "https://en.wikipedia.org/wiki/Monotone comparative statics"
  },
  "{\\displaystyle \\sum _{n=1}^{N}Q_{n}=\\{\\sum _{n=1}^{N}q_{n}\\mid q_{n}\\in Q_{n},~1\\leq n\\leq N\\}.}": {
    "before": "This operation is clearly commutative and associative on the collection of non-empty sets. All such operations extend in a well-defined manner to recursive forms {\\displaystyle \\sum _{n=1}^{N}Q_{n}=Q_{1}+Q_{2}+\\ldots +Q_{N}.} By the principle of induction it is easy to see that ",
    "after": "Convex hulls of Minkowski sums [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "{\\displaystyle \\mathrm {Conv} (A+B)=\\mathrm {Conv} (A)+\\mathrm {Conv} (B).}": {
    "before": "Minkowski addition behaves well with respect to taking convex hulls. Specifically, for all subsets {\\displaystyle A,B\\subseteq X} of a real vector space, {\\displaystyle X} , the convex hull of their Minkowski sum is the Minkowski sum of their convex hulls. That is,",
    "after": "And by induction it follows that",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "{\\displaystyle \\mathrm {Conv} (\\sum _{n=1}^{N}Q_{n})=\\sum _{n=1}^{N}\\mathrm {Conv} (Q_{n})}": {
    "before": "{\\displaystyle \\mathrm {Conv} (A+B)=\\mathrm {Conv} (A)+\\mathrm {Conv} (B).} And by induction it follows that",
    "after": "for any {\\displaystyle N\\in \\mathbb {N} } and non-empty subsets {\\displaystyle Q_{n}\\subseteq X} , {\\displaystyle 1\\leq n\\leq N} .  ",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "{\\displaystyle x=\\sum _{n=1}^{D}q_{n}+\\sum _{n=D+1}^{N}q_{n}}": {
    "before": "Shuffling indices if necessary, this means that every point in {\\displaystyle \\mathrm {Conv} (Q)} can be decomposed as",
    "after": "where {\\displaystyle q_{n}\\in \\mathrm {Conv} (Q_{n})} for {\\displaystyle 1\\leq n\\leq D} and {\\displaystyle q_{n}\\in Q_{n}} for {\\displaystyle D+1\\leq n\\leq N} . Note that the reindexing depends on the point {\\displaystyle x} . ",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "{\\displaystyle \\mathrm {Conv} \\left(\\sum _{n=1}^{N}Q_{n}\\right)\\subseteq \\bigcup _{I\\subseteq \\{1,2,\\ldots N\\}:~|I|=D}\\left(\\sum _{n\\in I}\\mathrm {Conv} (Q_{n})+\\sum _{n\\notin I}Q_{n}\\right).}": {
    "before": "where {\\displaystyle q_{n}\\in \\mathrm {Conv} (Q_{n})} for {\\displaystyle 1\\leq n\\leq D} and {\\displaystyle q_{n}\\in Q_{n}} for {\\displaystyle D+1\\leq n\\leq N} . Note that the reindexing depends on the point {\\displaystyle x} .  The lemma may be stated succinctly as",
    "after": "The converse of Shapley–Folkman lemma [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "Graph( f ) = { ( x , f ( x ) ) }": {
    "before": "The graph of a function f is the set of the pairs of arguments x and function evaluations f ( x )",
    "after": "The epigraph of a real-valued function f is the set of points above the graph",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "Epi( f ) = { ( x , u ) : f ( x ) ≤ u } .": {
    "before": "The epigraph of a real-valued function f is the set of points above the graph The sine function is non-convex .",
    "after": "A real-valued function is defined to be a convex function if its epigraph is a convex set. ",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "f ( x ) = f ( ( x 1 , ..., x {\\displaystyle N} ) ) = Σ f n ( x n ).": {
    "before": "In many optimization problems, the objective function f is separable : that is, f is the sum of many summand-functions, each of which has its own argument:",
    "after": "For example, problems of linear optimization are separable. Given a separable problem with an optimal solution, we fix an optimal solution",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "x min = ( x 1 , ..., x {\\displaystyle N} ) min": {
    "before": "For example, problems of linear optimization are separable. Given a separable problem with an optimal solution, we fix an optimal solution",
    "after": "with the minimum value f ( x min ). For this separable problem, we also consider an optimal solution ( x min , f ( x min ) ) to the \" convexified problem \", where convex hulls are taken of the graphs of the summand functions. Such an optimal solution is the limit of a sequence of points in the convexified problem",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "( p 1 p 2 ) ( ω )= ( p 1 ( ω ), p 2 ( ω ) ) .": {
    "before": "A probability measure is a finite measure , and the Shapley–Folkman lemma has applications in non-probabilistic measure theory, such as the theories of volume and of vector measures . The Shapley–Folkman lemma enables a refinement of the Brunn–Minkowski inequality , which bounds the volume of sums in terms of the volumes of their summand-sets.  The volume of a set is defined in terms of the Lebesgue measure , which is defined on subsets of Euclidean space . In advanced measure-theory, the Shapley–Folkman lemma has been used to prove Lyapunov's theorem , which states that the range of a vector measure is convex.  Here, the traditional term \" range \" (alternatively, \"image\") is the set of values produced by the function. A vector measure is a vector-valued generalization of a measure; for example, if p 1 and p 2 are probability measures defined on the same measurable space , then the product function p 1 p 2 is a vector measure, where p 1 p 2 is defined for every event ω by",
    "after": "Lyapunov's theorem has been used in economics ,   in ( \"bang-bang\" ) control theory , and in statistical theory .  Lyapunov's theorem has been called a continuous counterpart of the Shapley–Folkman lemma,  which has itself been called a discrete analogue of Lyapunov's theorem. ",
    "url": "https://en.wikipedia.org/wiki/Shapley–Folkman lemma"
  },
  "{\\displaystyle Y_{t}=\\phi _{1}Y_{t-1}+\\phi _{2}Y_{t-2}+\\cdots +\\phi _{p}Y_{t-p}+\\epsilon _{t},}": {
    "before": "The most common form of parametric SDF estimate uses as a model an autoregressive model {\\displaystyle {\\text{AR}}(p)} of order {\\displaystyle p} .  : 392 A signal sequence {\\displaystyle \\{Y_{t}\\}} obeying a zero mean {\\displaystyle {\\text{AR}}(p)} process satisfies the equation",
    "after": "where the {\\displaystyle \\phi _{1},\\ldots ,\\phi _{p}} are fixed coefficients and {\\displaystyle \\epsilon _{t}} is a white noise process with zero mean and innovation variance {\\displaystyle \\sigma _{p}^{2}} . The SDF for this process is",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "{\\displaystyle S(f;\\phi _{1},\\ldots ,\\phi _{p},\\sigma _{p}^{2})={\\frac {\\sigma _{p}^{2}\\Delta t}{\\left|1-\\sum _{k=1}^{p}\\phi _{k}e^{-2i\\pi fk\\Delta t}\\right|^{2}}}\\qquad |f|<f_{N},}": {
    "before": "where the {\\displaystyle \\phi _{1},\\ldots ,\\phi _{p}} are fixed coefficients and {\\displaystyle \\epsilon _{t}} is a white noise process with zero mean and innovation variance {\\displaystyle \\sigma _{p}^{2}} . The SDF for this process is",
    "after": "with {\\displaystyle \\Delta t} the sampling time interval and {\\displaystyle f_{N}} the Nyquist frequency .",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "{\\displaystyle x(n)=\\sum _{i=1}^{p}A_{i}e^{jn\\omega _{i}}+w(n)} .": {
    "before": "A typical model for a signal {\\displaystyle x(n)} consists of a sum of {\\displaystyle p} complex exponentials in the presence of white noise , {\\displaystyle w(n)}",
    "after": "The power spectral density of {\\displaystyle x(n)} is composed of {\\displaystyle p} impulse functions in addition to the spectral density function due to noise.",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "Pisarenko's method {\\displaystyle {\\hat {P}}_{\\text{PHD}}\\left(e^{j\\omega }\\right)={\\frac {1}{\\left|\\mathbf {e} ^{H}\\mathbf {v} _{\\text{min}}\\right|^{2}}}} MUSIC {\\displaystyle {\\hat {P}}_{\\text{MU}}\\left(e^{j\\omega }\\right)={\\frac {1}{\\sum _{i=p+1}^{M}\\left|\\mathbf {e} ^{H}\\mathbf {v} _{i}\\right|^{2}}}} , Eigenvector method {\\displaystyle {\\hat {P}}_{\\text{EV}}\\left(e^{j\\omega }\\right)={\\frac {1}{\\sum _{i=p+1}^{M}{\\frac {1}{\\lambda _{i}}}\\left|\\mathbf {e} ^{H}\\mathbf {v} _{i}\\right|^{2}}}} Minimum norm method {\\displaystyle {\\hat {P}}_{\\text{MN}}\\left(e^{j\\omega }\\right)={\\frac {1}{\\left|\\mathbf {e} ^{H}\\mathbf {a} \\right|^{2}}};\\ \\mathbf {a} =\\lambda \\mathbf {P} _{n}\\mathbf {u} _{1}}": {
    "before": "The most common methods for frequency estimation involve identifying the noise subspace to extract these components. These methods are based on eigen decomposition of the autocorrelation matrix into a signal subspace and a noise subspace. After these subspaces are identified, a frequency estimation function is used to find the component frequencies from the noise subspace. The most popular methods of noise subspace based frequency estimation are Pisarenko's method , the multiple signal classification (MUSIC) method, the eigenvector method, and the minimum norm method.",
    "after": "Example calculation [ edit ]",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "{\\displaystyle {\\begin{aligned}x_{n}&=\\sum _{k}A_{k}\\sin(2\\pi \\nu _{k}n+\\phi _{k})\\\\&=\\sum _{k}A_{k}\\left(\\sin(\\phi _{k})\\cos(2\\pi \\nu _{k}n)+\\cos(\\phi _{k})\\sin(2\\pi \\nu _{k}n)\\right)\\\\&=\\sum _{k}\\left(\\overbrace {a_{k}} ^{A_{k}\\sin(\\phi _{k})}\\cos(2\\pi \\nu _{k}n)+\\overbrace {b_{k}} ^{A_{k}\\cos(\\phi _{k})}\\sin(2\\pi \\nu _{k}n)\\right)\\end{aligned}}}": {
    "before": "Suppose {\\displaystyle x_{n}} , from {\\displaystyle n=0} to {\\displaystyle N-1} is a time series (discrete time) with zero mean. Suppose that it is a sum of a finite number of periodic components (all frequencies are positive):",
    "after": "The variance of {\\displaystyle x_{n}} is, for a zero-mean function as above, given by",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "{\\displaystyle {\\frac {1}{N}}\\sum _{n=0}^{N-1}x_{n}^{2}.}": {
    "before": "The variance of {\\displaystyle x_{n}} is, for a zero-mean function as above, given by",
    "after": "If these data were samples taken from an electrical signal, this would be its average power (power is energy per unit time, so it is analogous to variance if energy is analogous to the amplitude squared).",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "{\\displaystyle \\lim _{N\\to \\infty }{\\frac {1}{N}}\\sum _{n=0}^{N-1}x_{n}^{2}.}": {
    "before": "Now, for simplicity, suppose the signal extends infinitely in time, so we pass to the limit as {\\displaystyle N\\to \\infty .} If the average power is bounded, which is almost always the case in reality, then the following limit exists and is the variance of the data.",
    "after": "Again, for simplicity, we will pass to continuous time, and assume that the signal extends infinitely in time in both directions. Then these two formulas become",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "{\\displaystyle x(t)=\\sum _{k}A_{k}\\sin(2\\pi \\nu _{k}t+\\phi _{k})}": {
    "before": "Again, for simplicity, we will pass to continuous time, and assume that the signal extends infinitely in time in both directions. Then these two formulas become",
    "after": "and {\\displaystyle \\lim _{T\\to \\infty }{\\frac {1}{2T}}\\int _{-T}^{T}x(t)^{2}dt.}",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "{\\displaystyle S(\\nu )=\\sum _{k:\\nu _{k}<\\nu }{\\frac {1}{2}}A_{k}^{2}.}": {
    "before": "Then the power as a function of frequency is {\\displaystyle {\\tfrac {1}{2}}A_{k}^{2},} and its statistical cumulative distribution function {\\displaystyle S(\\nu )} will be",
    "after": "{\\displaystyle S} is a step function , monotonically non-decreasing. Its jumps occur at the frequencies of the periodic components of {\\displaystyle x} , and the value of each jump is the power or variance of that component.",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "{\\displaystyle c(\\tau )=\\lim _{T\\to \\infty }{\\frac {1}{2T}}\\int _{-T}^{T}x(t)x(t+\\tau )dt.}": {
    "before": "The variance is the covariance of the data with itself. If we now consider the same data but with a lag of {\\displaystyle \\tau } , we can take the covariance of {\\displaystyle x(t)} with {\\displaystyle x(t+\\tau )} , and define this to be the autocorrelation function {\\displaystyle c} of the signal (or data) {\\displaystyle x} :",
    "after": "If it exists, it is an even function of {\\displaystyle \\tau .} If the average power is bounded, then {\\displaystyle c} exists everywhere, is finite, and is bounded by {\\displaystyle c(0),} which is the average power or variance of the data.",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "{\\displaystyle c(\\tau )=\\sum _{k}{\\frac {1}{2}}A_{k}^{2}\\cos(2\\pi \\nu _{k}\\tau ).}": {
    "before": "It can be shown that {\\displaystyle c} can be decomposed into periodic components with the same periods as {\\displaystyle x} :",
    "after": "This is in fact the spectral decomposition of {\\displaystyle c} over the different frequencies, and is related to the distribution of power of {\\displaystyle x} over the frequencies: the amplitude of a frequency component of {\\displaystyle c} is its contribution to the average power of the signal.",
    "url": "https://en.wikipedia.org/wiki/Spectral density estimation"
  },
  "{\\displaystyle P(n,p,c)=I_{p}\\left({\\frac {n+1}{2}},{\\frac {n+1}{2}}\\right)+0.5c(n-1)(0.5-p){\\frac {\\partial I_{p}({\\frac {n+1}{2}},{\\frac {n+1}{2}})}{\\partial p}},}": {
    "before": "Let {\\displaystyle p} be the probability of a juror voting for the correct alternative and {\\displaystyle c} be the (second-order) correlation coefficient between any two correct votes. If all higher-order correlation coefficients in the Bahadur representation  of the joint probability distribution of votes equal to zero, and {\\displaystyle (p,c)\\in {\\mathcal {B}}_{n}} is an admissible pair , then the probability of the jury collectively reaching the correct decision under simple majority is given by:",
    "after": "where {\\displaystyle I_{p}} is the regularized incomplete beta function .",
    "url": "https://en.wikipedia.org/wiki/Jury theorem"
  },
  "cost to the voter = (number of votes) 2 .": {
    "before": "Quadratic voting is based upon market principles , where each voter is given a budget of vote credits that they have the personal decisions and delegation to spend in order to influence the outcome of a range of decisions. If a participant has a strong support for or against a specific decision, additional votes could be allocated to proportionally demonstrate the voter's support. A vote pricing rule determines the cost of additional votes, with each vote becoming increasingly more expensive. By increasing voter credit costs, this demonstrates an individual's support and interests toward the particular decision.  If money is used, it is eventually cycled back to the voters based upon per capita. Both E. Glen Weyl and Steven Lalley published research in 2017 in which they claim to demonstrate that this decision-making policy expedites efficiency as the number of voters increases.  The simplified formula on how quadratic voting functions is ",
    "after": "Vote pricing example Number of votes \"Vote credit\" cost 1 1 2 4 3 9 4 16 5 25",
    "url": "https://en.wikipedia.org/wiki/Quadratic voting"
  },
  "This example illustrates the implementation of the dynamic time warping algorithm when the two sequences s and t are strings of discrete symbols. For two symbols x and y, d(x, y) is a distance between the symbols, e.g. d(x, y) ={\\displaystyle |x-y|}": {
    "before": "",
    "after": "",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "DTW := array [0..n, 0..m]": {
    "before": "int DTWDistance(s: array [1..n], t: array [1..m], w: int) {",
    "after": "w := max(w, abs(n-m)) // adapt window size (*)",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "for i := 0 to n": {
    "before": "w := max(w, abs(n-m)) // adapt window size (*)",
    "after": "for j:= 0 to m",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "for j := 0 to m": {
    "before": "for i := 0 to n",
    "after": "DTW[i, j] := infinity",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "DTW[i, j] := infinity": {
    "before": "for j:= 0 to m",
    "after": "DTW[0, 0] := 0",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "for i := 1 to n": {
    "before": "DTW[i, j] := 0",
    "after": "for j := max(1, i-w) to min(m, i+w)",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "for j := 1 to m": {
    "before": "for i := 1 to n",
    "after": "cost := d(s[i], t[j])",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "cost := d(s[i], t[j])": {
    "before": "for j := max(1, i-w) to min(m, i+w)",
    "after": "DTW[i, j] := cost + minimum(DTW[i-1, j ], // insertion",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "DTW[i, j] := cost + minimum(DTW[i-1, j ], // insertion": {
    "before": "cost := d(s[i], t[j])",
    "after": "DTW[i , j-1], // deletion",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "w := max(w, abs(n-m)) // adapt window size (*)": {
    "before": "DTW := array [0..n, 0..m]",
    "after": "for i := 0 to n",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "for j:= 0 to m": {
    "before": "for i := 0 to n",
    "after": "DTW[i, j] := infinity",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "for j := max(1, i-w) to min(m, i+w)": {
    "before": "for i := 1 to n",
    "after": "cost := d(s[i], t[j])",
    "url": "https://en.wikipedia.org/wiki/Dynamic time warping"
  },
  "v i = the number of points to be voted for candidate i u i = the voter's gain in utility if candidate i wins the election p ij = the (voter's perceived) pivot probability that candidates i and j will be tied for the most total points to win the election.": {
    "before": "This rational voter model assumes that the voter's utility of the election result is dependent only on which candidate wins and not on any other aspect of the election, for example showing support for a losing candidate in the vote tallies. The model also assumes the voter chooses how to vote individually and not in collaboration with other voters.Given a set of k candidates and a voter let:",
    "after": "Then the voter's prospective rating for a candidate i is defined as:",
    "url": "https://en.wikipedia.org/wiki/Strategic voting"
  },
  "{\\displaystyle R_{i}=\\sum _{j\\neq i}\\;p_{ij}\\cdot (u_{i}-u_{j})\\,}": {
    "before": "Then the voter's prospective rating for a candidate i is defined as:",
    "after": "The gain in expected utility for a given vote is given by:",
    "url": "https://en.wikipedia.org/wiki/Strategic voting"
  },
  "{\\displaystyle G(p,v,u)=\\sum _{i=1}^{k}\\;v_{i}\\cdot R_{i}\\,}": {
    "before": "The gain in expected utility for a given vote is given by:",
    "after": "The gain in expected utility can be maximized by choosing a vote with suitable values of v i , depending on the voting method and the voter's prospective ratings for each candidate. For specific voting methods, the gain can be maximized using the following rules:",
    "url": "https://en.wikipedia.org/wiki/Strategic voting"
  }
}